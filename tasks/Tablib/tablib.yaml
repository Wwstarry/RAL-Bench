task_id: tablib_dataset_databook_io
domain: data
difficulty: medium
description: "Implement a pure Python tabular data container library that is API-compatible\
  \ with\nthe core parts of the reference Tablib project used by the test suite. The\
  \ generated\nrepository must:\n\n- Provide a top-level `tablib` package importable\
  \ as `import tablib`, structured so that\n  at least the following modules exist:\n\
  \    * tablib\n    * tablib.core\n    * tablib.formats._csv\n    * tablib.formats._json\n\
  \n- Expose the key public API objects and attributes used by the tests, including\
  \ at least:\n    * Class `tablib.Dataset` with:\n        - Constructor supporting\
  \ `tablib.Dataset(*rows, headers=...)`, where headers is\n          an iterable\
  \ of column names and rows are iterables of field values.\n        - `headers` attribute\
  \ (get/set) describing the column names in order.\n        - Shape helpers: `height`\
  \ (number of rows) and `width` (number of columns).\n        - Row access:\n   \
  \         - Index slicing `dataset[start:stop]` returning a sequence of row tuples.\n\
  \            - Dictionary-style column access `dataset['column_name']` returning\
  \ an\n              iterable of values for that column.\n        - Row mutation:\n\
  \            - `append(row)` to add a single row.\n            - `append_col(values,\
  \ header=None)` to add a new column with an optional\n              header name\
  \ and values matching the current height.\n        - Serialization helpers:\n  \
  \          - `export(fmt)` returning a string representation for at least `fmt='csv'`\n\
  \              and `fmt='json'`.\n            - Attribute-style import/export for\
  \ CSV and JSON:\n                * `dataset.csv` getter returning a CSV string.\n\
  \                * `dataset.csv` setter accepting a CSV string and replacing the\
  \ content.\n                * `dataset.json` getter returning a JSON string.\n \
  \               * `dataset.json` setter accepting a JSON string and replacing the\
  \ content.\n        - Dict representation:\n            - `dataset.dict` property\
  \ returning a list of dictionaries, one per row,\n              mapping header names\
  \ to cell values. It is acceptable for imported\n              values to be coerced\
  \ to strings (for example, CSV imports may yield\n              `\"90\"` instead\
  \ of `90`) as long as the structure and ordering are\n              preserved.\n\
  \n    * Class `tablib.Databook` with:\n        - Constructor `tablib.Databook(datasets)`\
  \ where `datasets` is an iterable of\n          `Dataset` instances; each dataset\
  \ may have a `.title` attribute.\n        - `size` attribute exposing the number\
  \ of sheets in the book.\n        - JSON serialization helpers:\n            - `book.export('json')`\
  \ returning a JSON string representing the entire book.\n            - `book.json`\
  \ setter accepting a JSON string produced by `export('json')`\n              and\
  \ restoring the internal sheet structure (including sheet titles,\n            \
  \  headers, and row data).\n        - Sheet access API compatible with the tests:\n\
  \            - A `sheets()` method returning an iterable of `Dataset` objects in\
  \ order.\n            - Optionally, iteration support (`__iter__`) returning the\
  \ same sequence\n              of datasets.\n\n- Ensure `Dataset` and `Databook`\
  \ behave in a way that allows CSV/JSON roundtrips to\n  preserve table shape (headers,\
  \ height, width) and row ordering across formats.\n  Minor differences in value\
  \ types (such as numeric values represented as strings\n  after CSV/JSON import)\
  \ are acceptable, but the column names and logical row\n  identities must remain\
  \ stable.\n\n- Implement `Dataset.append`, `Dataset.append_col`, slicing, and column\
  \ access so that\n  they match the expectations in the tests, including:\n    *\
  \ appending rows and columns updates `height`, `width`, `headers`, and `.dict`\n\
  \      consistently;\n    * slicing returns row tuples with the same ordering as\
  \ originally inserted.\n\n- Implement `Databook` such that JSON export/import preserves:\n\
  \    * the number of sheets;\n    * sheet titles;\n    * sheet headers; and\n  \
  \  * per-sheet row content (as observed via `.dict` on each sheet).\n\n- Ensure\
  \ the generated repository behaves in a way that allows the provided black-box\n\
  \  tests to run successfully, including functional scenarios (Dataset and Databook\n\
  \  construction, CSV/JSON import/export, row and column mutation, slicing) and\n\
  \  performance/resource scenarios (bulk dataset creation, repeated export operations,\n\
  \  and memory usage under bulk workloads).\n"
interfaces:
  type: LIB
  language: python
  entry_point: tablib/__init__.py
reference_repository: ./repositories/Tablib
baseline_metrics:
  performance:
    performance_suite_time_s: 2.267515
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 5.457667
    resource_tests_total: 2
    avg_memory_mb: 34.54
    avg_cpu_percent: 99.1
  functional:
    functional_suite_time_s: 1.550296
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.567555
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.666207
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 31.0
      total_loc: 3330.0
  maintainability:
    maintainability_suite_time_s: 2.204547
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 31.0
      total_loc: 4978.0
      max_cc: 17.0
test_suite:
  functional: ./tests/Tablib/functional_test.py
  performance: ./tests/Tablib/performance_test.py
  resource: ./tests/Tablib/resource_test.py
  robustness: ./tests/Tablib/robustness_test.py
  security: ./tests/_generic/security_test.py
  maintainability: ./tests/_generic/maintainability_test.py
generated_repository: ./generation/Tablib
package:
  name: tablib
  root_dir: .
files:
- path: tablib/__init__.py
  role: package_init
  description: Package entry; exposes Dataset and Databook and wires up format registration.
- path: tablib/core.py
  role: core_dataset_databook_impl
  description: Implements the Dataset and Databook classes, including headers, dict
    views, and export helpers.
- path: tablib/formats/_csv.py
  role: csv_format_impl
  description: Handles conversion between Dataset instances and CSV string representations.
- path: tablib/formats/_json.py
  role: json_format_impl
  description: Handles conversion between Dataset/Databook instances and JSON string
    representations.
