project_name: Humanize
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Humanize\humanize.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Humanize
timestamp: '2026-01-01 11:35:32'
functional_score: 0.4
non_functional_score: 0.8255
non_functional_subscores:
  maintainability: 0.8487
  security: 1.0
  robustness: 1.0
  performance: 1.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "..FF.F...Fsssss                                                     \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________________________ test_naturalsize _______________________________\n\
      \n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024)\
      \ == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE    \
      \     \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE       \
      \  ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________\
      \ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric()\
      \ -> None:\n>       d = humanize.precisedelta(3661)  # seconds\n\ntests\\Humanize\\\
      functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nvalue = 3661, minimum_unit = 'seconds', suppress\
      \ = []\n\n    def precisedelta(value: Union[datetime, timedelta], minimum_unit:\
      \ str = \"seconds\", suppress: list = None) -> str:\n        \"\"\"\n      \
      \  Convert a time delta to a precise human-readable format.\n    \n        Args:\n\
      \            value: datetime object or timedelta\n            minimum_unit:\
      \ Minimum unit to display\n            suppress: List of units to suppress from\
      \ output\n    \n        Returns:\n            Precise human-readable time delta\
      \ string\n        \"\"\"\n        if suppress is None:\n            suppress\
      \ = []\n    \n        if isinstance(value, datetime):\n            now = datetime.now()\n\
      \            if value.tzinfo is not None and now.tzinfo is None:\n         \
      \       now = now.replace(tzinfo=value.tzinfo)\n            elif value.tzinfo\
      \ is None and now.tzinfo is not None:\n                value = value.replace(tzinfo=now.tzinfo)\n\
      \    \n            delta = now - value\n            total_seconds = abs(delta.total_seconds())\n\
      \        else:\n>           total_seconds = abs(value.total_seconds())\nE  \
      \         AttributeError: 'int' object has no attribute 'total_seconds'\n\n\
      generation\\Humanize\\humanize\\time.py:115: AttributeError\n______________________\
      \ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point()\
      \ -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier =\
      \ ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\n\
      E       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\
      \ntests\\Humanize\\functional_test.py:129: TypeError\n___________________ test_naturaltime_future_reference_point\
      \ ___________________\n\n    def test_naturaltime_future_reference_point() ->\
      \ None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref +\
      \ timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\n\
      E       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\
      \ntests\\Humanize\\functional_test.py:165: TypeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize\
      \ - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric\
      \ - Attribu...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point\
      \ - ...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n\
      4 failed, 6 passed, 5 skipped in 0.41s\n"
    elapsed_time_s: 1.544276
    avg_memory_mb: 32.04
    avg_cpu_percent: 101.1
    passed: 6
    failed: 4
    skipped: 5
    total: 15
    score_inputs_passed: 6
    score_inputs_failed: 4
    score_inputs_total: 15
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.15s

      '
    elapsed_time_s: 1.312073
    avg_memory_mb: 30.89
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.604119
    score_inputs_actual_time_s: 1.312073
  resource:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      _______________________ test_report_generation_pipeline _______________________\n\
      \n    def test_report_generation_pipeline() -> None:\n        \"\"\"\n     \
      \   Integration-like test: simulate a log/report formatting pipeline.\n    \
      \    Ensures humanize functions can be composed.\n        \"\"\"\n    \n   \
      \     base = {\n            \"bytes_sent\": 123456789,\n            \"items_processed\"\
      : 2345,\n            \"start\": datetime(2020, 1, 1, 12, 0, 0),\n          \
      \  \"end\": datetime(2020, 1, 1, 14, 30, 0),\n        }\n    \n        report\
      \ = {\n            \"size_human\": humanize.naturalsize(base[\"bytes_sent\"\
      ]),\n            \"items\": humanize.intcomma(base[\"items_processed\"]),\n\
      \            \"duration\": humanize.naturaldelta(base[\"end\"] - base[\"start\"\
      ]),\n>           \"finished\": humanize.naturaltime(base[\"end\"], when=base[\"\
      end\"]),\n        }\nE       TypeError: naturaltime() got an unexpected keyword\
      \ argument 'when'\n\ntests\\Humanize\\resource_test.py:63: TypeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Humanize/resource_test.py::test_report_generation_pipeline\
      \ - Typ...\n1 failed in 0.35s\n"
    elapsed_time_s: 1.567447
    avg_memory_mb: 31.04
    avg_cpu_percent: 96.8
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 30.73
    score_inputs_baseline_cpu_pct: 98.5
    score_inputs_actual_mem_mb: 31.04
    score_inputs_actual_cpu_pct: 96.8
  robustness:
    returncode: 0
    stdout: '...                                                                      [100%]

      3 passed in 0.12s

      '
    elapsed_time_s: 1.324944
    avg_memory_mb: 31.25
    avg_cpu_percent: 98.7
    passed: 3
    failed: 0
    skipped: 0
    total: 3
    score_inputs_passed: 3
    score_inputs_failed: 0
    score_inputs_total: 3
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=6.0 total_loc=327.0

      .

      1 passed in 0.10s

      '
    elapsed_time_s: 1.202215
    avg_memory_mb: 31.25
    avg_cpu_percent: 97.1
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 6.0
      total_loc: 327.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=29.1775 files_scanned=6.0 total_loc=327.0 max_cc=13.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.234124
    avg_memory_mb: 31.26
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 29.1775
      files_scanned: 6.0
      total_loc: 327.0
      max_cc: 13.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 5.2014
    score_inputs_generated_mi_min: 29.1775
    score_inputs_ratio_g_over_b: 5.6095474295382015
baseline_metrics:
  performance:
    performance_suite_time_s: 1.604119
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.196727
    resource_tests_total: 1
    avg_memory_mb: 30.73
    avg_cpu_percent: 98.5
  functional:
    functional_suite_time_s: 1.228457
    functional_tests_total: 15
  maintainability:
    maintainability_suite_time_s: 1.428683
    maintainability_tests_total: 1
    metrics:
      mi_min: 5.2014
      files_scanned: 12.0
      total_loc: 2595.0
      max_cc: 30.0
  robustness:
    robustness_suite_time_s: 1.219278
    robustness_tests_total: 3
  security:
    security_suite_time_s: 1.270661
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 7.0
      total_loc: 1285.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Humanize\pytest_logs
