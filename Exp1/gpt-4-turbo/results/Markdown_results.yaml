project_name: Markdown
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Markdown\markdown.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Markdown
timestamp: '2026-01-01 13:21:01'
functional_score: 0.3684
non_functional_score: 0.9215
non_functional_subscores:
  maintainability: 0.7819
  security: 1.0
  robustness: 1.0
  performance: 1.0
  resource: 1.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "......F.FFsssssssss                                                 \
      \     [100%]\n================================== FAILURES ===================================\n\
      _________________ test_html_escaping_in_text_but_not_in_code __________________\n\
      \n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src\
      \ = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n\
      \    \n            ```\n            literal <b> tag in code block\n        \
      \    ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n\
      \        norm = normalize_html(html)\n    \n        assert \"<b>\" in norm\n\
      >       assert \"literal &lt;b&gt; tag in code block\" in norm\nE       AssertionError:\
      \ assert 'literal &lt;b&gt; tag in code block' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt;\
      \ here.</p><pre><code>literal <b> tag in code block\\n</code></pre>'\n\ntests\\\
      Markdown\\functional_test.py:210: AssertionError\n___________________________\
      \ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-424/test_markdown_from_file0')\n\
      \n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n\
      \            \"\"\"\n            # Title from file\n    \n            Some text\
      \ from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"\
      input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n    \
      \    out_path = tmp_path / \"output.html\"\n        markdown.markdownFromFile(input=str(md_path),\
      \ output=str(out_path))\n>       html = out_path.read_text(encoding=\"utf-8\"\
      )\n\ntests\\Markdown\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\\
      Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with\
      \ self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\\
      AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n\
      \    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\
      \nself = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-424/test_markdown_from_file0/output.html')\n\
      name = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\
      \\pytest-424\\\\test_markdown_from_file0\\\\output.html'\nflags = 32896, mode\
      \ = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub\
      \ for the opener argument to built-in open()\n>       return self._accessor.open(self,\
      \ flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory:\
      \ 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-424\\\
      \\test_markdown_from_file0\\\\output.html'\n\nC:\\Users\\86152\\AppData\\Local\\\
      Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n_______________________\
      \ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr()\
      \ -> None:\n        src = textwrap.dedent(\n            \"\"\"\n           \
      \ Paragraph above\n    \n            ---\n    \n            Paragraph below\n\
      \            \"\"\"\n        )\n        html = markdown.markdown(src)\n    \
      \    norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE  \
      \     AssertionError: assert '<hr' in '<p>Paragraph above</p><p>---</p><p>Paragraph\
      \ below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\n\
      FAILED tests/Markdown/functional_test.py::test_markdown_from_file - FileNotFo...\n\
      FAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr -\
      \ A...\n3 failed, 7 passed, 9 skipped in 0.51s\n"
    elapsed_time_s: 1.77874
    avg_memory_mb: 34.16
    avg_cpu_percent: 98.1
    passed: 7
    failed: 3
    skipped: 9
    total: 19
    score_inputs_passed: 7
    score_inputs_failed: 3
    score_inputs_total: 19
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.13s

      '
    elapsed_time_s: 1.354317
    avg_memory_mb: 31.64
    avg_cpu_percent: 98.8
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.488889
    score_inputs_actual_time_s: 1.354317
  resource:
    returncode: 0
    stdout: '..                                                                       [100%]

      2 passed in 0.11s

      '
    elapsed_time_s: 1.320505
    avg_memory_mb: 31.47
    avg_cpu_percent: 97.4
    passed: 2
    failed: 0
    skipped: 0
    total: 2
    score_inputs_passed: 2
    score_inputs_failed: 0
    score_inputs_total: 2
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 31.96
    score_inputs_baseline_cpu_pct: 100.0
    score_inputs_actual_mem_mb: 31.47
    score_inputs_actual_cpu_pct: 97.4
  robustness:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.12s

      '
    elapsed_time_s: 1.436213
    avg_memory_mb: 31.77
    avg_cpu_percent: 98.8
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=3.0 total_loc=249.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.29119
    avg_memory_mb: 31.76
    avg_cpu_percent: 101.3
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 3.0
      total_loc: 249.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=19.2659 files_scanned=2.0 total_loc=249.0 max_cc=30.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.276528
    avg_memory_mb: 31.52
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 19.2659
      files_scanned: 2.0
      total_loc: 249.0
      max_cc: 30.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 5.374
    score_inputs_generated_mi_min: 19.2659
    score_inputs_ratio_g_over_b: 3.585020468924451
baseline_metrics:
  performance:
    performance_suite_time_s: 1.488889
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.323826
    resource_tests_total: 2
    avg_memory_mb: 31.96
    avg_cpu_percent: 100.0
  functional:
    functional_suite_time_s: 1.640586
    functional_tests_total: 19
  robustness:
    robustness_suite_time_s: 1.41468
    robustness_tests_total: 1
  security:
    security_suite_time_s: 1.482427
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 33.0
      total_loc: 5698.0
  maintainability:
    maintainability_suite_time_s: 1.975499
    maintainability_tests_total: 1
    metrics:
      mi_min: 5.374
      files_scanned: 33.0
      total_loc: 5698.0
      max_cc: 33.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Markdown\pytest_logs
