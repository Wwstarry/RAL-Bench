project_name: Dateutil
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Dateutil\dateutil.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Dateutil
timestamp: '2025-12-31 22:36:26'
functional_score: 0.0
non_functional_score: 0.4
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    error: 'Test file not found: D:\桌面\RealAppCodeBench_generic_eval\tests\Dateutil\functional_test.py'']'
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    elapsed_time_s: 0.0
    avg_memory_mb: 0.0
    avg_cpu_percent: 0.0
  performance:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      _______________________ test_dateutil_performance_smoke _______________________\n\
      \n    def test_dateutil_performance_smoke() -> None:\n        \"\"\"Smoke test\
      \ to ensure the performance benchmark runs successfully.\"\"\"\n>       metrics\
      \ = run_dateutil_performance_benchmark(iterations=10, rrule_span_days=30)\n\n\
      tests\\Dateutil\\performance_test.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dateutil\\performance_test.py:63:\
      \ in run_dateutil_performance_benchmark\n    rule = rrule(DAILY, dtstart=start,\
      \ count=rrule_span_days)\ngeneration\\Dateutil\\dateutil\\rrule.py:273: in rrule\n\
      \    return rrule_class(freq, interval=interval, dtstart=dtstart, count=count,\
      \ until=until,\ngeneration\\Dateutil\\dateutil\\rrule.py:273: in rrule\n   \
      \ return rrule_class(freq, interval=interval, dtstart=dtstart, count=count,\
      \ until=until,\nE   RecursionError: maximum recursion depth exceeded\n!!! Recursion\
      \ detected (same locals & position)\n=========================== short test\
      \ summary info ===========================\nFAILED tests/Dateutil/performance_test.py::test_dateutil_performance_smoke\
      \ - ...\n1 failed in 0.56s\n"
    elapsed_time_s: 1.934457
    avg_memory_mb: 35.03
    avg_cpu_percent: 97.5
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.285375
    score_inputs_actual_time_s: 1.934457
  resource:
    returncode: 1
    stdout: "FF                                                                  \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________________ test_meeting_schedule_integration ______________________\n\
      \n    def test_meeting_schedule_integration() -> None:\n        \"\"\"Integration\
      \ test for building a recurring meeting schedule.\"\"\"\n        start = dt.date(2020,\
      \ 1, 1)\n        end = dt.date(2020, 2, 29)\n    \n        # Approximate \"\
      Europe/Berlin\" as UTC+1 for this test.\n>       meetings = _generate_meeting_schedule(start,\
      \ end, offset_hours=1)\n\ntests\\Dateutil\\resource_test.py:75: \n_ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\\
      Dateutil\\resource_test.py:51: in _generate_meeting_schedule\n    rule = rrule(\n\
      generation\\Dateutil\\dateutil\\rrule.py:273: in rrule\n    return rrule_class(freq,\
      \ interval=interval, dtstart=dtstart, count=count, until=until,\ngeneration\\\
      Dateutil\\dateutil\\rrule.py:273: in rrule\n    return rrule_class(freq, interval=interval,\
      \ dtstart=dtstart, count=count, until=until,\nE   RecursionError: maximum recursion\
      \ depth exceeded\n!!! Recursion detected (same locals & position)\n_____________\
      \ test_duration_between_two_events_with_relativedelta _____________\n\n    def\
      \ test_duration_between_two_events_with_relativedelta() -> None:\n        \"\
      \"\"Use relativedelta to compute calendar duration between first and last meeting.\"\
      \"\"\n        start = dt.date(2020, 1, 1)\n        end = dt.date(2020, 3, 31)\n\
      \    \n        # Approximate \"America/New_York\" as UTC-5 for this test.\n\
      >       meetings = _generate_meeting_schedule(start, end, offset_hours=-5)\n\
      \ntests\\Dateutil\\resource_test.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dateutil\\resource_test.py:51:\
      \ in _generate_meeting_schedule\n    rule = rrule(\ngeneration\\Dateutil\\dateutil\\\
      rrule.py:273: in rrule\n    return rrule_class(freq, interval=interval, dtstart=dtstart,\
      \ count=count, until=until,\ngeneration\\Dateutil\\dateutil\\rrule.py:273: in\
      \ rrule\n    return rrule_class(freq, interval=interval, dtstart=dtstart, count=count,\
      \ until=until,\nE   RecursionError: maximum recursion depth exceeded\n!!! Recursion\
      \ detected (same locals & position)\n=========================== short test\
      \ summary info ===========================\nFAILED tests/Dateutil/resource_test.py::test_meeting_schedule_integration\
      \ - R...\nFAILED tests/Dateutil/resource_test.py::test_duration_between_two_events_with_relativedelta\n\
      2 failed in 0.50s\n"
    elapsed_time_s: 1.855601
    avg_memory_mb: 35.26
    avg_cpu_percent: 98.2
    passed: 0
    failed: 2
    skipped: 0
    total: 2
    score_inputs_passed: 0
    score_inputs_failed: 2
    score_inputs_total: 2
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 31.66
    score_inputs_baseline_cpu_pct: 100.0
    score_inputs_actual_mem_mb: 35.26
    score_inputs_actual_cpu_pct: 98.2
  robustness:
    returncode: 0
    stdout: "......                                                              \
      \     [100%]\n============================== warnings summary ===============================\n\
      tests\\Dateutil\\robustness_test.py:92\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dateutil\\robustness_test.py:92: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dateutil\\robustness_test.py:103\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dateutil\\robustness_test.py:103: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dateutil\\robustness_test.py:123\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dateutil\\robustness_test.py:123: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dateutil\\robustness_test.py:138\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dateutil\\robustness_test.py:138: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dateutil\\robustness_test.py:152\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dateutil\\robustness_test.py:152: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dateutil\\robustness_test.py:173\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dateutil\\robustness_test.py:173: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n\
      6 passed, 6 warnings in 0.21s\n"
    elapsed_time_s: 1.729962
    avg_memory_mb: 31.83
    avg_cpu_percent: 99.0
    passed: 6
    failed: 0
    skipped: 0
    total: 6
    score_inputs_passed: 6
    score_inputs_failed: 0
    score_inputs_total: 6
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=5.0 total_loc=805.0

      .

      1 passed in 0.14s

      '
    elapsed_time_s: 1.551064
    avg_memory_mb: 31.55
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 5.0
      total_loc: 805.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=16.0531 files_scanned=5.0 total_loc=805.0 max_cc=54.0

      .

      1 passed in 0.24s

      '
    elapsed_time_s: 1.589269
    avg_memory_mb: 31.88
    avg_cpu_percent: 98.9
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 16.0531
      files_scanned: 5.0
      total_loc: 805.0
      max_cc: 54.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 16.0531
baseline_metrics:
  performance:
    performance_suite_time_s: 1.285375
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.234135
    resource_tests_total: 2
    avg_memory_mb: 31.66
    avg_cpu_percent: 100.0
  functional:
    functional_suite_time_s: 1.125135
    functional_tests_total: 1
  robustness:
    robustness_suite_time_s: 1.313908
    robustness_tests_total: 6
  security:
    security_suite_time_s: 1.372555
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 22.0
      total_loc: 5945.0
  maintainability:
    maintainability_suite_time_s: 3.147629
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 37.0
      total_loc: 14362.0
      max_cc: 96.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Dateutil\pytest_logs
