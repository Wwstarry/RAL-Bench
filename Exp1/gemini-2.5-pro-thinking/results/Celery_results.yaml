project_name: Celery
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Celery\celery.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Celery
timestamp: '2026-01-01 19:49:11'
functional_score: 0.0
non_functional_score: 0.24
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 0.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "FFFFFFFFFF                                                          \
      \     [100%]\n================================== FAILURES ===================================\n\
      ___________________ test_001_import_celery_and_core_symbols ___________________\n\
      \n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n\
      \        import celery  # noqa: F401\n    \n        from celery import Celery\
      \  # noqa: F401\n>       from celery import chain, chord, group, signature \
      \ # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery'\
      \ (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\
      \ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay\
      \ _______________\n\n    def test_002_create_app_and_register_task_runs_delay()\
      \ -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.add\"\
      )\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:68:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nfunc = <function test_002_create_app_and_register_task_runs_delay.<locals>.add\
      \ at 0x000001ADC41099D0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\
      \ ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager()\
      \ -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.mul\"\
      )\n>       def mul(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:80:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nfunc = <function test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager.<locals>.mul\
      \ at 0x000001ADC41098B0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n__________________\
      \ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order()\
      \ -> None:\n        app = _make_app()\n>       from celery import group\nE \
      \      ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\\
      generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:90:\
      \ ImportError\n____________________ test_005_chain_passes_previous_result ____________________\n\
      \n    def test_005_chain_passes_previous_result() -> None:\n        app = _make_app()\n\
      >       from celery import chain\nE       ImportError: cannot import name 'chain'\
      \ from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\\
      celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:104: ImportError\n\
      _______________ test_006_chord_runs_callback_over_group_results _______________\n\
      \n    def test_006_chord_runs_callback_over_group_results() -> None:\n     \
      \   app = _make_app()\n>       from celery import chord, group\nE       ImportError:\
      \ cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\\
      generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:117:\
      \ ImportError\n______________ test_007_task_exception_propagates_in_eager_mode\
      \ _______________\n\n    def test_007_task_exception_propagates_in_eager_mode()\
      \ -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True\
      \ and\n        task_eager_propagates=True, the exception is raised immediately\
      \ during\n        delay()/apply_async() rather than on AsyncResult.get().\n\
      \    \n        This test accepts both correct behaviors:\n        - delay raises\
      \ ValueError directly, OR\n        - delay returns a result whose .get() raises\
      \ ValueError.\n        \"\"\"\n        app = _make_app()\n    \n        @app.task(name=\"\
      celery_test.boom\")\n>       def boom() -> None:\n\ntests\\Celery\\functional_test.py:145:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nfunc = <function test_007_task_exception_propagates_in_eager_mode.<locals>.boom\
      \ at 0x000001ADC40973A0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n_____________\
      \ test_008_disable_propagation_returns_failed_result ______________\n\n    def\
      \ test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\
      \"\n        With task_eager_propagates=False:\n          - Some Celery builds\
      \ still raise on get(..., propagate=True)\n          - get(..., propagate=False)\
      \ may return None OR return the exception object\n        We accept both behaviors\
      \ as long as the task is marked failed.\n        \"\"\"\n        app = _make_app()\n\
      >       app.conf.task_eager_propagates = False\nE       AttributeError: 'dict'\
      \ object has no attribute 'task_eager_propagates'\n\ntests\\Celery\\functional_test.py:166:\
      \ AttributeError\n_______________ test_009_signature_freeze_has_id_and_task_name\
      \ ________________\n\n    def test_009_signature_freeze_has_id_and_task_name()\
      \ -> None:\n        app = _make_app()\n>       from celery import signature\n\
      E       ImportError: cannot import name 'signature' from 'celery' (D:\\桌面\\\
      RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\n\
      tests\\Celery\\functional_test.py:191: ImportError\n____________ test_010_default_app_does_not_break_custom_app_usage\
      \ _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage()\
      \ -> None:\n        \"\"\"\n        Ensure that importing celery and using a\
      \ custom app is not polluted by globals.\n        \"\"\"\n        app = _make_app(\"\
      celery_test_app_2\")\n    \n        @app.task(name=\"celery_test_app_2.add\"\
      )\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:210:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nfunc = <function test_010_default_app_does_not_break_custom_app_usage.<locals>.add\
      \ at 0x000001ADC4109EE0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\n\
      FAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\n\
      FAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\n\
      FAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\n\
      FAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\n\
      FAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\n\
      FAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\n\
      FAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\n\
      FAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\n\
      FAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n\
      10 failed in 0.50s\n"
    elapsed_time_s: 1.641349
    avg_memory_mb: 32.74
    avg_cpu_percent: 100.0
    passed: 0
    failed: 10
    skipped: 0
    total: 10
    score_inputs_passed: 0
    score_inputs_failed: 10
    score_inputs_total: 10
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 1
    stdout: "FF                                                                  \
      \     [100%]\n================================== FAILURES ===================================\n\
      ____________ test_performance_001_many_small_tasks_finish_quickly _____________\n\
      \n    @pytest.mark.performance\n    def test_performance_001_many_small_tasks_finish_quickly()\
      \ -> None:\n        \"\"\"\n        Absolute threshold is intentionally conservative\
      \ to avoid false failures on slow CI.\n        \"\"\"\n        app = _make_app()\n\
      \    \n        @app.task(name=\"celery_perf.noop\")\n>       def noop(x: int)\
      \ -> int:\n\ntests\\Celery\\performance_test.py:55: \n_ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function\
      \ test_performance_001_many_small_tasks_finish_quickly.<locals>.noop at 0x00000278FF4F89D0>\n\
      \n    def decorator(func):\n        base = opts.pop('base', Task)\n        name\
      \ = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n\
      >       task_instance = base(func, self, name=name, **opts)\nE       TypeError:\
      \ celery.app.task.Task() got multiple values for keyword argument 'name'\n\n\
      generation\\Celery\\celery\\app\\base.py:51: TypeError\n______________ test_performance_002_group_batching_is_reasonable\
      \ ______________\n\n    @pytest.mark.performance\n    def test_performance_002_group_batching_is_reasonable()\
      \ -> None:\n        app = _make_app()\n>       from celery import group\nE \
      \      ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\\
      generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\performance_test.py:72:\
      \ ImportError\n============================== warnings summary ===============================\n\
      tests\\Celery\\performance_test.py:47\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Celery\\performance_test.py:47: PytestUnknownMarkWarning: Unknown pytest.mark.performance\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.performance\n\
      \ntests\\Celery\\performance_test.py:69\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Celery\\performance_test.py:69: PytestUnknownMarkWarning: Unknown pytest.mark.performance\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.performance\n\
      \n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n\
      =========================== short test summary info ===========================\n\
      FAILED tests/Celery/performance_test.py::test_performance_001_many_small_tasks_finish_quickly\n\
      FAILED tests/Celery/performance_test.py::test_performance_002_group_batching_is_reasonable\n\
      2 failed, 2 warnings in 0.35s\n"
    elapsed_time_s: 1.522694
    avg_memory_mb: 31.7
    avg_cpu_percent: 98.9
    passed: 0
    failed: 2
    skipped: 0
    total: 2
    score_inputs_passed: 0
    score_inputs_failed: 2
    score_inputs_total: 2
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 3.769039
    score_inputs_actual_time_s: 1.522694
  resource:
    returncode: 1
    stdout: "F.                                                                  \
      \     [100%]\n================================== FAILURES ===================================\n\
      _______ test_resource_001_tracemalloc_growth_is_bounded_for_many_tasks ________\n\
      \n    @pytest.mark.resource\n    def test_resource_001_tracemalloc_growth_is_bounded_for_many_tasks()\
      \ -> None:\n        \"\"\"\n        Use tracemalloc (stdlib) so the test stays\
      \ portable.\n        We only check that memory growth is not pathological.\n\
      \        \"\"\"\n        app = _make_app()\n    \n        @app.task(name=\"\
      celery_resource.small\")\n>       def small(x: int) -> int:\n\ntests\\Celery\\\
      resource_test.py:57: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_resource_001_tracemalloc_growth_is_bounded_for_many_tasks.<locals>.small\
      \ at 0x0000012E626E11F0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n==============================\
      \ warnings summary ===============================\ntests\\Celery\\resource_test.py:48\n\
      \  D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Celery\\resource_test.py:48:\
      \ PytestUnknownMarkWarning: Unknown pytest.mark.resource - is this a typo? \
      \ You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.resource\n\ntests\\Celery\\resource_test.py:85\n  D:\\桌面\\\
      RealAppCodeBench_generic_eval\\tests\\Celery\\resource_test.py:85: PytestUnknownMarkWarning:\
      \ Unknown pytest.mark.resource - is this a typo?  You can register custom marks\
      \ to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.resource\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n\
      =========================== short test summary info ===========================\n\
      FAILED tests/Celery/resource_test.py::test_resource_001_tracemalloc_growth_is_bounded_for_many_tasks\n\
      1 failed, 1 passed, 2 warnings in 0.35s\n"
    elapsed_time_s: 1.532948
    avg_memory_mb: 32.23
    avg_cpu_percent: 101.1
    passed: 1
    failed: 1
    skipped: 0
    total: 2
    score_inputs_passed: 1
    score_inputs_failed: 1
    score_inputs_total: 2
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 44.36
    score_inputs_baseline_cpu_pct: 99.2
    score_inputs_actual_mem_mb: 32.23
    score_inputs_actual_cpu_pct: 101.1
  robustness:
    returncode: 1
    stdout: "FFFFFF                                                              \
      \     [100%]\n================================== FAILURES ===================================\n\
      _________________ test_001_empty_args_and_kwargs_do_not_crash _________________\n\
      \n    def test_001_empty_args_and_kwargs_do_not_crash() -> None:\n        app\
      \ = _make_app()\n    \n        @app.task(name=\"celery_robust.const\")\n>  \
      \     def const() -> int:\n\ntests\\Celery\\robustness_test.py:50: \n_ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n\
      func = <function test_001_empty_args_and_kwargs_do_not_crash.<locals>.const\
      \ at 0x00000261BB1C9CA0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n_____________\
      \ test_002_unknown_task_name_signature_errors_cleanly _____________\n\n    def\
      \ test_002_unknown_task_name_signature_errors_cleanly() -> None:\n        app\
      \ = _make_app()\n>       from celery import signature\nE       ImportError:\
      \ cannot import name 'signature' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\\
      generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\robustness_test.py:59:\
      \ ImportError\n____________ test_003_large_payload_does_not_crash_eager_execution\
      \ ____________\n\n    def test_003_large_payload_does_not_crash_eager_execution()\
      \ -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_robust.echo_len\"\
      )\n>       def echo_len(s: str) -> int:\n\ntests\\Celery\\robustness_test.py:70:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nfunc = <function test_003_large_payload_does_not_crash_eager_execution.<locals>.echo_len\
      \ at 0x00000261BB2433A0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n_____________\
      \ test_004_chord_with_empty_header_behaves_reasonably _____________\n\n    def\
      \ test_004_chord_with_empty_header_behaves_reasonably() -> None:\n        app\
      \ = _make_app()\n>       from celery import chord, group\nE       ImportError:\
      \ cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\\
      generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\robustness_test.py:80:\
      \ ImportError\n___________________ test_005_task_can_return_dict_and_list ____________________\n\
      \n    def test_005_task_can_return_dict_and_list() -> None:\n        app = _make_app()\n\
      \    \n        @app.task(name=\"celery_robust.make_obj\")\n>       def make_obj()\
      \ -> Dict[str, Any]:\n\ntests\\Celery\\robustness_test.py:95: \n_ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc\
      \ = <function test_005_task_can_return_dict_and_list.<locals>.make_obj at 0x00000261BB243430>\n\
      \n    def decorator(func):\n        base = opts.pop('base', Task)\n        name\
      \ = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n\
      >       task_instance = base(func, self, name=name, **opts)\nE       TypeError:\
      \ celery.app.task.Task() got multiple values for keyword argument 'name'\n\n\
      generation\\Celery\\celery\\app\\base.py:51: TypeError\n__________________ test_006_propagation_toggle_is_respected\
      \ ___________________\n\n    def test_006_propagation_toggle_is_respected()\
      \ -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_robust.fail\"\
      )\n>       def fail() -> None:\n\ntests\\Celery\\robustness_test.py:109: \n\
      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _\n\nfunc = <function test_006_propagation_toggle_is_respected.<locals>.fail\
      \ at 0x00000261BB2435E0>\n\n    def decorator(func):\n        base = opts.pop('base',\
      \ Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__,\
      \ func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\n\
      E       TypeError: celery.app.task.Task() got multiple values for keyword argument\
      \ 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Celery/robustness_test.py::test_001_empty_args_and_kwargs_do_not_crash\n\
      FAILED tests/Celery/robustness_test.py::test_002_unknown_task_name_signature_errors_cleanly\n\
      FAILED tests/Celery/robustness_test.py::test_003_large_payload_does_not_crash_eager_execution\n\
      FAILED tests/Celery/robustness_test.py::test_004_chord_with_empty_header_behaves_reasonably\n\
      FAILED tests/Celery/robustness_test.py::test_005_task_can_return_dict_and_list\n\
      FAILED tests/Celery/robustness_test.py::test_006_propagation_toggle_is_respected\n\
      6 failed in 0.38s\n"
    elapsed_time_s: 1.538955
    avg_memory_mb: 32.19
    avg_cpu_percent: 102.2
    passed: 0
    failed: 6
    skipped: 0
    total: 6
    score_inputs_passed: 0
    score_inputs_failed: 6
    score_inputs_total: 6
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=10.0 total_loc=215.0

      .

      1 passed in 0.10s

      '
    elapsed_time_s: 1.184202
    avg_memory_mb: 31.29
    avg_cpu_percent: 98.6
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 10.0
      total_loc: 215.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 4.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=37.9107 files_scanned=9.0 total_loc=215.0 max_cc=7.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.207295
    avg_memory_mb: 31.12
    avg_cpu_percent: 98.6
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 37.9107
      files_scanned: 9.0
      total_loc: 215.0
      max_cc: 7.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 37.9107
baseline_metrics:
  functional:
    functional_suite_time_s: 2.734527
    functional_tests_total: 10
  performance:
    performance_suite_time_s: 3.769039
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 9.788972
    resource_tests_total: 2
    avg_memory_mb: 44.36
    avg_cpu_percent: 99.2
  robustness:
    robustness_suite_time_s: 4.859838
    robustness_tests_total: 6
  security:
    security_suite_time_s: 2.146028
    security_tests_total: 1
    metrics:
      high_risk_count: 4.0
      files_scanned: 161.0
      total_loc: 32227.0
  maintainability:
    maintainability_suite_time_s: 4.314273
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 156.0
      total_loc: 32227.0
      max_cc: 66.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Celery\pytest_logs
