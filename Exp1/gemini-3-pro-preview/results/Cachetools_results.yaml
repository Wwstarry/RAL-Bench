project_name: Cachetools
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Cachetools\cachetools.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Cachetools
timestamp: '2025-12-31 16:03:17'
functional_score: 0.9231
non_functional_score: 0.8798
non_functional_subscores:
  maintainability: 0.8036
  security: 1.0
  robustness: 0.8182
  performance: 0.8353
  resource: 0.995
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: ".F...........                                                       \
      \     [100%]\n================================== FAILURES ===================================\n\
      __________________________ test_ttl_cache_expiration __________________________\n\
      \n    def test_ttl_cache_expiration():\n        ttl_seconds = 0.2\n        cache\
      \ = TTLCache(maxsize=10, ttl=ttl_seconds)\n    \n        cache[\"answer\"] =\
      \ 42\n        assert cache[\"answer\"] == 42\n        assert \"answer\" in cache\n\
      \    \n        # Wait long enough for the entry to expire\n        time.sleep(ttl_seconds\
      \ + 0.3)\n    \n        # After TTL has passed, the key should no longer be\
      \ considered valid\n        # Implementations may clean up lazily, but membership\
      \ and access\n        # must not behave as if the value is still present.\n\
      >       assert \"answer\" not in cache\nE       AssertionError: assert 'answer'\
      \ not in TTLCache([], maxsize=10, currsize=0)\n\ntests\\Cachetools\\functional_test.py:62:\
      \ AssertionError\n=========================== short test summary info ===========================\n\
      FAILED tests/Cachetools/functional_test.py::test_ttl_cache_expiration - Asser...\n\
      1 failed, 12 passed in 2.06s\n"
    elapsed_time_s: 3.432527
    avg_memory_mb: 32.68
    avg_cpu_percent: 53.5
    passed: 12
    failed: 1
    skipped: 0
    total: 13
    score_inputs_passed: 12
    score_inputs_failed: 1
    score_inputs_total: 13
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.13s

      '
    elapsed_time_s: 1.493271
    avg_memory_mb: 31.21
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.247364
    score_inputs_actual_time_s: 1.493271
  resource:
    returncode: 0
    stdout: '..                                                                       [100%]

      2 passed in 0.23s

      '
    elapsed_time_s: 1.697245
    avg_memory_mb: 31.29
    avg_cpu_percent: 99.0
    passed: 2
    failed: 0
    skipped: 0
    total: 2
    score_inputs_passed: 2
    score_inputs_failed: 0
    score_inputs_total: 2
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 31.07
    score_inputs_baseline_cpu_pct: 98.7
    score_inputs_actual_mem_mb: 31.29
    score_inputs_actual_cpu_pct: 99.0
  robustness:
    returncode: 1
    stdout: "...FF......                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      ___________ test_popitem_on_empty_cache_raises_keyerror[FIFOCache] ____________\n\
      \ncache_cls = 'FIFOCache'\n\n    @pytest.mark.parametrize(\"cache_cls\", [\"\
      FIFOCache\", \"LFUCache\", \"LRUCache\"])\n    def test_popitem_on_empty_cache_raises_keyerror(cache_cls:\
      \ str):\n        cachetools = _import_cachetools()\n>       cls = getattr(cachetools,\
      \ cache_cls)\nE       AttributeError: module 'cachetools' has no attribute 'FIFOCache'\n\
      \ntests\\Cachetools\\robustness_test.py:116: AttributeError\n____________ test_popitem_on_empty_cache_raises_keyerror[LFUCache]\
      \ ____________\n\ncache_cls = 'LFUCache'\n\n    @pytest.mark.parametrize(\"\
      cache_cls\", [\"FIFOCache\", \"LFUCache\", \"LRUCache\"])\n    def test_popitem_on_empty_cache_raises_keyerror(cache_cls:\
      \ str):\n        cachetools = _import_cachetools()\n>       cls = getattr(cachetools,\
      \ cache_cls)\nE       AttributeError: module 'cachetools' has no attribute 'LFUCache'\n\
      \ntests\\Cachetools\\robustness_test.py:116: AttributeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Cachetools/robustness_test.py::test_popitem_on_empty_cache_raises_keyerror[FIFOCache]\n\
      FAILED tests/Cachetools/robustness_test.py::test_popitem_on_empty_cache_raises_keyerror[LFUCache]\n\
      2 failed, 9 passed in 0.47s\n"
    elapsed_time_s: 1.858976
    avg_memory_mb: 31.8
    avg_cpu_percent: 99.1
    passed: 9
    failed: 2
    skipped: 0
    total: 11
    score_inputs_passed: 9
    score_inputs_failed: 2
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=6.0 total_loc=264.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.417533
    avg_memory_mb: 31.55
    avg_cpu_percent: 97.7
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 6.0
      total_loc: 264.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=34.0609 files_scanned=6.0 total_loc=264.0 max_cc=14.0

      .

      1 passed in 0.15s

      '
    elapsed_time_s: 1.437367
    avg_memory_mb: 31.52
    avg_cpu_percent: 97.6
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 34.0609
      files_scanned: 6.0
      total_loc: 264.0
      max_cc: 14.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 8.3242
    score_inputs_generated_mi_min: 34.0609
    score_inputs_ratio_g_over_b: 4.091792604694746
baseline_metrics:
  performance:
    performance_suite_time_s: 1.247364
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.330613
    resource_tests_total: 2
    avg_memory_mb: 31.07
    avg_cpu_percent: 98.7
  functional:
    functional_suite_time_s: 2.774696
    functional_tests_total: 13
  robustness:
    robustness_suite_time_s: 1.275119
    robustness_tests_total: 11
  security:
    security_suite_time_s: 1.163912
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 5.0
      total_loc: 997.0
  maintainability:
    maintainability_suite_time_s: 1.271974
    maintainability_tests_total: 1
    metrics:
      mi_min: 8.3242
      files_scanned: 5.0
      total_loc: 997.0
      max_cc: 13.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Cachetools\pytest_logs
