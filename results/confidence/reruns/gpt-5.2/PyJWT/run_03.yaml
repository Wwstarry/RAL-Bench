project_name: PyJWT
task_file: D:\桌面\RAL-Bench\tasks\PyJWT\pyjwt.yaml
generated_repo: D:\桌面\RAL-Bench\generation\gpt-5.2\PyJWT
timestamp: '2026-01-21 23:08:47'
functional_score: 0.5455
non_functional_score: 0.7087
non_functional_subscores:
  maintainability: 0.8576
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: ".F.FF...F.s                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      _____________________ test_hs512_encode_decode_roundtrip ______________________\n\
      \n>   ???\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\PyJWT\\functional_test.py:148:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\PyJWT\\functional_test.py:130:\
      \ in _encode_decode\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read',\
      \ 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder\
      \ = None, kwargs = {}\n\n    def encode(\n        payload: Dict[str, Any],\n\
      \        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n    \
      \    headers: Optional[Dict[str, Any]] = None,\n        json_encoder=None,\n\
      \        **kwargs,\n    ) -> str:\n        if algorithm is None:\n         \
      \   algorithm = \"HS256\"\n        if algorithm != \"HS256\":\n>           raise\
      \ NotImplementedError(\"Only HS256 is supported in this implementation\")\n\
      E           NotImplementedError: Only HS256 is supported in this implementation\n\
      \ngeneration\\gpt-5.2\\PyJWT\\jwt\\api_jwt.py:58: NotImplementedError\n_______________\
      \ test_encode_decode_with_datetime_exp_in_future ________________\n\n>   ???\n\
      \nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\PyJWT\\functional_test.py:163:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\PyJWT\\functional_test.py:130:\
      \ in _encode_decode\n    ???\ngeneration\\gpt-5.2\\PyJWT\\jwt\\api_jwt.py:68:\
      \ in encode\n    payload_json = _json_dumps(payload).encode(\"utf-8\")\ngeneration\\\
      gpt-5.2\\PyJWT\\jwt\\api_jwt.py:30: in _json_dumps\n    return json.dumps(obj,\
      \ separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\\
      Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return\
      \ cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\\
      json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257:\
      \ in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder\
      \ object at 0x00000271EDB031C0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\
      \n    def default(self, o):\n        \"\"\"Implement this method in a subclass\
      \ such that it returns\n        a serializable object for ``o``, or calls the\
      \ base implementation\n        (to raise a ``TypeError``).\n    \n        For\
      \ example, to support arbitrary iterators, you could\n        implement default\
      \ like this::\n    \n            def default(self, o):\n                try:\n\
      \                    iterable = iter(o)\n                except TypeError:\n\
      \                    pass\n                else:\n                    return\
      \ list(iterable)\n                # Let the base class default method raise\
      \ the TypeError\n                return JSONEncoder.default(self, o)\n    \n\
      \        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__}\
      \ '\n                        f'is not JSON serializable')\nE       TypeError:\
      \ Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\\
      Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________\
      \ test_encode_decode_with_datetime_nbf_in_past _________________\n\n>   ???\n\
      \nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\PyJWT\\functional_test.py:171:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\PyJWT\\functional_test.py:130:\
      \ in _encode_decode\n    ???\ngeneration\\gpt-5.2\\PyJWT\\jwt\\api_jwt.py:68:\
      \ in encode\n    payload_json = _json_dumps(payload).encode(\"utf-8\")\ngeneration\\\
      gpt-5.2\\PyJWT\\jwt\\api_jwt.py:30: in _json_dumps\n    return json.dumps(obj,\
      \ separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\\
      Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return\
      \ cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\\
      json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257:\
      \ in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder\
      \ object at 0x00000271EDB06B20>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\
      \n    def default(self, o):\n        \"\"\"Implement this method in a subclass\
      \ such that it returns\n        a serializable object for ``o``, or calls the\
      \ base implementation\n        (to raise a ``TypeError``).\n    \n        For\
      \ example, to support arbitrary iterators, you could\n        implement default\
      \ like this::\n    \n            def default(self, o):\n                try:\n\
      \                    iterable = iter(o)\n                except TypeError:\n\
      \                    pass\n                else:\n                    return\
      \ list(iterable)\n                # Let the base class default method raise\
      \ the TypeError\n                return JSONEncoder.default(self, o)\n    \n\
      \        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__}\
      \ '\n                        f'is not JSON serializable')\nE       TypeError:\
      \ Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\\
      Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________\
      \ test_unverified_header_contains_alg_and_custom_kid ______________\n\n>   ???\n\
      E   AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\n\
      D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\PyJWT\\functional_test.py:210:\
      \ AttributeError\n=========================== short test summary info ===========================\n\
      FAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip -\
      \ N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\n\
      FAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\n\
      FAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n\
      4 failed, 6 passed, 1 skipped in 0.45s\n"
    elapsed_time_s: 1.763695
    avg_memory_mb: 33.13
    avg_cpu_percent: 100.0
    passed: 6
    failed: 4
    skipped: 1
    total: 11
    score_inputs_passed: 6
    score_inputs_failed: 4
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/PyJWT/performance_test.py _______________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      PyJWT\\performance_test.py:19: in <module>\n    ???\nE   RuntimeError: Target\
      \ repository does not exist: D:\\桌面\\RAL-Bench\\generation\\PyJWT\n===========================\
      \ short test summary info ===========================\nERROR tests/PyJWT/performance_test.py\
      \ - RuntimeError: Target repository does ...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.48s\n"
    elapsed_time_s: 1.696276
    avg_memory_mb: 35.22
    avg_cpu_percent: 101.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.272328
    score_inputs_actual_time_s: 1.696276
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ________________ ERROR collecting tests/PyJWT/resource_test.py ________________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      PyJWT\\resource_test.py:20: in <module>\n    ???\nE   RuntimeError: Target repository\
      \ does not exist: D:\\桌面\\RAL-Bench\\generation\\PyJWT\n===========================\
      \ short test summary info ===========================\nERROR tests/PyJWT/resource_test.py\
      \ - RuntimeError: Target repository does not...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.58s\n"
    elapsed_time_s: 1.807526
    avg_memory_mb: 35.25
    avg_cpu_percent: 98.2
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 32.45
    score_inputs_baseline_cpu_pct: 97.5
    score_inputs_actual_mem_mb: 35.25
    score_inputs_actual_cpu_pct: 98.2
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.13s

      '
    elapsed_time_s: 1.332565
    avg_memory_mb: 31.88
    avg_cpu_percent: 101.3
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=3.0 total_loc=148.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.269313
    avg_memory_mb: 31.8
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 3.0
      total_loc: 148.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=27.8174 files_scanned=3.0 total_loc=148.0 max_cc=15.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.262422
    avg_memory_mb: 31.7
    avg_cpu_percent: 102.7
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 27.8174
      files_scanned: 3.0
      total_loc: 148.0
      max_cc: 15.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 4.6208
    score_inputs_generated_mi_min: 27.8174
    score_inputs_ratio_g_over_b: 6.020039819944598
baseline_metrics:
  performance:
    performance_suite_time_s: 1.272328
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.374763
    resource_tests_total: 3
    avg_memory_mb: 32.45
    avg_cpu_percent: 97.5
  functional:
    functional_suite_time_s: 1.285872
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.543038
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.347434
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 12.0
      total_loc: 2146.0
  maintainability:
    maintainability_suite_time_s: 1.290264
    maintainability_tests_total: 1
    metrics:
      mi_min: 4.6208
      files_scanned: 12.0
      total_loc: 2146.0
      max_cc: 19.0
pytest_logs_dir: D:\桌面\RAL-Bench\results\PyJWT\pytest_logs
