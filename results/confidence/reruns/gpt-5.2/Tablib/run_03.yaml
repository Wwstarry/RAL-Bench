project_name: Tablib
task_file: D:\桌面\RAL-Bench\tasks\Tablib\tablib.yaml
generated_repo: D:\桌面\RAL-Bench\generation\gpt-5.2\Tablib
timestamp: '2026-01-21 23:31:02'
functional_score: 0.4545
non_functional_score: 0.4
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "FF..F..FFF.                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\
      \n>   ???\nE   AssertionError: assert False\nE    +  where False = isinstance({'data':\
      \ [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace',\
      \ 36]], 'headers': ['first_name', 'last_name', 'age']}, list)\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Tablib\\functional_test.py:146: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip\
      \ ___________________\n\n>   ???\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset\
      \ object at 0x0000024E8D8D5E20>, fmt = 'tsv'\n\n    def export(self, fmt: str)\
      \ -> str:\n        fmt = (fmt or \"\").lower()\n        if fmt == \"csv\":\n\
      \            return csv_format.export_dataset(self)\n        if fmt == \"json\"\
      :\n            return json_format.export_dataset(self)\n>       raise ValueError(f\"\
      Unsupported format: {fmt}\")\nE       ValueError: Unsupported format: tsv\n\n\
      generation\\gpt-5.2\\Tablib\\tablib\\core.py:135: ValueError\n__________________\
      \ test_dataset_insert_and_pop_row_semantics __________________\n\n>   ???\n\
      E   AttributeError: 'Dataset' object has no attribute 'insert'\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Tablib\\functional_test.py:233: AttributeError\n________________ test_dataset_export_json_contains_all_records\
      \ ________________\n\n>   ???\nE   AssertionError: assert False\nE    +  where\
      \ False = isinstance({'data': [['John', 'Adams', 90], ['George', 'Washington',\
      \ 67], ['Ada', 'Lovelace', 36]], 'headers': ['first_name', 'last_name', 'age']},\
      \ list)\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py:278:\
      \ AssertionError\n______________ test_dataset_export_html_contains_table_structure\
      \ ______________\n\n>   ???\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object\
      \ at 0x0000024E8D943A60>, fmt = 'html'\n\n    def export(self, fmt: str) ->\
      \ str:\n        fmt = (fmt or \"\").lower()\n        if fmt == \"csv\":\n  \
      \          return csv_format.export_dataset(self)\n        if fmt == \"json\"\
      :\n            return json_format.export_dataset(self)\n>       raise ValueError(f\"\
      Unsupported format: {fmt}\")\nE       ValueError: Unsupported format: html\n\
      \ngeneration\\gpt-5.2\\Tablib\\tablib\\core.py:135: ValueError\n__________________\
      \ test_databook_multi_sheet_json_roundtrip ___________________\n\n>   ???\n\
      E   AssertionError: assert False\nE    +  where False = isinstance({'sheets':\
      \ [{'data': [[1, 'a'], [2, 'b']], 'headers': ['id', 'value'], 'title': 'First'},\
      \ {'data': [[3, 'c'], [4, 'd']], 'headers': ['id', 'value'], 'title': 'Second'}]},\
      \ list)\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py:324:\
      \ AssertionError\n=========================== short test summary info ===========================\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_import_csv_and_json_roundtrip\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_json_contains_all_records\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n\
      FAILED tests/Tablib/functional_test.py::test_databook_multi_sheet_json_roundtrip\n\
      6 failed, 5 passed in 0.40s\n"
    elapsed_time_s: 1.611382
    avg_memory_mb: 32.14
    avg_cpu_percent: 99.0
    passed: 5
    failed: 6
    skipped: 0
    total: 11
    score_inputs_passed: 5
    score_inputs_failed: 6
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Tablib/performance_test.py ______________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Tablib\\performance_test.py:18: in <module>\n    ???\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/performance_test.py -\
      \ RuntimeError: Unsupported TABLIB_TAR...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.49s\n"
    elapsed_time_s: 1.686749
    avg_memory_mb: 36.4
    avg_cpu_percent: 101.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.267515
    score_inputs_actual_time_s: 1.686749
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _______________ ERROR collecting tests/Tablib/resource_test.py ________________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Tablib\\resource_test.py:18: in <module>\n    ???\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/resource_test.py - RuntimeError:\
      \ Unsupported TABLIB_TARGET...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during\
      \ collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.49s\n"
    elapsed_time_s: 1.674111
    avg_memory_mb: 36.23
    avg_cpu_percent: 101.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 34.54
    score_inputs_baseline_cpu_pct: 99.1
    score_inputs_actual_mem_mb: 36.23
    score_inputs_actual_cpu_pct: 101.0
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.13s

      '
    elapsed_time_s: 1.366383
    avg_memory_mb: 31.32
    avg_cpu_percent: 98.8
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=4.0 total_loc=283.0

      .

      1 passed in 0.10s

      '
    elapsed_time_s: 1.261622
    avg_memory_mb: 31.73
    avg_cpu_percent: 98.7
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 4.0
      total_loc: 283.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=24.7872 files_scanned=4.0 total_loc=283.0 max_cc=14.0

      .

      1 passed in 0.14s

      '
    elapsed_time_s: 1.372348
    avg_memory_mb: 31.98
    avg_cpu_percent: 97.6
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 24.7872
      files_scanned: 4.0
      total_loc: 283.0
      max_cc: 14.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 24.7872
baseline_metrics:
  performance:
    performance_suite_time_s: 2.267515
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 5.457667
    resource_tests_total: 2
    avg_memory_mb: 34.54
    avg_cpu_percent: 99.1
  functional:
    functional_suite_time_s: 1.550296
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.567555
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.666207
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 31.0
      total_loc: 3330.0
  maintainability:
    maintainability_suite_time_s: 2.204547
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 31.0
      total_loc: 4978.0
      max_cc: 17.0
pytest_logs_dir: D:\桌面\RAL-Bench\results\Tablib\pytest_logs
