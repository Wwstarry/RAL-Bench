project_name: Typer
task_file: D:\桌面\RAL-Bench\tasks\Typer\typer.yaml
generated_repo: D:\桌面\RAL-Bench\generation\gpt-5.2\Typer
timestamp: '2026-01-21 23:47:57'
functional_score: 0.1667
non_functional_score: 0.7383
non_functional_subscores:
  maintainability: 0.9397
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "FFFFFF..FFFF                                                        \
      \     [100%]\n================================== FAILURES ===================================\n\
      __________________________ test_simple_hello_command __________________________\n\
      \n>   ???\nE   AssertionError: assert 2 == 0\nE    +  where 2 = Result(stdout='',\
      \ stderr='Error: No such command: World\\n', exit_code=2, exception=None).exit_code\n\
      \nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Typer\\functional_test.py:199:\
      \ AssertionError\n______________________ test_simple_hello_command_excited ______________________\n\
      \n>   ???\nE   AssertionError: assert 2 == 0\nE    +  where 2 = Result(stdout='',\
      \ stderr='Error: No such option: --excited\\n', exit_code=2, exception=None).exit_code\n\
      \nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Typer\\functional_test.py:207:\
      \ AssertionError\n_______________ test_greeter_help_mentions_option_and_argument\
      \ ________________\n\n>   ???\nE   AssertionError: assert '--excited' in 'Usage:\
      \ app [OPTIONS] COMMAND [ARGS]...\\n\\nOptions:\\n  --help         Show this\
      \ message and exit.\\n\\nCommands:\\n'\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:216: AssertionError\n_____________________\
      \ test_todo_list_empty_shows_no_tasks _____________________\n\n>   ???\nE  \
      \ AssertionError: assert 'No tasks.' in ''\nE    +  where '' = Result(stdout='',\
      \ stderr='', exit_code=0, exception=None).stdout\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:224: AssertionError\n----------------------------\
      \ Captured stdout call -----------------------------\nNo tasks.\n___________________________\
      \ test_todo_add_and_list ____________________________\n\n>   ???\nE   AssertionError:\
      \ assert 'Added: Write tests' in ''\nE    +  where '' = Result(stdout='', stderr='',\
      \ exit_code=0, exception=None).stdout\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:234: AssertionError\n----------------------------\
      \ Captured stdout call -----------------------------\nAdded: Write tests\nAdded:\
      \ Review PRs\n_____________________ test_todo_remove_then_list_updates ______________________\n\
      \n>   ???\nE   assert 1 == 0\nE    +  where 1 = Result(stdout='', stderr=\"\
      Error: unsupported operand type(s) for -: 'str' and 'int'\\n\", exit_code=1,\
      \ exception=TypeError(\"unsupported operand type(s) for -: 'str' and 'int'\"\
      )).exit_code\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Typer\\functional_test.py:252:\
      \ AssertionError\n---------------------------- Captured stdout call -----------------------------\n\
      Added: Task 1\nAdded: Task 2\n________________________ test_prompt_option_happy_path\
      \ ________________________\n\n>   ???\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   ???\nE   TypeError: Option()\
      \ got an unexpected keyword argument 'prompt'\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path\
      \ ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch\
      \ object at 0x000002E44DCF5280>\n\n>   ???\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   ???\nE   TypeError: Option()\
      \ got an unexpected keyword argument 'envvar'\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output\
      \ ______________\n\n>   ???\nE   AssertionError: assert 'running' in ''\nE \
      \   +  where '' = Result(stdout='', stderr='', exit_code=0, exception=None).stdout\n\
      \nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Typer\\functional_test.py:301:\
      \ AssertionError\n---------------------------- Captured stdout call -----------------------------\n\
      running\n____________________ test_typed_arguments_and_float_option ____________________\n\
      \n>   ???\nE   assert 1 == 0\nE    +  where 1 = Result(stdout='', stderr=\"\
      Error: can't multiply sequence by non-int of type 'str'\\n\", exit_code=1, exception=TypeError(\"\
      can't multiply sequence by non-int of type 'str'\")).exit_code\n\nD:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Typer\\functional_test.py:313: AssertionError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command\
      \ - AssertionE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited\
      \ - As...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\n\
      FAILED tests/Typer/functional_test.py::test_todo_list_empty_shows_no_tasks -\
      \ ...\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - AssertionErro...\n\
      FAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates -\
      \ a...\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path\
      \ - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path\
      \ - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\n\
      FAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n\
      10 failed, 2 passed in 0.38s\n"
    elapsed_time_s: 1.645318
    avg_memory_mb: 32.01
    avg_cpu_percent: 98.0
    passed: 2
    failed: 10
    skipped: 0
    total: 12
    score_inputs_passed: 2
    score_inputs_failed: 10
    score_inputs_total: 12
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Typer/performance_test.py _______________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Typer\\performance_test.py:18: in <module>\n    ???\nE   RuntimeError: Target\
      \ repository does not exist: D:\\桌面\\RAL-Bench\\generation\\Typer\n===========================\
      \ short test summary info ===========================\nERROR tests/Typer/performance_test.py\
      \ - RuntimeError: Target repository does ...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.48s\n"
    elapsed_time_s: 1.679431
    avg_memory_mb: 36.0
    avg_cpu_percent: 99.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.64517
    score_inputs_actual_time_s: 1.679431
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ________________ ERROR collecting tests/Typer/resource_test.py ________________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Typer\\resource_test.py:17: in <module>\n    ???\nE   RuntimeError: Target repository\
      \ does not exist: D:\\桌面\\RAL-Bench\\generation\\Typer\n===========================\
      \ short test summary info ===========================\nERROR tests/Typer/resource_test.py\
      \ - RuntimeError: Target repository does not...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.46s\n"
    elapsed_time_s: 1.636658
    avg_memory_mb: 35.86
    avg_cpu_percent: 100.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 39.07
    score_inputs_baseline_cpu_pct: 99.2
    score_inputs_actual_mem_mb: 35.86
    score_inputs_actual_cpu_pct: 100.0
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.13s

      '
    elapsed_time_s: 1.325079
    avg_memory_mb: 31.78
    avg_cpu_percent: 98.7
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=5.0 total_loc=370.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.237185
    avg_memory_mb: 32.0
    avg_cpu_percent: 101.4
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 5.0
      total_loc: 370.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=14.6778 files_scanned=4.0 total_loc=370.0 max_cc=44.0

      .

      1 passed in 0.15s

      '
    elapsed_time_s: 1.28433
    avg_memory_mb: 32.24
    avg_cpu_percent: 101.3
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 14.6778
      files_scanned: 4.0
      total_loc: 370.0
      max_cc: 44.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.9413
    score_inputs_generated_mi_min: 14.6778
    score_inputs_ratio_g_over_b: 15.59311590353766
baseline_metrics:
  performance:
    performance_suite_time_s: 1.64517
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 2.053706
    resource_tests_total: 2
    avg_memory_mb: 39.07
    avg_cpu_percent: 99.2
  functional:
    functional_suite_time_s: 2.016633
    functional_tests_total: 12
  robustness:
    robustness_suite_time_s: 2.19185
    robustness_tests_total: 4
  security:
    security_suite_time_s: 2.161153
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 16.0
      total_loc: 4106.0
  maintainability:
    maintainability_suite_time_s: 2.28696
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.9413
      files_scanned: 16.0
      total_loc: 4106.0
      max_cc: 30.0
pytest_logs_dir: D:\桌面\RAL-Bench\results\Typer\pytest_logs
