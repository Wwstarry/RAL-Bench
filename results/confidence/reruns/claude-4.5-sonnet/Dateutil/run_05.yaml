project_name: Dateutil
task_file: D:\桌面\RAL-Bench\tasks\Dateutil\dateutil.yaml
generated_repo: D:\桌面\RAL-Bench\generation\claude-4.5-sonnet\Dateutil
timestamp: '2026-01-21 22:25:46'
functional_score: 0.0
non_functional_score: 0.3733
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 0.8333
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    error: 'Test file not found: D:\桌面\RAL-Bench\tests\Dateutil\functional_test.py'']'
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    elapsed_time_s: 0.0
    avg_memory_mb: 0.0
    avg_cpu_percent: 0.0
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _____________ ERROR collecting tests/Dateutil/performance_test.py _____________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Dateutil\\performance_test.py:19: in <module>\n    ???\nE   RuntimeError: Target\
      \ repository does not exist: D:\\桌面\\RAL-Bench\\generation\\Dateutil\n===========================\
      \ short test summary info ===========================\nERROR tests/Dateutil/performance_test.py\
      \ - RuntimeError: Target repository do...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.57s\n"
    elapsed_time_s: 1.812253
    avg_memory_mb: 35.54
    avg_cpu_percent: 95.4
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.285375
    score_inputs_actual_time_s: 1.812253
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Dateutil/resource_test.py _______________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Dateutil\\resource_test.py:18: in <module>\n    ???\nE   RuntimeError: Target\
      \ repository does not exist: D:\\桌面\\RAL-Bench\\generation\\Dateutil\n===========================\
      \ short test summary info ===========================\nERROR tests/Dateutil/resource_test.py\
      \ - RuntimeError: Target repository does ...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.49s\n"
    elapsed_time_s: 1.72726
    avg_memory_mb: 35.57
    avg_cpu_percent: 100.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 31.66
    score_inputs_baseline_cpu_pct: 100.0
    score_inputs_actual_mem_mb: 35.57
    score_inputs_actual_cpu_pct: 100.0
  robustness:
    returncode: 1
    stdout: "F.....                                                              \
      \     [100%]\n================================== FAILURES ===================================\n\
      ________________ test_dateutil_importable_and_parser_available ________________\n\
      \n    @pytest.mark.timeout(10)\n    def test_dateutil_importable_and_parser_available():\n\
      \        \"\"\"\n        Robustness 1: module should be importable and expose\
      \ parser.parse.\n        \"\"\"\n        dateutil = _import_dateutil()\n>  \
      \     assert hasattr(dateutil, \"parser\"), \"dateutil.parser must exist\"\n\
      E       AssertionError: dateutil.parser must exist\nE       assert False\nE\
      \        +  where False = hasattr(<module 'dateutil' from 'D:\\\\桌面\\\\RAL-Bench\\\
      \\generation\\\\claude-4.5-sonnet\\\\Dateutil\\\\dateutil\\\\__init__.py'>,\
      \ 'parser')\n\ntests\\Dateutil\\robustness_test.py:98: AssertionError\n==============================\
      \ warnings summary ===============================\ntests\\Dateutil\\robustness_test.py:92\n\
      \  D:\\桌面\\RAL-Bench\\tests\\Dateutil\\robustness_test.py:92: PytestUnknownMarkWarning:\
      \ Unknown pytest.mark.timeout - is this a typo?  You can register custom marks\
      \ to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.timeout(10)\n\ntests\\Dateutil\\robustness_test.py:103\n \
      \ D:\\桌面\\RAL-Bench\\tests\\Dateutil\\robustness_test.py:103: PytestUnknownMarkWarning:\
      \ Unknown pytest.mark.timeout - is this a typo?  You can register custom marks\
      \ to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.timeout(10)\n\ntests\\Dateutil\\robustness_test.py:123\n \
      \ D:\\桌面\\RAL-Bench\\tests\\Dateutil\\robustness_test.py:123: PytestUnknownMarkWarning:\
      \ Unknown pytest.mark.timeout - is this a typo?  You can register custom marks\
      \ to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.timeout(10)\n\ntests\\Dateutil\\robustness_test.py:138\n \
      \ D:\\桌面\\RAL-Bench\\tests\\Dateutil\\robustness_test.py:138: PytestUnknownMarkWarning:\
      \ Unknown pytest.mark.timeout - is this a typo?  You can register custom marks\
      \ to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.timeout(10)\n\ntests\\Dateutil\\robustness_test.py:152\n \
      \ D:\\桌面\\RAL-Bench\\tests\\Dateutil\\robustness_test.py:152: PytestUnknownMarkWarning:\
      \ Unknown pytest.mark.timeout - is this a typo?  You can register custom marks\
      \ to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.timeout(10)\n\ntests\\Dateutil\\robustness_test.py:173\n \
      \ D:\\桌面\\RAL-Bench\\tests\\Dateutil\\robustness_test.py:173: PytestUnknownMarkWarning:\
      \ Unknown pytest.mark.timeout - is this a typo?  You can register custom marks\
      \ to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html\n\
      \    @pytest.mark.timeout(10)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n\
      =========================== short test summary info ===========================\n\
      FAILED tests/Dateutil/robustness_test.py::test_dateutil_importable_and_parser_available\n\
      1 failed, 5 passed, 6 warnings in 0.46s\n"
    elapsed_time_s: 1.673521
    avg_memory_mb: 31.4
    avg_cpu_percent: 96.0
    passed: 5
    failed: 1
    skipped: 0
    total: 6
    score_inputs_passed: 5
    score_inputs_failed: 1
    score_inputs_total: 6
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=5.0 total_loc=646.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.28887
    avg_memory_mb: 31.84
    avg_cpu_percent: 96.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 5.0
      total_loc: 646.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=21.2128 files_scanned=5.0 total_loc=646.0 max_cc=20.0

      .

      1 passed in 0.17s

      '
    elapsed_time_s: 1.343095
    avg_memory_mb: 31.78
    avg_cpu_percent: 101.3
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 21.2128
      files_scanned: 5.0
      total_loc: 646.0
      max_cc: 20.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 21.2128
baseline_metrics:
  performance:
    performance_suite_time_s: 1.285375
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.234135
    resource_tests_total: 2
    avg_memory_mb: 31.66
    avg_cpu_percent: 100.0
  functional:
    functional_suite_time_s: 1.125135
    functional_tests_total: 1
  robustness:
    robustness_suite_time_s: 1.313908
    robustness_tests_total: 6
  security:
    security_suite_time_s: 1.372555
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 22.0
      total_loc: 5945.0
  maintainability:
    maintainability_suite_time_s: 3.147629
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 37.0
      total_loc: 14362.0
      max_cc: 96.0
pytest_logs_dir: D:\桌面\RAL-Bench\results\Dateutil\pytest_logs
