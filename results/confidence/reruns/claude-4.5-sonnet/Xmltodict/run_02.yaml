project_name: Xmltodict
task_file: D:\桌面\RAL-Bench\tasks\Xmltodict\xmltodict.yaml
generated_repo: D:\桌面\RAL-Bench\generation\claude-4.5-sonnet\Xmltodict
timestamp: '2026-01-21 23:53:48'
functional_score: 0.0
non_functional_score: 0.4
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _____________ ERROR collecting tests/Xmltodict/functional_test.py _____________\n\
      ImportError while importing test module 'D:\\桌面\\RAL-Bench\\tests\\Xmltodict\\\
      functional_test.py'.\nHint: make sure your test modules/packages have valid\
      \ Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Xmltodict\\\
      functional_test.py:49: in <module>\n    ???\nE   ModuleNotFoundError: No module\
      \ named 'xmltodict'\n=========================== short test summary info ===========================\n\
      ERROR tests/Xmltodict/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1\
      \ error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.45s\n"
    elapsed_time_s: 1.647221
    avg_memory_mb: 35.77
    avg_cpu_percent: 100.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ____________ ERROR collecting tests/Xmltodict/performance_test.py _____________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Xmltodict\\performance_test.py:21: in <module>\n    ???\nE   RuntimeError: Target\
      \ repository does not exist: D:\\桌面\\RAL-Bench\\generation\\Xmltodict\n===========================\
      \ short test summary info ===========================\nERROR tests/Xmltodict/performance_test.py\
      \ - RuntimeError: Target repository d...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1\
      \ error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.52s\n"
    elapsed_time_s: 1.678738
    avg_memory_mb: 35.49
    avg_cpu_percent: 103.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.593666
    score_inputs_actual_time_s: 1.678738
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Xmltodict/resource_test.py ______________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\\
      __init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:],\
      \ package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n\
      <frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\nD:\\桌面\\RealAppCodeBench_generic_eval\\tests\\\
      Xmltodict\\resource_test.py:20: in <module>\n    ???\nE   RuntimeError: Target\
      \ repository does not exist: D:\\桌面\\RAL-Bench\\generation\\Xmltodict\n===========================\
      \ short test summary info ===========================\nERROR tests/Xmltodict/resource_test.py\
      \ - RuntimeError: Target repository does...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n"
    elapsed_time_s: 1.663102
    avg_memory_mb: 35.46
    avg_cpu_percent: 96.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 32.5
    score_inputs_baseline_cpu_pct: 98.9
    score_inputs_actual_mem_mb: 35.46
    score_inputs_actual_cpu_pct: 96.0
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.12s

      '
    elapsed_time_s: 1.31799
    avg_memory_mb: 30.82
    avg_cpu_percent: 100.0
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=0.0 total_loc=0.0

      .

      1 passed in 0.09s

      '
    elapsed_time_s: 1.268832
    avg_memory_mb: 31.2
    avg_cpu_percent: 101.3
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 0.0
      total_loc: 0.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 1
    stdout: 'MAINT_METRICS mi_min=0.0000 files_scanned=0.0 total_loc=0.0 max_cc=0.0

      F

      ================================== FAILURES ===================================

      _____________________ test_maintainability_metrics_smoke ______________________


      >   ???

      E   AssertionError: No python files scanned under: D:\桌面\RAL-Bench\generation\claude-4.5-sonnet\Xmltodict

      E   assert 0.0 >= 1.0


      D:\桌面\RealAppCodeBench_generic_eval\tests\_generic\maintainability_test.py:380:
      AssertionError

      =========================== short test summary info ===========================

      FAILED tests/_generic/maintainability_test.py::test_maintainability_metrics_smoke

      1 failed in 0.39s

      '
    elapsed_time_s: 1.563341
    avg_memory_mb: 31.26
    avg_cpu_percent: 100.0
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 0.0
      total_loc: 0.0
      max_cc: 0.0
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 9.2435
    score_inputs_generated_mi_min: 0.0
    score_inputs_ratio_g_over_b: 0.0
baseline_metrics:
  performance:
    performance_suite_time_s: 1.593666
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.556051
    resource_tests_total: 2
    avg_memory_mb: 32.5
    avg_cpu_percent: 98.9
  functional:
    functional_suite_time_s: 1.63732
    functional_tests_total: 12
  robustness:
    robustness_suite_time_s: 1.692569
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.470756
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 1.0
      total_loc: 542.0
  maintainability:
    maintainability_suite_time_s: 1.751538
    maintainability_tests_total: 1
    metrics:
      mi_min: 9.2435
      files_scanned: 3.0
      total_loc: 1446.0
      max_cc: 44.0
pytest_logs_dir: D:\桌面\RAL-Bench\results\Xmltodict\pytest_logs
