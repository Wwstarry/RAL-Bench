project_name: Dataset
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Dataset\dataset.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation_m1\Dataset
timestamp: '2026-01-14 21:35:54'
functional_score: 0.6364
non_functional_score: 0.6508
non_functional_subscores:
  maintainability: 0.6966
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "F....F..F.F                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________________ test_insert_and_query_basic_rows _______________________\n\
      \n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n\
      \        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\"\
      , \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\"\
      , \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"\
      name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n\
      \    \n        assert \"id\" in _table_columns(table)\n        assert \"name\"\
      \ in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n\
      \        assert len(table) == 3\n    \n        alice = table.find_one(name=\"\
      Alice\")\n        assert alice is not None\n        assert alice[\"country\"\
      ] == \"DE\"\n    \n        older = list(table.find(age={\">=\": 40}))\n>   \
      \    assert {row[\"name\"] for row in older} == {\"Bob\", \"Charlie\"}\nE  \
      \     AssertionError: assert set() == {'Bob', 'Charlie'}\nE         \nE    \
      \     Extra items in the right set:\nE         'Charlie'\nE         'Bob'\n\
      E         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:156:\
      \ AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\
      \n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n\
      \        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"\
      n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n\
      >       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4,\
      \ 5, 6]\nE         \nE         Right contains 3 more items, first extra item:\
      \ 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249:\
      \ AssertionError\n___________________ test_drop_table_removes_from_db_tables\
      \ ____________________\n\n    def test_drop_table_removes_from_db_tables() ->\
      \ None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"\
      ]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\n\
      E       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database\
      \ object at 0x0000019F071DFDF0>)\n\ntests\\Dataset\\functional_test.py:301:\
      \ AssertionError\n_____________________ test_distinct_returns_unique_values\
      \ _____________________\n\n    def test_distinct_returns_unique_values() ->\
      \ None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n\
      \        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"\
      }])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values =\
      \ {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n\
      _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _\n\n.0 = <list_iterator object at 0x0000019F071CB370>\n\n>   values = {r[\"\
      c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\n\
      tests\\Dataset\\functional_test.py:333: TypeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows\
      \ - A...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset\
      \ - as...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\n\
      FAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n\
      4 failed, 7 passed in 4.02s\n"
    elapsed_time_s: 5.521042
    avg_memory_mb: 33.81
    avg_cpu_percent: 96.5
    passed: 7
    failed: 4
    skipped: 0
    total: 11
    score_inputs_passed: 7
    score_inputs_failed: 4
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _____________ ERROR collecting tests/Dataset/performance_test.py ______________\n\
      tests\\Dataset\\performance_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported DATASET_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ DATASET_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Dataset/performance_test.py\
      \ - RuntimeError: Unsupported DATASET_T...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.64s\n"
    elapsed_time_s: 2.186456
    avg_memory_mb: 35.27
    avg_cpu_percent: 97.8
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.781374
    score_inputs_actual_time_s: 2.186456
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _______________ ERROR collecting tests/Dataset/resource_test.py _______________\n\
      tests\\Dataset\\resource_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported DATASET_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ DATASET_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Dataset/resource_test.py - RuntimeError:\
      \ Unsupported DATASET_TARG...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during\
      \ collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.68s\n"
    elapsed_time_s: 2.189645
    avg_memory_mb: 35.91
    avg_cpu_percent: 100.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 55.98
    score_inputs_baseline_cpu_pct: 100.6
    score_inputs_actual_mem_mb: 35.91
    score_inputs_actual_cpu_pct: 100.0
  robustness:
    returncode: 0
    stdout: "......                                                              \
      \     [100%]\n============================== warnings summary ===============================\n\
      tests\\Dataset\\robustness_test.py:92\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dataset\\robustness_test.py:92: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dataset\\robustness_test.py:102\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dataset\\robustness_test.py:102: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dataset\\robustness_test.py:120\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dataset\\robustness_test.py:120: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dataset\\robustness_test.py:135\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dataset\\robustness_test.py:135: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dataset\\robustness_test.py:149\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dataset\\robustness_test.py:149: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \ntests\\Dataset\\robustness_test.py:163\n  D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Dataset\\robustness_test.py:163: PytestUnknownMarkWarning: Unknown pytest.mark.timeout\
      \ - is this a typo?  You can register custom marks to avoid this warning - for\
      \ details, see https://docs.pytest.org/en/stable/how-to/mark.html\n    @pytest.mark.timeout(10)\n\
      \n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n\
      6 passed, 6 warnings in 0.21s\n"
    elapsed_time_s: 1.753191
    avg_memory_mb: 31.95
    avg_cpu_percent: 97.1
    passed: 6
    failed: 0
    skipped: 0
    total: 6
    score_inputs_passed: 6
    score_inputs_failed: 0
    score_inputs_total: 6
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=3.0 total_loc=335.0

      .

      1 passed in 0.17s

      '
    elapsed_time_s: 1.692092
    avg_memory_mb: 31.64
    avg_cpu_percent: 97.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 3.0
      total_loc: 335.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=17.7191 files_scanned=3.0 total_loc=335.0 max_cc=13.0

      .

      1 passed in 0.23s

      '
    elapsed_time_s: 1.706195
    avg_memory_mb: 31.62
    avg_cpu_percent: 99.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 17.7191
      files_scanned: 3.0
      total_loc: 335.0
      max_cc: 13.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 7.7184
    score_inputs_generated_mi_min: 17.7191
    score_inputs_ratio_g_over_b: 2.2956959991708126
baseline_metrics:
  performance:
    performance_suite_time_s: 2.781374
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 2.854474
    resource_tests_total: 2
    avg_memory_mb: 55.98
    avg_cpu_percent: 100.6
  functional:
    functional_suite_time_s: 4.552087
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 2.083828
    robustness_tests_total: 6
  security:
    security_suite_time_s: 1.286846
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 6.0
      total_loc: 1131.0
  maintainability:
    maintainability_suite_time_s: 1.311875
    maintainability_tests_total: 1
    metrics:
      mi_min: 7.7184
      files_scanned: 6.0
      total_loc: 1131.0
      max_cc: 16.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Dataset\pytest_logs
