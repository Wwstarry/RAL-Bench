project_name: Markdown
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Markdown\markdown.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Markdown
timestamp: '2025-12-31 15:04:53'
functional_score: 0.4737
non_functional_score: 0.778
non_functional_subscores:
  maintainability: 0.7866
  security: 1.0
  robustness: 1.0
  performance: 0.7905
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "......F...sssssssss                                                 \
      \     [100%]\n================================== FAILURES ===================================\n\
      _________________ test_html_escaping_in_text_but_not_in_code __________________\n\
      \n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src\
      \ = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n\
      \    \n            ```\n            literal <b> tag in code block\n        \
      \    ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n\
      \        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\n\
      E       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt;\
      \ here.</p>\\n<p>``` literal &lt;b&gt; tag in code block ```</p>'\n\ntests\\\
      Markdown\\functional_test.py:209: AssertionError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\n\
      1 failed, 9 passed, 9 skipped in 0.61s\n"
    elapsed_time_s: 4.721936
    avg_memory_mb: 32.64
    avg_cpu_percent: 42.2
    passed: 9
    failed: 1
    skipped: 9
    total: 19
    score_inputs_passed: 9
    score_inputs_failed: 1
    score_inputs_total: 19
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.14s

      '
    elapsed_time_s: 1.883546
    avg_memory_mb: 31.2
    avg_cpu_percent: 92.9
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.488889
    score_inputs_actual_time_s: 1.883546
  resource:
    returncode: 1
    stdout: ".F                                                                  \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________________ test_batch_conversion_integration ______________________\n\
      \n    def test_batch_conversion_integration() -> None:\n        \"\"\"Integration\
      \ test for converting multiple documents sequentially.\"\"\"\n        docs =\
      \ [\n            \"# Doc 1\\n\\nFirst document.\",\n            \"## Doc 2\\\
      n\\nSecond document with *emphasis*.\",\n            textwrap.dedent(\n    \
      \            \"\"\"\n                # Doc 3\n    \n                - item A\n\
      \                - item B\n    \n                ```python\n               \
      \ print(\"hello\")\n                ```\n                \"\"\"\n          \
      \  ),\n        ]\n    \n        html_outputs = [markdown.markdown(src) for src\
      \ in docs]\n        norms = [normalize_html(html) for html in html_outputs]\n\
      \    \n        assert len(norms) == 3\n        assert \"Doc 1\" in norms[0]\n\
      \        assert \"<h1>\" in norms[0] or \"<h2>\" in norms[0]\n    \n       \
      \ assert \"Doc 2\" in norms[1]\n        assert \"<em>\" in norms[1] or \"<i>\"\
      \ in norms[1]\n    \n        assert \"Doc 3\" in norms[2]\n        assert \"\
      <ul>\" in norms[2]\n>       assert \"<code>\" in norms[2]\nE       AssertionError:\
      \ assert '<code>' in '<h1>Doc 3</h1>\\n<ul>\\n<li>item A</li>\\n<li>item B</li>\\\
      n</ul>\\n<p>```python print(&quot;hello&quot;) ```</p>'\n\ntests\\Markdown\\\
      resource_test.py:131: AssertionError\n=========================== short test\
      \ summary info ===========================\nFAILED tests/Markdown/resource_test.py::test_batch_conversion_integration\
      \ - A...\n1 failed, 1 passed in 0.40s\n"
    elapsed_time_s: 2.217076
    avg_memory_mb: 31.74
    avg_cpu_percent: 87.5
    passed: 1
    failed: 1
    skipped: 0
    total: 2
    score_inputs_passed: 1
    score_inputs_failed: 1
    score_inputs_total: 2
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 31.96
    score_inputs_baseline_cpu_pct: 100.0
    score_inputs_actual_mem_mb: 31.74
    score_inputs_actual_cpu_pct: 87.5
  robustness:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.14s

      '
    elapsed_time_s: 1.847489
    avg_memory_mb: 30.83
    avg_cpu_percent: 95.5
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=3.0 total_loc=248.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.612534
    avg_memory_mb: 31.55
    avg_cpu_percent: 96.9
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 3.0
      total_loc: 248.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=19.8113 files_scanned=3.0 total_loc=248.0 max_cc=14.0

      .

      1 passed in 0.20s

      '
    elapsed_time_s: 1.815443
    avg_memory_mb: 31.45
    avg_cpu_percent: 104.9
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 19.8113
      files_scanned: 3.0
      total_loc: 248.0
      max_cc: 14.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 5.374
    score_inputs_generated_mi_min: 19.8113
    score_inputs_ratio_g_over_b: 3.6865091179754375
baseline_metrics:
  performance:
    performance_suite_time_s: 1.488889
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.323826
    resource_tests_total: 2
    avg_memory_mb: 31.96
    avg_cpu_percent: 100.0
  functional:
    functional_suite_time_s: 1.640586
    functional_tests_total: 19
  robustness:
    robustness_suite_time_s: 1.41468
    robustness_tests_total: 1
  security:
    security_suite_time_s: 1.482427
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 33.0
      total_loc: 5698.0
  maintainability:
    maintainability_suite_time_s: 1.975499
    maintainability_tests_total: 1
    metrics:
      mi_min: 5.374
      files_scanned: 33.0
      total_loc: 5698.0
      max_cc: 33.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Markdown\pytest_logs
