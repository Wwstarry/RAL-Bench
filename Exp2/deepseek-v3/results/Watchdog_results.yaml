project_name: Watchdog
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Watchdog\watchdog.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Watchdog
timestamp: '2025-12-31 15:52:24'
functional_score: 0.0
non_functional_score: 0.6922
non_functional_subscores:
  maintainability: 0.8117
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _____________ ERROR collecting tests/Watchdog/functional_test.py ______________\n\
      ImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\\
      tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages\
      \ have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\\
      Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return\
      \ _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55:\
      \ in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\n\
      E   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events'\
      \ (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n\
      =========================== short test summary info ===========================\n\
      ERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1\
      \ error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n"
    elapsed_time_s: 1.949484
    avg_memory_mb: 35.81
    avg_cpu_percent: 97.4
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      _______________________ test_watchdog_performance_smoke _______________________\n\
      \ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-306/test_watchdog_performance_smok0')\n\
      \n    def test_watchdog_performance_smoke(tmp_path: Path) -> None:\n       \
      \ \"\"\"Smoke test to ensure the performance benchmark runs successfully.\"\"\
      \"\n>       metrics = run_watchdog_benchmark(tmp_path, n=40)\n\ntests\\Watchdog\\\
      performance_test.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntmp = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-306/test_watchdog_performance_smok0')\n\
      n = 40\n\n    def run_watchdog_benchmark(tmp: Path, n: int = 80) -> Dict[str,\
      \ float]:\n        \"\"\"Create n files and measure how many created events\
      \ are observed.\"\"\"\n        handler = _Counter()\n        obs = Observer()\n\
      \        obs.schedule(handler, str(tmp), recursive=False)\n    \n        start\
      \ = time.perf_counter()\n        obs.start()\n    \n        for i in range(n):\n\
      \            (tmp / f\"f{i}.txt\").write_text(\"x\")\n        time.sleep(0.3)\n\
      \    \n        obs.stop()\n>       obs.join(timeout=1)\nE       TypeError: join()\
      \ got an unexpected keyword argument 'timeout'\n\ntests\\Watchdog\\performance_test.py:54:\
      \ TypeError\n=========================== short test summary info ===========================\n\
      FAILED tests/Watchdog/performance_test.py::test_watchdog_performance_smoke -\
      \ ...\n1 failed in 1.41s\n"
    elapsed_time_s: 2.689159
    avg_memory_mb: 31.69
    avg_cpu_percent: 62.0
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.112658
    score_inputs_actual_time_s: 2.689159
  resource:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      _______________________ test_recursive_directory_events _______________________\n\
      \ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-307/test_recursive_directory_event0')\n\
      \n    def test_recursive_directory_events(tmp_path: Path) -> None:\n       \
      \ \"\"\"Recursive observer should record events in subdirectories.\"\"\"\n \
      \       handler = _Recorder()\n        obs = Observer()\n        obs.schedule(handler,\
      \ str(tmp_path), recursive=True)\n        obs.start()\n    \n        sub = tmp_path\
      \ / \"sub\"\n        sub.mkdir()\n        (sub / \"inner.txt\").write_text(\"\
      hello\")\n        time.sleep(0.3)\n    \n        obs.stop()\n>       obs.join(timeout=1)\n\
      E       TypeError: join() got an unexpected keyword argument 'timeout'\n\ntests\\\
      Watchdog\\resource_test.py:52: TypeError\n=========================== short\
      \ test summary info ===========================\nFAILED tests/Watchdog/resource_test.py::test_recursive_directory_events\
      \ - Typ...\n1 failed in 1.41s\n"
    elapsed_time_s: 2.903767
    avg_memory_mb: 31.8
    avg_cpu_percent: 63.3
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 31.56
    score_inputs_baseline_cpu_pct: 81.7
    score_inputs_actual_mem_mb: 31.8
    score_inputs_actual_cpu_pct: 63.3
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 3.20s

      '
    elapsed_time_s: 4.633764
    avg_memory_mb: 31.16
    avg_cpu_percent: 33.8
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=4.0 total_loc=180.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.472714
    avg_memory_mb: 31.11
    avg_cpu_percent: 98.9
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 4.0
      total_loc: 180.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 1.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=29.9302 files_scanned=4.0 total_loc=180.0 max_cc=6.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.471154
    avg_memory_mb: 31.45
    avg_cpu_percent: 97.7
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 29.9302
      files_scanned: 4.0
      total_loc: 180.0
      max_cc: 6.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 6.9411
    score_inputs_generated_mi_min: 29.9302
    score_inputs_ratio_g_over_b: 4.3120254714670585
baseline_metrics:
  performance:
    performance_suite_time_s: 2.112658
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 2.079845
    resource_tests_total: 1
    avg_memory_mb: 31.56
    avg_cpu_percent: 81.7
  functional:
    functional_suite_time_s: 2.321923
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.853684
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.92476
    security_tests_total: 1
    metrics:
      high_risk_count: 1.0
      files_scanned: 32.0
      total_loc: 5334.0
  maintainability:
    maintainability_suite_time_s: 2.571561
    maintainability_tests_total: 1
    metrics:
      mi_min: 6.9411
      files_scanned: 54.0
      total_loc: 8226.0
      max_cc: 30.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Watchdog\pytest_logs
