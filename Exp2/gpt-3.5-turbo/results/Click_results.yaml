project_name: Click
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Click\click.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Click
timestamp: '2025-12-31 20:57:40'
functional_score: 0.2727
non_functional_score: 0.24
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 0.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "FFFFF...FFF                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      ________________ test_simple_command_with_argument_and_option _________________\n\
      \n    def test_simple_command_with_argument_and_option():\n        @click.command()\n\
      \        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"\
      name\")\n        def greet(count: int, name: str) -> None:\n            for\
      \ _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n\
      \        runner = CliRunner()\n        result = runner.invoke(greet, [\"--count\"\
      , \"3\", \"World\"])\n    \n>       assert result.exit_code == 0\nE       assert\
      \ 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x000001ECCEC94E80>.exit_code\n\
      \ntests\\Click\\functional_test.py:143: AssertionError\n________________________\
      \ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n\
      \        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n\
      \        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\"\
      )\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli,\
      \ [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 2 == 0\nE\
      \        +  where 2 = <click.testing.Result object at 0x000001ECCEC72310>.exit_code\n\
      \ntests\\Click\\functional_test.py:157: AssertionError\n_________________________\
      \ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n\
      \        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:167:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp\
      \ = _make_group(f, name=name, cls=cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_group_with_subcommands.<locals>.cli\
      \ at 0x000001ECCECB2B80>\nname = None, cls = None, attrs = {}, grp_name = 'cli'\n\
      grp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group object at 0x000001ECCECAC1C0>\n\
      \n    def _make_group(f, name=None, cls=None, **attrs):\n        grp_name =\
      \ name or f.__name__\n        grp_cls = cls or Group\n        grp = grp_cls(name=grp_name,\
      \ **attrs)\n        # Add commands from decorated functions attached to group\n\
      >       f(grp)\nE       TypeError: cli() takes 0 positional arguments but 1\
      \ was given\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n___________________\
      \ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n\
      \        @click.group(help=\"Top level group\")\n>       def cli() -> None:\n\
      \ntests\\Click\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\\
      decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls,\
      \ **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _\n\nf = <function test_help_output_for_command_and_group.<locals>.cli\
      \ at 0x000001ECCECB2D30>\nname = None, cls = None, attrs = {'help': 'Top level\
      \ group'}, grp_name = 'cli'\ngrp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group\
      \ object at 0x000001ECCEC727F0>\n\n    def _make_group(f, name=None, cls=None,\
      \ **attrs):\n        grp_name = name or f.__name__\n        grp_cls = cls or\
      \ Group\n        grp = grp_cls(name=grp_name, **attrs)\n        # Add commands\
      \ from decorated functions attached to group\n>       f(grp)\nE       TypeError:\
      \ cli() takes 0 positional arguments but 1 was given\n\ngeneration\\Click\\\
      click\\decorators.py:54: TypeError\n____________________ test_get_current_context_propagation\
      \ _____________________\n\n    def test_get_current_context_propagation():\n\
      \        @click.group()\n        @click.option(\"--config\", type=str, default=\"\
      default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp\
      \ = _make_group(f, name=name, cls=cls, **attrs)\ngeneration\\Click\\click\\\
      decorators.py:54: in _make_group\n    f(grp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nconfig = <click.core.Group\
      \ object at 0x000001ECCED08880>\n\n    @click.group()\n    @click.option(\"\
      --config\", type=str, default=\"default.cfg\")\n    def cli(config: str) ->\
      \ None:\n>       ctx = click.get_current_context()\nE       AttributeError:\
      \ module 'click' has no attribute 'get_current_context'\n\ntests\\Click\\functional_test.py:223:\
      \ AttributeError\n_______________ test_default_map_provides_default_option_value\
      \ ________________\n\n    def test_default_map_provides_default_option_value():\n\
      \        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:291:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp\
      \ = _make_group(f, name=name, cls=cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_default_map_provides_default_option_value.<locals>.cli\
      \ at 0x000001ECCEC29310>\nname = None, cls = None, attrs = {}, grp_name = 'cli'\n\
      grp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group object at 0x000001ECCED0D1F0>\n\
      \n    def _make_group(f, name=None, cls=None, **attrs):\n        grp_name =\
      \ name or f.__name__\n        grp_cls = cls or Group\n        grp = grp_cls(name=grp_name,\
      \ **attrs)\n        # Add commands from decorated functions attached to group\n\
      >       f(grp)\nE       TypeError: cli() takes 0 positional arguments but 1\
      \ was given\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n_______________\
      \ test_parameter_type_validation_error_exit_code ________________\n\n    def\
      \ test_parameter_type_validation_error_exit_code():\n        @click.command()\n\
      \        @click.option(\"--count\", type=int, required=True)\n        def cli(count:\
      \ int) -> None:\n            click.echo(f\"COUNT={count}\")\n    \n        runner\
      \ = CliRunner()\n        r = runner.invoke(cli, [\"--count\", \"not-an-int\"\
      ])\n>       assert r.exit_code != 0\nE       assert 0 != 0\nE        +  where\
      \ 0 = <click.testing.Result object at 0x000001ECCED05910>.exit_code\n\ntests\\\
      Click\\functional_test.py:313: AssertionError\n_____________ test_path_type_creates_writable_path_in_isolated_fs\
      \ _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n\
      \        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False,\
      \ writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\
      \ntests\\Click\\functional_test.py:319: AttributeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\n\
      FAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\n\
      FAILED tests/Click/functional_test.py::test_group_with_subcommands - TypeErro...\n\
      FAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\n\
      FAILED tests/Click/functional_test.py::test_get_current_context_propagation\n\
      FAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\n\
      FAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\n\
      FAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n\
      8 failed, 3 passed in 3.18s\n"
    elapsed_time_s: 4.32341
    avg_memory_mb: 32.49
    avg_cpu_percent: 97.8
    passed: 3
    failed: 8
    skipped: 0
    total: 11
    score_inputs_passed: 3
    score_inputs_failed: 8
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________________ test_many_invocations_performance ______________________\n\
      \n    def test_many_invocations_performance():\n        @click.command()\n \
      \       @click.option(\"--count\", type=int, default=1)\n        @click.argument(\"\
      name\")\n        def greet(count: int, name: str) -> None:\n            for\
      \ _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n\
      \        runner = CliRunner()\n    \n        num_runs = 1000\n        start\
      \ = time.perf_counter()\n        for i in range(num_runs):\n            result\
      \ = runner.invoke(greet, [\"--count\", \"1\", f\"User-{i}\"])\n>           assert\
      \ result.exit_code == 0\nE           assert 1 == 0\nE            +  where 1\
      \ = <click.testing.Result object at 0x0000025BFB9494F0>.exit_code\n\ntests\\\
      Click\\performance_test.py:39: AssertionError\n=========================== short\
      \ test summary info ===========================\nFAILED tests/Click/performance_test.py::test_many_invocations_performance\
      \ - a...\n1 failed in 0.31s\n"
    elapsed_time_s: 1.518374
    avg_memory_mb: 31.79
    avg_cpu_percent: 97.8
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.523511
    score_inputs_actual_time_s: 1.518374
  resource:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      ___________________ test_repeated_invocations_memory_usage ____________________\n\
      \n    def test_repeated_invocations_memory_usage():\n        @click.command()\n\
      \        @click.option(\"--times\", type=int, default=1)\n        @click.argument(\"\
      name\")\n        def greet(times: int, name: str) -> None:\n            for\
      \ _ in range(times):\n                click.echo(f\"Hello {name}!\")\n    \n\
      \        runner = CliRunner()\n    \n        before = _memory_mb()\n    \n \
      \       for i in range(300):\n            result = runner.invoke(greet, [\"\
      --times\", \"3\", f\"User-{i}\"])\n>           assert result.exit_code == 0\n\
      E           assert 1 == 0\nE            +  where 1 = <click.testing.Result object\
      \ at 0x000001CFB2DBE970>.exit_code\n\ntests\\Click\\resource_test.py:45: AssertionError\n\
      =========================== short test summary info ===========================\n\
      FAILED tests/Click/resource_test.py::test_repeated_invocations_memory_usage\n\
      1 failed in 0.33s\n"
    elapsed_time_s: 1.49933
    avg_memory_mb: 33.34
    avg_cpu_percent: 102.3
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 34.28
    score_inputs_baseline_cpu_pct: 97.6
    score_inputs_actual_mem_mb: 33.34
    score_inputs_actual_cpu_pct: 102.3
  robustness:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________ test_click_robustness_invalid_inputs_do_not_crash ______________\n\
      \n    def test_click_robustness_invalid_inputs_do_not_crash():\n        \"\"\
      \"\n        Robustness tests should be version-tolerant:\n          - Invalid\
      \ inputs may raise exceptions (acceptable).\n          - Some invalid inputs\
      \ may be coerced/ignored (also acceptable).\n        Requirement: no hard crashes;\
      \ library remains importable and callable.\n        \"\"\"\n        click =\
      \ _import_click()\n    \n        results: list[Tuple[bool, str]] = []\n    \n\
      \        # 1) Construct basic objects\n        cmd = click.Command(name=\"test\"\
      )\n        group = click.Group(name=\"test_group\")\n    \n        # 2) Callback\
      \ non-callable: assignment may or may not raise; both OK\n        def _set_callback():\n\
      \            cmd.callback = \"not a function\"  # type: ignore[assignment]\n\
      \    \n        results.append(_run_case(\"Command callback set to non-callable\"\
      , _set_callback))\n    \n        # 3) Option invalid type: signature/validation\
      \ varies across versions\n>       results.append(_run_case(\"Option with invalid\
      \ type\", click.Option, [\"--test\"], type=\"not a type\"))  # type: ignore[arg-type]\n\
      E       AttributeError: module 'click' has no attribute 'Option'\n\ntests\\\
      Click\\robustness_test.py:107: AttributeError\n=========================== short\
      \ test summary info ===========================\nFAILED tests/Click/robustness_test.py::test_click_robustness_invalid_inputs_do_not_crash\n\
      1 failed in 0.30s\n"
    elapsed_time_s: 1.452633
    avg_memory_mb: 31.82
    avg_cpu_percent: 102.4
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=4.0 total_loc=700.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.218678
    avg_memory_mb: 32.26
    avg_cpu_percent: 101.4
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 4.0
      total_loc: 700.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 2.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=8.9283 files_scanned=4.0 total_loc=700.0 max_cc=25.0

      .

      1 passed in 0.16s

      '
    elapsed_time_s: 1.270523
    avg_memory_mb: 32.53
    avg_cpu_percent: 97.3
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 8.9283
      files_scanned: 4.0
      total_loc: 700.0
      max_cc: 25.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 8.9283
baseline_metrics:
  performance:
    performance_suite_time_s: 1.523511
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.392334
    resource_tests_total: 1
    avg_memory_mb: 34.28
    avg_cpu_percent: 97.6
  functional:
    functional_suite_time_s: 3.08833
    functional_tests_total: 11
  security:
    security_suite_time_s: 1.36602
    security_tests_total: 1
    metrics:
      high_risk_count: 2.0
      files_scanned: 16.0
      total_loc: 7731.0
  maintainability:
    maintainability_suite_time_s: 1.770477
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 16.0
      total_loc: 7731.0
      max_cc: 43.0
  robustness:
    robustness_suite_time_s: 1.208987
    robustness_tests_total: 1
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Click\pytest_logs
