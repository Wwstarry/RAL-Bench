project_name: Tablib
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Tablib\tablib.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Tablib
timestamp: '2025-12-31 14:02:35'
functional_score: 0.5455
non_functional_score: 0.4
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: ".F..F.F.F.F                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      __________________ test_dataset_export_import_tsv_roundtrip ___________________\n\
      \n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"\
      TSV export/import should preserve shape and values (type-coercion tolerant).\"\
      \"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"\
      tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n\
      >       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000277FA1EDF10>, fmt\
      \ = 'tsv'\n\n    def export(self, fmt):\n        \"\"\"Export dataset to a format.\n\
      \    \n        Args:\n            fmt: Format string ('csv', 'json', etc.)\n\
      \    \n        Returns:\n            String representation in the requested\
      \ format\n        \"\"\"\n        fmt = fmt.lower()\n    \n        if fmt ==\
      \ 'csv':\n            from tablib.formats import _csv\n            return _csv.export_set(self)\n\
      \        elif fmt == 'json':\n            from tablib.formats import _json\n\
      \            return _json.export_set(self)\n        else:\n>           raise\
      \ ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported\
      \ format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:157: ValueError\n__________________\
      \ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics()\
      \ -> None:\n        \"\"\"Dataset should support inserting and popping rows\
      \ (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"\
      name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n\
      \    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"\
      b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\n\
      tests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence\
      \ __________________\n\n    def test_dataset_title_and_headers_persistence()\
      \ -> None:\n        \"\"\"Dataset title and headers should be assignable and\
      \ remain consistent.\"\"\"\n        data = tablib.Dataset(headers=(\"k\", \"\
      v\"))\n        data.title = \"Config\"\n        data.append((\"a\", 1))\n  \
      \      data.append((\"b\", 2))\n    \n        assert getattr(data, \"title\"\
      ) == \"Config\"\n        assert tuple(data.headers) == (\"k\", \"v\")\n    \
      \    assert data.height == 2\n>       assert data[1][0] == \"b\"\n\ntests\\\
      Tablib\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object\
      \ at 0x00000277FA268CD0>, key = 1\n\n    def __getitem__(self, key):\n     \
      \   \"\"\"Get rows by slice or column by name.\n    \n        Args:\n      \
      \      key: Either a slice for rows or a string for column access\n    \n  \
      \      Returns:\n            For slice: list of row tuples\n            For\
      \ string: list of column values\n        \"\"\"\n        if isinstance(key,\
      \ slice):\n            return self._data[key]\n        elif isinstance(key,\
      \ str):\n            # Column access by header name\n            if self._headers\
      \ is None:\n                raise KeyError(f\"No headers defined\")\n      \
      \      if key not in self._headers:\n                raise KeyError(f\"Column\
      \ '{key}' not found\")\n    \n            col_index = self._headers.index(key)\n\
      \            return [row[col_index] if col_index < len(row) else None for row\
      \ in self._data]\n        else:\n>           raise TypeError(f\"Invalid key\
      \ type: {type(key)}\")\nE           TypeError: Invalid key type: <class 'int'>\n\
      \ngeneration\\Tablib\\tablib\\core.py:119: TypeError\n______________ test_dataset_export_html_contains_table_structure\
      \ ______________\n\n    def test_dataset_export_html_contains_table_structure()\
      \ -> None:\n        \"\"\"HTML export (if available) should include a table-like\
      \ structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n\
      \            pytest.skip(\"html format not available in this tablib build\"\
      )\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"\
      html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset\
      \ object at 0x00000277FA2973D0>, fmt = 'html'\n\n    def export(self, fmt):\n\
      \        \"\"\"Export dataset to a format.\n    \n        Args:\n          \
      \  fmt: Format string ('csv', 'json', etc.)\n    \n        Returns:\n      \
      \      String representation in the requested format\n        \"\"\"\n     \
      \   fmt = fmt.lower()\n    \n        if fmt == 'csv':\n            from tablib.formats\
      \ import _csv\n            return _csv.export_set(self)\n        elif fmt ==\
      \ 'json':\n            from tablib.formats import _json\n            return\
      \ _json.export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported\
      \ format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\\
      Tablib\\tablib\\core.py:157: ValueError\n_________________ test_databook_add_sheet_and_iteration_order\
      \ _________________\n\n    def test_databook_add_sheet_and_iteration_order()\
      \ -> None:\n        \"\"\"Databook should allow adding sheets and preserve the\
      \ order in iteration.\"\"\"\n        s1 = tablib.Dataset((1, \"x\"), headers=(\"\
      id\", \"val\"))\n        s1.title = \"S1\"\n        s2 = tablib.Dataset((2,\
      \ \"y\"), headers=(\"id\", \"val\"))\n        s2.title = \"S2\"\n    \n    \
      \    book = tablib.Databook([s1])\n    \n        if hasattr(book, \"add_sheet\"\
      ):\n            book.add_sheet(s2)  # type: ignore[attr-defined]\n        else:\n\
      \            # Fallback: reconstruct via the public constructor (still normal\
      \ usage).\n            book = tablib.Databook([s1, s2])\n    \n        assert\
      \ book.size == 2\n    \n        sheets = _iter_databook_sheets(book)\n     \
      \   assert len(sheets) == 2\n        assert sheets[0].title == \"S1\"\n    \
      \    assert sheets[1].title == \"S2\"\n>       assert sheets[0][0] == (1, \"\
      x\")\n\ntests\\Tablib\\functional_test.py:365: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset\
      \ object at 0x00000277FA211D90>, key = 0\n\n    def __getitem__(self, key):\n\
      \        \"\"\"Get rows by slice or column by name.\n    \n        Args:\n \
      \           key: Either a slice for rows or a string for column access\n   \
      \ \n        Returns:\n            For slice: list of row tuples\n          \
      \  For string: list of column values\n        \"\"\"\n        if isinstance(key,\
      \ slice):\n            return self._data[key]\n        elif isinstance(key,\
      \ str):\n            # Column access by header name\n            if self._headers\
      \ is None:\n                raise KeyError(f\"No headers defined\")\n      \
      \      if key not in self._headers:\n                raise KeyError(f\"Column\
      \ '{key}' not found\")\n    \n            col_index = self._headers.index(key)\n\
      \            return [row[col_index] if col_index < len(row) else None for row\
      \ in self._data]\n        else:\n>           raise TypeError(f\"Invalid key\
      \ type: {type(key)}\")\nE           TypeError: Invalid key type: <class 'int'>\n\
      \ngeneration\\Tablib\\tablib\\core.py:119: TypeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_title_and_headers_persistence\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n\
      FAILED tests/Tablib/functional_test.py::test_databook_add_sheet_and_iteration_order\n\
      5 failed, 6 passed in 0.70s\n"
    elapsed_time_s: 2.219669
    avg_memory_mb: 32.43
    avg_cpu_percent: 94.9
    passed: 6
    failed: 5
    skipped: 0
    total: 11
    score_inputs_passed: 6
    score_inputs_failed: 5
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Tablib/performance_test.py ______________\n\
      tests\\Tablib\\performance_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported TABLIB_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/performance_test.py -\
      \ RuntimeError: Unsupported TABLIB_TAR...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.66s\n"
    elapsed_time_s: 2.253848
    avg_memory_mb: 35.46
    avg_cpu_percent: 100.0
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.267515
    score_inputs_actual_time_s: 2.253848
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _______________ ERROR collecting tests/Tablib/resource_test.py ________________\n\
      tests\\Tablib\\resource_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported TABLIB_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/resource_test.py - RuntimeError:\
      \ Unsupported TABLIB_TARGET...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during\
      \ collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.64s\n"
    elapsed_time_s: 2.216741
    avg_memory_mb: 35.39
    avg_cpu_percent: 99.2
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 34.54
    score_inputs_baseline_cpu_pct: 99.1
    score_inputs_actual_mem_mb: 35.39
    score_inputs_actual_cpu_pct: 99.2
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.18s

      '
    elapsed_time_s: 1.77679
    avg_memory_mb: 31.25
    avg_cpu_percent: 98.1
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=4.0 total_loc=287.0

      .

      1 passed in 0.14s

      '
    elapsed_time_s: 1.64518
    avg_memory_mb: 31.42
    avg_cpu_percent: 98.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 4.0
      total_loc: 287.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=24.2587 files_scanned=4.0 total_loc=287.0 max_cc=9.0

      .

      1 passed in 0.18s

      '
    elapsed_time_s: 1.671037
    avg_memory_mb: 31.1
    avg_cpu_percent: 99.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 24.2587
      files_scanned: 4.0
      total_loc: 287.0
      max_cc: 9.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 24.2587
baseline_metrics:
  performance:
    performance_suite_time_s: 2.267515
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 5.457667
    resource_tests_total: 2
    avg_memory_mb: 34.54
    avg_cpu_percent: 99.1
  functional:
    functional_suite_time_s: 1.550296
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.567555
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.666207
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 31.0
      total_loc: 3330.0
  maintainability:
    maintainability_suite_time_s: 2.204547
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 31.0
      total_loc: 4978.0
      max_cc: 17.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Tablib\pytest_logs
