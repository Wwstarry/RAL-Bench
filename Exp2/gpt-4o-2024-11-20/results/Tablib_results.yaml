project_name: Tablib
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Tablib\tablib.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Tablib
timestamp: '2025-12-31 13:06:22'
functional_score: 0.1818
non_functional_score: 0.4
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "FF.FF.FFFFF                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      ______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\
      \n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n   \
      \     \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\
      \"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip\
      \ via export + .csv setter.\n        csv_text = data.export(\"csv\")\n     \
      \   assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n\
      \        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers\
      \ == data.headers\n        assert loaded_csv.height == data.height\n       \
      \ assert loaded_csv.width == data.width\n    \n        orig_dict_norm = _normalize_dict_rows(data.dict)\n\
      \        loaded_dict_norm = _normalize_dict_rows(loaded_csv.dict)\n        assert\
      \ loaded_dict_norm == orig_dict_norm\n    \n        # JSON roundtrip via export\
      \ + .json setter.\n        json_text = data.export(\"json\")\n        assert\
      \ isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n\
      >       assert isinstance(parsed, list)\nE       AssertionError: assert False\n\
      E        +  where False = isinstance({'headers': ['first_name', 'last_name',\
      \ 'age'], 'rows': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada',\
      \ 'Lovelace', 36]]}, list)\n\ntests\\Tablib\\functional_test.py:146: AssertionError\n\
      __________________ test_dataset_export_import_tsv_roundtrip ___________________\n\
      \n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"\
      TSV export/import should preserve shape and values (type-coercion tolerant).\"\
      \"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"\
      tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n\
      >       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CEF5DF0>, fmt\
      \ = 'tsv'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n        \
      \    from .formats._csv import export_set\n            return export_set(self)\n\
      \        elif fmt == 'json':\n            from .formats._json import export_set\n\
      \            return export_set(self)\n        else:\n>           raise ValueError(f\"\
      Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\
      \ngeneration\\Tablib\\tablib\\core.py:65: ValueError\n_______________ test_dataset_row_column_operations_and_slicing\
      \ ________________\n\n    def test_dataset_row_column_operations_and_slicing()\
      \ -> None:\n        \"\"\"Validate row appending, column appending, and slicing\
      \ semantics.\"\"\"\n        data = tablib.Dataset()\n>       data.headers =\
      \ (\"city\", \"country\")\n\ntests\\Tablib\\functional_test.py:201: \n_ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\
      \nself = <tablib.core.Dataset object at 0x000001BF0CF06940>\nheaders = ('city',\
      \ 'country')\n\n    @headers.setter\n    def headers(self, headers):\n     \
      \   if headers and len(headers) != self.width:\n>           raise ValueError(\"\
      Number of headers must match the number of columns\")\nE           ValueError:\
      \ Number of headers must match the number of columns\n\ngeneration\\Tablib\\\
      tablib\\core.py:22: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics\
      \ __________________\n\n    def test_dataset_insert_and_pop_row_semantics()\
      \ -> None:\n        \"\"\"Dataset should support inserting and popping rows\
      \ (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"\
      name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n\
      \    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"\
      b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\n\
      tests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence\
      \ __________________\n\n    def test_dataset_title_and_headers_persistence()\
      \ -> None:\n        \"\"\"Dataset title and headers should be assignable and\
      \ remain consistent.\"\"\"\n        data = tablib.Dataset(headers=(\"k\", \"\
      v\"))\n        data.title = \"Config\"\n        data.append((\"a\", 1))\n  \
      \      data.append((\"b\", 2))\n    \n        assert getattr(data, \"title\"\
      ) == \"Config\"\n        assert tuple(data.headers) == (\"k\", \"v\")\n    \
      \    assert data.height == 2\n>       assert data[1][0] == \"b\"\n\ntests\\\
      Tablib\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object\
      \ at 0x000001BF0CF06E20>, key = 1\n\n    def __getitem__(self, key):\n     \
      \   if isinstance(key, slice):\n            return [tuple(row) for row in self._data[key]]\n\
      \        elif isinstance(key, str):\n            if key not in self._headers:\n\
      \                raise KeyError(f\"Column '{key}' not found in headers\")\n\
      \            idx = self._headers.index(key)\n            return [row[idx] for\
      \ row in self._data]\n        else:\n>           raise TypeError(\"Invalid key\
      \ type\")\nE           TypeError: Invalid key type\n\ngeneration\\Tablib\\tablib\\\
      core.py:42: TypeError\n________________ test_dataset_export_json_contains_all_records\
      \ ________________\n\n    def test_dataset_export_json_contains_all_records()\
      \ -> None:\n        \"\"\"JSON export should serialize all dataset records in\
      \ a list-like structure.\"\"\"\n        data = _build_sample_dataset()\n   \
      \     json_text = data.export(\"json\")\n        assert isinstance(json_text,\
      \ str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed,\
      \ list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'headers':\
      \ ['first_name', 'last_name', 'age'], 'rows': [['John', 'Adams', 90], ['George',\
      \ 'Washington', 67], ['Ada', 'Lovelace', 36]]}, list)\n\ntests\\Tablib\\functional_test.py:278:\
      \ AssertionError\n______________ test_dataset_export_html_contains_table_structure\
      \ ______________\n\n    def test_dataset_export_html_contains_table_structure()\
      \ -> None:\n        \"\"\"HTML export (if available) should include a table-like\
      \ structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n\
      \            pytest.skip(\"html format not available in this tablib build\"\
      )\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"\
      html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset\
      \ object at 0x000001BF0CE604C0>, fmt = 'html'\n\n    def export(self, fmt):\n\
      \        if fmt == 'csv':\n            from .formats._csv import export_set\n\
      \            return export_set(self)\n        elif fmt == 'json':\n        \
      \    from .formats._json import export_set\n            return export_set(self)\n\
      \        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\"\
      )\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\\
      tablib\\core.py:65: ValueError\n__________________ test_databook_multi_sheet_json_roundtrip\
      \ ___________________\n\n    def test_databook_multi_sheet_json_roundtrip()\
      \ -> None:\n        \"\"\"Databook should preserve sheet structure when exported/imported\
      \ as JSON.\"\"\"\n        sheet1 = tablib.Dataset(\n            (1, \"a\"),\n\
      \            (2, \"b\"),\n            headers=(\"id\", \"value\"),\n       \
      \ )\n        sheet1.title = \"First\"\n    \n        sheet2 = tablib.Dataset(\n\
      \            (3, \"c\"),\n            (4, \"d\"),\n            headers=(\"id\"\
      , \"value\"),\n        )\n        sheet2.title = \"Second\"\n    \n        book\
      \ = tablib.Databook([sheet1, sheet2])\n    \n        json_text = book.export(\"\
      json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n\
      \        assert isinstance(parsed, list)\n        assert len(parsed) == 2\n\
      \    \n>       loaded_book = tablib.Databook()\nE       TypeError: __init__()\
      \ missing 1 required positional argument: 'datasets'\n\ntests\\Tablib\\functional_test.py:327:\
      \ TypeError\n_________________ test_databook_add_sheet_and_iteration_order _________________\n\
      \n    def test_databook_add_sheet_and_iteration_order() -> None:\n        \"\
      \"\"Databook should allow adding sheets and preserve the order in iteration.\"\
      \"\"\n        s1 = tablib.Dataset((1, \"x\"), headers=(\"id\", \"val\"))\n \
      \       s1.title = \"S1\"\n        s2 = tablib.Dataset((2, \"y\"), headers=(\"\
      id\", \"val\"))\n        s2.title = \"S2\"\n    \n        book = tablib.Databook([s1])\n\
      \    \n        if hasattr(book, \"add_sheet\"):\n            book.add_sheet(s2)\
      \  # type: ignore[attr-defined]\n        else:\n            # Fallback: reconstruct\
      \ via the public constructor (still normal usage).\n            book = tablib.Databook([s1,\
      \ s2])\n    \n        assert book.size == 2\n    \n        sheets = _iter_databook_sheets(book)\n\
      \        assert len(sheets) == 2\n        assert sheets[0].title == \"S1\"\n\
      \        assert sheets[1].title == \"S2\"\n>       assert sheets[0][0] == (1,\
      \ \"x\")\n\ntests\\Tablib\\functional_test.py:365: \n_ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset\
      \ object at 0x000001BF0CEE3C40>, key = 0\n\n    def __getitem__(self, key):\n\
      \        if isinstance(key, slice):\n            return [tuple(row) for row\
      \ in self._data[key]]\n        elif isinstance(key, str):\n            if key\
      \ not in self._headers:\n                raise KeyError(f\"Column '{key}' not\
      \ found in headers\")\n            idx = self._headers.index(key)\n        \
      \    return [row[idx] for row in self._data]\n        else:\n>           raise\
      \ TypeError(\"Invalid key type\")\nE           TypeError: Invalid key type\n\
      \ngeneration\\Tablib\\tablib\\core.py:42: TypeError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_csv_and_json_roundtrip\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_row_column_operations_and_slicing\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_title_and_headers_persistence\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_json_contains_all_records\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n\
      FAILED tests/Tablib/functional_test.py::test_databook_multi_sheet_json_roundtrip\n\
      FAILED tests/Tablib/functional_test.py::test_databook_add_sheet_and_iteration_order\n\
      9 failed, 2 passed in 0.48s\n"
    elapsed_time_s: 1.594868
    avg_memory_mb: 32.69
    avg_cpu_percent: 100.0
    passed: 2
    failed: 9
    skipped: 0
    total: 11
    score_inputs_passed: 2
    score_inputs_failed: 9
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Tablib/performance_test.py ______________\n\
      tests\\Tablib\\performance_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported TABLIB_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/performance_test.py -\
      \ RuntimeError: Unsupported TABLIB_TAR...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.54s\n"
    elapsed_time_s: 1.890576
    avg_memory_mb: 35.59
    avg_cpu_percent: 95.6
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.267515
    score_inputs_actual_time_s: 1.890576
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _______________ ERROR collecting tests/Tablib/resource_test.py ________________\n\
      tests\\Tablib\\resource_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported TABLIB_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/resource_test.py - RuntimeError:\
      \ Unsupported TABLIB_TARGET...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during\
      \ collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.54s\n"
    elapsed_time_s: 1.816063
    avg_memory_mb: 35.0
    avg_cpu_percent: 99.1
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 34.54
    score_inputs_baseline_cpu_pct: 99.1
    score_inputs_actual_mem_mb: 35.0
    score_inputs_actual_cpu_pct: 99.1
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.13s

      '
    elapsed_time_s: 1.355335
    avg_memory_mb: 31.02
    avg_cpu_percent: 97.5
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=4.0 total_loc=147.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.339909
    avg_memory_mb: 31.07
    avg_cpu_percent: 102.6
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 4.0
      total_loc: 147.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=30.5549 files_scanned=4.0 total_loc=147.0 max_cc=6.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.474967
    avg_memory_mb: 31.42
    avg_cpu_percent: 95.5
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 30.5549
      files_scanned: 4.0
      total_loc: 147.0
      max_cc: 6.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 30.5549
baseline_metrics:
  performance:
    performance_suite_time_s: 2.267515
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 5.457667
    resource_tests_total: 2
    avg_memory_mb: 34.54
    avg_cpu_percent: 99.1
  functional:
    functional_suite_time_s: 1.550296
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.567555
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.666207
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 31.0
      total_loc: 3330.0
  maintainability:
    maintainability_suite_time_s: 2.204547
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 31.0
      total_loc: 4978.0
      max_cc: 17.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Tablib\pytest_logs
