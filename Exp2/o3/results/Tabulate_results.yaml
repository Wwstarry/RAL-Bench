project_name: Tabulate
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Tabulate\tabulate.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Tabulate
timestamp: '2026-01-01 22:02:30'
functional_score: 0.5833
non_functional_score: 0.52
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 1.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "..FF.F...FF.                                                        \
      \     [100%]\n================================== FAILURES ===================================\n\
      ___________________ test_headers_firstrow_and_simple_format ___________________\n\
      \n    def test_headers_firstrow_and_simple_format() -> None:\n        table\
      \ = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n    \
      \        [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"\
      firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n   \
      \     assert lines[0].strip().startswith(\"Name\")\n        assert \"Age\" in\
      \ lines[0]\n        # separator line usually contains dashes\n>       assert\
      \ \"-\" in lines[1].replace(\" \", \"\")\nE       AssertionError: assert '-'\
      \ in 'Alice24'\nE        +  where 'Alice24' = <built-in method replace of str\
      \ object at 0x0000024BE0E16BF0>(' ', '')\nE        +    where <built-in method\
      \ replace of str object at 0x0000024BE0E16BF0> = 'Alice  24'.replace\n\ntests\\\
      Tabulate\\functional_test.py:123: AssertionError\n___________________ test_headers_keys_on_dict_of_iterables\
      \ ____________________\n\n    def test_headers_keys_on_dict_of_iterables() ->\
      \ None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n  \
      \          \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table,\
      \ headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"\
      Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'key  value   \
      \        '\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n________________________\
      \ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats()\
      \ -> None:\n        table = [\n            [\"item\", \"qty\"],\n          \
      \  [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n\
      \        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0],\
      \ tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n\
      tabular_data = [['spam', 42], ['eggs', 451], ['bacon', 0]]\nheaders = ['item',\
      \ 'qty'], tablefmt = 'github', showindex = False\nstralign = 'left', numalign\
      \ = 'decimal', floatfmt = 'g', missingval = ''\n\n    def tabulate(\n      \
      \  tabular_data: Any,\n        headers: Any = (),\n        tablefmt: str = \"\
      simple\",\n        showindex: bool | Sequence[Any] = False,\n        stralign:\
      \ str | None = \"left\",\n        numalign: str | None = \"decimal\",\n    \
      \    floatfmt: str = \"g\",\n        missingval: str = \"\",\n    ) -> str:\n\
      \        \"\"\"\n        Format *tabular_data* into a table.\n    \n       \
      \ Only a subset of arguments of the original *tabulate* function\n        is\
      \ implemented, but the most frequently used ones are present.\n        \"\"\"\
      \n    \n        fmt = TABLE_FORMATS.get(tablefmt)\n        if fmt is None:\n\
      >           raise ValueError(f\"Unknown table format {tablefmt!r}\")\nE    \
      \       ValueError: Unknown table format 'github'\n\ngeneration\\Tabulate\\\
      tabulate\\core.py:173: ValueError\n_______________ test_disable_numparse_preserves_numeric_strings\
      \ _______________\n\n    def test_disable_numparse_preserves_numeric_strings()\
      \ -> None:\n        rows = [\n            [\"code\", \"value\"],\n         \
      \   [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output\
      \ = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\n\
      E       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\
      \ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________\
      \ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text()\
      \ -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n  \
      \      rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n\
      \            [2, \"short\"],\n        ]\n>       output = tabulate(\n      \
      \      rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\"\
      ,\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate()\
      \ got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251:\
      \ TypeError\n=========================== short test summary info ===========================\n\
      FAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\n\
      FAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\n\
      FAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\n\
      FAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\n\
      FAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n\
      5 failed, 7 passed in 0.50s\n"
    elapsed_time_s: 1.812845
    avg_memory_mb: 33.23
    avg_cpu_percent: 100.0
    passed: 7
    failed: 5
    skipped: 0
    total: 12
    score_inputs_passed: 7
    score_inputs_failed: 5
    score_inputs_total: 12
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.19s

      '
    elapsed_time_s: 1.435699
    avg_memory_mb: 31.61
    avg_cpu_percent: 97.7
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.772085
    score_inputs_actual_time_s: 1.435699
  resource:
    returncode: 1
    stdout: "F                                                                   \
      \     [100%]\n================================== FAILURES ===================================\n\
      _____________________ test_memory_usage_for_large_tables ______________________\n\
      \n    def test_memory_usage_for_large_tables():\n        rows = [\n        \
      \    [f\"row-{i}\", i, i * 0.1234, f\"value-{i % 10}\"]\n            for i in\
      \ range(5000)\n        ]\n        headers = [\"name\", \"index\", \"metric\"\
      , \"tag\"]\n    \n        before = _memory_mb()\n    \n        # Call tabulate\
      \ several times to exercise allocations.\n        out1 = tabulate(rows, headers=headers,\
      \ tablefmt=\"simple\")\n>       out2 = tabulate(rows, headers=headers, tablefmt=\"\
      github\")\n\ntests\\Tabulate\\resource_test.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data =\
      \ [['row-0', 0, 0.0, 'value-0'], ['row-1', 1, 0.1234, 'value-1'], ['row-2',\
      \ 2, 0.2468, 'value-2'], ['row-3', 3, 0.3702, 'value-3'], ['row-4', 4, 0.4936,\
      \ 'value-4'], ['row-5', 5, 0.617, 'value-5'], ...]\nheaders = ['name', 'index',\
      \ 'metric', 'tag'], tablefmt = 'github'\nshowindex = False, stralign = 'left',\
      \ numalign = 'decimal', floatfmt = 'g'\nmissingval = ''\n\n    def tabulate(\n\
      \        tabular_data: Any,\n        headers: Any = (),\n        tablefmt: str\
      \ = \"simple\",\n        showindex: bool | Sequence[Any] = False,\n        stralign:\
      \ str | None = \"left\",\n        numalign: str | None = \"decimal\",\n    \
      \    floatfmt: str = \"g\",\n        missingval: str = \"\",\n    ) -> str:\n\
      \        \"\"\"\n        Format *tabular_data* into a table.\n    \n       \
      \ Only a subset of arguments of the original *tabulate* function\n        is\
      \ implemented, but the most frequently used ones are present.\n        \"\"\"\
      \n    \n        fmt = TABLE_FORMATS.get(tablefmt)\n        if fmt is None:\n\
      >           raise ValueError(f\"Unknown table format {tablefmt!r}\")\nE    \
      \       ValueError: Unknown table format 'github'\n\ngeneration\\Tabulate\\\
      tabulate\\core.py:173: ValueError\n=========================== short test summary\
      \ info ===========================\nFAILED tests/Tabulate/resource_test.py::test_memory_usage_for_large_tables\
      \ - ...\n1 failed in 0.52s\n"
    elapsed_time_s: 1.938593
    avg_memory_mb: 36.5
    avg_cpu_percent: 99.1
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 36.26
    score_inputs_baseline_cpu_pct: 99.0
    score_inputs_actual_mem_mb: 36.5
    score_inputs_actual_cpu_pct: 99.1
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.32s

      '
    elapsed_time_s: 1.719822
    avg_memory_mb: 31.7
    avg_cpu_percent: 100.0
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=4.0 total_loc=418.0

      .

      1 passed in 0.12s

      '
    elapsed_time_s: 1.554503
    avg_memory_mb: 31.84
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 4.0
      total_loc: 418.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=19.0830 files_scanned=4.0 total_loc=418.0 max_cc=49.0

      .

      1 passed in 0.16s

      '
    elapsed_time_s: 1.457716
    avg_memory_mb: 31.84
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 19.083
      files_scanned: 4.0
      total_loc: 418.0
      max_cc: 49.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 19.083
baseline_metrics:
  performance:
    performance_suite_time_s: 1.772085
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 3.401749
    resource_tests_total: 1
    avg_memory_mb: 36.26
    avg_cpu_percent: 99.0
  functional:
    functional_suite_time_s: 1.659825
    functional_tests_total: 12
  robustness:
    robustness_suite_time_s: 2.291708
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.459004
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 1.0
      total_loc: 2425.0
  maintainability:
    maintainability_suite_time_s: 1.673018
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 1.0
      total_loc: 2425.0
      max_cc: 77.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Tabulate\pytest_logs
