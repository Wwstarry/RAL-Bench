{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Astral", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "not enough values to unpack (expected 3, got 2)", "returncode": 1, "elapsed_time_s": 1.650895, "avg_memory_mb": 32.9, "avg_cpu_percent": 90.9, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 18:29:34", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_sun_times_basic_sanity _________________________\n\n    def test_sun_times_basic_sanity() -> None:\n        \"\"\"sun() returns expected keys and times are in a plausible order.\"\"\"\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nobserver = <astral.locationinfo.Observer object at 0x0000024DA5B84F70>\ndate = datetime.date(2020, 6, 1), tzinfo = datetime.timezone.utc\n\n    def sun(observer, date=None, tzinfo=None):\n        \"\"\"Calculate all sun-related values for a date.\n    \n        Args:\n            observer: LocationInfo observer attribute or similar\n            date: The date for which to calculate the times. Default is today.\n            tzinfo: The timezone to use for the returned times.\n    \n        Returns:\n            A dictionary with keys 'dawn', 'sunrise', 'noon', 'sunset', 'dusk'\n            containing the respective times as datetime objects.\n        \"\"\"\n        if date is None:\n            date = datetime.date.today()\n    \n        if tzinfo is None:\n            tzinfo = datetime.timezone.utc\n    \n        # Sunrise/sunset zenith adjusted for elevation\n        sunrise_sunset_zenith = 90 + _adjust_to_horizon(observer.elevation)\n    \n        # Civil dawn/dusk zenith angle (6 degrees below horizon)\n        dawn_dusk_zenith = 96  # 90 + 6\n    \n        # Calculate times\n>       sunrise, sunset, noon = _calculate_sunrise_sunset(observer, date, tzinfo, sunrise_sunset_zenith)\nE       ValueError: not enough values to unpack (expected 3, got 2)\n\ngeneration\\Astral\\astral\\sun.py:181: ValueError\n______________________ test_sun_time_changes_across_days ______________________\n\n    def test_sun_time_changes_across_days() -> None:\n        \"\"\"Sunrise and sunset should change slightly between consecutive days.\"\"\"\n        loc = _london_location()\n        d1 = dt.date(2020, 1, 1)\n        d2 = d1 + dt.timedelta(days=1)\n    \n>       s1 = sun(_observer_from_location(loc), date=d1, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nobserver = <astral.locationinfo.Observer object at 0x0000024DA457ADC0>\ndate = datetime.date(2020, 1, 1), tzinfo = datetime.timezone.utc\n\n    def sun(observer, date=None, tzinfo=None):\n        \"\"\"Calculate all sun-related values for a date.\n    \n        Args:\n            observer: LocationInfo observer attribute or similar\n            date: The date for which to calculate the times. Default is today.\n            tzinfo: The timezone to use for the returned times.\n    \n        Returns:\n            A dictionary with keys 'dawn', 'sunrise', 'noon', 'sunset', 'dusk'\n            containing the respective times as datetime objects.\n        \"\"\"\n        if date is None:\n            date = datetime.date.today()\n    \n        if tzinfo is None:\n            tzinfo = datetime.timezone.utc\n    \n        # Sunrise/sunset zenith adjusted for elevation\n        sunrise_sunset_zenith = 90 + _adjust_to_horizon(observer.elevation)\n    \n        # Civil dawn/dusk zenith angle (6 degrees below horizon)\n        dawn_dusk_zenith = 96  # 90 + 6\n    \n        # Calculate times\n>       sunrise, sunset, noon = _calculate_sunrise_sunset(observer, date, tzinfo, sunrise_sunset_zenith)\nE       ValueError: not enough values to unpack (expected 3, got 2)\n\ngeneration\\Astral\\astral\\sun.py:181: ValueError\n_________________________ test_sun_returns_datetimes __________________________\n\n    def test_sun_returns_datetimes() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:185: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "faead3fab09ae2735ae64060ea39ae1426827753", "stdout_len": 9852, "stdout": "FF...FFF...                                                              [100%]\n================================== FAILURES ===================================\n_________________________ test_sun_times_basic_sanity _________________________\n\n    def test_sun_times_basic_sanity() -> None:\n        \"\"\"sun() returns expected keys and times are in a plausible order.\"\"\"\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nobserver = <astral.locationinfo.Observer object at 0x0000024DA5B84F70>\ndate = datetime.date(2020, 6, 1), tzinfo = datetime.timezone.utc\n\n    def sun(observer, date=None, tzinfo=None):\n        \"\"\"Calculate all sun-related values for a date.\n    \n        Args:\n            observer: LocationInfo observer attribute or similar\n            date: The date for which to calculate the times. Default is today.\n            tzinfo: The timezone to use for the returned times.\n    \n        Returns:\n            A dictionary with keys 'dawn', 'sunrise', 'noon', 'sunset', 'dusk'\n            containing the respective times as datetime objects.\n        \"\"\"\n        if date is None:\n            date = datetime.date.today()\n    \n        if tzinfo is None:\n            tzinfo = datetime.timezone.utc\n    \n        # Sunrise/sunset zenith adjusted for elevation\n        sunrise_sunset_zenith = 90 + _adjust_to_horizon(observer.elevation)\n    \n        # Civil dawn/dusk zenith angle (6 degrees below horizon)\n        dawn_dusk_zenith = 96  # 90 + 6\n    \n        # Calculate times\n>       sunrise, sunset, noon = _calculate_sunrise_sunset(observer, date, tzinfo, sunrise_sunset_zenith)\nE       ValueError: not enough values to unpack (expected 3, got 2)\n\ngeneration\\Astral\\astral\\sun.py:181: ValueError\n______________________ test_sun_time_changes_across_days ______________________\n\n    def test_sun_time_changes_across_days() -> None:\n        \"\"\"Sunrise and sunset should change slightly between consecutive days.\"\"\"\n        loc = _london_location()\n        d1 = dt.date(2020, 1, 1)\n        d2 = d1 + dt.timedelta(days=1)\n    \n>       s1 = sun(_observer_from_location(loc), date=d1, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nobserver = <astral.locationinfo.Observer object at 0x0000024DA457ADC0>\ndate = datetime.date(2020, 1, 1), tzinfo = datetime.timezone.utc\n\n    def sun(observer, date=None, tzinfo=None):\n        \"\"\"Calculate all sun-related values for a date.\n    \n        Args:\n            observer: LocationInfo observer attribute or similar\n            date: The date for which to calculate the times. Default is today.\n            tzinfo: The timezone to use for the returned times.\n    \n        Returns:\n            A dictionary with keys 'dawn', 'sunrise', 'noon', 'sunset', 'dusk'\n            containing the respective times as datetime objects.\n        \"\"\"\n        if date is None:\n            date = datetime.date.today()\n    \n        if tzinfo is None:\n            tzinfo = datetime.timezone.utc\n    \n        # Sunrise/sunset zenith adjusted for elevation\n        sunrise_sunset_zenith = 90 + _adjust_to_horizon(observer.elevation)\n    \n        # Civil dawn/dusk zenith angle (6 degrees below horizon)\n        dawn_dusk_zenith = 96  # 90 + 6\n    \n        # Calculate times\n>       sunrise, sunset, noon = _calculate_sunrise_sunset(observer, date, tzinfo, sunrise_sunset_zenith)\nE       ValueError: not enough values to unpack (expected 3, got 2)\n\ngeneration\\Astral\\astral\\sun.py:181: ValueError\n_________________________ test_sun_returns_datetimes __________________________\n\n    def test_sun_returns_datetimes() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:185: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nobserver = <astral.locationinfo.Observer object at 0x0000024DA5B92310>\ndate = datetime.date(2020, 6, 1), tzinfo = datetime.timezone.utc\n\n    def sun(observer, date=None, tzinfo=None):\n        \"\"\"Calculate all sun-related values for a date.\n    \n        Args:\n            observer: LocationInfo observer attribute or similar\n            date: The date for which to calculate the times. Default is today.\n            tzinfo: The timezone to use for the returned times.\n    \n        Returns:\n            A dictionary with keys 'dawn', 'sunrise', 'noon', 'sunset', 'dusk'\n            containing the respective times as datetime objects.\n        \"\"\"\n        if date is None:\n            date = datetime.date.today()\n    \n        if tzinfo is None:\n            tzinfo = datetime.timezone.utc\n    \n        # Sunrise/sunset zenith adjusted for elevation\n        sunrise_sunset_zenith = 90 + _adjust_to_horizon(observer.elevation)\n    \n        # Civil dawn/dusk zenith angle (6 degrees below horizon)\n        dawn_dusk_zenith = 96  # 90 + 6\n    \n        # Calculate times\n>       sunrise, sunset, noon = _calculate_sunrise_sunset(observer, date, tzinfo, sunrise_sunset_zenith)\nE       ValueError: not enough values to unpack (expected 3, got 2)\n\ngeneration\\Astral\\astral\\sun.py:181: ValueError\n_________________ test_sun_noon_is_between_sunrise_and_sunset _________________\n\n    def test_sun_noon_is_between_sunrise_and_sunset() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 3, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:196: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nobserver = <astral.locationinfo.Observer object at 0x0000024DA5B74880>\ndate = datetime.date(2020, 3, 1), tzinfo = datetime.timezone.utc\n\n    def sun(observer, date=None, tzinfo=None):\n        \"\"\"Calculate all sun-related values for a date.\n    \n        Args:\n            observer: LocationInfo observer attribute or similar\n            date: The date for which to calculate the times. Default is today.\n            tzinfo: The timezone to use for the returned times.\n    \n        Returns:\n            A dictionary with keys 'dawn', 'sunrise', 'noon', 'sunset', 'dusk'\n            containing the respective times as datetime objects.\n        \"\"\"\n        if date is None:\n            date = datetime.date.today()\n    \n        if tzinfo is None:\n            tzinfo = datetime.timezone.utc\n    \n        # Sunrise/sunset zenith adjusted for elevation\n        sunrise_sunset_zenith = 90 + _adjust_to_horizon(observer.elevation)\n    \n        # Civil dawn/dusk zenith angle (6 degrees below horizon)\n        dawn_dusk_zenith = 96  # 90 + 6\n    \n        # Calculate times\n>       sunrise, sunset, noon = _calculate_sunrise_sunset(observer, date, tzinfo, sunrise_sunset_zenith)\nE       ValueError: not enough values to unpack (expected 3, got 2)\n\ngeneration\\Astral\\astral\\sun.py:181: ValueError\n_______ test_sun_times_differ_between_locations_same_date_or_one_raises _______\n\n    def test_sun_times_differ_between_locations_same_date_or_one_raises() -> None:\n        \"\"\"\n        Some generated implementations have edge-case bugs for certain longitudes that can\n        yield out-of-range hours (e.g., hour < 0 or > 23) and raise ValueError.\n        This test remains targeted (different locations) while being compatible across\n        implementations by accepting either:\n          - both computations succeed and differ, OR\n          - one implementation raises a clear exception for the second location.\n        \"\"\"\n        london = _london_location()\n        nyc = _new_york_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s_l = sun(_observer_from_location(london), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nobserver = <astral.locationinfo.Observer object at 0x0000024DA5B6C880>\ndate = datetime.date(2020, 6, 1), tzinfo = datetime.timezone.utc\n\n    def sun(observer, date=None, tzinfo=None):\n        \"\"\"Calculate all sun-related values for a date.\n    \n        Args:\n            observer: LocationInfo observer attribute or similar\n            date: The date for which to calculate the times. Default is today.\n            tzinfo: The timezone to use for the returned times.\n    \n        Returns:\n            A dictionary with keys 'dawn', 'sunrise', 'noon', 'sunset', 'dusk'\n            containing the respective times as datetime objects.\n        \"\"\"\n        if date is None:\n            date = datetime.date.today()\n    \n        if tzinfo is None:\n            tzinfo = datetime.timezone.utc\n    \n        # Sunrise/sunset zenith adjusted for elevation\n        sunrise_sunset_zenith = 90 + _adjust_to_horizon(observer.elevation)\n    \n        # Civil dawn/dusk zenith angle (6 degrees below horizon)\n        dawn_dusk_zenith = 96  # 90 + 6\n    \n        # Calculate times\n>       sunrise, sunset, noon = _calculate_sunrise_sunset(observer, date, tzinfo, sunrise_sunset_zenith)\nE       ValueError: not enough values to unpack (expected 3, got 2)\n\ngeneration\\Astral\\astral\\sun.py:181: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Astral/functional_test.py::test_sun_times_basic_sanity - ValueEr...\nFAILED tests/Astral/functional_test.py::test_sun_time_changes_across_days - V...\nFAILED tests/Astral/functional_test.py::test_sun_returns_datetimes - ValueErr...\nFAILED tests/Astral/functional_test.py::test_sun_noon_is_between_sunrise_and_sunset\nFAILED tests/Astral/functional_test.py::test_sun_times_differ_between_locations_same_date_or_one_raises\n5 failed, 6 passed in 0.48s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'celery.utils.threads'", "returncode": 1, "elapsed_time_s": 28.557364, "avg_memory_mb": 33.66, "avg_cpu_percent": 0.71, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2026-01-01 18:32:44", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n>       from celery import Celery  # noqa: F401\n\ntests\\Celery\\functional_test.py:60: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositorie", "stdout_sha1": "18b54b07fe2a269d9d2b007fbdb16b7891ffc1eb", "stdout_len": 13407, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n>       from celery import Celery  # noqa: F401\n\ntests\\Celery\\functional_test.py:60: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n>       app = _make_app(\"celery_test_app_2\")\n\ntests\\Celery\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Celery\\functional_test.py:32: in _make_app\n    from celery import Celery\nrepositories\\celery\\celery\\local.py:459: in __getattr__\n    module = __import__(self._object_origins[name], None, None,\nrepositories\\celery\\celery\\app\\__init__.py:2: in <module>\n    from celery import _state\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"Internal state.\n    \n    This is an internal module containing thread state\n    like the ``current_app``, and ``current_task``.\n    \n    This module shouldn't be used directly.\n    \"\"\"\n    \n    import os\n    import sys\n    import threading\n    import weakref\n    \n    from celery.local import Proxy\n>   from celery.utils.threads import LocalStack\nE   ModuleNotFoundError: No module named 'celery.utils.threads'\n\nrepositories\\celery\\celery\\_state.py:15: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.75s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Click", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'click.utils'", "returncode": 2, "elapsed_time_s": 5.447154, "avg_memory_mb": 36.3, "avg_cpu_percent": 96.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 18:34:38", "stdout_excerpt": "====\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:9: in <module>\n    from .core import Context, Command, Group, Argument, Option, Parameter\ngeneration\\Click\\click\\core.py:15: in <module>\n    from .utils import echo\nE   ModuleNotFoundError: No module named 'click.utils'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.06s\n", "stdout_sha1": "0c3be1d6a1bcb4a96f54c2676af835219b09378a", "stdout_len": 1080, "stdout": "\n=================================== ERRORS ====================================\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:9: in <module>\n    from .core import Context, Command, Group, Argument, Option, Parameter\ngeneration\\Click\\click\\core.py:15: in <module>\n    from .utils import echo\nE   ModuleNotFoundError: No module named 'click.utils'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.06s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Dataset", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Database' object has no attribute 'ensure_schema'", "returncode": 1, "elapsed_time_s": 29.238648, "avg_memory_mb": 45.83, "avg_cpu_percent": 0.91, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 18:38:51", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n>       table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n\ntests\\Dataset\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c586a5b0>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n>       table.insert_many(rows)\n\ntests\\Dataset\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:172: in insert_many\n    self._sync_columns(sync_row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58e7c70>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-433/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n>       table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n\ntests\\Dataset\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58d4ca0>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n        db = create_in_memory_db()\n        table = db[\"items\"]\n    \n        rows = [{\"name\": \"A\"}, {\"name\": \"B\"}, {\"name\": \"C\"}]\n>       ret = table.insert_many(rows)\n\ntests\\Dataset\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "0ee2d7913f1e90c1b87287466c0e21316625f2c4", "stdout_len": 13449, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n>       table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n\ntests\\Dataset\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c586a5b0>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n>       table.insert_many(rows)\n\ntests\\Dataset\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:172: in insert_many\n    self._sync_columns(sync_row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58e7c70>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-433/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n>       table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n\ntests\\Dataset\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58d4ca0>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n        db = create_in_memory_db()\n        table = db[\"items\"]\n    \n        rows = [{\"name\": \"A\"}, {\"name\": \"B\"}, {\"name\": \"C\"}]\n>       ret = table.insert_many(rows)\n\ntests\\Dataset\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:172: in insert_many\n    self._sync_columns(sync_row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58ca340>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n        db = create_in_memory_db()\n        table = db[\"t\"]\n>       table.insert({\"name\": \"only\"})\n\ntests\\Dataset\\functional_test.py:237: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58c4700>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n>           table.insert({\"n\": i})\n\ntests\\Dataset\\functional_test.py:246: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58c5ac0>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n        db = create_in_memory_db()\n        table = db[\"people\"]\n>       table.insert({\"name\": \"Alice\", \"age\": 30})\n\ntests\\Dataset\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58f7160>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n_______________________ test_delete_and_clear_all_rows ________________________\n\n    def test_delete_and_clear_all_rows() -> None:\n        \"\"\"\n        Older dataset.Table may not expose truncate().\n        Clear a table and end at 0 rows without relying on result iteration for DML.\n        \"\"\"\n        db = create_in_memory_db()\n        table = db[\"logs\"]\n>       table.insert_many([{\"kind\": \"a\"}, {\"kind\": \"b\"}, {\"kind\": \"b\"}])\n\ntests\\Dataset\\functional_test.py:270: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:172: in insert_many\n    self._sync_columns(sync_row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58d4670>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n>       table.insert({\"x\": 1})\n\ntests\\Dataset\\functional_test.py:299: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:118: in insert\n    row = self._sync_columns(row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c47e81f0>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n_____________________ test_raw_sql_query_with_parameters ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-433/test_raw_sql_query_with_parame0')\n\n    def test_raw_sql_query_with_parameters(tmp_path: Path) -> None:\n        db_path = tmp_path / \"param.db\"\n        db = dataset.connect(\"sqlite:///%s\" % str(db_path))\n        table = db[\"kv\"]\n>       table.insert_many([{\"k\": \"a\", \"v\": 1}, {\"k\": \"b\", \"v\": 2}])\n\ntests\\Dataset\\functional_test.py:319: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:172: in insert_many\n    self._sync_columns(sync_row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c58eb6a0>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n>       table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n\ntests\\Dataset\\functional_test.py:330: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Dataset\\dataset\\table.py:172: in insert_many\n    self._sync_columns(sync_row, ensure, types=types)\nrepositories\\Dataset\\dataset\\table.py:366: in _sync_columns\n    ensure = self._check_ensure(ensure)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Database' object has no attribute 'lock'\") raised in repr()] Table object at 0x167c477ff70>\nensure = None\n\n    def _check_ensure(self, ensure):\n        if ensure is None:\n>           return self.db.ensure_schema\nE           AttributeError: 'Database' object has no attribute 'ensure_schema'\n\nrepositories\\Dataset\\dataset\\table.py:386: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - A...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - Att...\nFAILED tests/Dataset/functional_test.py::test_transactions_commit_and_rollback\nFAILED tests/Dataset/functional_test.py::test_insert_many_returns_ids_and_count\nFAILED tests/Dataset/functional_test.py::test_find_one_missing_returns_none\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - At...\nFAILED tests/Dataset/functional_test.py::test_table_all_iteration_and_row_shape\nFAILED tests/Dataset/functional_test.py::test_delete_and_clear_all_rows - Att...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_raw_sql_query_with_parameters\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n11 failed in 5.07s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 18:40:45", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('line' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\" or 'lines' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\")", "returncode": 1, "elapsed_time_s": 2.532968, "avg_memory_mb": 32.88, "avg_cpu_percent": 72.3, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2026-01-01 18:42:35", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_006_bin_scripts_exist __________________________\n\n    def test_006_bin_scripts_exist():\n        base = _resolve_repo_root()\n        b = base / \"bin\"\n        assert b.is_dir(), \"Expected bin/ directory\"\n        assert (b / \"fail2ban-client\").is_file(), \"Expected bin/fail2ban-client\"\n        assert (b / \"fail2ban-server\").is_file(), \"Expected bin/fail2ban-server\"\n>       assert (b / \"fail2ban-regex\").is_file(), \"Expected bin/fail2ban-regex\"\nE       AssertionError: Expected bin/fail2ban-regex\nE       assert False\nE        +  where False = is_file()\nE        +    where is_file = (WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Fail2ban/bin') / 'fail2ban-regex').is_file\n\ntests\\Fail2ban\\functional_test.py:144: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           assert ('line' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\" or 'lines' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\")\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_006_bin_scripts_exist - Assert...\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n2 failed, 10 passed in 1.19s\n", "stdout_sha1": "05504f8c06f22fc5080cc9c6cdbe668728018ea7", "stdout_len": 3611, "stdout": ".....F.....F                                                             [100%]\n================================== FAILURES ===================================\n_________________________ test_006_bin_scripts_exist __________________________\n\n    def test_006_bin_scripts_exist():\n        base = _resolve_repo_root()\n        b = base / \"bin\"\n        assert b.is_dir(), \"Expected bin/ directory\"\n        assert (b / \"fail2ban-client\").is_file(), \"Expected bin/fail2ban-client\"\n        assert (b / \"fail2ban-server\").is_file(), \"Expected bin/fail2ban-server\"\n>       assert (b / \"fail2ban-regex\").is_file(), \"Expected bin/fail2ban-regex\"\nE       AssertionError: Expected bin/fail2ban-regex\nE       assert False\nE        +  where False = is_file()\nE        +    where is_file = (WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Fail2ban/bin') / 'fail2ban-regex').is_file\n\ntests\\Fail2ban\\functional_test.py:144: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           assert ('line' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\" or 'lines' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\")\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_006_bin_scripts_exist - Assert...\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n2 failed, 10 passed in 1.19s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ImportError", "exception_msg": "cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)", "returncode": 1, "elapsed_time_s": 4.094798, "avg_memory_mb": 77.72, "avg_cpu_percent": 99.6, "passed": 1, "failed": 11, "skipped": 0, "total": 12, "functional_score": 0.0833, "timestamp": "2026-01-01 18:44:29", "stdout_excerpt": "==== FAILURES ===================================\n___________________________ test_001_import_folium ____________________________\n\n    def test_001_import_folium():\n        _prepend_import_path()\n>       import folium  # noqa: F401\n\ntests\\Folium\\functional_test.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:44: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:53: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n       ", "stdout_sha1": "b7bc3cb5c72f57b208e948ed3cfe43f2cbf3bb69", "stdout_len": 8329, "stdout": ".FFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n___________________________ test_001_import_folium ____________________________\n\n    def test_001_import_folium():\n        _prepend_import_path()\n>       import folium  # noqa: F401\n\ntests\\Folium\\functional_test.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:44: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:53: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-434/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:149: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n______________ test_010_plugins_markercluster_module_importable _______________\n\n    def test_010_plugins_markercluster_module_importable():\n        _prepend_import_path()\n>       plugins = _plugins_module()\n\ntests\\Folium\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Folium\\functional_test.py:29: in _plugins_module\n    return importlib.import_module(\"folium.plugins\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from folium.map import Map, TileLayer, LayerControl\nE   ImportError: cannot import name 'Map' from 'folium.map' (D:\\桌面\\RealAppCodeBench_generic_eval\\repositories\\folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\__init__.py:1: ImportError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_001_import_folium - ImportError:...\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root - ImportEr...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Impor...\nFAILED tests/Folium/functional_test.py::test_010_plugins_markercluster_module_importable\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n11 failed, 1 passed in 2.56s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Humanize", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.536997, "avg_memory_mb": 31.12, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 18:47:55", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "", "exception_msg": "", "returncode": 124, "elapsed_time_s": 60.057415, "avg_memory_mb": 45.57, "avg_cpu_percent": 0.22, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 18:50:51", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_png_roundtrip_with_imread_and_imwrite __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_png_roundtrip_with_imread0')\n\n    def test_png_roundtrip_with_imread_and_imwrite(tmp_path: Path) -> None:\n        \"\"\"Exercise a simple PNG roundtrip and verify image shape and data.\"\"\"\n        img = _make_color_image()\n        path = tmp_path / \"test.png\"\n    \n>       iio.imwrite(path, img)\n\ntests\\Imageio\\functional_test.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Imageio\\imageio\\v3.py:139: in imwrite\n    with imopen(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_png_roundtrip_with_imread0/test.png')\nio_mode = 'w', plugin = None, extension = None, format_hint = None\nlegacy_mode = False, kwargs = {}\nrequest = <imageio.core.request.Request object at 0x000001F6CDA6F3A0>\nsource = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_png_roundtrip_with_imread0/test.png')\n\n    def imopen(\n        uri,\n        io_mode,\n        *,\n        plugin=None,\n        extension=None,\n        format_hint=None,\n        legacy_mode=False,\n        **kwargs,\n    ):\n        \"\"\"Open an ImageResource.\n    \n        .. warning::\n            This warning is for pypy users. If you are not using a context manager,\n            remember to deconstruct the returned plugin to avoid leaking the file\n            handle to an unclosed file.\n    \n        Parameters\n        ----------\n        uri : str or pathlib.Path or bytes or file or Request\n            The :doc:`ImageResource <../../user_guide/requests>` to load the\n            image from.\n        io_mode : str\n            The mode in which the file is opened. Possible values are::\n    \n                ``r`` - open the file for reading\n                ``w`` - open the file for writing\n    \n            Depreciated since v2.9:\n            A second character can be added to give the reader a hint on what\n            the user expects. This will be ignored by new plugins and will\n            only have an effect on legacy plugins. Possible values are::\n    \n                ``i`` for a single image,\n                ``I`` for multiple images,\n                ``v`` for a single volume,\n                ``V`` for multiple volumes,\n                ``?`` for don't care\n    \n        plugin : str, Plugin, or None\n            The plugin to use. If set to None imopen will perform a\n            search for a matching plugin. If not None, this takes priority over\n            the provided format hint.\n        extension : str\n            If not None, treat the provided ImageResource as if it had the given\n            extension. This affects the order in which backends are considered, and\n            when writing this may also influence the format used when encoding.\n        format_hint : str\n            Deprecated. Use `extension` instead.\n        legacy_mode : bool\n            If true use the v2 behavior when searching for a suitable\n            plugin. This will ignore v3 plugins and will check ``plugin``\n            against known extensions if no plugin with the given name can be found.\n        **kwargs : Any\n            Additional keyword arguments will be passed to the plugin upon\n            construction.\n    \n        Notes\n        -----\n        Registered plugins are controlled via the ``known_plugins`` dict in\n        ``imageio.config``.\n    \n        Passing a ``Request`` as the uri is only supported if ``legacy_mode``\n        is ``True``. In this case ``io_mode`` is ignored.\n    \n        Using the kwarg ``format_hint`` does not enforce the given format. It merely\n        provides a `hint` to the selection process and plugin. The selection\n        processes uses this hint for optimization; however, a plugin's", "stdout_sha1": "2c2240b3913882ca2c9f6211063ae1abef5a1340", "stdout_len": 18669, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n_________________ test_png_roundtrip_with_imread_and_imwrite __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_png_roundtrip_with_imread0')\n\n    def test_png_roundtrip_with_imread_and_imwrite(tmp_path: Path) -> None:\n        \"\"\"Exercise a simple PNG roundtrip and verify image shape and data.\"\"\"\n        img = _make_color_image()\n        path = tmp_path / \"test.png\"\n    \n>       iio.imwrite(path, img)\n\ntests\\Imageio\\functional_test.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Imageio\\imageio\\v3.py:139: in imwrite\n    with imopen(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_png_roundtrip_with_imread0/test.png')\nio_mode = 'w', plugin = None, extension = None, format_hint = None\nlegacy_mode = False, kwargs = {}\nrequest = <imageio.core.request.Request object at 0x000001F6CDA6F3A0>\nsource = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_png_roundtrip_with_imread0/test.png')\n\n    def imopen(\n        uri,\n        io_mode,\n        *,\n        plugin=None,\n        extension=None,\n        format_hint=None,\n        legacy_mode=False,\n        **kwargs,\n    ):\n        \"\"\"Open an ImageResource.\n    \n        .. warning::\n            This warning is for pypy users. If you are not using a context manager,\n            remember to deconstruct the returned plugin to avoid leaking the file\n            handle to an unclosed file.\n    \n        Parameters\n        ----------\n        uri : str or pathlib.Path or bytes or file or Request\n            The :doc:`ImageResource <../../user_guide/requests>` to load the\n            image from.\n        io_mode : str\n            The mode in which the file is opened. Possible values are::\n    \n                ``r`` - open the file for reading\n                ``w`` - open the file for writing\n    \n            Depreciated since v2.9:\n            A second character can be added to give the reader a hint on what\n            the user expects. This will be ignored by new plugins and will\n            only have an effect on legacy plugins. Possible values are::\n    \n                ``i`` for a single image,\n                ``I`` for multiple images,\n                ``v`` for a single volume,\n                ``V`` for multiple volumes,\n                ``?`` for don't care\n    \n        plugin : str, Plugin, or None\n            The plugin to use. If set to None imopen will perform a\n            search for a matching plugin. If not None, this takes priority over\n            the provided format hint.\n        extension : str\n            If not None, treat the provided ImageResource as if it had the given\n            extension. This affects the order in which backends are considered, and\n            when writing this may also influence the format used when encoding.\n        format_hint : str\n            Deprecated. Use `extension` instead.\n        legacy_mode : bool\n            If true use the v2 behavior when searching for a suitable\n            plugin. This will ignore v3 plugins and will check ``plugin``\n            against known extensions if no plugin with the given name can be found.\n        **kwargs : Any\n            Additional keyword arguments will be passed to the plugin upon\n            construction.\n    \n        Notes\n        -----\n        Registered plugins are controlled via the ``known_plugins`` dict in\n        ``imageio.config``.\n    \n        Passing a ``Request`` as the uri is only supported if ``legacy_mode``\n        is ``True``. In this case ``io_mode`` is ignored.\n    \n        Using the kwarg ``format_hint`` does not enforce the given format. It merely\n        provides a `hint` to the selection process and plugin. The selection\n        processes uses this hint for optimization; however, a plugin's decision how\n        to read a ImageResource will - typically - still be based on the content of\n        the resource.\n    \n    \n        Examples\n        --------\n    \n        >>> import imageio.v3 as iio\n        >>> with iio.imopen(\"/path/to/image.png\", \"r\") as file:\n        >>>     im = file.read()\n    \n        >>> with iio.imopen(\"/path/to/output.jpg\", \"w\") as file:\n        >>>     file.write(im)\n    \n        \"\"\"\n    \n        if isinstance(uri, Request) and legacy_mode:\n            warnings.warn(\n                \"`iio.core.Request` is a low-level object and using it\"\n                \" directly as input to `imopen` is discouraged. This will raise\"\n                \" an exception in ImageIO v3.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n    \n            request = uri\n            uri = request.raw_uri\n            io_mode = request.mode.io_mode\n            request.format_hint = format_hint\n        else:\n            request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n    \n        source = \"<bytes>\" if isinstance(uri, bytes) else uri\n    \n        # fast-path based on plugin\n        # (except in legacy mode)\n        if plugin is not None:\n            if isinstance(plugin, str):\n                try:\n                    config = known_plugins[plugin]\n                except KeyError:\n                    request.finish()\n                    raise ValueError(\n                        f\"`{plugin}` is not a registered plugin name.\"\n                    ) from None\n    \n                def loader(request, **kwargs):\n                    return config.plugin_class(request, **kwargs)\n    \n            else:\n    \n                def loader(request, **kwargs):\n                    return plugin(request, **kwargs)\n    \n            try:\n                return loader(request, **kwargs)\n            except InitializationError as class_specific:\n                err_from = class_specific\n                err_type = RuntimeError if legacy_mode else IOError\n                err_msg = f\"`{plugin}` can not handle the given uri.\"\n            except ImportError:\n                err_from = None\n                err_type = ImportError\n                err_msg = (\n                    f\"The `{config.name}` plugin is not installed. \"\n                    f\"Use `pip install imageio[{config.install_name}]` to install it.\"\n                )\n            except Exception as generic_error:\n                err_from = generic_error\n                err_type = IOError\n                err_msg = f\"An unknown error occurred while initializing plugin `{plugin}`.\"\n    \n            request.finish()\n            raise err_type(err_msg) from err_from\n    \n        # fast-path based on format_hint\n        if request.format_hint is not None:\n            for candidate_format in known_extensions[format_hint]:\n                for plugin_name in candidate_format.priority:\n                    config = known_plugins[plugin_name]\n    \n                    try:\n                        candidate_plugin = config.plugin_class\n                    except ImportError:\n                        # not installed\n                        continue\n    \n                    try:\n                        plugin_instance = candidate_plugin(request, **kwargs)\n                    except InitializationError:\n                        # file extension doesn't match file type\n                        continue\n    \n                    return plugin_instance\n            else:\n                resource = (\n                    \"<bytes>\" if isinstance(request.raw_uri, bytes) else request.raw_uri\n                )\n                warnings.warn(f\"`{resource}` can not be opened as a `{format_hint}` file.\")\n    \n        # fast-path based on file extension\n        if request.extension in known_extensions:\n            for candidate_format in known_extensions[request.extension]:\n                for plugin_name in candidate_format.priority:\n                    config = known_plugins[plugin_name]\n    \n                    try:\n                        candidate_plugin = config.plugin_class\n                    except ImportError:\n                        # not installed\n                        continue\n    \n                    try:\n                        plugin_instance = candidate_plugin(request, **kwargs)\n                    except InitializationError:\n                        # file extension doesn't match file type\n                        continue\n    \n                    return plugin_instance\n    \n        # error out for read-only special targets\n        # this is hacky; can we come up with a better solution for this?\n        if request.mode.io_mode == IOMode.write:\n            if isinstance(uri, str) and uri.startswith(SPECIAL_READ_URIS):\n                request.finish()\n                err_type = ValueError if legacy_mode else IOError\n                err_msg = f\"`{source}` is read-only.\"\n                raise err_type(err_msg)\n    \n        # error out for directories\n        # this is a bit hacky and should be cleaned once we decide\n        # how to gracefully handle DICOM\n        if request._uri_type == URI_FILENAME and Path(request.raw_uri).is_dir():\n            request.finish()\n            err_type = ValueError if legacy_mode else IOError\n            err_msg = (\n                \"ImageIO does not generally support reading folders. \"\n                \"Limited support may be available via specific plugins. \"\n                \"Specify the plugin explicitly using the `plugin` kwarg, e.g. `plugin='DICOM'`\"\n            )\n            raise err_type(err_msg)\n    \n        # close the current request here and use fresh/new ones while trying each\n        # plugin This is slow (means potentially reopening a resource several\n        # times), but should only happen rarely because this is the fallback if all\n        # else fails.\n        request.finish()\n    \n        # fallback option: try all plugins\n        for config in known_plugins.values():\n            # each plugin gets its own request\n            request = Request(uri, io_mode, format_hint=format_hint)\n    \n            try:\n                plugin_instance = config.plugin_class(request, **kwargs)\n            except InitializationError:\n                continue\n            except ImportError:\n                continue\n            else:\n                return plugin_instance\n    \n        err_type = ValueError if legacy_mode else IOError\n        err_msg = f\"Could not find a backend to open `{source}`` with iomode `{io_mode}`.\"\n    \n        # check if a missing plugin could help\n        if request.extension in known_extensions:\n            missing_plugins = list()\n    \n            formats = known_extensions[request.extension]\n            plugin_names = [\n                plugin for file_format in formats for plugin in file_format.priority\n            ]\n            for name in plugin_names:\n                config = known_plugins[name]\n    \n                try:\n                    config.plugin_class\n                    continue\n                except ImportError:\n                    missing_plugins.append(config)\n    \n            if len(missing_plugins) > 0:\n                install_candidates = \"\\n\".join(\n                    [\n                        (\n                            f\"  {config.name}:  \"\n                            f\"pip install imageio[{config.install_name}]\"\n                        )\n                        for config in missing_plugins\n                    ]\n                )\n                err_msg += (\n                    \"\\nBased on the extension, the following plugins might add capable backends:\\n\"\n                    f\"{install_candidates}\"\n                )\n    \n        request.finish()\n>       raise err_type(err_msg)\nE       OSError: Could not find a backend to open `C:\\Users\\86152\\AppData\\Local\\Temp\\pytest-of-86152\\pytest-437\\test_png_roundtrip_with_imread0\\test.png`` with iomode `w`.\nE       Based on the extension, the following plugins might add capable backends:\nE         pillow:  pip install imageio[pillow]\nE         PNG-PIL:  pip install imageio[pillow]\nE         PNG-FI:  pip install imageio[freeimage]\nE         ITK:  pip install imageio[simpleitk]\nE         pyav:  pip install imageio[pyav]\nE         opencv:  pip install imageio[opencv]\n\nrepositories\\Imageio\\imageio\\core\\imopen.py:281: OSError\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Imageio\\imageio\\v3.py:139: in imwrite\n    with imopen(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_gif_multiframe_roundtrip_0/anim.gif')\nio_mode = 'w', plugin = None, extension = None, format_hint = None\nlegacy_mode = False, kwargs = {}\nrequest = <imageio.core.request.Request object at 0x000001F6CE31B9A0>\nsource = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-437/test_gif_multiframe_roundtrip_0/anim.gif')\n\n    def imopen(\n        uri,\n        io_mode,\n        *,\n        plugin=None,\n        extension=None,\n        format_hint=None,\n        legacy_mode=False,\n        **kwargs,\n    ):\n        \"\"\"Open an ImageResource.\n    \n        .. warning::\n            This warning is for pypy users. If you are not using a context manager,\n            remember to deconstruct the returned plugin to avoid leaking the file\n            handle to an unclosed file.\n    \n        Parameters\n        ----------\n        uri : str or pathlib.Path or bytes or file or Request\n            The :doc:`ImageResource <../../user_guide/requests>` to load the\n            image from.\n        io_mode : str\n            The mode in which the file is opened. Possible values are::\n    \n                ``r`` - open the file for reading\n                ``w`` - open the file for writing\n    \n            Depreciated since v2.9:\n            A second character can be added to give the reader a hint on what\n            the user expects. This will be ignored by new plugins and will\n            only have an effect on legacy plugins. Possible values are::\n    \n                ``i`` for a single image,\n                ``I`` for multiple images,\n                ``v`` for a single volume,\n                ``V`` for multiple volumes,\n                ``?`` for don't care\n    \n        plugin : str, Plugin, or None\n            The plugin to use. If set to None imopen will perform a\n            search for a matching plugin. If not None, this takes priority over\n            the provided format hint.\n        extension : str\n            If not None, treat the provided ImageResource as if it had the given\n            extension. This affects the order in which backends are considered, and\n            when writing this may also influence the format used when encoding.\n        format_hint : str\n            Deprecated. Use `extension` instead.\n        legacy_mode : bool\n            If true use the v2 behavior when searching for a suitable\n            plugin. This will ignore v3 plugins and will check ``plugin``\n            against known extensions if no plugin with the given name can be found.\n        **kwargs : Any\n            Additional keyword arguments will be passed to the plugin upon\n            construction.\n    \n        Notes\n        -----\n        Registered plugins are controlled via the ``known_plugins`` dict in\n        ``imageio.config``.\n    \n        Passing a ``Request`` as the uri is only supported if ``legacy_mode``\n        is ``True``. In this case ``io_mode`` is ignored.\n    \n        Using the kwarg ``format_hint`` does not enforce the given format. It merely\n        provides a `hint` to the selection process and plugin. The selection\n        processes uses this hint for optimization; however, a plugin's decision how\n        to read a ImageResource will - typically - still be based on the content of\n        the resource.\n    \n    \n        Examples\n        --------\n    \n        >>> import imageio.v3 as iio\n        >>> with iio.imopen(\"/path/to/image.png\", \"r\") as file:\n        >>>     im = file.read()\n    \n        >>> with iio.imopen(\"/path/to/output.jpg\", \"w\") as file:\n        >>>     file.write(im)\n    \n        \"\"\"\n    \n        if isinstance(uri, Request) and legacy_mode:\n            warnings.warn(\n                \"`iio.core.Request` is a low-level object and using it\"\n                \" directly as input to `imopen` is discouraged. This will raise\"\n                \" an exception in ImageIO v3.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n    \n            request = uri\n            uri = request.raw_uri\n            io_mode = request.mode.io_mode\n            request.format_hint = format_hint\n        else:\n            request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n    \n        source = \"<bytes>\" if isinstance(uri, bytes) else uri\n    \n        # fast-path based on plugin\n        # (except in legacy mode)\n        if plugin is not None:\n            if isinstance(plugin, str):\n                try:\n                    config = known_plugins[plugin]\n                except KeyError:\n                    request.finish()\n                    raise ValueError(\n                        f\"`{plugin}` is not a registered plugin name.\"\n                    ) from None\n    \n                def loader(request, **kwargs):\n                    return config.plugin_class(request, **kwargs)\n    \n            else:\n    \n                def loader(request, **kwargs):\n                    return plugin(request, **kwargs)\n    \n            try:\n                return loader(request, **kwargs)\n            except InitializationError as class_specific:\n                err_from = class_specific\n                err_type = RuntimeError if legacy_mode else IOError\n                err_msg = f\"`{plugin}` can not handle the given uri.\"\n            except ImportError:\n                err_from = None\n                err_type = ImportError\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Lifelines", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 3.870162, "avg_memory_mb": 93.56, "avg_cpu_percent": 91.3, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 18:53:01", "stdout_excerpt": "\n1 skipped in 2.16s\n", "stdout_sha1": "a85097b9d72205c87937b39cf1ccb8649746055a", "stdout_len": 20, "stdout": "\n1 skipped in 2.16s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Loguru", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "add() got an unexpected keyword argument 'colorize'", "returncode": 1, "elapsed_time_s": 2.00945, "avg_memory_mb": 16.16, "avg_cpu_percent": 49.15, "passed": 2, "failed": 9, "skipped": 0, "total": 11, "functional_score": 0.1818, "timestamp": "2026-01-01 18:54:39", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable", "stdout_sha1": "be997e7ae6fb89fd2926227c606bd13810d171a9", "stdout_len": 11039, "stdout": "FFFFF.FFFF.                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} user={extra[user]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-438/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n        logger.remove()\n        logger.add(log_path, format=\"{level}:{message}\", level=\"INFO\")\n    \n        logger.info(\"file-line-1\")\n        logger.warning(\"file-line-2\")\n    \n>       assert log_path.exists()\nE       AssertionError: assert False\nE        +  where False = exists()\nE        +    where exists = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-438/test_add_file_sink_writes_line0/loguru_test.log').exists\n\ntests\\Loguru\\functional_test.py:184: AssertionError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n>       log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n\ntests\\Loguru\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n>       log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n\ntests\\Loguru\\functional_test.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} patched={extra[patched]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n\ntests\\Loguru\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - Ty...\nFAILED tests/Loguru/functional_test.py::test_level_filtering - TypeError: add...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Typ...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Type...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Ass...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\n9 failed, 2 passed in 0.64s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'mailpile.safe_popen'", "returncode": 2, "elapsed_time_s": 2.560232, "avg_memory_mb": 35.98, "avg_cpu_percent": 74.5, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 18:56:28", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ModuleNotFoundError: No module named 'mailpile.safe_popen'\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.15s\n", "stdout_sha1": "c5985a65f1222cd5c295b53aa60bc85c6db94d55", "stdout_len": 925, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ModuleNotFoundError: No module named 'mailpile.safe_popen'\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.15s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 1.918738, "avg_memory_mb": 33.06, "avg_cpu_percent": 100.0, "passed": 7, "failed": 3, "skipped": 9, "total": 19, "functional_score": 0.3684, "timestamp": "2026-01-01 18:57:44", "stdout_excerpt": "==== FAILURES ===================================\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<a \" in norm and \"</a>\" in norm\n        assert 'href=\"https://example.com\"' in norm\n>       assert \"<img \" in norm\nE       assert '<img ' in '<p>A <a href=\"https://example.com\">link</a> and\\nan image: !<a href=\"https://example.com/image.png\">alt text</a></p>'\n\ntests\\Markdown\\functional_test.py:191: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_links_and_images - assert '<im...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.51s\n", "stdout_sha1": "dc3c8782e3e5ed1eceab7a2223aac2efaaffff40", "stdout_len": 2437, "stdout": ".....FF..Fsssssssss                                                      [100%]\n================================== FAILURES ===================================\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<a \" in norm and \"</a>\" in norm\n        assert 'href=\"https://example.com\"' in norm\n>       assert \"<img \" in norm\nE       assert '<img ' in '<p>A <a href=\"https://example.com\">link</a> and\\nan image: !<a href=\"https://example.com/image.png\">alt text</a></p>'\n\ntests\\Markdown\\functional_test.py:191: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_links_and_images - assert '<im...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.51s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 1.881317, "avg_memory_mb": 31.77, "avg_cpu_percent": 102.6, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2026-01-01 18:59:18", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.53s\n", "stdout_sha1": "06bf97c301e114625a734336749d3bdd72fd951f", "stdout_len": 3013, "stdout": "........FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.53s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.462137, "avg_memory_mb": 30.45, "avg_cpu_percent": 97.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:01:12", "stdout_excerpt": "\n1 skipped in 0.11s\n", "stdout_sha1": "75923eec7092d4a8427af710fe49bcf2a0b64e5b", "stdout_len": 20, "stdout": "\n1 skipped in 0.11s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Pendulum", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.43618, "avg_memory_mb": 30.59, "avg_cpu_percent": 101.2, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:03:07", "stdout_excerpt": "\n1 skipped in 0.12s\n", "stdout_sha1": "2c297eff6659b1c3f522bd1a20de05b2bdd71aca", "stdout_len": 20, "stdout": "\n1 skipped in 0.12s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.390103, "avg_memory_mb": 14.36, "avg_cpu_percent": 100.1, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:05:35", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 12, in <module>\n    from pygments.lex import lex\nImportError: cannot import name 'lex' from 'pygments.lex' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py)\n", "stdout_sha1": "8daaca5481814e655e1f0d22dc6a75ade28f2924", "stdout_len": 1603, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 12, in <module>\n    from pygments.lex import lex\nImportError: cannot import name 'lex' from 'pygments.lex' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py)\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.863816, "avg_memory_mb": 33.77, "avg_cpu_percent": 100.0, "passed": 5, "failed": 5, "skipped": 1, "total": 11, "functional_score": 0.4545, "timestamp": "2026-01-01 19:06:37", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(\n        payload: Dict[str, Any],\n        key: str,\n        algorithm: str = \"HS256\",\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Encode a JWT with the given payload, key and algorithm.\n    \n        Args:\n            payload: The JWT payload to encode.\n            key: The secret key used for signing.\n            algorithm: The algorithm to use for signing. Currently only HS256 is supported.\n            **kwargs: Additional options (not used in this implementation).\n    \n        Returns:\n            A string representing the encoded JWT.\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(f\"Algorithm {algorithm} not supported\")\nE           NotImplementedError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:41: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:48: in encode\n    payload_part = base64url_encode(json.dumps(payload, separators=(',', ':')).encode('utf-8'))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000222DC077CD0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, ", "stdout_sha1": "dd6648d0f4dfc6bac2b91b9019ab3e53024a56c7", "stdout_len": 9566, "stdout": ".F.FF...FFs                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(\n        payload: Dict[str, Any],\n        key: str,\n        algorithm: str = \"HS256\",\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Encode a JWT with the given payload, key and algorithm.\n    \n        Args:\n            payload: The JWT payload to encode.\n            key: The secret key used for signing.\n            algorithm: The algorithm to use for signing. Currently only HS256 is supported.\n            **kwargs: Additional options (not used in this implementation).\n    \n        Returns:\n            A string representing the encoded JWT.\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(f\"Algorithm {algorithm} not supported\")\nE           NotImplementedError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:41: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:48: in encode\n    payload_part = base64url_encode(json.dumps(payload, separators=(',', ':')).encode('utf-8'))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000222DC077CD0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:48: in encode\n    payload_part = base64url_encode(json.dumps(payload, separators=(',', ':')).encode('utf-8'))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000222DC0918B0>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n_________________________ test_decode_with_bytes_key __________________________\n\n    def test_decode_with_bytes_key() -> None:\n        payload = {\"user\": \"bob\", \"plan\": \"pro\"}\n        key = b\"secret-bytes\"\n>       decoded = _encode_decode(payload, key=key, algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'plan': 'pro', 'user': 'bob'}, key = b'secret-bytes'\nalgorithm = 'HS256', kwargs = {}, header = {'alg': 'HS256', 'typ': 'JWT'}\nheader_part = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9'\npayload_part = 'eyJ1c2VyIjoiYm9iIiwicGxhbiI6InBybyJ9'\nmessage = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyIjoiYm9iIiwicGxhbiI6InBybyJ9'\n\n    def encode(\n        payload: Dict[str, Any],\n        key: str,\n        algorithm: str = \"HS256\",\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Encode a JWT with the given payload, key and algorithm.\n    \n        Args:\n            payload: The JWT payload to encode.\n            key: The secret key used for signing.\n            algorithm: The algorithm to use for signing. Currently only HS256 is supported.\n            **kwargs: Additional options (not used in this implementation).\n    \n        Returns:\n            A string representing the encoded JWT.\n        \"\"\"\n        if algorithm != \"HS256\":\n            raise NotImplementedError(f\"Algorithm {algorithm} not supported\")\n    \n        # Create the header\n        header = {\"typ\": \"JWT\", \"alg\": algorithm}\n    \n        # Encode header and payload\n        header_part = base64url_encode(json.dumps(header, separators=(',', ':')).encode('utf-8'))\n        payload_part = base64url_encode(json.dumps(payload, separators=(',', ':')).encode('utf-8'))\n    \n        # Create the message to sign\n        message = f\"{header_part}.{payload_part}\"\n    \n        # Sign the message with HMAC-SHA256\n        signature = hmac.new(\n>           key.encode('utf-8'),\n            message.encode('utf-8'),\n            hashlib.sha256\n        ).digest()\nE       AttributeError: 'bytes' object has no attribute 'encode'\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:55: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\nFAILED tests/PyJWT/functional_test.py::test_decode_with_bytes_key - Attribute...\n5 failed, 5 passed, 1 skipped in 0.58s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "PyPDF", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where <built-in method get of dict object at 0x0000019C8E024FC0> = {'/Author': 'Author Name', '/Title': 'Doc Title'}.get", "returncode": 1, "elapsed_time_s": 1.902725, "avg_memory_mb": 32.38, "avg_cpu_percent": 99.1, "passed": 8, "failed": 3, "skipped": 1, "total": 12, "functional_score": 0.6667, "timestamp": "2026-01-01 19:08:09", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-440/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n        reader = PdfReader(str(pdf_path))\n        page = reader.pages[0]\n        w, h = _page_size(page)\n    \n>       assert w > 0 and h > 0\nE       assert (0.0 > 0)\n\ntests\\PyPDF\\functional_test.py:149: AssertionError\n_____________ test_encrypted_pdf_allows_page_access_after_decrypt _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-440/test_encrypted_pdf_allows_page0')\n\n    def test_encrypted_pdf_allows_page_access_after_decrypt(tmp_path: Path) -> None:\n        \"\"\"After decrypting, basic page access should succeed and page size is valid.\"\"\"\n        src = tmp_path / \"plain2.pdf\"\n        enc = tmp_path / \"encrypted2.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        writer.add_page(reader.pages[0])\n        writer.encrypt(\"pw\")\n    \n        with enc.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        enc_reader = PdfReader(str(enc))\n        assert enc_reader.is_encrypted\n        assert enc_reader.decrypt(\"pw\")\n    \n        page = enc_reader.pages[0]\n        w, h = _page_size(page)\n>       assert w > 0 and h > 0\nE       assert (0.0 > 0)\n\ntests\\PyPDF\\functional_test.py:272: AssertionError\n___________________ test_metadata_multiple_fields_roundtrip ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-440/test_metadata_multiple_fields_0')\n\n    def test_metadata_multiple_fields_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Add several info dict fields and ensure they can be read back.\"\"\"\n        src = tmp_path / \"src_info.pdf\"\n        dst = tmp_path / \"info.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        writer.add_page(reader.pages[0])\n    \n        writer.add_metadata(\n            {\n                \"/Title\": \"Doc Title\",\n                \"/Author\": \"Author Name\",\n                \"/Subject\": \"Subject Line\",\n                \"/Producer\": \"PyPDF\",\n            }\n        )\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n        meta = reader2.metadata\n        assert meta is not None\n        assert meta.get(\"/Title\") == \"Doc Title\"\n        assert meta.get(\"/Author\") == \"Author Name\"\n>       assert meta.get(\"/Subject\") == \"Subject Line\"\nE       AssertionError: assert None == 'Subject Line'\nE        +  where None = <built-in method get of dict object at 0x0000019C8E024FC0>('/Subject')\nE        +    where <built-in method get of dict object at 0x0000019C8E024FC0> = {'/Author': 'Author Name', '/Title': 'Doc Title'}.get\n\ntests\\PyPDF\\functional_test.py:329: AssertionError\n============================== warnings summary ===============================\ngeneration\\PyPDF\\pypdf\\pdf.py:81\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:81: DeprecationWarning: invalid escape sequence \\s\n    info_match = re.search(b\"/Info\\s+(\\d+)\\s+\\d+\\s+R\", data)\n\ngeneration\\PyPDF\\pypdf\\pdf.py:84\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:84: DeprecationWarning: invalid escape sequence \\s\n    title_match = re.search(b\"/Title\\s*\\((.*?)\\)\", data)\n\ngeneration\\PyPDF\\pypdf\\pdf.py:88\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:88: DeprecationWarning: invalid escape sequence \\s\n    author_match = re.search(b\"/Author\\s*\\((.*?)\\)\", data)\n\ngeneration\\PyPDF\\pypdf\\pdf.py:93\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generat", "stdout_sha1": "d03a97664967d12ece428de87a6d2a4c40c566e7", "stdout_len": 4912, "stdout": ".F.....F.Fs.                                                             [100%]\n================================== FAILURES ===================================\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-440/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n        reader = PdfReader(str(pdf_path))\n        page = reader.pages[0]\n        w, h = _page_size(page)\n    \n>       assert w > 0 and h > 0\nE       assert (0.0 > 0)\n\ntests\\PyPDF\\functional_test.py:149: AssertionError\n_____________ test_encrypted_pdf_allows_page_access_after_decrypt _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-440/test_encrypted_pdf_allows_page0')\n\n    def test_encrypted_pdf_allows_page_access_after_decrypt(tmp_path: Path) -> None:\n        \"\"\"After decrypting, basic page access should succeed and page size is valid.\"\"\"\n        src = tmp_path / \"plain2.pdf\"\n        enc = tmp_path / \"encrypted2.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        writer.add_page(reader.pages[0])\n        writer.encrypt(\"pw\")\n    \n        with enc.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        enc_reader = PdfReader(str(enc))\n        assert enc_reader.is_encrypted\n        assert enc_reader.decrypt(\"pw\")\n    \n        page = enc_reader.pages[0]\n        w, h = _page_size(page)\n>       assert w > 0 and h > 0\nE       assert (0.0 > 0)\n\ntests\\PyPDF\\functional_test.py:272: AssertionError\n___________________ test_metadata_multiple_fields_roundtrip ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-440/test_metadata_multiple_fields_0')\n\n    def test_metadata_multiple_fields_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Add several info dict fields and ensure they can be read back.\"\"\"\n        src = tmp_path / \"src_info.pdf\"\n        dst = tmp_path / \"info.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        writer.add_page(reader.pages[0])\n    \n        writer.add_metadata(\n            {\n                \"/Title\": \"Doc Title\",\n                \"/Author\": \"Author Name\",\n                \"/Subject\": \"Subject Line\",\n                \"/Producer\": \"PyPDF\",\n            }\n        )\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n        meta = reader2.metadata\n        assert meta is not None\n        assert meta.get(\"/Title\") == \"Doc Title\"\n        assert meta.get(\"/Author\") == \"Author Name\"\n>       assert meta.get(\"/Subject\") == \"Subject Line\"\nE       AssertionError: assert None == 'Subject Line'\nE        +  where None = <built-in method get of dict object at 0x0000019C8E024FC0>('/Subject')\nE        +    where <built-in method get of dict object at 0x0000019C8E024FC0> = {'/Author': 'Author Name', '/Title': 'Doc Title'}.get\n\ntests\\PyPDF\\functional_test.py:329: AssertionError\n============================== warnings summary ===============================\ngeneration\\PyPDF\\pypdf\\pdf.py:81\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:81: DeprecationWarning: invalid escape sequence \\s\n    info_match = re.search(b\"/Info\\s+(\\d+)\\s+\\d+\\s+R\", data)\n\ngeneration\\PyPDF\\pypdf\\pdf.py:84\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:84: DeprecationWarning: invalid escape sequence \\s\n    title_match = re.search(b\"/Title\\s*\\((.*?)\\)\", data)\n\ngeneration\\PyPDF\\pypdf\\pdf.py:88\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:88: DeprecationWarning: invalid escape sequence \\s\n    author_match = re.search(b\"/Author\\s*\\((.*?)\\)\", data)\n\ngeneration\\PyPDF\\pypdf\\pdf.py:93\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:93: DeprecationWarning: invalid escape sequence \\s\n    page_count = len(re.findall(b\"/Type\\s*/Page[^s]\", data))\n\ngeneration\\PyPDF\\pypdf\\pdf.py:107\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\PyPDF\\pypdf\\pdf.py:107: DeprecationWarning: invalid escape sequence \\s\n    rotation_match = re.search(b\"/Rotate\\s+(\\d+)\", data)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nFAILED tests/PyPDF/functional_test.py::test_blank_page_has_expected_size - as...\nFAILED tests/PyPDF/functional_test.py::test_encrypted_pdf_allows_page_access_after_decrypt\nFAILED tests/PyPDF/functional_test.py::test_metadata_multiple_fields_roundtrip\n3 failed, 8 passed, 1 skipped, 5 warnings in 0.60s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'function' object has no attribute 'at'", "returncode": 1, "elapsed_time_s": 1.614863, "avg_memory_mb": 32.04, "avg_cpu_percent": 106.2, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-01 19:13:13", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:97: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:148: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"ran\")\n    \n>       j = schedule.every(10).seconds.do(job)\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:184: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().day.at(\"10:30\").do(job)\nE       AttributeError: 'function' object has no attribute 'at'\n\ntests\\Schedule\\functional_test.py:210: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().monday.at(\"09", "stdout_sha1": "23c470b785f8a0dc0d0364ffd995358ec68b76e6", "stdout_len": 7273, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:97: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:148: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"ran\")\n    \n>       j = schedule.every(10).seconds.do(job)\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:184: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().day.at(\"10:30\").do(job)\nE       AttributeError: 'function' object has no attribute 'at'\n\ntests\\Schedule\\functional_test.py:210: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().monday.at(\"09:00\").do(job)\nE       AttributeError: 'function' object has no attribute 'at'\n\ntests\\Schedule\\functional_test.py:224: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       schedule.every().hour.do(job)\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:253: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n>       schedule.every().minute.do(a).tag(\"alpha\")\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:269: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:290: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_run_pending_executes_due_job_without_sleep\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_day_at_sets_time_component_in_next_run\nFAILED tests/Schedule/functional_test.py::test_weekday_scheduling_creates_job_and_next_run\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n12 failed in 0.48s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'list' object has no attribute 'items'", "returncode": 1, "elapsed_time_s": 1.534775, "avg_memory_mb": 32.09, "avg_cpu_percent": 98.9, "passed": 9, "failed": 3, "skipped": 0, "total": 12, "functional_score": 0.75, "timestamp": "2026-01-01 19:14:13", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n__________ test_lowercase_false_preserves_case_for_remaining_tokens ___________\n\n    def test_lowercase_false_preserves_case_for_remaining_tokens() -> None:\n        \"\"\"lowercase=False should preserve original case for non-removed words.\"\"\"\n        mixed = \"thIs Has a stopword Stopword\"\n        result = slugify(mixed, stopwords=[\"Stopword\"], lowercase=False)\n    \n        assert \"thIs\" in result\n        assert \"Has\" in result\n>       assert \"Stopword\" not in result\nE       AssertionError: assert 'Stopword' not in 'thIs-Has-a-...ord-Stopword'\nE         \nE         'Stopword' is contained here:\nE           thIs-Has-a-stopword-Stopword\nE         ?                     ++++++++\n\ntests\\Slugify\\functional_test.py:202: AssertionError\n___________________ test_replacements_apply_before_slugging ___________________\n\n    def test_replacements_apply_before_slugging() -> None:\n        \"\"\"replacements should transform substrings before final slug is produced.\"\"\"\n        text = \"C# is not C++\"\n>       result = slugify(text, replacements=[[\"C#\", \"Csharp\"], [\"C++\", \"Cpp\"]])\n\ntests\\Slugify\\functional_test.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'C# is not C++', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = [['C#', 'Csharp'], ['C++', 'Cpp']], kwargs = {}\n\n    def slugify(text, allow_unicode=False, max_length=None, word_boundary=False,\n                separator='-', regex_pattern=None, stopwords=None, lowercase=True,\n                replacements=None, **kwargs):\n        \"\"\"\n        Convert text to a slug.\n    \n        Parameters:\n        - text: The string to convert\n        - allow_unicode: Whether to allow non-ASCII characters in the slug\n        - max_length: Maximum length of the slug\n        - word_boundary: Whether to truncate at word boundaries when using max_length\n        - separator: Character to replace whitespace and punctuation with\n        - regex_pattern: Custom regex pattern to filter characters\n        - stopwords: List of words to remove from the slug\n        - lowercase: Whether to convert the slug to lowercase\n        - replacements: Dictionary of {str: str} to replace before slugifying\n    \n        Returns:\n        A slugified string.\n        \"\"\"\n        if text is None:\n            return ''\n    \n        text = str(text)\n    \n        # Apply custom replacements first if provided\n        if replacements:\n>           for old, new in replacements.items():\nE           AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Slugify\\slugify\\slugify.py:32: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_lowercase_false_preserves_case_for_remaining_tokens\nFAILED tests/Slugify/functional_test.py::test_replacements_apply_before_slugging\n3 failed, 9 passed in 0.36s\n", "stdout_sha1": "3362629f47d5641055c6b412b5bd1d06a559e364", "stdout_len": 3816, "stdout": ".......F.FF.                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n__________ test_lowercase_false_preserves_case_for_remaining_tokens ___________\n\n    def test_lowercase_false_preserves_case_for_remaining_tokens() -> None:\n        \"\"\"lowercase=False should preserve original case for non-removed words.\"\"\"\n        mixed = \"thIs Has a stopword Stopword\"\n        result = slugify(mixed, stopwords=[\"Stopword\"], lowercase=False)\n    \n        assert \"thIs\" in result\n        assert \"Has\" in result\n>       assert \"Stopword\" not in result\nE       AssertionError: assert 'Stopword' not in 'thIs-Has-a-...ord-Stopword'\nE         \nE         'Stopword' is contained here:\nE           thIs-Has-a-stopword-Stopword\nE         ?                     ++++++++\n\ntests\\Slugify\\functional_test.py:202: AssertionError\n___________________ test_replacements_apply_before_slugging ___________________\n\n    def test_replacements_apply_before_slugging() -> None:\n        \"\"\"replacements should transform substrings before final slug is produced.\"\"\"\n        text = \"C# is not C++\"\n>       result = slugify(text, replacements=[[\"C#\", \"Csharp\"], [\"C++\", \"Cpp\"]])\n\ntests\\Slugify\\functional_test.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'C# is not C++', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = [['C#', 'Csharp'], ['C++', 'Cpp']], kwargs = {}\n\n    def slugify(text, allow_unicode=False, max_length=None, word_boundary=False,\n                separator='-', regex_pattern=None, stopwords=None, lowercase=True,\n                replacements=None, **kwargs):\n        \"\"\"\n        Convert text to a slug.\n    \n        Parameters:\n        - text: The string to convert\n        - allow_unicode: Whether to allow non-ASCII characters in the slug\n        - max_length: Maximum length of the slug\n        - word_boundary: Whether to truncate at word boundaries when using max_length\n        - separator: Character to replace whitespace and punctuation with\n        - regex_pattern: Custom regex pattern to filter characters\n        - stopwords: List of words to remove from the slug\n        - lowercase: Whether to convert the slug to lowercase\n        - replacements: Dictionary of {str: str} to replace before slugifying\n    \n        Returns:\n        A slugified string.\n        \"\"\"\n        if text is None:\n            return ''\n    \n        text = str(text)\n    \n        # Apply custom replacements first if provided\n        if replacements:\n>           for old, new in replacements.items():\nE           AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Slugify\\slugify\\slugify.py:32: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_lowercase_false_preserves_case_for_remaining_tokens\nFAILED tests/Slugify/functional_test.py::test_replacements_apply_before_slugging\n3 failed, 9 passed in 0.36s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "+  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode", "returncode": 1, "elapsed_time_s": 3.500655, "avg_memory_mb": 33.08, "avg_cpu_percent": 41.9, "passed": 7, "failed": 2, "skipped": 0, "total": 9, "functional_score": 0.7778, "timestamp": "2026-01-01 19:15:35", "stdout_excerpt": "==== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000002111B3D99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-u url] [-d direct] [--data data] [--cookie cookie]\\n                 [--level level] [--risk risk] [--technique tech] [-h] [-hh]\\n                 [--version]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x000002111B3D99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n2 failed, 7 passed in 2.35s\n", "stdout_sha1": "7c470c07589dfa59153de784c22a9301168bf2ee", "stdout_len": 2454, "stdout": "....F...F                                                                [100%]\n================================== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000002111B3D99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-u url] [-d direct] [--data data] [--cookie cookie]\\n                 [--level level] [--risk risk] [--technique tech] [-h] [-hh]\\n                 [--version]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x000002111B3D99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n2 failed, 7 passed in 2.35s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'ModelField' from 'pydantic.fields' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\fields.py)", "returncode": 2, "elapsed_time_s": 2.211406, "avg_memory_mb": 40.47, "avg_cpu_percent": 99.3, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:16:59", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:1: in <module>\n    from .main import SQLModel, Field, Relationship\ngeneration\\SQLModel\\sqlmodel\\main.py:6: in <module>\n    from pydantic.fields import ModelField\nE   ImportError: cannot import name 'ModelField' from 'pydantic.fields' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\fields.py)\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.88s\n", "stdout_sha1": "609310100b652b4a6ad25499f98d4daab18eb78a", "stdout_len": 1211, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:1: in <module>\n    from .main import SQLModel, Field, Relationship\ngeneration\\SQLModel\\sqlmodel\\main.py:6: in <module>\n    from pydantic.fields import ModelField\nE   ImportError: cannot import name 'ModelField' from 'pydantic.fields' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\fields.py)\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.88s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Stegano", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+ /\\ufffd\\ufffd\\ufffdA6\\ufffd\\ufffd,y\\ufffd\\uf", "returncode": 1, "elapsed_time_s": 4.250356, "avg_memory_mb": 39.02, "avg_cpu_percent": 99.6, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 19:20:00", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = lsb.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'o\\ufffd\\ufffd\\ufffd@\\ufffd\\ufffd\\ufffdD^\\ufffd\\ufffd...\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH' == 'hello world'\nE         \nE         - hello world\nE         + o\\ufffd\\ufffd\\ufffd@\\ufffd\\ufffd\\ufffdD^\\ufffd\\ufffd\\ufffdm\\ufffd\\ufffd\\ufffdni\\ufffds\\ufffd\\ufffd\\ufffd\\ufffd\\x7f\\ufffd\\ufffd\\ufffdc\\u1a40D8\\ufffd\\ufffd\\ufffdl@?NL\\ufffd\\ufffd@\\ufffd\\ufffd\\x03 \\ufffdk\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH\n\ntests\\Stegano\\functional_test.py:94: AssertionError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n        encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n        encoded_img.save(str(output))\n    \n        gen2 = generators.eratosthenes()\n        revealed = lsb.reveal(str(output), generator=gen2)\n>       assert revealed == secret\nE       AssertionError: assert 'y\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdOzI\\ufffd\\ufffd...\\ufffd\\ufffd\\\\x15\\u0311\\ufffdk\\ufffdV\\ufffd\\ufffd' == 'generator secret'\nE         \nE         - generator secret\nE         + y\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdOzI\\ufffd\\ufffd\\x1b3\\x1a\\ufffd\\ufffd\\ufffd{\\ufffd\\ufffd\\x17\\ufffd78\\ufffdb\\ufffd\nE         \nE         + S5}&\\ufffd\\ufffd\nE         \nE         + \\ufffd'\\ufffd\\x12j>Y\\ufffdL\\ufffd\\ufffd...\nE         \nE         ...Full output truncated (10 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:110: AssertionError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = lsb.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'o@\\u0315Hr\\ufffd\\ufffdE^\\ufffd\\ufffde...\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH' == 'This is a lo... hello-world!'\nE         \nE         - This is a longer secret message with punctuation: 12345, hello-world!\nE         + o@\\u0315Hr\\ufffd\\ufffdE^\\ufffd\\ufffde1\\ufffd\\ufffdoi\\ufffd3\\ufffd\\ufffd`\\ufffd\\u030dw\\ufffd\\ufffd\\ufffdk\\u1bc3U8\\ufffd\\ufffd\\ufffdd\\ufffd?MMi\\ufffd \\ufffd\\ufffd\\x03&\\ufffd{:\\ufffd\\ufffd\\u0467_'\\ufffdzH\\ufffd\\u0195\\ufffd\\ufffd\\x02\\u020e}\\ufffd\\ufffd\\x15#\\ufffd7\\ufffd\\ufffd8\\ufffd_#4\\x1fUs]\\ufffd\\ufffd\\t\\ufffd0\\x16i\\ufffd(\\ufffd\\x1fYW\\u049e\\ufffd\\ufffdu\\ufffd\\ufffd_\\x17R\\ufffd\\ufffd\\ufffdm\\ufffdaS\\x03O\\x16\\ufffd\nE         \nE         + /\\ufffd\\ufffd\\ufffdA6\\ufffd\\ufffd,y\\ufffd\\uf", "stdout_sha1": "9da857359de729d508bf892df70382ec52934b52", "stdout_len": 8531, "stdout": "FFFF....FFF.                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = lsb.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'o\\ufffd\\ufffd\\ufffd@\\ufffd\\ufffd\\ufffdD^\\ufffd\\ufffd...\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH' == 'hello world'\nE         \nE         - hello world\nE         + o\\ufffd\\ufffd\\ufffd@\\ufffd\\ufffd\\ufffdD^\\ufffd\\ufffd\\ufffdm\\ufffd\\ufffd\\ufffdni\\ufffds\\ufffd\\ufffd\\ufffd\\ufffd\\x7f\\ufffd\\ufffd\\ufffdc\\u1a40D8\\ufffd\\ufffd\\ufffdl@?NL\\ufffd\\ufffd@\\ufffd\\ufffd\\x03 \\ufffdk\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH\n\ntests\\Stegano\\functional_test.py:94: AssertionError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n        encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n        encoded_img.save(str(output))\n    \n        gen2 = generators.eratosthenes()\n        revealed = lsb.reveal(str(output), generator=gen2)\n>       assert revealed == secret\nE       AssertionError: assert 'y\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdOzI\\ufffd\\ufffd...\\ufffd\\ufffd\\\\x15\\u0311\\ufffdk\\ufffdV\\ufffd\\ufffd' == 'generator secret'\nE         \nE         - generator secret\nE         + y\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdOzI\\ufffd\\ufffd\\x1b3\\x1a\\ufffd\\ufffd\\ufffd{\\ufffd\\ufffd\\x17\\ufffd78\\ufffdb\\ufffd\nE         \nE         + S5}&\\ufffd\\ufffd\nE         \nE         + \\ufffd'\\ufffd\\x12j>Y\\ufffdL\\ufffd\\ufffd...\nE         \nE         ...Full output truncated (10 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:110: AssertionError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = lsb.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'o@\\u0315Hr\\ufffd\\ufffdE^\\ufffd\\ufffde...\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH' == 'This is a lo... hello-world!'\nE         \nE         - This is a longer secret message with punctuation: 12345, hello-world!\nE         + o@\\u0315Hr\\ufffd\\ufffdE^\\ufffd\\ufffde1\\ufffd\\ufffdoi\\ufffd3\\ufffd\\ufffd`\\ufffd\\u030dw\\ufffd\\ufffd\\ufffdk\\u1bc3U8\\ufffd\\ufffd\\ufffdd\\ufffd?MMi\\ufffd \\ufffd\\ufffd\\x03&\\ufffd{:\\ufffd\\ufffd\\u0467_'\\ufffdzH\\ufffd\\u0195\\ufffd\\ufffd\\x02\\u020e}\\ufffd\\ufffd\\x15#\\ufffd7\\ufffd\\ufffd8\\ufffd_#4\\x1fUs]\\ufffd\\ufffd\\t\\ufffd0\\x16i\\ufffd(\\ufffd\\x1fYW\\u049e\\ufffd\\ufffdu\\ufffd\\ufffd_\\x17R\\ufffd\\ufffd\\ufffdm\\ufffdaS\\x03O\\x16\\ufffd\nE         \nE         + /\\ufffd\\ufffd\\ufffdA6\\ufffd\\ufffd,y\\ufffd\\ufffd\\u056e\\ufffd6\\u01f2w\\ufffd1C\\ufffdb2<\\ufffd0\\u04b1C\\ufffd=\nE         \nE         + i\\ufffdC\\ufffdF\\ufffdI\\ufffd\\x18L|\\ufffd\\x18\\ufffdG\\ufffd\\ufffd\\ufffd`\\t\\ufffd\\ufffd\\ufffdl\\u033aO#N\\ufffdb_\\u020c\\ufffdx\\ufffd...\nE         \nE         ...Full output truncated (4 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:124: AssertionError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n        img_obj = lsb.hide(str(LENNA_PNG), secret)\n        revealed = lsb.reveal(img_obj)\n>       assert revealed == secret\nE       AssertionError: assert 'o\\ufffd\\ufffd@z\\ufffd\\ufffdT^\\ufffd\\ufffd\\ufffd...\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH' == 'object input'\nE         \nE         - object input\nE         + o\\ufffd\\ufffd@z\\ufffd\\ufffdT^\\ufffd\\ufffd\\ufffde=\\ufffd\\ufffdna\\ufffd\\x11\\ufffd\\ufffdd\\ufffd\\u03dc\\x7f\\ufffd\\ufffd\\ufffds\\u5be1D0\\x18\\ufffd\\ufffdl@?NL\\ufffd\\ufffd@\\ufffd\\ufffd\\x03 \\ufffdk\\ufffd\\ufffd\\ufffd\\u047fSe\\ufffdzH\\u0206\\ufffd\\ufffdH\n\ntests\\Stegano\\functional_test.py:134: AssertionError\n________________________ test_wav_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_wav_hide_and_reveal_text0')\n\n    def test_wav_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"wav.hide writes output WAV; wav.reveal returns the same string.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"wav secret\"\n        output = tmp_path / \"out.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert '' == 'wav secret'\nE         \nE         - wav secret\n\ntests\\Stegano\\functional_test.py:224: AssertionError\n_____________________ test_wav_hide_and_reveal_short_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_wav_hide_and_reveal_short0')\n\n    def test_wav_hide_and_reveal_short_text(tmp_path: Path) -> None:\n        \"\"\"A short message should also roundtrip.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"ok\"\n        output = tmp_path / \"out_short.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert '' == 'ok'\nE         \nE         - ok\n\ntests\\Stegano\\functional_test.py:239: AssertionError\n____________________ test_wav_hide_and_reveal_longer_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-443/test_wav_hide_and_reveal_longe0')\n\n    def test_wav_hide_and_reveal_longer_text(tmp_path: Path) -> None:\n        \"\"\"Roundtrip a longer ASCII message via WAV backend.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\"\n        output = tmp_path / \"out_long.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert '' == 'WAV backend ...nopqrstuvwxyz'\nE         \nE         - WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\n\ntests\\Stegano\\functional_test.py:254: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Asse...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_text - Asse...\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_short_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_longer_text\n7 failed, 5 passed in 2.85s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Tablib", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)", "returncode": 2, "elapsed_time_s": 1.823256, "avg_memory_mb": 36.62, "avg_cpu_percent": 99.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:21:03", "stdout_excerpt": "====\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:1: in <module>\n    from .core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:1: in <module>\n    from tablib.formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_json.py:2: in <module>\n    from tablib.core import Dataset, Databook\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.55s\n", "stdout_sha1": "d66cc3919e5024025084a51530f4f10e05ced731", "stdout_len": 1318, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:1: in <module>\n    from .core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:1: in <module>\n    from tablib.formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_json.py:2: in <module>\n    from tablib.core import Dataset, Databook\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.55s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Tabulate", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'tabulate.core'", "returncode": 2, "elapsed_time_s": 2.23087, "avg_memory_mb": 34.66, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:22:55", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Tabulate/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tabulate\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tabulate\\functional_test.py:67: in <module>\n    from tabulate import tabulate  # type: ignore  # noqa: E402\ngeneration\\Tabulate\\tabulate\\__init__.py:5: in <module>\n    from tabulate.core import tabulate\nE   ModuleNotFoundError: No module named 'tabulate.core'\n=========================== short test summary info ===========================\nERROR tests/Tabulate/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.70s\n", "stdout_sha1": "fccb67a40c5ae12151435d483acf07caf92f3899", "stdout_len": 1002, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Tabulate/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tabulate\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tabulate\\functional_test.py:67: in <module>\n    from tabulate import tabulate  # type: ignore  # noqa: E402\ngeneration\\Tabulate\\tabulate\\__init__.py:5: in <module>\n    from tabulate.core import tabulate\nE   ModuleNotFoundError: No module named 'tabulate.core'\n=========================== short test summary info ===========================\nERROR tests/Tabulate/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.70s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for /: 'str' and 'str'", "returncode": 1, "elapsed_time_s": 25.908554, "avg_memory_mb": 32.81, "avg_cpu_percent": 0.68, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 19:24:48", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B901670>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B901B20>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B960850>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:119: in draw\n    totals = [sum(row) for row in self.data.data]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000024E1B960580>\n\n>   totals = [sum(row) for row in self.data.data]\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:119: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B9715B0>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B971130>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nBars\n\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B960160>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = ", "stdout_sha1": "cd189a12657e13e29063c434107a7c4898cecb0a", "stdout_len": 14496, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B901670>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B901B20>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B960850>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:119: in draw\n    totals = [sum(row) for row in self.data.data]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000024E1B960580>\n\n>   totals = [sum(row) for row in self.data.data]\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:119: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B9715B0>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B971130>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nBars\n\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B960160>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B9600D0>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Values\n\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B8D0790>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Labels\", width=10, no_labels=True, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B8D0B50>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Labels\n\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B8F3130>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Suffix\", width=18, suffix=\"%\", format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B8F3220>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nSuffix\n\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B9607C0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Fmt\", width=20, format=\"{:>6.2f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B960550>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nFmt\n\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B9769A0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack Labels\", width=25, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:119: in draw\n    totals = [sum(row) for row in self.data.data]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000024E1B9763D0>\n\n>   totals = [sum(row) for row in self.data.data]\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:119: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack Labels\n\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B903610>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack No Values\", width=30, no_values=True, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:119: in draw\n    totals = [sum(row) for row in self.data.data]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000024E1B903A60>\n\n>   totals = [sum(row) for row in self.data.data]\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:119: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack No Values\n\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B8F2E80>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=None, width=15, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B8F2250>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000024E1B8F4FD0>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:83: in draw\n    normalized_data = self.normalize_data()\ngeneration\\Termgraph\\termgraph\\charts.py:41: in normalize_data\n    normalized.append([int((val / max_val) * self.args.width) for val in row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <str_iterator object at 0x0000024E1B8F47C0>\n\n>   normalized.append([int((val / max_val) * self.args.width) for val in row])\nE   TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:41: TypeError\n---------------------------- Captured stdout call -----------------------------\nNarrow\n\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 0.81s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where False = callable(None)", "returncode": 1, "elapsed_time_s": 2.159932, "avg_memory_mb": 16.42, "avg_cpu_percent": 48.0, "passed": 4, "failed": 8, "skipped": 0, "total": 12, "functional_score": 0.3333, "timestamp": "2026-01-01 19:26:52", "stdout_excerpt": "==== FAILURES ===================================\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-444/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46", "stdout_sha1": "fa588d2eb440f14fc4c2355f8cbdcfa68366ce29", "stdout_len": 9003, "stdout": "..FFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-444/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-444/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-444/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _import_no_command_rule() -> Tuple[Callable[[Any], Any], Callable[[Any], Any]]:\n        mod = importlib.import_module(\"thefuck.rules.no_command\")\n        match_fn = getattr(mod, \"match\", None)\n        get_new_fn = getattr(mod, \"get_new_command\", None)\n    \n>       assert callable(match_fn), \"thefuck.rules.no_command.match not found/callable\"\nE       AssertionError: thefuck.rules.no_command.match not found/callable\nE       assert False\nE        +  where False = callable(None)\n\ntests\\TheFuck\\functional_test.py:46: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n8 failed, 4 passed in 0.66s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "TinyDB", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'TinyDB' object has no attribute 'insert_multiple'", "returncode": 1, "elapsed_time_s": 2.321251, "avg_memory_mb": 16.41, "avg_cpu_percent": 48.15, "passed": 1, "failed": 11, "skipped": 0, "total": 12, "functional_score": 0.0833, "timestamp": "2026-01-01 19:28:36", "stdout_excerpt": "==== FAILURES ===================================\n___________________________ test_insert_and_search ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_insert_and_search0')\n\n    def test_insert_and_search(tmp_path: Path) -> None:\n        \"\"\"Basic insert + search on the default table.\"\"\"\n        db_path = tmp_path / \"db.json\"\n        db = TinyDB(str(db_path))\n    \n        User = Query()\n>       db.insert({\"name\": \"Alice\", \"age\": 30})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:63: AttributeError\n_______________________ test_multiple_tables_isolation ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_multiple_tables_isolation0')\n\n    def test_multiple_tables_isolation(tmp_path: Path) -> None:\n        \"\"\"Data in different tables should be isolated.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"write code\", \"done\": False})\n        tasks.insert({\"title\": \"write tests\", \"done\": False})\n        logs.insert({\"event\": \"created_tasks\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:88: TypeError\n___________________________ test_update_and_remove ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_update_and_remove0')\n\n    def test_update_and_remove(tmp_path: Path) -> None:\n        \"\"\"Update and remove operations should work on matching documents.\"\"\"\n        db = _open_db(tmp_path)\n    \n        Task = Query()\n        table = db.table(\"tasks\")\n    \n        table.insert({\"title\": \"task-1\", \"done\": False})\n        table.insert({\"title\": \"task-2\", \"done\": False})\n        table.insert({\"title\": \"task-3\", \"done\": False})\n    \n>       table.update({\"done\": True}, Task.title == \"task-2\")\nE       AttributeError: 'Query' object has no attribute 'title'\n\ntests\\TinyDB\\functional_test.py:108: AttributeError\n_________________________ test_where_helper_querying __________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_where_helper_querying0')\n\n    def test_where_helper_querying(tmp_path: Path) -> None:\n        \"\"\"where('field') helper should build a working query for search().\"\"\"\n        db = _open_db(tmp_path)\n>       db.insert({\"name\": \"Alice\", \"city\": \"Tokyo\"})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:125: AttributeError\n______________________ test_get_returns_single_document _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_get_returns_single_docume0')\n\n    def test_get_returns_single_document(tmp_path: Path) -> None:\n        \"\"\"get(query) should retrieve one matching document.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n>       db.insert({\"name\": \"Alice\", \"age\": 30})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:140: AttributeError\n________________________ test_insert_multiple_and_all _________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_insert_multiple_and_all0')\n\n    def test_insert_multiple_and_all(tmp_path: Path) -> None:\n        \"\"\"insert_multiple should add several documents and return their ids.\"\"\"\n        db = _open_db(tmp_path)\n    \n        docs = [\n            {\"k\": \"a\", \"v\": 1},\n            {\"k\": \"b\", \"v\": 2},\n            {\"k\": \"c\", \"v\": 3},\n        ]\n>       ids = db.insert_multiple(docs)\nE       AttributeError: 'TinyDB' object has no attribute 'insert_multiple'\n\ntests\\TinyDB\\functional_test.py:160: AttributeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_pa", "stdout_sha1": "714575f3d7048e2429fc23cb4f3c86c17447a9a9", "stdout_len": 8096, "stdout": "FFFFFFFFFFF.                                                             [100%]\n================================== FAILURES ===================================\n___________________________ test_insert_and_search ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_insert_and_search0')\n\n    def test_insert_and_search(tmp_path: Path) -> None:\n        \"\"\"Basic insert + search on the default table.\"\"\"\n        db_path = tmp_path / \"db.json\"\n        db = TinyDB(str(db_path))\n    \n        User = Query()\n>       db.insert({\"name\": \"Alice\", \"age\": 30})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:63: AttributeError\n_______________________ test_multiple_tables_isolation ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_multiple_tables_isolation0')\n\n    def test_multiple_tables_isolation(tmp_path: Path) -> None:\n        \"\"\"Data in different tables should be isolated.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"write code\", \"done\": False})\n        tasks.insert({\"title\": \"write tests\", \"done\": False})\n        logs.insert({\"event\": \"created_tasks\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:88: TypeError\n___________________________ test_update_and_remove ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_update_and_remove0')\n\n    def test_update_and_remove(tmp_path: Path) -> None:\n        \"\"\"Update and remove operations should work on matching documents.\"\"\"\n        db = _open_db(tmp_path)\n    \n        Task = Query()\n        table = db.table(\"tasks\")\n    \n        table.insert({\"title\": \"task-1\", \"done\": False})\n        table.insert({\"title\": \"task-2\", \"done\": False})\n        table.insert({\"title\": \"task-3\", \"done\": False})\n    \n>       table.update({\"done\": True}, Task.title == \"task-2\")\nE       AttributeError: 'Query' object has no attribute 'title'\n\ntests\\TinyDB\\functional_test.py:108: AttributeError\n_________________________ test_where_helper_querying __________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_where_helper_querying0')\n\n    def test_where_helper_querying(tmp_path: Path) -> None:\n        \"\"\"where('field') helper should build a working query for search().\"\"\"\n        db = _open_db(tmp_path)\n>       db.insert({\"name\": \"Alice\", \"city\": \"Tokyo\"})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:125: AttributeError\n______________________ test_get_returns_single_document _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_get_returns_single_docume0')\n\n    def test_get_returns_single_document(tmp_path: Path) -> None:\n        \"\"\"get(query) should retrieve one matching document.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n>       db.insert({\"name\": \"Alice\", \"age\": 30})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:140: AttributeError\n________________________ test_insert_multiple_and_all _________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_insert_multiple_and_all0')\n\n    def test_insert_multiple_and_all(tmp_path: Path) -> None:\n        \"\"\"insert_multiple should add several documents and return their ids.\"\"\"\n        db = _open_db(tmp_path)\n    \n        docs = [\n            {\"k\": \"a\", \"v\": 1},\n            {\"k\": \"b\", \"v\": 2},\n            {\"k\": \"c\", \"v\": 3},\n        ]\n>       ids = db.insert_multiple(docs)\nE       AttributeError: 'TinyDB' object has no attribute 'insert_multiple'\n\ntests\\TinyDB\\functional_test.py:160: AttributeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_contains_and_count0')\n\n    def test_contains_and_count(tmp_path: Path) -> None:\n        \"\"\"contains and count should reflect stored data and queries.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n>       db.insert({\"name\": \"Alice\", \"age\": 30})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:176: AttributeError\n_____________________ test_persistence_reopen_and_search ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_persistence_reopen_and_se0')\n\n    def test_persistence_reopen_and_search(tmp_path: Path) -> None:\n        \"\"\"Data should persist on disk and be readable after reopening.\"\"\"\n        db_path = tmp_path / \"persist.json\"\n    \n        db1 = TinyDB(str(db_path))\n>       db1.insert({\"name\": \"Ada\", \"lang\": \"Python\"})\nE       AttributeError: 'TinyDB' object has no attribute 'insert'\n\ntests\\TinyDB\\functional_test.py:194: AttributeError\n_________________ test_table_truncate_clears_only_that_table __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_table_truncate_clears_onl0')\n\n    def test_table_truncate_clears_only_that_table(tmp_path: Path) -> None:\n        \"\"\"truncate on a table should clear its rows without affecting other tables.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"t1\"})\n        tasks.insert({\"title\": \"t2\"})\n        logs.insert({\"event\": \"created\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:215: TypeError\n____________________________ test_update_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_update_by_doc_id0')\n\n    def test_update_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"update with doc_ids should modify the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        doc_id = table.insert({\"name\": \"ItemA\", \"qty\": 1})\n>       assert len(table) == 1\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:231: TypeError\n____________________________ test_remove_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-445/test_remove_by_doc_id0')\n\n    def test_remove_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"remove with doc_ids should delete the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        id1 = table.insert({\"name\": \"A\"})\n        id2 = table.insert({\"name\": \"B\"})\n>       assert len(table) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:249: TypeError\n=========================== short test summary info ===========================\nFAILED tests/TinyDB/functional_test.py::test_insert_and_search - AttributeErr...\nFAILED tests/TinyDB/functional_test.py::test_multiple_tables_isolation - Type...\nFAILED tests/TinyDB/functional_test.py::test_update_and_remove - AttributeErr...\nFAILED tests/TinyDB/functional_test.py::test_where_helper_querying - Attribut...\nFAILED tests/TinyDB/functional_test.py::test_get_returns_single_document - At...\nFAILED tests/TinyDB/functional_test.py::test_insert_multiple_and_all - Attrib...\nFAILED tests/TinyDB/functional_test.py::test_contains_and_count - AttributeEr...\nFAILED tests/TinyDB/functional_test.py::test_persistence_reopen_and_search - ...\nFAILED tests/TinyDB/functional_test.py::test_table_truncate_clears_only_that_table\nFAILED tests/TinyDB/functional_test.py::test_update_by_doc_id - TypeError: ob...\nFAILED tests/TinyDB/functional_test.py::test_remove_by_doc_id - TypeError: ob...\n11 failed, 1 passed in 0.83s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "SystemExit: 2", "returncode": 1, "elapsed_time_s": 23.564776, "avg_memory_mb": 35.87, "avg_cpu_percent": 0.67, "passed": 2, "failed": 10, "skipped": 0, "total": 12, "functional_score": 0.1667, "timestamp": "2026-01-01 19:30:13", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n        app = _create_greeter_app()\n>       result = runner.invoke(app, [\"World\"])\n\ntests\\Typer\\functional_test.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1821: in parse_args\n    self.error(msg % ' '.join(argv))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2575: in error\n    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 2, message = '__main__.py: error: unrecognized arguments: World\\n'\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 2\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n        app = _create_greeter_app()\n        # Safer ordering across Click versions: options before args.\n>       result = runner.invoke(app, [\"--excited\", \"World\"])\n\ntests\\Typer\\functional_test.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1821: in parse_args\n    self.error(msg % ' '.join(argv))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2575: in error\n    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 2\nmessage = '__main__.py: error: unrecognized arguments: --excited World\\n'\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 2\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n        app = _create_greeter_app()\n>       result = runner.invoke(app, [\"--help\"])\n\ntests\\Typer\\functional_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1818: in parse_args\n    args, argv = self.parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1851: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2060: in _parse_known_args\n    start_index = consume_optional(start_index)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2000: in consume_optional\n    take_action(action, args, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1928: in ", "stdout_sha1": "c4747ce838d95beb722d138eea92d1119db2e758", "stdout_len": 16901, "stdout": "FFF..FFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n        app = _create_greeter_app()\n>       result = runner.invoke(app, [\"World\"])\n\ntests\\Typer\\functional_test.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1821: in parse_args\n    self.error(msg % ' '.join(argv))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2575: in error\n    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 2, message = '__main__.py: error: unrecognized arguments: World\\n'\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 2\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n        app = _create_greeter_app()\n        # Safer ordering across Click versions: options before args.\n>       result = runner.invoke(app, [\"--excited\", \"World\"])\n\ntests\\Typer\\functional_test.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1821: in parse_args\n    self.error(msg % ' '.join(argv))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2575: in error\n    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 2\nmessage = '__main__.py: error: unrecognized arguments: --excited World\\n'\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 2\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n        app = _create_greeter_app()\n>       result = runner.invoke(app, [\"--help\"])\n\ntests\\Typer\\functional_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1818: in parse_args\n    args, argv = self.parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1851: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2060: in _parse_known_args\n    start_index = consume_optional(start_index)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2000: in consume_optional\n    take_action(action, args, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1928: in take_action\n    action(self, namespace, argument_values, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1093: in __call__\n    parser.exit()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 0, message = None\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 0\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result 1>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n        app = _create_todo_app()\n>       result = runner.invoke(app, [\"--help\"])\n\ntests\\Typer\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1818: in parse_args\n    args, argv = self.parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1851: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2060: in _parse_known_args\n    start_index = consume_optional(start_index)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2000: in consume_optional\n    take_action(action, args, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1928: in take_action\n    action(self, namespace, argument_values, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1093: in __call__\n    parser.exit()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 0, message = None\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 0\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n>       result = runner.invoke(app, [\"add\", \"--help\"])\n\ntests\\Typer\\functional_test.py:273: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1818: in parse_args\n    args, argv = self.parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1851: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2042: in _parse_known_args\n    positionals_end_index = consume_positionals(start_index)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2019: in consume_positionals\n    take_action(action, args)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1928: in take_action\n    action(self, namespace, argument_values, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1207: in __call__\n    subnamespace, arg_strings = parser.parse_known_args(arg_strings, None)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1851: in parse_known_args\n    namespace, args = self._parse_known_args(args, namespace)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2060: in _parse_known_args\n    start_index = consume_optional(start_index)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2000: in consume_optional\n    take_action(action, args, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1928: in take_action\n    action(self, namespace, argument_values, option_string)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1093: in __call__\n    parser.exit()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py add', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 0, message = None\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 0\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000023B77313370>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n        app = _create_callback_app()\n    \n        r1 = runner.invoke(app, [\"run\"])\n        assert r1.exit_code == 0\n        assert \"running\" in r1.stdout\n        assert \"verbose\" not in r1.stdout\n    \n>       r2 = runner.invoke(app, [\"--verbose\", \"run\"])\n\ntests\\Typer\\functional_test.py:304: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Typer\\typer\\testing\\runner.py:62: in invoke\n    exit_code = cli()\ngeneration\\Typer\\typer\\main.py:112: in __call__\n    args = self.parser.parse_args()\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1821: in parse_args\n    self.error(msg % ' '.join(argv))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2575: in error\n    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nstatus = 2, message = '__main__.py: error: unrecognized arguments: --verbose\\n'\n\n    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n>       _sys.exit(status)\nE       SystemExit: 2\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562: SystemExit\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n>       app = _create_types_app()\n\ntests\\Typer\\functional_test.py:310: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:181: in _create_types_app\n    def calc(x: int, y: int, scale: float = typer.Option(1.0, \"--scale\")) -> None:\ngeneration\\Typer\\typer\\main.py:60: in decorator\n    parser.add_argument(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = ArgumentParser(prog='__main__.py calc', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\nargs = ('--scale',)\nkwargs = {'default': 1.0, 'dest': 'scale', 'help': ' (default: 1.0)', 'option_strings': ['--scale'], ...}\nchars = '-', action_class = <class 'argparse._StoreAction'>\naction = _StoreAction(option_strings=['--scale'], dest='scale', nargs=None, const=None, default=1.0, type='float', choices=None, help=' (default: 1.0)', metavar=None)\ntype_func = 'float'\n\n    def add_argument(self, *args, **kwargs):\n        \"\"\"\n        add_argument(dest, ..., name=value, ...)\n        add_argument(option_string, option_string, ..., name=value, ...)\n        \"\"\"\n    \n        # if no positional args are supplied or only one is supplied and\n        # it doesn't look like an option string, parse a positional\n        # argument\n        chars = self.prefix_chars\n        if not args or len(args) == 1 and args[0][0] not in chars:\n            if args and 'dest' in kwargs:\n                raise ValueError('dest supplied twice for positional argument')\n            kwargs = self._get_positional_kwargs(*args, **kwargs)\n    \n        # otherwise, we're adding an optional argument\n        else:\n            kwargs = self._get_optional_kwargs(*args, **kwargs)\n    \n        # if no default was supplied, use the parser-level default\n        if 'default' not in kwargs:\n            dest = kwargs['dest']\n            if dest in self._defaults:\n                kwargs['default'] = self._defaults[dest]\n            elif self.argument_default is not None:\n                kwargs['default'] = self.argument_default\n    \n        # create the action object, and add it to the parser\n        action_class = self._pop_action_class(kwargs)\n        if not callable(action_class):\n            raise ValueError('unknown action \"%s\"' % (action_class,))\n        action = action_class(**kwargs)\n    \n        # raise an error if the action type is not callable\n        type_func = self._registry_get('type', action.type, action.type)\n        if not callable(type_func):\n>           raise ValueError('%r is not callable' % (type_func,))\nE           ValueError: 'float' is not callable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1421: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - SystemExit: 2\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - Sy...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_help_output_includes_commands - S...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n10 failed, 2 passed in 22.19s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'watchdog.observers.api'", "returncode": 2, "elapsed_time_s": 2.113135, "avg_memory_mb": 35.33, "avg_cpu_percent": 99.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:32:02", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:54: in <module>\n    from watchdog.observers import Observer  # type: ignore  # noqa: E402\ngeneration\\Watchdog\\watchdog\\observers\\__init__.py:9: in <module>\n    from watchdog.observers.api import Observer\nE   ModuleNotFoundError: No module named 'watchdog.observers.api'\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.66s\n", "stdout_sha1": "3455725165c811ccfb9c1b4ea99aa72bfcf522d8", "stdout_len": 1040, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:54: in <module>\n    from watchdog.observers import Observer  # type: ignore  # noqa: E402\ngeneration\\Watchdog\\watchdog\\observers\\__init__.py:9: in <module>\n    from watchdog.observers.api import Observer\nE   ModuleNotFoundError: No module named 'watchdog.observers.api'\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.66s\n"}
{"model": "claude-3.7-sonnet-20250219-thinking", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'list' object has no attribute 'items'", "returncode": 1, "elapsed_time_s": 25.777486, "avg_memory_mb": 34.44, "avg_cpu_percent": 0.57, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-01 19:33:59", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B0477CD0>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B04DA670>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n_______________________ test_parse_attributes_and_text ________________________\n\n    def test_parse_attributes_and_text() -> None:\n        \"\"\"Attributes and text content should be exposed using @attr and #text keys.\"\"\"\n        xml = '<user id=\"123\">Alice</user>'\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B034AB80>, name = 'user'\nattrs = ['id', '123']\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n___________________ test_unparse_roundtrip_basic_structure ____________________\n\n    def test_unparse_roundtrip_basic_structure() -> None:\n        \"\"\"unparse() followed by parse() should preserve the logical structure.\"\"\"\n        original = {\n            \"root\": {\n                \"item\": [\n                    {\"@id\": \"1\", \"#text\": \"A\"},\n                    {\"@id\": \"2\", \"#text\": \"B\"},\n                ]\n ", "stdout_sha1": "c2ee00ec78a43b24da7d1a20553b85c769cae96e", "stdout_len": 16605, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B0477CD0>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B04DA670>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n_______________________ test_parse_attributes_and_text ________________________\n\n    def test_parse_attributes_and_text() -> None:\n        \"\"\"Attributes and text content should be exposed using @attr and #text keys.\"\"\"\n        xml = '<user id=\"123\">Alice</user>'\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B034AB80>, name = 'user'\nattrs = ['id', '123']\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n___________________ test_unparse_roundtrip_basic_structure ____________________\n\n    def test_unparse_roundtrip_basic_structure() -> None:\n        \"\"\"unparse() followed by parse() should preserve the logical structure.\"\"\"\n        original = {\n            \"root\": {\n                \"item\": [\n                    {\"@id\": \"1\", \"#text\": \"A\"},\n                    {\"@id\": \"2\", \"#text\": \"B\"},\n                ]\n            }\n        }\n    \n        xml = _unparse(original)\n>       round_tripped = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B04DE340>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B04D91F0>, name = 'root'\nattrs = ['xmlns:x', 'http://example.com/x']\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:150: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B04EAAF0>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n>       data = _parse(xml, force_list=(\"item\",))\n\ntests\\Xmltodict\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B05658B0>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n_____________ test_custom_attr_prefix_and_cdata_key_if_supported ______________\n\n    def test_custom_attr_prefix_and_cdata_key_if_supported() -> None:\n        \"\"\"attr_prefix / cdata_key customization should reflect in output when supported.\"\"\"\n        xml = '<user id=\"7\">Bob</user>'\n    \n>       data = _parse(xml, attr_prefix=\"$\", cdata_key=\"text\")\n\ntests\\Xmltodict\\functional_test.py:176: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B0360F70>, name = 'user'\nattrs = ['id', '7']\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n>       data = _parse(xml, xml_attribs=False)\n\ntests\\Xmltodict\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B036B400>, name = 'user'\nattrs = ['id', '9']\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n______________________ test_dict_constructor_ordereddict ______________________\n\n    def test_dict_constructor_ordereddict() -> None:\n        \"\"\"dict_constructor should allow choosing mapping type (e.g., OrderedDict) when supported.\"\"\"\n        xml = \"<root><a>1</a><b>2</b></root>\"\n>       data = _parse(xml, dict_constructor=OrderedDict)\n\ntests\\Xmltodict\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B04DABB0>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n_____________________ test_unparse_pretty_and_parse_back ______________________\n\n    def test_unparse_pretty_and_parse_back() -> None:\n        \"\"\"Pretty/full_document knobs should not break roundtrip of basic structure.\"\"\"\n        original: Dict[str, Any] = {\"root\": {\"x\": \"1\", \"y\": \"2\"}}\n    \n        xml = _unparse(original, pretty=True, full_document=True)\n        assert \"<root>\" in xml or \"<root\" in xml\n    \n>       round_tripped = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:226: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B0477D60>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n______________ test_postprocessor_transforms_value_if_supported _______________\n\n    def test_postprocessor_transforms_value_if_supported() -> None:\n        \"\"\"postprocessor can transform values in a happy-path parse when supported.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n    \n        def _pp(path: Any, key: str, value: Any) -> Any:\n            if key == \"message\" and isinstance(value, str):\n                return key, value.upper()\n            return key, value\n    \n>       data = _parse(xml, postprocessor=_pp)\n\ntests\\Xmltodict\\functional_test.py:239: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:86: in parse\n    parser.Parse(xml_input)\nC:\\A\\31\\s\\Modules\\pyexpat.c:407: in StartElement\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <xmltodict._DictSAXHandler object at 0x00000281B034A8B0>, name = 'root'\nattrs = []\n\n    def start_element(self, name, attrs):\n        name = self._build_name(name)\n        attrs = self.dict_constructor([(self._build_name(key), value)\n>                                     for key, value in attrs.items()])\nE       AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Xmltodict\\xmltodict.py:175: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_parse_simple_element - Attrib...\nFAILED tests/Xmltodict/functional_test.py::test_parse_repeated_elements_as_list\nFAILED tests/Xmltodict/functional_test.py::test_parse_attributes_and_text - A...\nFAILED tests/Xmltodict/functional_test.py::test_unparse_roundtrip_basic_structure\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\nFAILED tests/Xmltodict/functional_test.py::test_parse_nested_structure - Attr...\nFAILED tests/Xmltodict/functional_test.py::test_force_list_option_for_single_element\nFAILED tests/Xmltodict/functional_test.py::test_custom_attr_prefix_and_cdata_key_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_xml_attribs_false_drops_attributes_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_dict_constructor_ordereddict\nFAILED tests/Xmltodict/functional_test.py::test_unparse_pretty_and_parse_back\nFAILED tests/Xmltodict/functional_test.py::test_postprocessor_transforms_value_if_supported\n12 failed in 24.40s\n"}
{"model": "claude-4.5-haiku", "project": "Astral", "failure_stage": "pre-test", "failure_type": "syntax_error", "exception_type": "SyntaxError", "exception_msg": "unmatched ')'", "returncode": 2, "elapsed_time_s": 2.38695, "avg_memory_mb": 36.95, "avg_cpu_percent": 95.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:28:10", "stdout_excerpt": "====\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\ngeneration\\Astral\\astral\\__init__.py:6: in <module>\n    from .sun import sun, sunrise, sunset\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Astral\\astral\\sun.py\", line 77\nE       seconds = 21.448 - t * (4680.93 + t * (1.55 + t * (1999.25 - t * (51.38 + t * (249.67 + t * (-39.05 + t * (7.12 + t * (12.36 + t * (-1.06 + t * 0.01801))))))))))\nE                                                                                                                                                                       ^\nE   SyntaxError: unmatched ')'\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.86s\n", "stdout_sha1": "52fa1a3124442b58f15030be46c299b06fd008e8", "stdout_len": 1896, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\ngeneration\\Astral\\astral\\__init__.py:6: in <module>\n    from .sun import sun, sunrise, sunset\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Astral\\astral\\sun.py\", line 77\nE       seconds = 21.448 - t * (4680.93 + t * (1.55 + t * (1999.25 - t * (51.38 + t * (249.67 + t * (-39.05 + t * (7.12 + t * (12.36 + t * (-1.06 + t * 0.01801))))))))))\nE                                                                                                                                                                       ^\nE   SyntaxError: unmatched ')'\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.86s\n"}
{"model": "claude-4.5-haiku", "project": "Cachetools", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "StopIteration", "returncode": 1, "elapsed_time_s": 3.480365, "avg_memory_mb": 33.25, "avg_cpu_percent": 54.9, "passed": 11, "failed": 2, "skipped": 0, "total": 13, "functional_score": 0.8462, "timestamp": "2026-01-01 11:28:43", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_lru_cache_clear_resets_state ______________________\n\n    def test_lru_cache_clear_resets_state():\n        cache = LRUCache(maxsize=2)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n        assert len(cache) == 2\n    \n>       cache.clear()\n\ntests\\Cachetools\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_collections_abc.py:844: in clear\n    self.popitem()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache({}, maxsize=2)\n\n    def popitem(self):\n        \"\"\"Remove and return the least recently used (key, value) pair.\"\"\"\n        # Get the first (least recently used) key\n>       key = next(iter(self.__order))\nE       StopIteration\n\ngeneration\\Cachetools\\cachetools\\lru.py:57: StopIteration\n_____________ test_cached_decorator_cache_clear_forces_recompute ______________\n\n    def test_cached_decorator_cache_clear_forces_recompute():\n        cache = LRUCache(maxsize=32)\n        calls = {\"count\": 0}\n    \n        @cached(cache=cache)\n        def f(x: int) -> int:\n            calls[\"count\"] += 1\n            return x + 1\n    \n        assert f(1) == 2\n        assert calls[\"count\"] == 1\n        assert f(1) == 2\n        assert calls[\"count\"] == 1  # cached\n    \n>       cache.clear()\n\ntests\\Cachetools\\functional_test.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_collections_abc.py:844: in clear\n    self.popitem()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache({}, maxsize=32)\n\n    def popitem(self):\n        \"\"\"Remove and return the least recently used (key, value) pair.\"\"\"\n        # Get the first (least recently used) key\n>       key = next(iter(self.__order))\nE       StopIteration\n\ngeneration\\Cachetools\\cachetools\\lru.py:57: StopIteration\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_clear_resets_state\nFAILED tests/Cachetools/functional_test.py::test_cached_decorator_cache_clear_forces_recompute\n2 failed, 11 passed in 2.10s\n", "stdout_sha1": "31494f591bd2c2056fbf184ec0eca46be494989a", "stdout_len": 2431, "stdout": "......F...F..                                                            [100%]\n================================== FAILURES ===================================\n______________________ test_lru_cache_clear_resets_state ______________________\n\n    def test_lru_cache_clear_resets_state():\n        cache = LRUCache(maxsize=2)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n        assert len(cache) == 2\n    \n>       cache.clear()\n\ntests\\Cachetools\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_collections_abc.py:844: in clear\n    self.popitem()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache({}, maxsize=2)\n\n    def popitem(self):\n        \"\"\"Remove and return the least recently used (key, value) pair.\"\"\"\n        # Get the first (least recently used) key\n>       key = next(iter(self.__order))\nE       StopIteration\n\ngeneration\\Cachetools\\cachetools\\lru.py:57: StopIteration\n_____________ test_cached_decorator_cache_clear_forces_recompute ______________\n\n    def test_cached_decorator_cache_clear_forces_recompute():\n        cache = LRUCache(maxsize=32)\n        calls = {\"count\": 0}\n    \n        @cached(cache=cache)\n        def f(x: int) -> int:\n            calls[\"count\"] += 1\n            return x + 1\n    \n        assert f(1) == 2\n        assert calls[\"count\"] == 1\n        assert f(1) == 2\n        assert calls[\"count\"] == 1  # cached\n    \n>       cache.clear()\n\ntests\\Cachetools\\functional_test.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_collections_abc.py:844: in clear\n    self.popitem()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache({}, maxsize=32)\n\n    def popitem(self):\n        \"\"\"Remove and return the least recently used (key, value) pair.\"\"\"\n        # Get the first (least recently used) key\n>       key = next(iter(self.__order))\nE       StopIteration\n\ngeneration\\Cachetools\\cachetools\\lru.py:57: StopIteration\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_clear_resets_state\nFAILED tests/Cachetools/functional_test.py::test_cached_decorator_cache_clear_forces_recompute\n2 failed, 11 passed in 2.10s\n"}
{"model": "claude-4.5-haiku", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword argument 'include'", "returncode": 1, "elapsed_time_s": 2.09253, "avg_memory_mb": 32.65, "avg_cpu_percent": 100.0, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2026-01-01 11:29:19", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=", "stdout_sha1": "ae02555b215bfd487100edf3323412b2011e843c", "stdout_len": 8919, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n>       app = _make_app(\"celery_test_app_2\")\n\ntests\\Celery\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app_2'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.76s\n"}
{"model": "claude-4.5-haiku", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where 1 = <Result exit_code=1>.exit_code", "returncode": 1, "elapsed_time_s": 5.691336, "avg_memory_mb": 32.26, "avg_cpu_percent": 97.5, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 11:30:16", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n        def greet(count: int, name: str) -> None:\n            for _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n        runner = CliRunner()\n        result = runner.invoke(greet, [\"--count\", \"3\", \"World\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:143: AssertionError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n        @cli.command()\n        @click.argument(\"name\")\n        def hello(name: str) -> None:\n            click.echo(f\"Hello {name}\")\n    \n        @cli.command()\n        @click.argument(\"name\")\n        def goodbye(name: str) -> None:\n            click.echo(f\"Goodbye {name}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"hello\", \"Alice\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:183: AssertionError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n        @cli.command(help=\"Say hello\")\n        @click.option(\"--shout/--no-shout\", default=False)\n        @click.argument(\"name\")\n        def hello(name: str, shout: bool) -> None:\n            msg = f\"Hello {name}\"\n            if shout:\n                msg = msg.upper()\n            click.echo(msg)\n    \n        runner = CliRunner()\n    \n        group_help = runner.invoke(cli, [\"--help\"])\n        assert group_help.exit_code == 0\n>       assert \"Top level group\" in group_help.output\nE       AssertionError: assert 'Top level group' in ''\nE        +  where '' = <Result exit_code=0>.output\n\ntests\\Click\\functional_test.py:209: AssertionError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n        @cli.command()\n        def show() -> None:\n            ctx = click.get_current_context()\n            cfg = ctx.obj.get(\"config\")\n            click.echo(f\"CONFIG={cfg}\")\n    \n        runner = CliRunner()\n        result = runner.invoke(cli, [\"--config\", \"custom.cfg\", \"show\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:235: AssertionError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert res", "stdout_sha1": "f0c74928870ae9455b797f1706cbf5220170cf66", "stdout_len": 8275, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n        def greet(count: int, name: str) -> None:\n            for _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n        runner = CliRunner()\n        result = runner.invoke(greet, [\"--count\", \"3\", \"World\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:143: AssertionError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n        @cli.command()\n        @click.argument(\"name\")\n        def hello(name: str) -> None:\n            click.echo(f\"Hello {name}\")\n    \n        @cli.command()\n        @click.argument(\"name\")\n        def goodbye(name: str) -> None:\n            click.echo(f\"Goodbye {name}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"hello\", \"Alice\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:183: AssertionError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n        @cli.command(help=\"Say hello\")\n        @click.option(\"--shout/--no-shout\", default=False)\n        @click.argument(\"name\")\n        def hello(name: str, shout: bool) -> None:\n            msg = f\"Hello {name}\"\n            if shout:\n                msg = msg.upper()\n            click.echo(msg)\n    \n        runner = CliRunner()\n    \n        group_help = runner.invoke(cli, [\"--help\"])\n        assert group_help.exit_code == 0\n>       assert \"Top level group\" in group_help.output\nE       AssertionError: assert 'Top level group' in ''\nE        +  where '' = <Result exit_code=0>.output\n\ntests\\Click\\functional_test.py:209: AssertionError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n        @cli.command()\n        def show() -> None:\n            ctx = click.get_current_context()\n            cfg = ctx.obj.get(\"config\")\n            click.echo(f\"CONFIG={cfg}\")\n    \n        runner = CliRunner()\n        result = runner.invoke(cli, [\"--config\", \"custom.cfg\", \"show\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:235: AssertionError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert result.exit_code != 0\n>       assert isinstance(result.exception, CustomError)\nE       AssertionError: assert False\nE        +  where False = isinstance(None, <class 'functional_test.test_command_exception_is_exposed_in_result.<locals>.CustomError'>)\nE        +    where None = <Result exit_code=1>.exception\n\ntests\\Click\\functional_test.py:251: AssertionError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n        def cli(name: str) -> None:\n            click.echo(f\"NAME={name}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:269: AssertionError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:285: AssertionError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n        @cli.command()\n        @click.option(\"--count\", type=int, default=1)\n        def run(count: int) -> None:\n            click.echo(f\"COUNT={count}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [\"run\"], default_map={\"run\": {\"count\": 7}})\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Click\\functional_test.py:301: AssertionError\n_______________ test_parameter_type_validation_error_exit_code ________________\n\n    def test_parameter_type_validation_error_exit_code():\n        @click.command()\n        @click.option(\"--count\", type=int, required=True)\n        def cli(count: int) -> None:\n            click.echo(f\"COUNT={count}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [\"--count\", \"not-an-int\"])\n        assert r.exit_code != 0\n>       assert (\"Invalid value\" in r.output) or (\"Error\" in r.output)\nE       AssertionError: assert ('Invalid value' in '' or 'Error' in '')\nE        +  where '' = <Result exit_code=1>.output\nE        +  and   '' = <Result exit_code=1>.output\n\ntests\\Click\\functional_test.py:314: AssertionError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - assert 1...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_command_exception_is_exposed_in_result\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - a...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n11 failed in 4.27s\n"}
{"model": "claude-4.5-haiku", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "xpected: 150.0", "returncode": 1, "elapsed_time_s": 5.196673, "avg_memory_mb": 34.02, "avg_cpu_percent": 97.6, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 11:31:56", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x0000022578BFCC10>\nfilters = {'age': {'>=': 40}}, where_parts = ['age = ?']\nwhere_values = [{'>=': 40}], col = 'age', val = {'>=': 40}\nwhere_clause = 'age = ?', sql = 'SELECT * FROM users WHERE age = ?'\n\n    def find(self, **filters):\n        \"\"\"\n        Find rows matching the given filters.\n    \n        Args:\n            **filters: Column name to value mappings for WHERE clause\n    \n        Yields:\n            Row dictionaries.\n        \"\"\"\n        if not self._table_exists():\n            return\n    \n        if not filters:\n            # No filters, return all rows\n            for row in self.all():\n                yield row\n            return\n    \n        # Build WHERE clause\n        where_parts = []\n        where_values = []\n        for col, val in filters.items():\n            where_parts.append(f\"{col} = ?\")\n            where_values.append(val)\n    \n        where_clause = ' AND '.join(where_parts)\n        sql = f\"SELECT * FROM {self.name} WHERE {where_clause}\"\n    \n        cursor = self.database._connection.cursor()\n        cursor.row_factory = sqlite3.Row\n>       cursor.execute(sql, where_values)\nE       sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\table.py:281: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n>       rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n\ntests\\Dataset\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x0000022578C5F9D0>\nfilters = {'_limit': 3, '_offset': 4, 'order_by': 'n'}\nwhere_parts = ['order_by = ?', '_limit = ?', '_offset = ?']\nwhere_values = ['n', 3, 4], col = '_offset', val = 4\nwhere_clause = 'order_by = ? AND _limit = ", "stdout_sha1": "cbe52ca2ad64dc23fa3a43e66d4b3d701a80b655", "stdout_len": 6896, "stdout": "FF...F..F.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x0000022578BFCC10>\nfilters = {'age': {'>=': 40}}, where_parts = ['age = ?']\nwhere_values = [{'>=': 40}], col = 'age', val = {'>=': 40}\nwhere_clause = 'age = ?', sql = 'SELECT * FROM users WHERE age = ?'\n\n    def find(self, **filters):\n        \"\"\"\n        Find rows matching the given filters.\n    \n        Args:\n            **filters: Column name to value mappings for WHERE clause\n    \n        Yields:\n            Row dictionaries.\n        \"\"\"\n        if not self._table_exists():\n            return\n    \n        if not filters:\n            # No filters, return all rows\n            for row in self.all():\n                yield row\n            return\n    \n        # Build WHERE clause\n        where_parts = []\n        where_values = []\n        for col, val in filters.items():\n            where_parts.append(f\"{col} = ?\")\n            where_values.append(val)\n    \n        where_clause = ' AND '.join(where_parts)\n        sql = f\"SELECT * FROM {self.name} WHERE {where_clause}\"\n    \n        cursor = self.database._connection.cursor()\n        cursor.row_factory = sqlite3.Row\n>       cursor.execute(sql, where_values)\nE       sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\table.py:281: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n>       rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n\ntests\\Dataset\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x0000022578C5F9D0>\nfilters = {'_limit': 3, '_offset': 4, 'order_by': 'n'}\nwhere_parts = ['order_by = ?', '_limit = ?', '_offset = ?']\nwhere_values = ['n', 3, 4], col = '_offset', val = 4\nwhere_clause = 'order_by = ? AND _limit = ? AND _offset = ?'\nsql = 'SELECT * FROM nums WHERE order_by = ? AND _limit = ? AND _offset = ?'\n\n    def find(self, **filters):\n        \"\"\"\n        Find rows matching the given filters.\n    \n        Args:\n            **filters: Column name to value mappings for WHERE clause\n    \n        Yields:\n            Row dictionaries.\n        \"\"\"\n        if not self._table_exists():\n            return\n    \n        if not filters:\n            # No filters, return all rows\n            for row in self.all():\n                yield row\n            return\n    \n        # Build WHERE clause\n        where_parts = []\n        where_values = []\n        for col, val in filters.items():\n            where_parts.append(f\"{col} = ?\")\n            where_values.append(val)\n    \n        where_clause = ' AND '.join(where_parts)\n        sql = f\"SELECT * FROM {self.name} WHERE {where_clause}\"\n    \n        cursor = self.database._connection.cursor()\n        cursor.row_factory = sqlite3.Row\n>       cursor.execute(sql, where_values)\nE       sqlite3.OperationalError: no such column: order_by\n\ngeneration\\Dataset\\dataset\\table.py:281: OperationalError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x0000022578C6F310>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x00000225775C8EE0>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - ass...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n5 failed, 6 passed in 3.87s\n"}
{"model": "claude-4.5-haiku", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:32:48", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "claude-4.5-haiku", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "", "exception_msg": "assert ('match' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'found' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'failregex' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n')", "returncode": 1, "elapsed_time_s": 2.225869, "avg_memory_mb": 32.44, "avg_cpu_percent": 69.1, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 11:33:43", "stdout_excerpt": "==== FAILURES ===================================\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n            assert (\"line\" in out) or (\"lines\" in out)\n            # Try to detect match reporting; be tolerant across versions.\n>           assert (\"match\" in out) or (\"found\" in out) or (\"failregex\" in out)\nE           assert ('match' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'found' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'failregex' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n')\n\ntests\\Fail2ban\\functional_test.py:248: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n1 failed, 11 passed in 1.07s\n", "stdout_sha1": "966cd6220bc534a28060dfd8c8d9c1a6d7ad9397", "stdout_len": 3220, "stdout": "...........F                                                             [100%]\n================================== FAILURES ===================================\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n            assert (\"line\" in out) or (\"lines\" in out)\n            # Try to detect match reporting; be tolerant across versions.\n>           assert (\"match\" in out) or (\"found\" in out) or (\"failregex\" in out)\nE           assert ('match' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'found' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'failregex' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n')\n\ntests\\Fail2ban\\functional_test.py:248: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n1 failed, 11 passed in 1.07s\n"}
{"model": "claude-4.5-haiku", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword arg", "returncode": 1, "elapsed_time_s": 1.620654, "avg_memory_mb": 32.19, "avg_cpu_percent": 97.9, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 11:34:35", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.Marker([0, 0], tooltip=\"t\").add_to(m)\nE       AttributeError: 'Marker' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:69: AttributeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.CircleMarker([0, 0], radius=5).add_to(m)\nE       AttributeError: 'CircleMarker' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:82: AttributeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n>       folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:92: TypeError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, name=\"g\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:115: TypeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-393/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       mc = MarkerCluster(name=\"mc\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword arg", "stdout_sha1": "29aa7fae70b26998a6e220fcd4c5246cc19ab3e1", "stdout_len": 4853, "stdout": "....FFFFFF.F                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.Marker([0, 0], tooltip=\"t\").add_to(m)\nE       AttributeError: 'Marker' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:69: AttributeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.CircleMarker([0, 0], radius=5).add_to(m)\nE       AttributeError: 'CircleMarker' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:82: AttributeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n>       folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:92: TypeError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, name=\"g\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:115: TypeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-393/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       mc = MarkerCluster(name=\"mc\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:174: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n7 failed, 5 passed in 0.47s\n"}
{"model": "claude-4.5-haiku", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "naturaltime() got an unexpected keyword argument 'when'", "returncode": 1, "elapsed_time_s": 1.544276, "avg_memory_mb": 32.04, "avg_cpu_percent": 101.1, "passed": 6, "failed": 4, "skipped": 5, "total": 15, "functional_score": 0.4, "timestamp": "2026-01-01 11:35:32", "stdout_excerpt": "==== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n>       d = humanize.precisedelta(3661)  # seconds\n\ntests\\Humanize\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nvalue = 3661, minimum_unit = 'seconds', suppress = []\n\n    def precisedelta(value: Union[datetime, timedelta], minimum_unit: str = \"seconds\", suppress: list = None) -> str:\n        \"\"\"\n        Convert a time delta to a precise human-readable format.\n    \n        Args:\n            value: datetime object or timedelta\n            minimum_unit: Minimum unit to display\n            suppress: List of units to suppress from output\n    \n        Returns:\n            Precise human-readable time delta string\n        \"\"\"\n        if suppress is None:\n            suppress = []\n    \n        if isinstance(value, datetime):\n            now = datetime.now()\n            if value.tzinfo is not None and now.tzinfo is None:\n                now = now.replace(tzinfo=value.tzinfo)\n            elif value.tzinfo is None and now.tzinfo is not None:\n                value = value.replace(tzinfo=now.tzinfo)\n    \n            delta = now - value\n            total_seconds = abs(delta.total_seconds())\n        else:\n>           total_seconds = abs(value.total_seconds())\nE           AttributeError: 'int' object has no attribute 'total_seconds'\n\ngeneration\\Humanize\\humanize\\time.py:115: AttributeError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - Attribu...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n4 failed, 6 passed, 5 skipped in 0.41s\n", "stdout_sha1": "01689691f0958be422ff35412e2482f5afdbb6f5", "stdout_len": 3253, "stdout": "..FF.F...Fsssss                                                          [100%]\n================================== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n>       d = humanize.precisedelta(3661)  # seconds\n\ntests\\Humanize\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nvalue = 3661, minimum_unit = 'seconds', suppress = []\n\n    def precisedelta(value: Union[datetime, timedelta], minimum_unit: str = \"seconds\", suppress: list = None) -> str:\n        \"\"\"\n        Convert a time delta to a precise human-readable format.\n    \n        Args:\n            value: datetime object or timedelta\n            minimum_unit: Minimum unit to display\n            suppress: List of units to suppress from output\n    \n        Returns:\n            Precise human-readable time delta string\n        \"\"\"\n        if suppress is None:\n            suppress = []\n    \n        if isinstance(value, datetime):\n            now = datetime.now()\n            if value.tzinfo is not None and now.tzinfo is None:\n                now = now.replace(tzinfo=value.tzinfo)\n            elif value.tzinfo is None and now.tzinfo is not None:\n                value = value.replace(tzinfo=now.tzinfo)\n    \n            delta = now - value\n            total_seconds = abs(delta.total_seconds())\n        else:\n>           total_seconds = abs(value.total_seconds())\nE           AttributeError: 'int' object has no attribute 'total_seconds'\n\ngeneration\\Humanize\\humanize\\time.py:115: AttributeError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - Attribu...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n4 failed, 6 passed, 5 skipped in 0.41s\n"}
{"model": "claude-4.5-haiku", "project": "Imageio", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "module 'imageio.v3' has no attribute 'imopen'", "returncode": 1, "elapsed_time_s": 2.704916, "avg_memory_mb": 44.08, "avg_cpu_percent": 96.4, "passed": 6, "failed": 4, "skipped": 0, "total": 10, "functional_score": 0.6, "timestamp": "2026-01-01 11:36:18", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-396/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape[0] == frames.shape[0]\nE       assert 20 == 5\n\ntests\\Imageio\\functional_test.py:194: AssertionError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-396/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-396/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n4 failed, 6 passed in 1.16s\n", "stdout_sha1": "94c042e5ef2696a299318fdec6abf60fdabbb72b", "stdout_len": 3212, "stdout": "...F..FFF.                                                               [100%]\n================================== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-396/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape[0] == frames.shape[0]\nE       assert 20 == 5\n\ntests\\Imageio\\functional_test.py:194: AssertionError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-396/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-396/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n4 failed, 6 passed in 1.16s\n"}
{"model": "claude-4.5-haiku", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "fit() got an unexpected keyword", "returncode": 1, "elapsed_time_s": 6.34135, "avg_memory_mb": 73.11, "avg_cpu_percent": 72.75, "passed": 0, "failed": 15, "skipped": 0, "total": 15, "functional_score": 0.0, "timestamp": "2026-01-01 11:37:03", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.533387  0.642376\\ntreatment  0.296529  0.470911.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x00000231EDE3DC70>()\nE        +    where <built-in method lower of str object at 0x00000231EDE3DC70> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x00000231ABB74670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x00000231ABB74670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.533387  0.642376\\ntreatment  0.296529  0.470911.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword ", "stdout_sha1": "3b59fe4ef036671797fce109cc4735729314a01c", "stdout_len": 10777, "stdout": "FFFFFFFFFFFFFFF                                                          [100%]\n================================== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.533387  0.642376\\ntreatment  0.296529  0.470911.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x00000231EDE3DC70>()\nE        +    where <built-in method lower of str object at 0x00000231EDE3DC70> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x00000231ABB74670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x00000231ABB74670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.533387  0.642376\\ntreatment  0.296529  0.470911.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:169: TypeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:182: TypeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:191: TypeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:204: TypeError\n_________________ test_coxph_params_index_matches_covariates __________________\n\n    def test_coxph_params_index_matches_covariates() -> None:\n        \"\"\"Cox model params_ should be indexed by covariate names.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        params = cph.params_\n>       assert list(params.index) == [\"age\", \"treatment\"]\nE       AttributeError: 'numpy.ndarray' object has no attribute 'index'\n\ntests\\Lifelines\\functional_test.py:216: AttributeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x_low = pd.DataFrame({\"age\": [25], \"treatment\": [0]})\n        x_high = pd.DataFrame({\"age\": [55], \"treatment\": [1]})\n    \n>       h_low = float(cph.predict_partial_hazard(x_low).iloc[0])\nE       AttributeError: 'CoxPHFitter' object has no attribute 'predict_partial_hazard'\n\ntests\\Lifelines\\functional_test.py:240: AttributeError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x = pd.DataFrame({\"age\": [30, 60], \"treatment\": [0, 1]})\n        sf = cph.predict_survival_function(x)\n    \n        assert isinstance(sf, pd.DataFrame)\n>       assert sf.shape[1] == 2\nE       assert 1 == 2\n\ntests\\Lifelines\\functional_test.py:257: AssertionError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n_____________ test_coxph_fit_on_waltons_with_binary_group_feature _____________\n\n    def test_coxph_fit_on_waltons_with_binary_group_feature() -> None:\n        \"\"\"Fit CoxPH on Waltons dataset using a binary treated indicator derived from group.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        df2 = df.copy()\n        df2[\"treated\"] = (df2[\"group\"] != \"control\").astype(int)\n    \n        model_df = df2[[\"T\", \"E\", \"treated\"]].rename(columns={\"T\": \"duration\", \"E\": \"event\"})\n    \n        cph = CoxPHFitter()\n        cph.fit(model_df, duration_col=\"duration\", event_col=\"event\")\n    \n>       coef = float(cph.params_.loc[\"treated\"])\nE       AttributeError: 'numpy.ndarray' object has no attribute 'loc'\n\ntests\\Lifelines\\functional_test.py:286: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_small_manual_dataset\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_waltons_groups - TypeE...\nFAILED tests/Lifelines/functional_test.py::test_coxph_basic_fit - AssertionEr...\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_at_time_zero_is_one\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_is_non_increasing_over_time\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_params_index_matches_covariates\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\nFAILED tests/Lifelines/functional_test.py::test_coxph_fit_on_waltons_with_binary_group_feature\n15 failed in 4.66s\n"}
{"model": "claude-4.5-haiku", "project": "Loguru", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'Logger' object has no attribute 'patch'", "returncode": 1, "elapsed_time_s": 1.999258, "avg_memory_mb": 32.98, "avg_cpu_percent": 99.2, "passed": 5, "failed": 6, "skipped": 0, "total": 11, "functional_score": 0.4545, "timestamp": "2026-01-01 11:37:38", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n>       log.log(\"INFO\", \"hello-info\")\nE       AttributeError: 'Logger' object has no attribute 'log'\n\ntests\\Loguru\\functional_test.py:125: AttributeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n    \n        bound = log.bind(user=\"alice\", request_id=\"req-123\")\n        bound.info(\"hello\")\n    \n        out = buf.getvalue()\n        assert \"INFO:\" in out\n        assert \"hello\" in out\n>       assert \"user=alice\" in out\nE       AssertionError: assert 'user=alice' in 'INFO:hello user={extra[user]} req={extra[request_id]}\\n'\n\ntests\\Loguru\\functional_test.py:142: AssertionError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x0000029466EABCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\ntests\\Loguru\\functional_test.py:211: AttributeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n    \n        log.debug(", "stdout_sha1": "e6397169e79847fe60c2ad8b15f03d152ca158c9", "stdout_len": 5049, "stdout": "..FFF..FFF.                                                              [100%]\n================================== FAILURES ===================================\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n>       log.log(\"INFO\", \"hello-info\")\nE       AttributeError: 'Logger' object has no attribute 'log'\n\ntests\\Loguru\\functional_test.py:125: AttributeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n    \n        bound = log.bind(user=\"alice\", request_id=\"req-123\")\n        bound.info(\"hello\")\n    \n        out = buf.getvalue()\n        assert \"INFO:\" in out\n        assert \"hello\" in out\n>       assert \"user=alice\" in out\nE       AssertionError: assert 'user=alice' in 'INFO:hello user={extra[user]} req={extra[request_id]}\\n'\n\ntests\\Loguru\\functional_test.py:142: AssertionError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x0000029466EABCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\ntests\\Loguru\\functional_test.py:211: AttributeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n    \n        log.debug(\"nope\")\n        log.info(\"yep\")\n    \n        out = buf.getvalue()\n>       assert \"nope\" not in out\nE       AssertionError: assert 'nope' not in 'DEBUG:nope\\nINFO:yep\\n'\nE         \nE         'nope' is contained here:\nE           DEBUG:nope\nE         ?       ++++\nE           INFO:yep\n\ntests\\Loguru\\functional_test.py:229: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Att...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Asse...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\n6 failed, 5 passed in 0.58s\n"}
{"model": "claude-4.5-haiku", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 3.062169, "avg_memory_mb": 35.92, "avg_cpu_percent": 64.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:38:36", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.66s\n", "stdout_sha1": "189ff10c7054586ef40989b6eeb4fc42b28c83f2", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.66s\n"}
{"model": "claude-4.5-haiku", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 2.064899, "avg_memory_mb": 32.11, "avg_cpu_percent": 99.2, "passed": 5, "failed": 5, "skipped": 9, "total": 19, "functional_score": 0.2632, "timestamp": "2026-01-01 11:39:11", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_emphasis_and_strong ___________________________\n\n    def test_emphasis_and_strong() -> None:\n        src = \"This is *italic* and **bold** and __also bold__.\"\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<em>\" in norm and \"</em>\" in norm\nE       AssertionError: assert ('<em>' in '<p>This is &lt;em&gt;italic&lt;/em&gt; and &lt;strong&gt;bold&lt;/strong&gt; and &lt;strong&gt;also bold&lt;/strong&gt;.</p>')\n\ntests\\Markdown\\functional_test.py:122: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       AssertionError: assert ('<a ' in '<p>A &lt;a href=&quot;https://example.com&quot;&gt;link&lt;/a&gt; and\\nan image: &lt;img alt=&quot;alt text&quot; src=&quot;https://example.com/image.png&quot; /&gt;</p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n__________________ test_markdown_class_multiple_conversions ___________________\n\n    def test_markdown_class_multiple_conversions() -> None:\n        src1 = \"# First\\n\\nParagraph.\"\n        src2 = \"Second document with *emphasis*.\"\n    \n        md = markdown.Markdown()\n        html1 = md.convert(src1)\n        if hasattr(md, \"reset\"):\n            md.reset()\n        html2 = md.convert(src2)\n    \n        norm1 = normalize_html(html1)\n        norm2 = normalize_html(html2)\n    \n        assert \"First\" in norm1\n        assert \"Paragraph.\" in norm1\n        assert \"<h1>\" in norm1\n    \n        assert \"Second document\" in norm2\n>       assert \"<em>\" in norm2 or \"<i>\" in norm2\nE       AssertionError: assert ('<em>' in '<p>Second document with &lt;em&gt;emphasis&lt;/em&gt;.</p>' or '<i>' in '<p>Second document with &lt;em&gt;emphasis&lt;/em&gt;.</p>')\n\ntests\\Markdown\\functional_test.py:231: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_emphasis_and_strong - Assertio...\nFAILED tests/Markdown/functional_test.py::test_links_and_images - AssertionEr...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_class_multiple_conversions\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n5 failed, 5 passed, 9 skipped in 0.58s\n", "stdout_sha1": "f51f342d1375abdad5e273f4e0267fb6b42355c2", "stdout_len": 4035, "stdout": ".F...FFF.Fsssssssss                                                      [100%]\n================================== FAILURES ===================================\n__________________________ test_emphasis_and_strong ___________________________\n\n    def test_emphasis_and_strong() -> None:\n        src = \"This is *italic* and **bold** and __also bold__.\"\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<em>\" in norm and \"</em>\" in norm\nE       AssertionError: assert ('<em>' in '<p>This is &lt;em&gt;italic&lt;/em&gt; and &lt;strong&gt;bold&lt;/strong&gt; and &lt;strong&gt;also bold&lt;/strong&gt;.</p>')\n\ntests\\Markdown\\functional_test.py:122: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       AssertionError: assert ('<a ' in '<p>A &lt;a href=&quot;https://example.com&quot;&gt;link&lt;/a&gt; and\\nan image: &lt;img alt=&quot;alt text&quot; src=&quot;https://example.com/image.png&quot; /&gt;</p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n__________________ test_markdown_class_multiple_conversions ___________________\n\n    def test_markdown_class_multiple_conversions() -> None:\n        src1 = \"# First\\n\\nParagraph.\"\n        src2 = \"Second document with *emphasis*.\"\n    \n        md = markdown.Markdown()\n        html1 = md.convert(src1)\n        if hasattr(md, \"reset\"):\n            md.reset()\n        html2 = md.convert(src2)\n    \n        norm1 = normalize_html(html1)\n        norm2 = normalize_html(html2)\n    \n        assert \"First\" in norm1\n        assert \"Paragraph.\" in norm1\n        assert \"<h1>\" in norm1\n    \n        assert \"Second document\" in norm2\n>       assert \"<em>\" in norm2 or \"<i>\" in norm2\nE       AssertionError: assert ('<em>' in '<p>Second document with &lt;em&gt;emphasis&lt;/em&gt;.</p>' or '<i>' in '<p>Second document with &lt;em&gt;emphasis&lt;/em&gt;.</p>')\n\ntests\\Markdown\\functional_test.py:231: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_emphasis_and_strong - Assertio...\nFAILED tests/Markdown/functional_test.py::test_links_and_images - AssertionEr...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_class_multiple_conversions\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n5 failed, 5 passed, 9 skipped in 0.58s\n"}
{"model": "claude-4.5-haiku", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 2.004177, "avg_memory_mb": 32.16, "avg_cpu_percent": 98.4, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2026-01-01 11:40:03", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.56s\n", "stdout_sha1": "21d65ececb8fc353e9e43f089cfa9bcb7c9c4223", "stdout_len": 3013, "stdout": "........FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.56s\n"}
{"model": "claude-4.5-haiku", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.53913, "avg_memory_mb": 31.82, "avg_cpu_percent": 95.6, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:40:48", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "claude-4.5-haiku", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "ValueError", "exception_msg": "Not naive datetime (tzinfo is already set)", "returncode": 1, "elapsed_time_s": 2.587184, "avg_memory_mb": 33.39, "avg_cpu_percent": 93.1, "passed": 2, "failed": 10, "skipped": 1, "total": 13, "functional_score": 0.1538, "timestamp": "2026-01-01 11:41:27", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n>       dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n\ntests\\Pendulum\\functional_test.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:28: in in_timezone\n    converted = self.astimezone(tz)\ngeneration\\Pendulum\\pendulum\\timezone.py:24: in utcoffset\n    return self._tz.utcoffset(dt)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytz\\tzinfo.py:425: in utcoffset\n    dt = self.localize(dt, is_dst)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <DstTzInfo 'Asia/Tokyo' LMT+9:19:00 STD>\ndt = DateTime(2020, 1, 1, 12, 0, 0, 0, tz='Asia/Tokyo'), is_dst = None\n\n    def localize(self, dt, is_dst=False):\n        '''Convert naive time to local time.\n    \n        This method should be used to construct localtimes, rather\n        than passing a tzinfo argument to a datetime constructor.\n    \n        is_dst is used to determine the correct timezone in the ambigous\n        period at the end of daylight saving time.\n    \n        >>> from pytz import timezone\n        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'\n        >>> amdam = timezone('Europe/Amsterdam')\n        >>> dt  = datetime(2004, 10, 31, 2, 0, 0)\n        >>> loc_dt1 = amdam.localize(dt, is_dst=True)\n        >>> loc_dt2 = amdam.localize(dt, is_dst=False)\n        >>> loc_dt1.strftime(fmt)\n        '2004-10-31 02:00:00 CEST (+0200)'\n        >>> loc_dt2.strftime(fmt)\n        '2004-10-31 02:00:00 CET (+0100)'\n        >>> str(loc_dt2 - loc_dt1)\n        '1:00:00'\n    \n        Use is_dst=None to raise an AmbiguousTimeError for ambiguous\n        times at the end of daylight saving time\n    \n        >>> try:\n        ...     loc_dt1 = amdam.localize(dt, is_dst=None)\n        ... except AmbiguousTimeError:\n        ...     print('Ambiguous')\n        Ambiguous\n    \n        is_dst defaults to False\n    \n        >>> amdam.localize(dt) == amdam.localize(dt, False)\n        True\n    \n        is_dst is also used to determine the correct timezone in the\n        wallclock times jumped over at the start of daylight saving time.\n    \n        >>> pacific = timezone('US/Pacific')\n        >>> dt = datetime(2008, 3, 9, 2, 0, 0)\n        >>> ploc_dt1 = pacific.localize(dt, is_dst=True)\n        >>> ploc_dt2 = pacific.localize(dt, is_dst=False)\n        >>> ploc_dt1.strftime(fmt)\n        '2008-03-09 02:00:00 PDT (-0700)'\n        >>> ploc_dt2.strftime(fmt)\n        '2008-03-09 02:00:00 PST (-0800)'\n        >>> str(ploc_dt2 - ploc_dt1)\n        '1:00:00'\n    \n        Use is_dst=None to raise a NonExistentTimeError for these skipped\n        times.\n    \n        >>> try:\n        ...     loc_dt1 = pacific.localize(dt, is_dst=None)\n        ... except NonExistentTimeError:\n        ...     print('Non-existent')\n        Non-existent\n        '''\n        if dt.tzinfo is not None:\n>           raise ValueError('Not naive datetime (tzinfo is already set)')\nE           ValueError: Not naive datetime (tzinfo is already set)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytz\\tzinfo.py:321: ValueError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\n\ntests\\Pendulum\\functional_test.py:104: \n_ _ _ _ _ _ _ _ _ _ _", "stdout_sha1": "8ac91a7df08fee1eed5b83f793ec816196b579f2", "stdout_len": 11863, "stdout": "F.FFFFFF.sFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n>       dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n\ntests\\Pendulum\\functional_test.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:28: in in_timezone\n    converted = self.astimezone(tz)\ngeneration\\Pendulum\\pendulum\\timezone.py:24: in utcoffset\n    return self._tz.utcoffset(dt)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytz\\tzinfo.py:425: in utcoffset\n    dt = self.localize(dt, is_dst)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <DstTzInfo 'Asia/Tokyo' LMT+9:19:00 STD>\ndt = DateTime(2020, 1, 1, 12, 0, 0, 0, tz='Asia/Tokyo'), is_dst = None\n\n    def localize(self, dt, is_dst=False):\n        '''Convert naive time to local time.\n    \n        This method should be used to construct localtimes, rather\n        than passing a tzinfo argument to a datetime constructor.\n    \n        is_dst is used to determine the correct timezone in the ambigous\n        period at the end of daylight saving time.\n    \n        >>> from pytz import timezone\n        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'\n        >>> amdam = timezone('Europe/Amsterdam')\n        >>> dt  = datetime(2004, 10, 31, 2, 0, 0)\n        >>> loc_dt1 = amdam.localize(dt, is_dst=True)\n        >>> loc_dt2 = amdam.localize(dt, is_dst=False)\n        >>> loc_dt1.strftime(fmt)\n        '2004-10-31 02:00:00 CEST (+0200)'\n        >>> loc_dt2.strftime(fmt)\n        '2004-10-31 02:00:00 CET (+0100)'\n        >>> str(loc_dt2 - loc_dt1)\n        '1:00:00'\n    \n        Use is_dst=None to raise an AmbiguousTimeError for ambiguous\n        times at the end of daylight saving time\n    \n        >>> try:\n        ...     loc_dt1 = amdam.localize(dt, is_dst=None)\n        ... except AmbiguousTimeError:\n        ...     print('Ambiguous')\n        Ambiguous\n    \n        is_dst defaults to False\n    \n        >>> amdam.localize(dt) == amdam.localize(dt, False)\n        True\n    \n        is_dst is also used to determine the correct timezone in the\n        wallclock times jumped over at the start of daylight saving time.\n    \n        >>> pacific = timezone('US/Pacific')\n        >>> dt = datetime(2008, 3, 9, 2, 0, 0)\n        >>> ploc_dt1 = pacific.localize(dt, is_dst=True)\n        >>> ploc_dt2 = pacific.localize(dt, is_dst=False)\n        >>> ploc_dt1.strftime(fmt)\n        '2008-03-09 02:00:00 PDT (-0700)'\n        >>> ploc_dt2.strftime(fmt)\n        '2008-03-09 02:00:00 PST (-0800)'\n        >>> str(ploc_dt2 - ploc_dt1)\n        '1:00:00'\n    \n        Use is_dst=None to raise a NonExistentTimeError for these skipped\n        times.\n    \n        >>> try:\n        ...     loc_dt1 = pacific.localize(dt, is_dst=None)\n        ... except NonExistentTimeError:\n        ...     print('Non-existent')\n        Non-existent\n        '''\n        if dt.tzinfo is not None:\n>           raise ValueError('Not naive datetime (tzinfo is already set)')\nE           ValueError: Not naive datetime (tzinfo is already set)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytz\\tzinfo.py:321: ValueError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\n\ntests\\Pendulum\\functional_test.py:104: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DateTime(2011, 8, 1, 0, 0, 0, 0, tz='UTC'), kwargs = {'months': 1}\n\n    def add(self, **kwargs):\n        \"\"\"Add a duration to this datetime.\"\"\"\n>       duration = Duration(**kwargs)\nE       TypeError: __new__() got an unexpected keyword argument 'months'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:41: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n        s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\n>       assert s == \"2021/12/31 23:59:58\"\nE       AssertionError: assert 'YYYY/MM/DD HH:mm:ss' == '2021/12/31 23:59:58'\nE         \nE         - 2021/12/31 23:59:58\nE         + YYYY/MM/DD HH:mm:ss\n\ntests\\Pendulum\\functional_test.py:137: AssertionError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n>       dt_ny = dt_utc.in_timezone(\"America/New_York\")\n\ntests\\Pendulum\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:28: in in_timezone\n    converted = self.astimezone(tz)\ngeneration\\Pendulum\\pendulum\\timezone.py:24: in utcoffset\n    return self._tz.utcoffset(dt)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytz\\tzinfo.py:425: in utcoffset\n    dt = self.localize(dt, is_dst)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>\ndt = DateTime(2020, 6, 1, 0, 0, 0, 0, tz='America/New_York'), is_dst = None\n\n    def localize(self, dt, is_dst=False):\n        '''Convert naive time to local time.\n    \n        This method should be used to construct localtimes, rather\n        than passing a tzinfo argument to a datetime constructor.\n    \n        is_dst is used to determine the correct timezone in the ambigous\n        period at the end of daylight saving time.\n    \n        >>> from pytz import timezone\n        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'\n        >>> amdam = timezone('Europe/Amsterdam')\n        >>> dt  = datetime(2004, 10, 31, 2, 0, 0)\n        >>> loc_dt1 = amdam.localize(dt, is_dst=True)\n        >>> loc_dt2 = amdam.localize(dt, is_dst=False)\n        >>> loc_dt1.strftime(fmt)\n        '2004-10-31 02:00:00 CEST (+0200)'\n        >>> loc_dt2.strftime(fmt)\n        '2004-10-31 02:00:00 CET (+0100)'\n        >>> str(loc_dt2 - loc_dt1)\n        '1:00:00'\n    \n        Use is_dst=None to raise an AmbiguousTimeError for ambiguous\n        times at the end of daylight saving time\n    \n        >>> try:\n        ...     loc_dt1 = amdam.localize(dt, is_dst=None)\n        ... except AmbiguousTimeError:\n        ...     print('Ambiguous')\n        Ambiguous\n    \n        is_dst defaults to False\n    \n        >>> amdam.localize(dt) == amdam.localize(dt, False)\n        True\n    \n        is_dst is also used to determine the correct timezone in the\n        wallclock times jumped over at the start of daylight saving time.\n    \n        >>> pacific = timezone('US/Pacific')\n        >>> dt = datetime(2008, 3, 9, 2, 0, 0)\n        >>> ploc_dt1 = pacific.localize(dt, is_dst=True)\n        >>> ploc_dt2 = pacific.localize(dt, is_dst=False)\n        >>> ploc_dt1.strftime(fmt)\n        '2008-03-09 02:00:00 PDT (-0700)'\n        >>> ploc_dt2.strftime(fmt)\n        '2008-03-09 02:00:00 PST (-0800)'\n        >>> str(ploc_dt2 - ploc_dt1)\n        '1:00:00'\n    \n        Use is_dst=None to raise a NonExistentTimeError for these skipped\n        times.\n    \n        >>> try:\n        ...     loc_dt1 = pacific.localize(dt, is_dst=None)\n        ... except NonExistentTimeError:\n        ...     print('Non-existent')\n        Non-existent\n        '''\n        if dt.tzinfo is not None:\n>           raise ValueError('Not naive datetime (tzinfo is already set)')\nE           ValueError: Not naive datetime (tzinfo is already set)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytz\\tzinfo.py:321: ValueError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_diff_for_humans_months - TypeE...\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n10 failed, 2 passed, 1 skipped in 1.20s\n"}
{"model": "claude-4.5-haiku", "project": "Petl", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Use -v to get more diff", "returncode": 1, "elapsed_time_s": 1.995957, "avg_memory_mb": 33.07, "avg_cpu_percent": 98.3, "passed": 4, "failed": 2, "skipped": 6, "total": 12, "functional_score": 0.3333, "timestamp": "2026-01-01 11:42:02", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:22: in __iter__\n    if self.predicate(row):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = [1, 10, None]\n\n>   table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\nE   TypeError: list indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:166: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-399/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n2 failed, 4 passed, 6 skipped in 0.62s\n", "stdout_sha1": "3b25b8b698f279c8fc1c21bc1a55fc33a6aa748c", "stdout_len": 2542, "stdout": ".F.ss..sFsss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:22: in __iter__\n    if self.predicate(row):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = [1, 10, None]\n\n>   table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\nE   TypeError: list indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:166: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-399/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n2 failed, 4 passed, 6 skipped in 0.62s\n"}
{"model": "claude-4.5-haiku", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.423769, "avg_memory_mb": 13.93, "avg_cpu_percent": 95.3, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:42:50", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 14, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\formatters\\__init__.py\", line 5, in <module>\n    from pygments.util import ClassNotFound\nModuleNotFoundError: No module named 'pygments.util'\n", "stdout_sha1": "9adb95d97e6056fffb4f5ed15315ca90dcb3ab46", "stdout_len": 1588, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 14, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\formatters\\__init__.py\", line 5, in <module>\n    from pygments.util import ClassNotFound\nModuleNotFoundError: No module named 'pygments.util'\n"}
{"model": "claude-4.5-haiku", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object", "returncode": 1, "elapsed_time_s": 1.995573, "avg_memory_mb": 33.41, "avg_cpu_percent": 100.0, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 11:43:15", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None, kwargs = {}\n\n    def encode(\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        headers: Optional[Dict[str, Any]] = None,\n        json_encoder: Optional[type] = None,\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Encode a JWT token.\n    \n        Args:\n            payload: Dictionary containing the claims to encode\n            key: Secret key for signing\n            algorithm: Algorithm to use for signing (default: HS256)\n            headers: Optional dictionary of additional header fields\n            json_encoder: Optional custom JSON encoder class\n            **kwargs: Additional arguments (ignored for compatibility)\n    \n        Returns:\n            Encoded JWT token as a string\n    \n        Raises:\n            InvalidAlgorithmError: If algorithm is not supported\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise InvalidAlgorithmError(f\"Algorithm {algorithm} is not supported\")\nE           jwt.exceptions.InvalidAlgorithmError: Algorithm HS512 is not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:75: InvalidAlgorithmError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:84: in encode\n    payload_bytes = json.dumps(payload, separators=(\",\", \":\"), cls=json_encoder).encode(\"utf-8\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000023F26087D30>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object ", "stdout_sha1": "76fd574ae9bdf986b448913ccdf9dd6bfac75050", "stdout_len": 7457, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None, kwargs = {}\n\n    def encode(\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        headers: Optional[Dict[str, Any]] = None,\n        json_encoder: Optional[type] = None,\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Encode a JWT token.\n    \n        Args:\n            payload: Dictionary containing the claims to encode\n            key: Secret key for signing\n            algorithm: Algorithm to use for signing (default: HS256)\n            headers: Optional dictionary of additional header fields\n            json_encoder: Optional custom JSON encoder class\n            **kwargs: Additional arguments (ignored for compatibility)\n    \n        Returns:\n            Encoded JWT token as a string\n    \n        Raises:\n            InvalidAlgorithmError: If algorithm is not supported\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise InvalidAlgorithmError(f\"Algorithm {algorithm} is not supported\")\nE           jwt.exceptions.InvalidAlgorithmError: Algorithm HS512 is not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:75: InvalidAlgorithmError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:84: in encode\n    payload_bytes = json.dumps(payload, separators=(\",\", \":\"), cls=json_encoder).encode(\"utf-8\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000023F26087D30>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:84: in encode\n    payload_bytes = json.dumps(payload, separators=(\",\", \":\"), cls=json_encoder).encode(\"utf-8\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000023F260F2A90>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - j...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.59s\n"}
{"model": "claude-4.5-haiku", "project": "PyPDF", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.463936, "avg_memory_mb": 31.95, "avg_cpu_percent": 97.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:44:08", "stdout_excerpt": "\n1 skipped in 0.13s\n", "stdout_sha1": "4c4ceb412a81fcf19d92b45ee51d2d9a1553d8c3", "stdout_len": 20, "stdout": "\n1 skipped in 0.13s\n"}
{"model": "claude-4.5-haiku", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.57631, "avg_memory_mb": 32.1, "avg_cpu_percent": 97.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:45:52", "stdout_excerpt": "\n1 skipped in 0.18s\n", "stdout_sha1": "635cfd0c225802c418c315f97bcf9f1555f8b14a", "stdout_len": 20, "stdout": "\n1 skipped in 0.18s\n"}
{"model": "claude-4.5-haiku", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Job' object has no attribute 'minute'", "returncode": 1, "elapsed_time_s": 1.953332, "avg_memory_mb": 32.49, "avg_cpu_percent": 98.3, "passed": 6, "failed": 6, "skipped": 0, "total": 12, "functional_score": 0.5, "timestamp": "2026-01-01 11:46:21", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n>       schedule.cancel_job(j2)\nE       AttributeError: module 'schedule' has no attribute 'cancel_job'\n\ntests\\Schedule\\functional_test.py:151: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n>       schedule.every().minute.do(a).tag(\"alpha\")\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:269: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:290: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n6 failed, 6 passed in 0.56s\n", "stdout_sha1": "383e62bbd32438bc0295a02797f154d248a53b67", "stdout_len": 3801, "stdout": "..FF.F..F.FF                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n>       schedule.cancel_job(j2)\nE       AttributeError: module 'schedule' has no attribute 'cancel_job'\n\ntests\\Schedule\\functional_test.py:151: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n>       schedule.every().minute.do(a).tag(\"alpha\")\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:269: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:290: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n6 failed, 6 passed in 0.56s\n"}
{"model": "claude-4.5-haiku", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'thIs' in 'ths-as-a-stopword-topword'", "returncode": 1, "elapsed_time_s": 1.903695, "avg_memory_mb": 31.62, "avg_cpu_percent": 99.1, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2026-01-01 11:46:44", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n__________ test_lowercase_false_preserves_case_for_remaining_tokens ___________\n\n    def test_lowercase_false_preserves_case_for_remaining_tokens() -> None:\n        \"\"\"lowercase=False should preserve original case for non-removed words.\"\"\"\n        mixed = \"thIs Has a stopword Stopword\"\n        result = slugify(mixed, stopwords=[\"Stopword\"], lowercase=False)\n    \n>       assert \"thIs\" in result\nE       AssertionError: assert 'thIs' in 'ths-as-a-stopword-topword'\n\ntests\\Slugify\\functional_test.py:200: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_lowercase_false_preserves_case_for_remaining_tokens\n2 failed, 10 passed in 0.45s\n", "stdout_sha1": "8af44dd48cb23cc350e6570b8d697ebce8a2f1ff", "stdout_len": 1574, "stdout": ".......F.F..                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n__________ test_lowercase_false_preserves_case_for_remaining_tokens ___________\n\n    def test_lowercase_false_preserves_case_for_remaining_tokens() -> None:\n        \"\"\"lowercase=False should preserve original case for non-removed words.\"\"\"\n        mixed = \"thIs Has a stopword Stopword\"\n        result = slugify(mixed, stopwords=[\"Stopword\"], lowercase=False)\n    \n>       assert \"thIs\" in result\nE       AssertionError: assert 'thIs' in 'ths-as-a-stopword-topword'\n\ntests\\Slugify\\functional_test.py:200: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_lowercase_false_preserves_case_for_remaining_tokens\n2 failed, 10 passed in 0.45s\n"}
{"model": "claude-4.5-haiku", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('no such option' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n' or 'unrecognized' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n' or 'unknown' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n')", "returncode": 1, "elapsed_time_s": 3.122587, "avg_memory_mb": 32.45, "avg_cpu_percent": 59.1, "passed": 3, "failed": 6, "skipped": 0, "total": 9, "functional_score": 0.3333, "timestamp": "2026-01-01 11:47:49", "stdout_excerpt": "==== FAILURES ===================================\n______________ test_003_help_runs_and_mentions_usage_or_options _______________\n\n    def test_003_help_runs_and_mentions_usage_or_options():\n        p = _run_cli([\"-h\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... <module>\\n    from lib.controller.controller import start\\nModuleNotFoundError: No module named \\'lib.controller\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:58: AssertionError\n_________________________ test_004_advanced_help_runs _________________________\n\n    def test_004_advanced_help_runs():\n        p = _run_cli([\"-hh\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... <module>\\n    from lib.controller.controller import start\\nModuleNotFoundError: No module named \\'lib.controller\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:65: AssertionError\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       assert None is not None\nE        +  where None = <function search at 0x000002879D1F99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n')\nE        +    where <function search at 0x000002879D1F99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       assert ('no such option' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n' or 'unrecognized' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n' or 'unknown' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_impor", "stdout_sha1": "1f497354d421d292688cae303c4b1e6489de2cfa", "stdout_len": 6257, "stdout": "..FFFFF.F                                                                [100%]\n================================== FAILURES ===================================\n______________ test_003_help_runs_and_mentions_usage_or_options _______________\n\n    def test_003_help_runs_and_mentions_usage_or_options():\n        p = _run_cli([\"-h\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... <module>\\n    from lib.controller.controller import start\\nModuleNotFoundError: No module named \\'lib.controller\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:58: AssertionError\n_________________________ test_004_advanced_help_runs _________________________\n\n    def test_004_advanced_help_runs():\n        p = _run_cli([\"-hh\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... <module>\\n    from lib.controller.controller import start\\nModuleNotFoundError: No module named \\'lib.controller\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:65: AssertionError\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       assert None is not None\nE        +  where None = <function search at 0x000002879D1F99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n')\nE        +    where <function search at 0x000002879D1F99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       assert ('no such option' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n' or 'unrecognized' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n' or 'unknown' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...n <module>\\n    from lib.controller.controller import start\\nmodulenotfounderror: no module named \\'lib.controller\\'\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_importable():\n        \"\"\"\n        Alignment anchors (must exist in BOTH reference and generated repos):\n    \n          - lib.parse.cmdline.cmdLineParser\n          - lib.core.option.init, lib.core.option.initOptions\n          - lib.core.data: cmdLineOptions, conf, kb\n          - lib.core.settings: VERSION, DESCRIPTION\n          - lib.controller.controller.start\n    \n        Only checks importability + symbol presence; does not execute scanning logic.\n        \"\"\"\n        repo = _repo_root()\n        sys.path.insert(0, str(repo))\n        try:\n>           from lib.parse.cmdline import cmdLineParser  # noqa: F401\nE           ModuleNotFoundError: No module named 'lib.parse.cmdline'\n\ntests\\Sqlmap\\functional_test.py:110: ModuleNotFoundError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... <module>\\n    from lib.controller.controller import start\\nModuleNotFoundError: No module named \\'lib.controller\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_003_help_runs_and_mentions_usage_or_options\nFAILED tests/Sqlmap/functional_test.py::test_004_advanced_help_runs - Asserti...\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_006_invalid_option_reports_error_cleanly\nFAILED tests/Sqlmap/functional_test.py::test_007_alignment_api_surface_symbols_importable\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n6 failed, 3 passed in 1.76s\n"}
{"model": "claude-4.5-haiku", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "TypeError", "exception_msg": "metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases", "returncode": 2, "elapsed_time_s": 2.231182, "avg_memory_mb": 40.86, "avg_cpu_percent": 98.5, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:48:25", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:104: in <module>\n    class SQLModel(BaseModel, metaclass=SQLModelMetaclass):\nE   TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - TypeError: metaclass conflict: the ...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.81s\n", "stdout_sha1": "7f51f820f8c0222d0bb862b894af6c2289e80e00", "stdout_len": 780, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:104: in <module>\n    class SQLModel(BaseModel, metaclass=SQLModelMetaclass):\nE   TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - TypeError: metaclass conflict: the ...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.81s\n"}
{"model": "claude-4.5-haiku", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "struc", "returncode": 1, "elapsed_time_s": 9.178938, "avg_memory_mb": 38.34, "avg_cpu_percent": 98.8, "passed": 8, "failed": 4, "skipped": 0, "total": 12, "functional_score": 0.6667, "timestamp": "2026-01-01 11:49:23", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-400/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x000001E6F0B8BCF0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        \"\"\"\n        Hide a message in an image using LSB steganography.\n    \n        Args:\n            image: PIL Image or path to image file\n            message: String message to hide\n            generator: Optional generator for pixel selection (default: sequential)\n            shift: Bit shift for LSB position (default: 0)\n            encoding: Text encoding (default: \"UTF-8\")\n            auto_convert_rgb: Convert image to RGB if needed (default: False)\n    \n        Returns:\n            PIL Image with hidden message\n        \"\"\"\n        if isinstance(image, str):\n            img = Image.open(image)\n        else:\n            img = image.copy()\n    \n        if auto_convert_rgb and img.mode != 'RGB':\n            img = img.convert('RGB')\n    \n        if img.mode not in ('RGB', 'RGBA'):\n            raise ValueError(f\"Unsupported image mode: {img.mode}\")\n    \n        # Encode message\n        message_bytes = message.encode(encoding)\n        message_bits = _bytes_to_bits(message_bytes)\n    \n        # Add length header (32 bits for message length)\n        length = len(message_bytes)\n        length_bits = _int_to_bits(length, 32)\n        all_bits = length_bits + message_bits\n    \n        # Get pixel data\n        pixels = img.load()\n        width, height = img.size\n    \n        # Determine which pixels to use\n        if generator is None:\n            pixel_indices = range(width * height)\n        else:\n>           pixel_indices = generator()\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:53: TypeError\n________________________ test_wav_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-400/test_wav_hide_and_reveal_text0')\n\n    def test_wav_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"wav.hide writes output WAV; wav.reveal returns the same string.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"wav secret\"\n        output = tmp_path / \"out.wav\"\n    \n>       wav.hide(str(wav_in), secret, str(output))\n\ntests\\Stegano\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\wav\\wav.py:61: in hide\n    audio_data = _samples_to_audio(samples, sample_width, n_channels)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsamples = [65526, 65530, 65526, 4, 65520, 0, ...], sample_width = 2\nn_channels = 1\n\n    def _samples_to_audio(samples, sample_width, n_channels):\n        \"\"\"Convert list of samples back to audio data\"\"\"\n        audio_data = b''\n    \n        if sample_width == 1:\n            for sample in samples:\n                audio_data += bytes([sample & 0xFF])\n        elif sample_width == 2:\n            for sample in samples:\n>               audio_data += struct.pack('<h', sample & 0xFFFF)\nE               struc", "stdout_sha1": "ec385a151250840cf871ceae9399d2162078beed", "stdout_len": 7556, "stdout": ".F......FFF.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-400/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x000001E6F0B8BCF0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        \"\"\"\n        Hide a message in an image using LSB steganography.\n    \n        Args:\n            image: PIL Image or path to image file\n            message: String message to hide\n            generator: Optional generator for pixel selection (default: sequential)\n            shift: Bit shift for LSB position (default: 0)\n            encoding: Text encoding (default: \"UTF-8\")\n            auto_convert_rgb: Convert image to RGB if needed (default: False)\n    \n        Returns:\n            PIL Image with hidden message\n        \"\"\"\n        if isinstance(image, str):\n            img = Image.open(image)\n        else:\n            img = image.copy()\n    \n        if auto_convert_rgb and img.mode != 'RGB':\n            img = img.convert('RGB')\n    \n        if img.mode not in ('RGB', 'RGBA'):\n            raise ValueError(f\"Unsupported image mode: {img.mode}\")\n    \n        # Encode message\n        message_bytes = message.encode(encoding)\n        message_bits = _bytes_to_bits(message_bytes)\n    \n        # Add length header (32 bits for message length)\n        length = len(message_bytes)\n        length_bits = _int_to_bits(length, 32)\n        all_bits = length_bits + message_bits\n    \n        # Get pixel data\n        pixels = img.load()\n        width, height = img.size\n    \n        # Determine which pixels to use\n        if generator is None:\n            pixel_indices = range(width * height)\n        else:\n>           pixel_indices = generator()\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:53: TypeError\n________________________ test_wav_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-400/test_wav_hide_and_reveal_text0')\n\n    def test_wav_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"wav.hide writes output WAV; wav.reveal returns the same string.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"wav secret\"\n        output = tmp_path / \"out.wav\"\n    \n>       wav.hide(str(wav_in), secret, str(output))\n\ntests\\Stegano\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\wav\\wav.py:61: in hide\n    audio_data = _samples_to_audio(samples, sample_width, n_channels)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsamples = [65526, 65530, 65526, 4, 65520, 0, ...], sample_width = 2\nn_channels = 1\n\n    def _samples_to_audio(samples, sample_width, n_channels):\n        \"\"\"Convert list of samples back to audio data\"\"\"\n        audio_data = b''\n    \n        if sample_width == 1:\n            for sample in samples:\n                audio_data += bytes([sample & 0xFF])\n        elif sample_width == 2:\n            for sample in samples:\n>               audio_data += struct.pack('<h', sample & 0xFFFF)\nE               struct.error: short format requires (-32768) <= number <= 32767\n\ngeneration\\Stegano\\stegano\\wav\\wav.py:152: error\n_____________________ test_wav_hide_and_reveal_short_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-400/test_wav_hide_and_reveal_short0')\n\n    def test_wav_hide_and_reveal_short_text(tmp_path: Path) -> None:\n        \"\"\"A short message should also roundtrip.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"ok\"\n        output = tmp_path / \"out_short.wav\"\n    \n>       wav.hide(str(wav_in), secret, str(output))\n\ntests\\Stegano\\functional_test.py:234: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\wav\\wav.py:61: in hide\n    audio_data = _samples_to_audio(samples, sample_width, n_channels)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsamples = [65526, 65530, 65526, 4, 65520, 0, ...], sample_width = 2\nn_channels = 1\n\n    def _samples_to_audio(samples, sample_width, n_channels):\n        \"\"\"Convert list of samples back to audio data\"\"\"\n        audio_data = b''\n    \n        if sample_width == 1:\n            for sample in samples:\n                audio_data += bytes([sample & 0xFF])\n        elif sample_width == 2:\n            for sample in samples:\n>               audio_data += struct.pack('<h', sample & 0xFFFF)\nE               struct.error: short format requires (-32768) <= number <= 32767\n\ngeneration\\Stegano\\stegano\\wav\\wav.py:152: error\n____________________ test_wav_hide_and_reveal_longer_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-400/test_wav_hide_and_reveal_longe0')\n\n    def test_wav_hide_and_reveal_longer_text(tmp_path: Path) -> None:\n        \"\"\"Roundtrip a longer ASCII message via WAV backend.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\"\n        output = tmp_path / \"out_long.wav\"\n    \n>       wav.hide(str(wav_in), secret, str(output))\n\ntests\\Stegano\\functional_test.py:249: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\wav\\wav.py:61: in hide\n    audio_data = _samples_to_audio(samples, sample_width, n_channels)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsamples = [65526, 65530, 65526, 4, 65520, 0, ...], sample_width = 2\nn_channels = 1\n\n    def _samples_to_audio(samples, sample_width, n_channels):\n        \"\"\"Convert list of samples back to audio data\"\"\"\n        audio_data = b''\n    \n        if sample_width == 1:\n            for sample in samples:\n                audio_data += bytes([sample & 0xFF])\n        elif sample_width == 2:\n            for sample in samples:\n>               audio_data += struct.pack('<h', sample & 0xFFFF)\nE               struct.error: short format requires (-32768) <= number <= 32767\n\ngeneration\\Stegano\\stegano\\wav\\wav.py:152: error\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_text - stru...\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_short_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_longer_text\n4 failed, 8 passed in 7.76s\n"}
{"model": "claude-4.5-haiku", "project": "Tablib", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)", "returncode": 2, "elapsed_time_s": 2.133259, "avg_memory_mb": 35.12, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:49:51", "stdout_excerpt": "====\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:5: in <module>\n    from tablib.core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:7: in <module>\n    from tablib.formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_csv.py:7: in <module>\n    from tablib.core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.67s\n", "stdout_sha1": "72cbf36309fe98b2ce717c937400e03e0a52c42a", "stdout_len": 1313, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:5: in <module>\n    from tablib.core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:7: in <module>\n    from tablib.formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_csv.py:7: in <module>\n    from tablib.core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.67s\n"}
{"model": "claude-4.5-haiku", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 1.951598, "avg_memory_mb": 33.25, "avg_cpu_percent": 99.1, "passed": 6, "failed": 6, "skipped": 0, "total": 12, "functional_score": 0.5, "timestamp": "2026-01-01 11:50:39", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]]\nheaders = ['f', 'i', 'r', 's', 't', 'r', ...], tablefmt = 'simple'\nfloatfmt = 'g', numalign = 'decimal', stralign = 'left', missingval = ''\nshowindex = False, disable_numparse = False, colalign = None\n\n    def tabulate(tabular_data, headers=(), tablefmt=\"simple\", floatfmt=\"g\",\n                 numalign=\"decimal\", stralign=\"left\", missingval=\"\",\n                 showindex=False, disable_numparse=False, colalign=None):\n        \"\"\"\n        Format a table from tabular data.\n    \n        Args:\n            tabular_data: List of lists, list of dicts, or dict\n            headers: List of header names or \"keys\" for dict keys\n            tablefmt: Table format name (e.g., \"grid\", \"pipe\", \"plain\")\n            floatfmt: Format string for floats (default \"g\")\n            numalign: Alignment for numbers (\"decimal\", \"right\", \"center\", \"left\")\n            stralign: Alignment for strings (\"left\", \"center\", \"right\")\n            missingval: String to use for missing values\n            showindex: Show row indices\n            disable_numparse: Don't parse numeric strings\n            colalign: Per-column alignment override\n    \n        Returns:\n            Formatted table as a string\n        \"\"\"\n    \n        # Get the table format\n        if isinstance(tablefmt, str):\n            fmt = get_named_table_format(tablefmt)\n        else:\n            fmt = tablefmt\n    \n        # Normalize data\n        rows, headers = _normalize_tabular_data(tabular_data, headers)\n    \n        # Convert headers to strings\n        if headers:\n            headers = [str(h) for h in headers]\n    \n        # Add index column if needed\n        if showindex:\n            if headers:\n                headers = [\"\"] + headers\n            rows = [[i] + list(row) for i, row in enumerate(rows)]\n    \n        # Convert all cells to strings and handle multiline\n        max_lines = 1\n        processed_rows = []\n        for row in rows:\n            processed_row = []\n            for cell in row:\n                lines = _split_multiline(cell)\n                processed_row.append(lines)\n                max_lines = max(max_lines, len(lines))\n            processed_rows.append(processed_row)\n    \n        # Expand multiline cells\n        expanded_rows = []\n        for row in processed_rows:\n            expanded_row = []\n            for lines in row:\n                # Pad lines to max_lines\n                padded = lines + [\"\"] * (max_lines - len(lines))\n                expanded_row.append(padded)\n            expanded_rows.append(expanded_row)\n    \n        # Transpose to get columns\n        if not expanded_rows:\n            columns = []\n        else:\n            num_cols = len(expanded_rows[0])\n            columns = []\n            for col_idx in range(num_cols):\n                col = []\n                for row in expanded_rows:\n                    col.extend(row[col_idx])\n                columns.append(col)\n    \n        # Calculate column widths\n        col_widths = []\n        for col_idx, col in enumerate(columns):\n            width = 0\n            if headers and col_idx < len(headers):\n                width = len(headers[col_idx])\n            for cell_lines in col:\n                for line in cell_lines:\n                    width = max(width, len(line))\n            col_widths.append(width)\n    \n        # Determine alignment for each column\n        alignments = []\n        for col_idx, col in enumerate(columns):\n            if colalign and col_idx <", "stdout_sha1": "5e7e1cec2790e22aca4dbac1823f5bb8d2815843", "stdout_len": 9679, "stdout": "..FF.F.FF.F.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]]\nheaders = ['f', 'i', 'r', 's', 't', 'r', ...], tablefmt = 'simple'\nfloatfmt = 'g', numalign = 'decimal', stralign = 'left', missingval = ''\nshowindex = False, disable_numparse = False, colalign = None\n\n    def tabulate(tabular_data, headers=(), tablefmt=\"simple\", floatfmt=\"g\",\n                 numalign=\"decimal\", stralign=\"left\", missingval=\"\",\n                 showindex=False, disable_numparse=False, colalign=None):\n        \"\"\"\n        Format a table from tabular data.\n    \n        Args:\n            tabular_data: List of lists, list of dicts, or dict\n            headers: List of header names or \"keys\" for dict keys\n            tablefmt: Table format name (e.g., \"grid\", \"pipe\", \"plain\")\n            floatfmt: Format string for floats (default \"g\")\n            numalign: Alignment for numbers (\"decimal\", \"right\", \"center\", \"left\")\n            stralign: Alignment for strings (\"left\", \"center\", \"right\")\n            missingval: String to use for missing values\n            showindex: Show row indices\n            disable_numparse: Don't parse numeric strings\n            colalign: Per-column alignment override\n    \n        Returns:\n            Formatted table as a string\n        \"\"\"\n    \n        # Get the table format\n        if isinstance(tablefmt, str):\n            fmt = get_named_table_format(tablefmt)\n        else:\n            fmt = tablefmt\n    \n        # Normalize data\n        rows, headers = _normalize_tabular_data(tabular_data, headers)\n    \n        # Convert headers to strings\n        if headers:\n            headers = [str(h) for h in headers]\n    \n        # Add index column if needed\n        if showindex:\n            if headers:\n                headers = [\"\"] + headers\n            rows = [[i] + list(row) for i, row in enumerate(rows)]\n    \n        # Convert all cells to strings and handle multiline\n        max_lines = 1\n        processed_rows = []\n        for row in rows:\n            processed_row = []\n            for cell in row:\n                lines = _split_multiline(cell)\n                processed_row.append(lines)\n                max_lines = max(max_lines, len(lines))\n            processed_rows.append(processed_row)\n    \n        # Expand multiline cells\n        expanded_rows = []\n        for row in processed_rows:\n            expanded_row = []\n            for lines in row:\n                # Pad lines to max_lines\n                padded = lines + [\"\"] * (max_lines - len(lines))\n                expanded_row.append(padded)\n            expanded_rows.append(expanded_row)\n    \n        # Transpose to get columns\n        if not expanded_rows:\n            columns = []\n        else:\n            num_cols = len(expanded_rows[0])\n            columns = []\n            for col_idx in range(num_cols):\n                col = []\n                for row in expanded_rows:\n                    col.extend(row[col_idx])\n                columns.append(col)\n    \n        # Calculate column widths\n        col_widths = []\n        for col_idx, col in enumerate(columns):\n            width = 0\n            if headers and col_idx < len(headers):\n                width = len(headers[col_idx])\n            for cell_lines in col:\n                for line in cell_lines:\n                    width = max(width, len(line))\n            col_widths.append(width)\n    \n        # Determine alignment for each column\n        alignments = []\n        for col_idx, col in enumerate(columns):\n            if colalign and col_idx < len(colalign):\n                alignments.append(colalign[col_idx])\n            else:\n                # Auto-detect alignment\n                has_number = False\n                has_text = False\n                for cell_lines in col:\n                    for line in cell_lines:\n                        if line:\n                            if _isnumber(line):\n                                has_number = True\n                            else:\n                                has_text = True\n    \n                if has_number and not has_text:\n                    alignments.append(numalign if numalign != \"decimal\" else \"right\")\n                else:\n                    alignments.append(stralign)\n    \n        # Align columns\n        aligned_columns = []\n        for col_idx, col in enumerate(columns):\n            aligned_col = []\n            for cell_lines in col:\n                aligned_lines = []\n                for line in cell_lines:\n                    aligned = _align_column([line], alignments[col_idx], col_widths[col_idx])[0]\n                    aligned_lines.append(aligned)\n                aligned_col.append(aligned_lines)\n            aligned_columns.append(aligned_col)\n    \n        # Build output\n        lines = []\n    \n        # Line above\n        if fmt.lineabove:\n            line = _build_line(fmt.lineabove, col_widths, fmt.padding)\n            lines.append(line)\n    \n        # Header row\n        if headers:\n            header_cells = []\n            for col_idx, h in enumerate(headers):\n>               aligned = _align_column([h], alignments[col_idx], col_widths[col_idx])[0]\nE               IndexError: list index out of range\n\ngeneration\\Tabulate\\tabulate\\core.py:219: IndexError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in '--------'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:112: in tabulate\n    fmt = get_named_table_format(tablefmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'github'\n\n    def get_named_table_format(name):\n        \"\"\"Get a table format by name.\"\"\"\n        if name not in _FORMATS:\n>           raise ValueError(f\"Unknown table format: {name}\")\nE           ValueError: Unknown table format: github\n\ngeneration\\Tabulate\\tabulate\\formats.py:301: ValueError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n        output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\n        lines = _lines(output)\n    \n        joined = \"\\n\".join(lines)\n        assert \"Alice\" in joined\n        assert \"Bob\" in joined\n>       assert \"N/A\" in joined\nE       AssertionError: assert 'N/A' in 'namestatus\\nAlice\\nBobok'\n\ntests\\Tabulate\\functional_test.py:213: AssertionError\n__________________ test_floatfmt_controls_numeric_rendering ___________________\n\n    def test_floatfmt_controls_numeric_rendering() -> None:\n        rows = [\n            [\"pi\", 3.14159],\n            [\"e\", 2.71828],\n        ]\n        output = tabulate(rows, headers=[\"name\", \"value\"], tablefmt=\"plain\", floatfmt=\".2f\")\n        lines = _lines(output)\n    \n        joined = \"\\n\".join(lines)\n        assert \"pi\" in joined and \"3.14\" in joined\n>       assert \"e\" in joined and \"2.72\" in joined\nE       AssertionError: assert ('e' in 'namevalue\\npi3.14159\\ne2.71828' and '2.72' in 'namevalue\\npi3.14159\\ne2.71828')\n\ntests\\Tabulate\\functional_test.py:227: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\nFAILED tests/Tabulate/functional_test.py::test_missingval_renders_placeholder\nFAILED tests/Tabulate/functional_test.py::test_floatfmt_controls_numeric_rendering\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n6 failed, 6 passed in 0.56s\n"}
{"model": "claude-4.5-haiku", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for +: 'int' and 'str'", "returncode": 1, "elapsed_time_s": 30.388723, "avg_memory_mb": 33.37, "avg_cpu_percent": 0.41, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 11:51:35", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D798490>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D798430>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D7FEA00>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001325D7FEBB0>\n\n    def draw(self):\n        \"\"\"\n        Render the stacked bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max total value for scaling\n        max_total = 0\n        for row in self.data.series:\n>           total = sum(row)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:131: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D7F4A90>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D7F4BE0>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            prin", "stdout_sha1": "fad619ebd83b2ba31dd7787695c2561b117f6a30", "stdout_len": 17816, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D798490>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D798430>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D7FEA00>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001325D7FEBB0>\n\n    def draw(self):\n        \"\"\"\n        Render the stacked bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max total value for scaling\n        max_total = 0\n        for row in self.data.series:\n>           total = sum(row)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:131: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D7F4A90>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D7F4BE0>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nBars\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D833B20>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D833B80>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Values\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D76FEB0>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Labels\", width=10, no_labels=True, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D76FC70>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Labels\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D826A00>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Suffix\", width=18, suffix=\"%\", format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D826A30>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nSuffix\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D830A30>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Fmt\", width=20, format=\"{:>6.2f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D830A90>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nFmt\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D7FCAF0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack Labels\", width=25, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001325D7FCD60>\n\n    def draw(self):\n        \"\"\"\n        Render the stacked bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max total value for scaling\n        max_total = 0\n        for row in self.data.series:\n>           total = sum(row)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:131: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack Labels\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D7587F0>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack No Values\", width=30, no_values=True, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001325D80B790>\n\n    def draw(self):\n        \"\"\"\n        Render the stacked bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max total value for scaling\n        max_total = 0\n        for row in self.data.series:\n>           total = sum(row)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:131: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack No Values\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D77E6D0>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=None, width=15, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D77E760>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001325D8218B0>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001325D821AC0>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if not self.data.series or not self.data.series[0]:\n            return\n    \n        # Print title if provided\n        if self.args.title:\n            print(self.args.title)\n    \n        # Calculate dimensions\n        num_rows = len(self.data.series)\n        num_series = len(self.data.series[0]) if self.data.series else 0\n    \n        if num_series == 0:\n            return\n    \n        # Find max value for scaling\n        max_value = 0\n        for row in self.data.series:\n            for val in row:\n>               if val > max_value:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:46: TypeError\n---------------------------- Captured stdout call -----------------------------\nNarrow\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 29.02s\n"}
{"model": "claude-4.5-haiku", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 2.126481, "avg_memory_mb": 32.5, "avg_cpu_percent": 95.3, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 11:52:08", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "ac2962a926d48c223a8d7feb460c97e21e401801", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-401/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-401/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-401/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001CF700F1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.79s\n"}
{"model": "claude-4.5-haiku", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.911513, "avg_memory_mb": 36.16, "avg_cpu_percent": 99.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:52:41", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n", "stdout_sha1": "819adfd80061416324348d158de8d8280857c381", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n"}
{"model": "claude-4.5-haiku", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'Result' object has no attribute 'stdout'", "returncode": 1, "elapsed_time_s": 2.061531, "avg_memory_mb": 33.14, "avg_cpu_percent": 100.8, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-01 11:53:14", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n        assert r.exit_code == 0\n>       assert \"No tasks.\" in r.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:224: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n        assert r1.exit_code == 0\n>       assert \"Added: Write tests\" in r1.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:234: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = Result(exit_code=1, output='', stderr='').exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n>       out = result.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:265: AttributeError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, ", "stdout_sha1": "f284f73afccca6344d9685c339ecf94414e8dd6d", "stdout_len": 8535, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n        assert r.exit_code == 0\n>       assert \"No tasks.\" in r.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:224: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n        assert r1.exit_code == 0\n>       assert \"Added: Write tests\" in r1.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:234: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = Result(exit_code=1, output='', stderr='').exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n>       out = result.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:265: AttributeError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n>       out = result.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:275: AttributeError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000026F93691400>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:159: AttributeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n>       app = _create_types_app()\n\ntests\\Typer\\functional_test.py:310: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_types_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"calc\" exists as a subcommand.\n        Covers typed arguments and a float option.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def calc(x: int, y: int, scale: float = typer.Option(1.0, \"--scale\")) -> None:\nE       TypeError: __init__() takes from 1 to 2 positional arguments but 3 were given\n\ntests\\Typer\\functional_test.py:181: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AttributeE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - At...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_list_empty_shows_no_tasks - ...\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - AttributeErro...\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - A...\nFAILED tests/Typer/functional_test.py::test_help_output_includes_commands - A...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n12 failed in 0.76s\n"}
{"model": "claude-4.5-haiku", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'FileSystemEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.936454, "avg_memory_mb": 36.54, "avg_cpu_percent": 98.3, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 11:53:43", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'FileSystemEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n", "stdout_sha1": "279bab004f8d80f956a1449ad2ae485c65c648bc", "stdout_len": 1011, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'FileSystemEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n"}
{"model": "claude-4.5-haiku", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "+  where False = any(<generator object test_namespace_prefix_is_preserved.<locals>.<genexpr> at 0x0000020356158580>)", "returncode": 1, "elapsed_time_s": 1.818324, "avg_memory_mb": 32.25, "avg_cpu_percent": 97.3, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 11:54:09", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n>       assert any(k.startswith(\"x:\") for k in keys)\nE       assert False\nE        +  where False = any(<generator object test_namespace_prefix_is_preserved.<locals>.<genexpr> at 0x0000020356158580>)\n\ntests\\Xmltodict\\functional_test.py:131: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\n1 failed, 11 passed in 0.44s\n", "stdout_sha1": "e8b1e58fcd49e9a3e285f771a621f71c01b1836b", "stdout_len": 1071, "stdout": "....F.......                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n>       assert any(k.startswith(\"x:\") for k in keys)\nE       assert False\nE        +  where False = any(<generator object test_namespace_prefix_is_preserved.<locals>.<genexpr> at 0x0000020356158580>)\n\ntests\\Xmltodict\\functional_test.py:131: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\n1 failed, 11 passed in 0.44s\n"}
{"model": "claude-4.5-sonnet", "project": "Cachetools", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "TypeError", "exception_msg": "nonempty __slots__ not supported for subtype of 'tuple'", "returncode": 2, "elapsed_time_s": 2.294141, "avg_memory_mb": 35.17, "avg_cpu_percent": 97.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:24:26", "stdout_excerpt": "====\n____________ ERROR collecting tests/Cachetools/functional_test.py _____________\ntests\\Cachetools\\functional_test.py:26: in <module>\n    from cachetools import LRUCache, TTLCache, cached  # type: ignore  # noqa: E402\ngeneration\\Cachetools\\cachetools\\__init__.py:8: in <module>\n    from .decorators import cached, cachedmethod\ngeneration\\Cachetools\\cachetools\\decorators.py:4: in <module>\n    from .keys import hashkey\ngeneration\\Cachetools\\cachetools\\keys.py:21: in <module>\n    class _HashedTuple(tuple):\nE   TypeError: nonempty __slots__ not supported for subtype of 'tuple'\n=========================== short test summary info ===========================\nERROR tests/Cachetools/functional_test.py - TypeError: nonempty __slots__ not...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.73s\n", "stdout_sha1": "2bf9491a03f6d4e27b7811206179994870fbdded", "stdout_len": 915, "stdout": "\n=================================== ERRORS ====================================\n____________ ERROR collecting tests/Cachetools/functional_test.py _____________\ntests\\Cachetools\\functional_test.py:26: in <module>\n    from cachetools import LRUCache, TTLCache, cached  # type: ignore  # noqa: E402\ngeneration\\Cachetools\\cachetools\\__init__.py:8: in <module>\n    from .decorators import cached, cachedmethod\ngeneration\\Cachetools\\cachetools\\decorators.py:4: in <module>\n    from .keys import hashkey\ngeneration\\Cachetools\\cachetools\\keys.py:21: in <module>\n    class _HashedTuple(tuple):\nE   TypeError: nonempty __slots__ not supported for subtype of 'tuple'\n=========================== short test summary info ===========================\nERROR tests/Cachetools/functional_test.py - TypeError: nonempty __slots__ not...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.73s\n"}
{"model": "claude-4.5-sonnet", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ImportError", "exception_msg": "cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)", "returncode": 1, "elapsed_time_s": 2.22998, "avg_memory_mb": 32.39, "avg_cpu_percent": 99.3, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2025-12-31 13:25:43", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.add\")\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_002_create_app_and_register_task_runs_delay.<locals>.add at 0x000002C4D87A74C0>\n\n    def decorator(func):\n        name = opts.get('name') or f'{self.main}.{func.__name__}'\n        bind = opts.get('bind', False)\n    \n>       task = Task(\n            func=func,\n            name=name,\n            app=self,\n            bind=bind,\n            **opts\n        )\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:80: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.mul\")\n>       def mul(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager.<locals>.mul at 0x000002C4D87A73A0>\n\n    def decorator(func):\n        name = opts.get('name') or f'{self.main}.{func.__name__}'\n        bind = opts.get('bind', False)\n    \n>       task = Task(\n            func=func,\n            name=name,\n            app=self,\n            bind=bind,\n            **opts\n        )\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:80: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n        app = _make_app()\n>       from celery import group\nE       ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:90: ImportError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n        app = _make_app()\n>       from celery import chain\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:104: ImportError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n        app = _make_app()\n>       from celery import chord, group\nE       ImportError: cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:117: ImportError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts bot", "stdout_sha1": "88ffbb5f53615068ae6b881ef66970af8f61b18f", "stdout_len": 8673, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.add\")\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_002_create_app_and_register_task_runs_delay.<locals>.add at 0x000002C4D87A74C0>\n\n    def decorator(func):\n        name = opts.get('name') or f'{self.main}.{func.__name__}'\n        bind = opts.get('bind', False)\n    \n>       task = Task(\n            func=func,\n            name=name,\n            app=self,\n            bind=bind,\n            **opts\n        )\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:80: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.mul\")\n>       def mul(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager.<locals>.mul at 0x000002C4D87A73A0>\n\n    def decorator(func):\n        name = opts.get('name') or f'{self.main}.{func.__name__}'\n        bind = opts.get('bind', False)\n    \n>       task = Task(\n            func=func,\n            name=name,\n            app=self,\n            bind=bind,\n            **opts\n        )\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:80: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n        app = _make_app()\n>       from celery import group\nE       ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:90: ImportError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n        app = _make_app()\n>       from celery import chain\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:104: ImportError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n        app = _make_app()\n>       from celery import chord, group\nE       ImportError: cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:117: ImportError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.boom\")\n>       def boom() -> None:\n\ntests\\Celery\\functional_test.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_007_task_exception_propagates_in_eager_mode.<locals>.boom at 0x000002C4D873CE50>\n\n    def decorator(func):\n        name = opts.get('name') or f'{self.main}.{func.__name__}'\n        bind = opts.get('bind', False)\n    \n>       task = Task(\n            func=func,\n            name=name,\n            app=self,\n            bind=bind,\n            **opts\n        )\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:80: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n        app = _make_app()\n        app.conf.task_eager_propagates = False\n    \n        @app.task(name=\"celery_test.boom2\")\n>       def boom2() -> None:\n\ntests\\Celery\\functional_test.py:169: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_008_disable_propagation_returns_failed_result.<locals>.boom2 at 0x000002C4D87A7940>\n\n    def decorator(func):\n        name = opts.get('name') or f'{self.main}.{func.__name__}'\n        bind = opts.get('bind', False)\n    \n>       task = Task(\n            func=func,\n            name=name,\n            app=self,\n            bind=bind,\n            **opts\n        )\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:80: TypeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n        app = _make_app()\n>       from celery import signature\nE       ImportError: cannot import name 'signature' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:191: ImportError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n        app = _make_app(\"celery_test_app_2\")\n    \n        @app.task(name=\"celery_test_app_2.add\")\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:210: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_010_default_app_does_not_break_custom_app_usage.<locals>.add at 0x000002C4D87A7310>\n\n    def decorator(func):\n        name = opts.get('name') or f'{self.main}.{func.__name__}'\n        bind = opts.get('bind', False)\n    \n>       task = Task(\n            func=func,\n            name=name,\n            app=self,\n            bind=bind,\n            **opts\n        )\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:80: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.83s\n"}
{"model": "claude-4.5-sonnet", "project": "Click", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'click.utils'", "returncode": 2, "elapsed_time_s": 5.866445, "avg_memory_mb": 35.72, "avg_cpu_percent": 98.4, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:27:38", "stdout_excerpt": "====\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:5: in <module>\n    from .core import (\ngeneration\\Click\\click\\core.py:8: in <module>\n    from .utils import make_str, make_default_short_help\nE   ModuleNotFoundError: No module named 'click.utils'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.28s\n", "stdout_sha1": "85260db9132ef83d081f607323a94f563c3a2a04", "stdout_len": 1057, "stdout": "\n=================================== ERRORS ====================================\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:5: in <module>\n    from .core import (\ngeneration\\Click\\click\\core.py:8: in <module>\n    from .utils import make_str, make_default_short_help\nE   ModuleNotFoundError: No module named 'click.utils'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.28s\n"}
{"model": "claude-4.5-sonnet", "project": "Cmd2", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'Hello Alice' in ''", "returncode": 1, "elapsed_time_s": 5.712376, "avg_memory_mb": 32.0, "avg_cpu_percent": 99.7, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 13:29:05", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_echo_arguments_and_parsing _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x000001FD7ADEE820>\n\n    def test_echo_arguments_and_parsing(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, \"echo_args one two three\")\n>       assert \"one two three\" in output\nE       AssertionError: assert 'one two three' in '\\n'\n\ntests\\Cmd2\\functional_test.py:276: AssertionError\n_______________________ test_echo_arguments_with_quotes _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x000001FD7ADE3490>\n\n    def test_echo_arguments_with_quotes(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, 'echo_args \"hello world\" two')\n>       assert \"hello world two\" in output\nE       AssertionError: assert 'hello world two' in '\\n'\n\ntests\\Cmd2\\functional_test.py:283: AssertionError\n_____________________ test_multiple_commands_and_history ______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x000001FD7AD87490>\n\n    def test_multiple_commands_and_history(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        commands = [\"greet Alice\", \"greet Bob\", \"history\"]\n        output = run_commands(app, commands)\n>       assert \"Hello Alice\" in output\nE       AssertionError: assert 'Hello Alice' in ''\n\ntests\\Cmd2\\functional_test.py:321: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_and_parsing - Asser...\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_with_quotes - Asser...\nFAILED tests/Cmd2/functional_test.py::test_multiple_commands_and_history - As...\n3 failed, 8 passed in 4.17s\n", "stdout_sha1": "09a069e027fbe57d77135e1b03f815c0341e6e52", "stdout_len": 2059, "stdout": "..FF....F..                                                              [100%]\n================================== FAILURES ===================================\n_______________________ test_echo_arguments_and_parsing _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x000001FD7ADEE820>\n\n    def test_echo_arguments_and_parsing(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, \"echo_args one two three\")\n>       assert \"one two three\" in output\nE       AssertionError: assert 'one two three' in '\\n'\n\ntests\\Cmd2\\functional_test.py:276: AssertionError\n_______________________ test_echo_arguments_with_quotes _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x000001FD7ADE3490>\n\n    def test_echo_arguments_with_quotes(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, 'echo_args \"hello world\" two')\n>       assert \"hello world two\" in output\nE       AssertionError: assert 'hello world two' in '\\n'\n\ntests\\Cmd2\\functional_test.py:283: AssertionError\n_____________________ test_multiple_commands_and_history ______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x000001FD7AD87490>\n\n    def test_multiple_commands_and_history(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        commands = [\"greet Alice\", \"greet Bob\", \"history\"]\n        output = run_commands(app, commands)\n>       assert \"Hello Alice\" in output\nE       AssertionError: assert 'Hello Alice' in ''\n\ntests\\Cmd2\\functional_test.py:321: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_and_parsing - Asser...\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_with_quotes - Asser...\nFAILED tests/Cmd2/functional_test.py::test_multiple_commands_and_history - As...\n3 failed, 8 passed in 4.17s\n"}
{"model": "claude-4.5-sonnet", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "sqlite3.OperationalError: no such column: order_by", "returncode": 1, "elapsed_time_s": 6.072752, "avg_memory_mb": 34.03, "avg_cpu_percent": 98.7, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 13:30:05", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:233: in find\n    cursor = self.database.execute(sql, values)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001D902AB6AF0>\nsql = 'SELECT * FROM users WHERE age = ?', params = [{'>=': 40}]\n\n    def execute(self, sql, params=None):\n        \"\"\"\n        Execute a SQL statement.\n    \n        Args:\n            sql: SQL statement\n            params: Parameters (dict or tuple)\n    \n        Returns:\n            Cursor object\n        \"\"\"\n        if params is None:\n            params = {}\n>       return self._connection.execute(sql, params)\nE       sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\database.py:107: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n>       rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n\ntests\\Dataset\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:233: in find\n    cursor = self.database.execute(sql, values)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001D902AA8610>\nsql = 'SELECT * FROM nums WHERE order_by = ? AND _limit = ? AND _offset = ?'\nparams = ['n', 3, 4]\n\n    def execute(self, sql, params=None):\n        \"\"\"\n        Execute a SQL statement.\n    \n        Args:\n            sql: SQL statement\n            params: Parameters (dict or tuple)\n    \n        Returns:\n            Cursor object\n        \"\"\"\n        if params is None:\n            params = {}\n>       return self._connection.execute(sql, params)\nE       sqlite3.OperationalError: no such column: order_by\n\ngeneration\\Dataset\\da", "stdout_sha1": "43e369fc65539c931e838cca2e378386030ee0f6", "stdout_len": 5807, "stdout": "FF...F..F.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:233: in find\n    cursor = self.database.execute(sql, values)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001D902AB6AF0>\nsql = 'SELECT * FROM users WHERE age = ?', params = [{'>=': 40}]\n\n    def execute(self, sql, params=None):\n        \"\"\"\n        Execute a SQL statement.\n    \n        Args:\n            sql: SQL statement\n            params: Parameters (dict or tuple)\n    \n        Returns:\n            Cursor object\n        \"\"\"\n        if params is None:\n            params = {}\n>       return self._connection.execute(sql, params)\nE       sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\database.py:107: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n>       rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n\ntests\\Dataset\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:233: in find\n    cursor = self.database.execute(sql, values)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001D902AA8610>\nsql = 'SELECT * FROM nums WHERE order_by = ? AND _limit = ? AND _offset = ?'\nparams = ['n', 3, 4]\n\n    def execute(self, sql, params=None):\n        \"\"\"\n        Execute a SQL statement.\n    \n        Args:\n            sql: SQL statement\n            params: Parameters (dict or tuple)\n    \n        Returns:\n            Cursor object\n        \"\"\"\n        if params is None:\n            params = {}\n>       return self._connection.execute(sql, params)\nE       sqlite3.OperationalError: no such column: order_by\n\ngeneration\\Dataset\\dataset\\database.py:107: OperationalError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x000001D902B733D0>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001D902B77A30>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - ass...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n5 failed, 6 passed in 4.48s\n"}
{"model": "claude-4.5-sonnet", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:31:45", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "claude-4.5-sonnet", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where <built-in method lower of str object at 0x000001F5AF1083B0> = '12,000'.lower", "returncode": 1, "elapsed_time_s": 2.163074, "avg_memory_mb": 32.34, "avg_cpu_percent": 96.2, "passed": 12, "failed": 1, "skipped": 2, "total": 15, "functional_score": 0.8, "timestamp": "2025-12-31 13:38:35", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_intword_thousand_scale _________________________\n\n    def test_intword_thousand_scale() -> None:\n        if not hasattr(humanize, \"intword\"):\n            pytest.skip(\"humanize.intword is not available in this repository/version.\")\n        s = humanize.intword(12_000)\n        assert isinstance(s, str)\n        assert s\n>       assert \"thousand\" in s.lower()\nE       AssertionError: assert 'thousand' in '12,000'\nE        +  where '12,000' = <built-in method lower of str object at 0x000001F5AF1083B0>()\nE        +    where <built-in method lower of str object at 0x000001F5AF1083B0> = '12,000'.lower\n\ntests\\Humanize\\functional_test.py:195: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_intword_thousand_scale - Asser...\n1 failed, 12 passed, 2 skipped in 0.54s\n", "stdout_sha1": "f1dcc5998f6115a4b717cdf43888c308c15dd0da", "stdout_len": 1047, "stdout": "............Fss                                                          [100%]\n================================== FAILURES ===================================\n_________________________ test_intword_thousand_scale _________________________\n\n    def test_intword_thousand_scale() -> None:\n        if not hasattr(humanize, \"intword\"):\n            pytest.skip(\"humanize.intword is not available in this repository/version.\")\n        s = humanize.intword(12_000)\n        assert isinstance(s, str)\n        assert s\n>       assert \"thousand\" in s.lower()\nE       AssertionError: assert 'thousand' in '12,000'\nE        +  where '12,000' = <built-in method lower of str object at 0x000001F5AF1083B0>()\nE        +    where <built-in method lower of str object at 0x000001F5AF1083B0> = '12,000'.lower\n\ntests\\Humanize\\functional_test.py:195: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_intword_thousand_scale - Asser...\n1 failed, 12 passed, 2 skipped in 0.54s\n"}
{"model": "claude-4.5-sonnet", "project": "Imageio", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "module 'imageio.v3' has no attribute 'imopen'", "returncode": 1, "elapsed_time_s": 2.582477, "avg_memory_mb": 44.95, "avg_cpu_percent": 98.1, "passed": 7, "failed": 3, "skipped": 0, "total": 10, "functional_score": 0.7, "timestamp": "2025-12-31 13:39:57", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\n\ntests\\Imageio\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:416: in imwrite\n    _write_png(path, image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('<bytes>')\nimage = array([[[157, 193, 255],\n        [178, 141, 177],\n        [ 50,  58, 222],\n        ...,\n        [249,   7, 141],\n     ...[  9, 234,  27],\n        ...,\n        [219, 110, 131],\n        [255, 135, 132],\n        [203,  36, 116]]], dtype=uint8)\n\n    def _write_png(path: Path, image: np.ndarray) -> None:\n        \"\"\"Write a single image as PNG.\"\"\"\n        if image.ndim == 2:\n            # Grayscale\n            height, width = image.shape\n            color_type = 0\n            channels = 1\n            data = image.reshape(height, width, 1)\n        elif image.ndim == 3:\n            height, width, channels = image.shape\n            if channels == 1:\n                color_type = 0\n            elif channels == 3:\n                color_type = 2\n            else:\n                raise ValueError(f\"Unsupported number of channels: {channels}\")\n            data = image\n        else:\n            raise ValueError(f\"Unsupported image dimensions: {image.ndim}\")\n    \n        # Convert to uint8 if needed\n        if data.dtype != np.uint8:\n            data = data.astype(np.uint8)\n    \n>       with open(path, 'wb') as f:\nE       OSError: [Errno 22] Invalid argument: '<bytes>'\n\ngeneration\\Imageio\\imageio\\v3.py:47: OSError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-283/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape[0] == frames.shape[0]\nE       assert 20 == 5\n\ntests\\Imageio\\functional_test.py:194: AssertionError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-283/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n3 failed, 7 passed in 1.08s\n", "stdout_sha1": "2d6ff400db2a1c43fa109959cffc562abcc0a4e6", "stdout_len": 3776, "stdout": "...F..F.F.                                                               [100%]\n================================== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\n\ntests\\Imageio\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:416: in imwrite\n    _write_png(path, image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('<bytes>')\nimage = array([[[157, 193, 255],\n        [178, 141, 177],\n        [ 50,  58, 222],\n        ...,\n        [249,   7, 141],\n     ...[  9, 234,  27],\n        ...,\n        [219, 110, 131],\n        [255, 135, 132],\n        [203,  36, 116]]], dtype=uint8)\n\n    def _write_png(path: Path, image: np.ndarray) -> None:\n        \"\"\"Write a single image as PNG.\"\"\"\n        if image.ndim == 2:\n            # Grayscale\n            height, width = image.shape\n            color_type = 0\n            channels = 1\n            data = image.reshape(height, width, 1)\n        elif image.ndim == 3:\n            height, width, channels = image.shape\n            if channels == 1:\n                color_type = 0\n            elif channels == 3:\n                color_type = 2\n            else:\n                raise ValueError(f\"Unsupported number of channels: {channels}\")\n            data = image\n        else:\n            raise ValueError(f\"Unsupported image dimensions: {image.ndim}\")\n    \n        # Convert to uint8 if needed\n        if data.dtype != np.uint8:\n            data = data.astype(np.uint8)\n    \n>       with open(path, 'wb') as f:\nE       OSError: [Errno 22] Invalid argument: '<bytes>'\n\ngeneration\\Imageio\\imageio\\v3.py:47: OSError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-283/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape[0] == frames.shape[0]\nE       assert 20 == 5\n\ntests\\Imageio\\functional_test.py:194: AssertionError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-283/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n3 failed, 7 passed in 1.08s\n"}
{"model": "claude-4.5-sonnet", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'CoxPHFitter' object has no attribute 'concordance_index_'", "returncode": 1, "elapsed_time_s": 5.207046, "avg_memory_mb": 48.27, "avg_cpu_percent": 49.7, "passed": 9, "failed": 6, "skipped": 0, "total": 15, "functional_score": 0.6, "timestamp": "2025-12-31 13:41:29", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n        et = kmf.event_table\n        for col in [\"removed\", \"observed\", \"censored\", \"at_risk\"]:\n>           assert col in et.columns\nE           AssertionError: assert 'removed' in Index(['at_risk', 'observed'], dtype='object')\nE            +  where Index(['at_risk', 'observed'], dtype='object') =    at_risk  observed\\n2        6         1\\n3        5         0\\n4        4         1\\n5        3         1\\n6        2         1.columns\n\ntests\\Lifelines\\functional_test.py:185: AssertionError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test", "stdout_sha1": "ba1ff2edb2220b8020fc18064a046d57f957bbbd", "stdout_len": 4386, "stdout": ".....FFFF.F..F.                                                          [100%]\n================================== FAILURES ===================================\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n        et = kmf.event_table\n        for col in [\"removed\", \"observed\", \"censored\", \"at_risk\"]:\n>           assert col in et.columns\nE           AssertionError: assert 'removed' in Index(['at_risk', 'observed'], dtype='object')\nE            +  where Index(['at_risk', 'observed'], dtype='object') =    at_risk  observed\\n2        6         1\\n3        5         0\\n4        4         1\\n5        3         1\\n6        2         1.columns\n\ntests\\Lifelines\\functional_test.py:185: AssertionError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\n6 failed, 9 passed in 3.53s\n"}
{"model": "claude-4.5-sonnet", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 2.124104, "avg_memory_mb": 32.33, "avg_cpu_percent": 96.9, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 13:43:40", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.63s\n", "stdout_sha1": "544bcd4a606b6d00e783d4a5821fdb40a2984256", "stdout_len": 3013, "stdout": "........FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.63s\n"}
{"model": "claude-4.5-sonnet", "project": "Mutagen", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "KeyError", "exception_msg": "0", "returncode": 1, "elapsed_time_s": 2.115969, "avg_memory_mb": 32.63, "avg_cpu_percent": 102.3, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 13:45:02", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_easyid3_genre_and_albumartist_roundtrip _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-284/test_easyid3_genre_and_albumar0')\n\n    def test_easyid3_genre_and_albumartist_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common optional fields via EasyID3 (genre/albumartist).\"\"\"\n        audio_path = tmp_path / \"genre_albumartist.mp3\"\n    \n        tags = EasyID3()\n        tags[\"title\"] = [\"Tagged Song\"]\n        tags[\"artist\"] = [\"Main Artist\"]\n>       tags[\"albumartist\"] = [\"Album Artist\"]\n\ntests\\Mutagen\\functional_test.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.easyid3.EasyID3 object at 0x00000126B5AC5AF0>\nkey = 'albumartist', value = ['Album Artist']\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Set tag values for a key.\n    \n        Args:\n            key: Tag key (e.g., \"title\", \"artist\")\n            value: List of string values\n        \"\"\"\n        if key not in _EASY_MAP:\n>           raise KeyError(key)\nE           KeyError: 'albumartist'\n\ngeneration\\Mutagen\\mutagen\\easyid3.py:74: KeyError\n_______________ test_low_level_id3_frames_with_comment_and_apic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-284/test_low_level_id3_frames_with0')\n\n    def test_low_level_id3_frames_with_comment_and_apic(tmp_path: Path) -> None:\n        \"\"\"Use low-level ID3 frames to store text and embedded artwork.\"\"\"\n        audio_path = tmp_path / \"id3_frames.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Frame Title\"))\n        tags.add(TPE1(encoding=3, text=\"Frame Artist\"))\n        tags.add(\n            COMM(\n                encoding=3,\n                lang=\"eng\",\n                desc=\"Comment\",\n                text=\"This is a test comment.\",\n            )\n        )\n    \n        image_data = b\"\\xff\\xd8\\xff\\x00FAKEJPEGDATA\"\n        tags.add(\n            APIC(\n                encoding=3,\n                mime=\"image/jpeg\",\n                type=3,\n                desc=\"Cover\",\n                data=image_data,\n            )\n        )\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n    \n>       assert \"TIT2\" in loaded\n\ntests\\Mutagen\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3.ID3 object at 0x00000126B5ABC7C0>, frame_id = 0\n\n    def __getitem__(self, frame_id):\n        \"\"\"Get the first frame with the given ID.\"\"\"\n        frames = self._frames.get(frame_id, [])\n        if not frames:\n>           raise KeyError(frame_id)\nE           KeyError: 0\n\ngeneration\\Mutagen\\mutagen\\id3.py:216: KeyError\n=========================== short test summary info ===========================\nFAILED tests/Mutagen/functional_test.py::test_easyid3_genre_and_albumartist_roundtrip\nFAILED tests/Mutagen/functional_test.py::test_low_level_id3_frames_with_comment_and_apic\n2 failed, 10 passed in 0.68s\n", "stdout_sha1": "2492f321edcd3eacf40099387d76d8d09e253aeb", "stdout_len": 3191, "stdout": ".....F.F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_easyid3_genre_and_albumartist_roundtrip _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-284/test_easyid3_genre_and_albumar0')\n\n    def test_easyid3_genre_and_albumartist_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common optional fields via EasyID3 (genre/albumartist).\"\"\"\n        audio_path = tmp_path / \"genre_albumartist.mp3\"\n    \n        tags = EasyID3()\n        tags[\"title\"] = [\"Tagged Song\"]\n        tags[\"artist\"] = [\"Main Artist\"]\n>       tags[\"albumartist\"] = [\"Album Artist\"]\n\ntests\\Mutagen\\functional_test.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.easyid3.EasyID3 object at 0x00000126B5AC5AF0>\nkey = 'albumartist', value = ['Album Artist']\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Set tag values for a key.\n    \n        Args:\n            key: Tag key (e.g., \"title\", \"artist\")\n            value: List of string values\n        \"\"\"\n        if key not in _EASY_MAP:\n>           raise KeyError(key)\nE           KeyError: 'albumartist'\n\ngeneration\\Mutagen\\mutagen\\easyid3.py:74: KeyError\n_______________ test_low_level_id3_frames_with_comment_and_apic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-284/test_low_level_id3_frames_with0')\n\n    def test_low_level_id3_frames_with_comment_and_apic(tmp_path: Path) -> None:\n        \"\"\"Use low-level ID3 frames to store text and embedded artwork.\"\"\"\n        audio_path = tmp_path / \"id3_frames.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Frame Title\"))\n        tags.add(TPE1(encoding=3, text=\"Frame Artist\"))\n        tags.add(\n            COMM(\n                encoding=3,\n                lang=\"eng\",\n                desc=\"Comment\",\n                text=\"This is a test comment.\",\n            )\n        )\n    \n        image_data = b\"\\xff\\xd8\\xff\\x00FAKEJPEGDATA\"\n        tags.add(\n            APIC(\n                encoding=3,\n                mime=\"image/jpeg\",\n                type=3,\n                desc=\"Cover\",\n                data=image_data,\n            )\n        )\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n    \n>       assert \"TIT2\" in loaded\n\ntests\\Mutagen\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3.ID3 object at 0x00000126B5ABC7C0>, frame_id = 0\n\n    def __getitem__(self, frame_id):\n        \"\"\"Get the first frame with the given ID.\"\"\"\n        frames = self._frames.get(frame_id, [])\n        if not frames:\n>           raise KeyError(frame_id)\nE           KeyError: 0\n\ngeneration\\Mutagen\\mutagen\\id3.py:216: KeyError\n=========================== short test summary info ===========================\nFAILED tests/Mutagen/functional_test.py::test_easyid3_genre_and_albumartist_roundtrip\nFAILED tests/Mutagen/functional_test.py::test_low_level_id3_frames_with_comment_and_apic\n2 failed, 10 passed in 0.68s\n"}
{"model": "claude-4.5-sonnet", "project": "Pendulum", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.634536, "avg_memory_mb": 31.71, "avg_cpu_percent": 98.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:46:45", "stdout_excerpt": "\n1 skipped in 0.19s\n", "stdout_sha1": "defdb7f46dcd131fbdba9b7d779dbe0528dfb2bd", "stdout_len": 20, "stdout": "\n1 skipped in 0.19s\n"}
{"model": "claude-4.5-sonnet", "project": "Petl", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "sort() got an unexpected keyword argument 'reverse'", "returncode": 1, "elapsed_time_s": 2.059613, "avg_memory_mb": 32.5, "avg_cpu_percent": 100.8, "passed": 5, "failed": 1, "skipped": 6, "total": 12, "functional_score": 0.4167, "timestamp": "2025-12-31 13:47:31", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n1 failed, 5 passed, 6 skipped in 0.62s\n", "stdout_sha1": "a8eeb271cab21f171e954cd0f72be16e67879b8b", "stdout_len": 1049, "stdout": "...ss.Fs.sss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n1 failed, 5 passed, 6 skipped in 0.62s\n"}
{"model": "claude-4.5-sonnet", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.45172, "avg_memory_mb": 14.52, "avg_cpu_percent": 95.4, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:49:17", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 14, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\nModuleNotFoundError: No module named 'pygments.formatters.terminal'\n", "stdout_sha1": "41bc045475dbbd9d53010b74b398f8f744b6d9d6", "stdout_len": 1441, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 14, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\nModuleNotFoundError: No module named 'pygments.formatters.terminal'\n"}
{"model": "claude-4.5-sonnet", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 2.167722, "avg_memory_mb": 33.85, "avg_cpu_percent": 100.8, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 13:49:57", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x0000022A157F0FD0>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None\n\n    def encode(self, payload, key, algorithm=\"HS256\", headers=None, json_encoder=None):\n        \"\"\"\n        Encode a payload into a JWT string.\n    \n        Args:\n            payload: Dictionary containing the claims\n            key: Secret key for signing\n            algorithm: Signing algorithm (only HS256 supported)\n            headers: Optional additional headers\n            json_encoder: Optional custom JSON encoder\n    \n        Returns:\n            JWT string in format: header.payload.signature\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(f\"Algorithm {algorithm} not supported\")\nE           NotImplementedError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:56: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:65: in encode\n    payload_bytes = json.dumps(payload, separators=(',', ':'), cls=json_encoder).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000022A15875AC0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_d", "stdout_sha1": "e73a32db76184efd8917440204bd0d4038abcfd4", "stdout_len": 7155, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x0000022A157F0FD0>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None\n\n    def encode(self, payload, key, algorithm=\"HS256\", headers=None, json_encoder=None):\n        \"\"\"\n        Encode a payload into a JWT string.\n    \n        Args:\n            payload: Dictionary containing the claims\n            key: Secret key for signing\n            algorithm: Signing algorithm (only HS256 supported)\n            headers: Optional additional headers\n            json_encoder: Optional custom JSON encoder\n    \n        Returns:\n            JWT string in format: header.payload.signature\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(f\"Algorithm {algorithm} not supported\")\nE           NotImplementedError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:56: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:65: in encode\n    payload_bytes = json.dumps(payload, separators=(',', ':'), cls=json_encoder).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000022A15875AC0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:65: in encode\n    payload_bytes = json.dumps(payload, separators=(',', ':'), cls=json_encoder).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000022A158711C0>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.63s\n"}
{"model": "claude-4.5-sonnet", "project": "PyPDF", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "IndexError", "exception_msg": "list index out of range", "returncode": 1, "elapsed_time_s": 2.388773, "avg_memory_mb": 16.55, "avg_cpu_percent": 50.0, "passed": 1, "failed": 10, "skipped": 1, "total": 12, "functional_score": 0.0833, "timestamp": "2025-12-31 13:51:25", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=3)\n    \n        reader = PdfReader(str(pdf_path))\n>       assert len(reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf.reader.PdfReader object at 0x000001EE665A10D0>.pages\n\ntests\\PyPDF\\functional_test.py:137: AssertionError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n        reader = PdfReader(str(pdf_path))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:146: IndexError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n        _create_simple_pdf(pdf1, num_pages=1)\n        _create_simple_pdf(pdf2, num_pages=2)\n    \n        _write_pdf_with_pages([pdf1, pdf2], merged)\n    \n        merged_reader = PdfReader(str(merged))\n>       assert len(merged_reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf.reader.PdfReader object at 0x000001EE666258B0>.pages\n\ntests\\PyPDF\\functional_test.py:165: AssertionError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n        _create_simple_pdf(src, num_pages=4)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for page in reader.pages:\n            writer.add_page(page)\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n>       assert len(reader2.pages) == 4\nE       assert 0 == 4\nE        +  where 0 = len([])\nE        +    where [] = <pypdf.reader.PdfReader object at 0x000001EE665B57F0>.pages\n\ntests\\PyPDF\\functional_test.py:183: AssertionError\n______________________________ test_rotate_page _______________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_rotate_page0')\n\n    def test_rotate_page(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        rotated = tmp_path / \"rotated.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:192: IndexError\n_______________________ test_rotate_preserves_page_size _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_rotate_preserves_page_siz0')\n\n    def test_rotate_preserves_page_size(tmp_path: Path) -> None:\n        \"\"\"Rotating a blank page should keep a valid mediabox size.\"\"\"\n        src = tmp_path / \"src_size.pdf\"\n        rotated = tmp_path / \"rot_size.pdf\"\n        _create_simple_p", "stdout_sha1": "c3a082c67198893ce490ad623ce3d6af71d6199a", "stdout_len": 9032, "stdout": "FFFFFF.FFFsF                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=3)\n    \n        reader = PdfReader(str(pdf_path))\n>       assert len(reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf.reader.PdfReader object at 0x000001EE665A10D0>.pages\n\ntests\\PyPDF\\functional_test.py:137: AssertionError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n        reader = PdfReader(str(pdf_path))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:146: IndexError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n        _create_simple_pdf(pdf1, num_pages=1)\n        _create_simple_pdf(pdf2, num_pages=2)\n    \n        _write_pdf_with_pages([pdf1, pdf2], merged)\n    \n        merged_reader = PdfReader(str(merged))\n>       assert len(merged_reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf.reader.PdfReader object at 0x000001EE666258B0>.pages\n\ntests\\PyPDF\\functional_test.py:165: AssertionError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n        _create_simple_pdf(src, num_pages=4)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for page in reader.pages:\n            writer.add_page(page)\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n>       assert len(reader2.pages) == 4\nE       assert 0 == 4\nE        +  where 0 = len([])\nE        +    where [] = <pypdf.reader.PdfReader object at 0x000001EE665B57F0>.pages\n\ntests\\PyPDF\\functional_test.py:183: AssertionError\n______________________________ test_rotate_page _______________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_rotate_page0')\n\n    def test_rotate_page(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        rotated = tmp_path / \"rotated.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:192: IndexError\n_______________________ test_rotate_preserves_page_size _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_rotate_preserves_page_siz0')\n\n    def test_rotate_preserves_page_size(tmp_path: Path) -> None:\n        \"\"\"Rotating a blank page should keep a valid mediabox size.\"\"\"\n        src = tmp_path / \"src_size.pdf\"\n        rotated = tmp_path / \"rot_size.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:213: IndexError\n_____________ test_encrypted_pdf_allows_page_access_after_decrypt _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_encrypted_pdf_allows_page0')\n\n    def test_encrypted_pdf_allows_page_access_after_decrypt(tmp_path: Path) -> None:\n        \"\"\"After decrypting, basic page access should succeed and page size is valid.\"\"\"\n        src = tmp_path / \"plain2.pdf\"\n        enc = tmp_path / \"encrypted2.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n>       writer.add_page(reader.pages[0])\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:260: IndexError\n___________________________ test_metadata_roundtrip ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_metadata_roundtrip0')\n\n    def test_metadata_roundtrip(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"meta.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for page in reader.pages:\n            writer.add_page(page)\n    \n        writer.add_metadata(\n            {\n                \"/Title\": \"PyPDF Benchmark Document\",\n                \"/Author\": \"RealAppCodeBench\",\n            }\n        )\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n>       meta = reader2.metadata\n\ntests\\PyPDF\\functional_test.py:296: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf.reader.PdfReader object at 0x000001EE666255B0>\n\n    @property\n    def metadata(self) -> Dict[str, Any]:\n        \"\"\"Get document metadata.\"\"\"\n        if b'/Info' in self._trailer:\n            info_ref = self._trailer[b'/Info']\n            info_dict = self._resolve_object(info_ref)\n    \n            # Convert to string keys\n            result = {}\n>           for key, value in info_dict.items():\nE           AttributeError: 'bytes' object has no attribute 'items'\n\ngeneration\\PyPDF\\pypdf\\reader.py:324: AttributeError\n___________________ test_metadata_multiple_fields_roundtrip ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_metadata_multiple_fields_0')\n\n    def test_metadata_multiple_fields_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Add several info dict fields and ensure they can be read back.\"\"\"\n        src = tmp_path / \"src_info.pdf\"\n        dst = tmp_path / \"info.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n>       writer.add_page(reader.pages[0])\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:310: IndexError\n_________________ test_clone_document_by_writing_reader_pages _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-286/test_clone_document_by_writing0')\n\n    def test_clone_document_by_writing_reader_pages(tmp_path: Path) -> None:\n        \"\"\"Clone a document by copying pages and verify page count matches.\"\"\"\n        src = tmp_path / \"orig.pdf\"\n        dst = tmp_path / \"clone.pdf\"\n        _create_simple_pdf(src, num_pages=3)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for p in reader.pages:\n            writer.add_page(p)\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n>       assert len(reader2.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf.reader.PdfReader object at 0x000001EE665BF040>.pages\n\ntests\\PyPDF\\functional_test.py:372: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/PyPDF/functional_test.py::test_create_and_read_blank_pdf - asser...\nFAILED tests/PyPDF/functional_test.py::test_blank_page_has_expected_size - In...\nFAILED tests/PyPDF/functional_test.py::test_merge_two_pdfs - assert 0 == 3\nFAILED tests/PyPDF/functional_test.py::test_writer_add_page_preserves_page_count\nFAILED tests/PyPDF/functional_test.py::test_rotate_page - IndexError: list in...\nFAILED tests/PyPDF/functional_test.py::test_rotate_preserves_page_size - Inde...\nFAILED tests/PyPDF/functional_test.py::test_encrypted_pdf_allows_page_access_after_decrypt\nFAILED tests/PyPDF/functional_test.py::test_metadata_roundtrip - AttributeErr...\nFAILED tests/PyPDF/functional_test.py::test_metadata_multiple_fields_roundtrip\nFAILED tests/PyPDF/functional_test.py::test_clone_document_by_writing_reader_pages\n10 failed, 1 passed, 1 skipped in 0.87s\n"}
{"model": "claude-4.5-sonnet", "project": "Requests", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'requests.api'", "returncode": 2, "elapsed_time_s": 2.216445, "avg_memory_mb": 37.68, "avg_cpu_percent": 99.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:53:39", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Requests/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Requests\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Requests\\functional_test.py:40: in <module>\n    import requests  # noqa: E402\ngeneration\\Requests\\requests\\__init__.py:21: in <module>\n    from .api import request, get, head, post, patch, put, delete, options\nE   ModuleNotFoundError: No module named 'requests.api'\n=========================== short test summary info ===========================\nERROR tests/Requests/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.72s\n", "stdout_sha1": "6135278055771ee739be8bf89998c491d94a537e", "stdout_len": 1008, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Requests/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Requests\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Requests\\functional_test.py:40: in <module>\n    import requests  # noqa: E402\ngeneration\\Requests\\requests\\__init__.py:21: in <module>\n    from .api import request, get, head, post, patch, put, delete, options\nE   ModuleNotFoundError: No module named 'requests.api'\n=========================== short test summary info ===========================\nERROR tests/Requests/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.72s\n"}
{"model": "claude-4.5-sonnet", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.625337, "avg_memory_mb": 31.98, "avg_cpu_percent": 101.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:55:18", "stdout_excerpt": "\n1 skipped in 0.19s\n", "stdout_sha1": "defdb7f46dcd131fbdba9b7d779dbe0528dfb2bd", "stdout_len": 20, "stdout": "\n1 skipped in 0.19s\n"}
{"model": "claude-4.5-sonnet", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'schedule' has no attribute 'repeat'", "returncode": 1, "elapsed_time_s": 2.02819, "avg_memory_mb": 32.05, "avg_cpu_percent": 99.2, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 13:56:16", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\n1 failed, 11 passed in 0.49s\n", "stdout_sha1": "74e4ff555d9ede219586edd5f5f9e35875dbe38e", "stdout_len": 802, "stdout": "...F........                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\n1 failed, 11 passed in 0.49s\n"}
{"model": "claude-4.5-sonnet", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where <built-in method startswith of str object at 0x000001B9F1454E30> = 'thisisatest'.startswith", "returncode": 1, "elapsed_time_s": 2.032615, "avg_memory_mb": 31.74, "avg_cpu_percent": 99.2, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 13:56:49", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001B9F1454E30>('___')\nE        +    where <built-in method startswith of str object at 0x000001B9F1454E30> = 'thisisatest'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.50s\n", "stdout_sha1": "303a4482a82e8f94773373bd9517af606e4f032f", "stdout_len": 1078, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001B9F1454E30>('___')\nE        +    where <built-in method startswith of str object at 0x000001B9F1454E30> = 'thisisatest'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.50s\n"}
{"model": "claude-4.5-sonnet", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('no such option' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n' or 'unrecognized' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n' or 'unknown' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n')", "returncode": 1, "elapsed_time_s": 3.546675, "avg_memory_mb": 32.36, "avg_cpu_percent": 56.6, "passed": 3, "failed": 6, "skipped": 0, "total": 9, "functional_score": 0.3333, "timestamp": "2025-12-31 13:59:01", "stdout_excerpt": "==== FAILURES ===================================\n______________ test_003_help_runs_and_mentions_usage_or_options _______________\n\n    def test_003_help_runs_and_mentions_usage_or_options():\n        p = _run_cli([\"-h\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...odule>\\n    from lib.parse.cmdline import cmdLineParser\\nModuleNotFoundError: No module named \\'lib.parse.cmdline\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:58: AssertionError\n_________________________ test_004_advanced_help_runs _________________________\n\n    def test_004_advanced_help_runs():\n        p = _run_cli([\"-hh\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...odule>\\n    from lib.parse.cmdline import cmdLineParser\\nModuleNotFoundError: No module named \\'lib.parse.cmdline\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:65: AssertionError\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       assert None is not None\nE        +  where None = <function search at 0x000001FBE47699D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n')\nE        +    where <function search at 0x000001FBE47699D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       assert ('no such option' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n' or 'unrecognized' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n' or 'unknown' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_impor", "stdout_sha1": "c98f5d2cefdfe3e6db07ce16eca8e29ec7a3b6c7", "stdout_len": 6257, "stdout": "..FFFFF.F                                                                [100%]\n================================== FAILURES ===================================\n______________ test_003_help_runs_and_mentions_usage_or_options _______________\n\n    def test_003_help_runs_and_mentions_usage_or_options():\n        p = _run_cli([\"-h\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...odule>\\n    from lib.parse.cmdline import cmdLineParser\\nModuleNotFoundError: No module named \\'lib.parse.cmdline\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:58: AssertionError\n_________________________ test_004_advanced_help_runs _________________________\n\n    def test_004_advanced_help_runs():\n        p = _run_cli([\"-hh\"], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...odule>\\n    from lib.parse.cmdline import cmdLineParser\\nModuleNotFoundError: No module named \\'lib.parse.cmdline\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:65: AssertionError\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       assert None is not None\nE        +  where None = <function search at 0x000001FBE47699D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n')\nE        +    where <function search at 0x000001FBE47699D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       assert ('no such option' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n' or 'unrecognized' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n' or 'unknown' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\sqlmap\\\\sqlmap.py\", ...module>\\n    from lib.parse.cmdline import cmdlineparser\\nmodulenotfounderror: no module named \\'lib.parse.cmdline\\'\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_importable():\n        \"\"\"\n        Alignment anchors (must exist in BOTH reference and generated repos):\n    \n          - lib.parse.cmdline.cmdLineParser\n          - lib.core.option.init, lib.core.option.initOptions\n          - lib.core.data: cmdLineOptions, conf, kb\n          - lib.core.settings: VERSION, DESCRIPTION\n          - lib.controller.controller.start\n    \n        Only checks importability + symbol presence; does not execute scanning logic.\n        \"\"\"\n        repo = _repo_root()\n        sys.path.insert(0, str(repo))\n        try:\n>           from lib.parse.cmdline import cmdLineParser  # noqa: F401\nE           ModuleNotFoundError: No module named 'lib.parse.cmdline'\n\ntests\\Sqlmap\\functional_test.py:110: ModuleNotFoundError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 1 == 0\nE        +  where 1 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...odule>\\n    from lib.parse.cmdline import cmdLineParser\\nModuleNotFoundError: No module named \\'lib.parse.cmdline\\'\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_003_help_runs_and_mentions_usage_or_options\nFAILED tests/Sqlmap/functional_test.py::test_004_advanced_help_runs - Asserti...\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_006_invalid_option_reports_error_cleanly\nFAILED tests/Sqlmap/functional_test.py::test_007_alignment_api_surface_symbols_importable\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n6 failed, 3 passed in 2.06s\n"}
{"model": "claude-4.5-sonnet", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "type object 'SQLModel' has no attribute 'metadata'", "returncode": 2, "elapsed_time_s": 2.263459, "avg_memory_mb": 36.11, "avg_cpu_percent": 97.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 14:00:05", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: type object 'SQLModel' has no attribute 'metadata'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: type object 'SQLMod...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.72s\n", "stdout_sha1": "e51f83d737eba0d7aacf02ed5bab66b5adb6a449", "stdout_len": 570, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: type object 'SQLModel' has no attribute 'metadata'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: type object 'SQLMod...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.72s\n"}
{"model": "claude-4.5-sonnet", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'generator' object is not callable", "returncode": 1, "elapsed_time_s": 4.458881, "avg_memory_mb": 36.41, "avg_cpu_percent": 96.0, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 14:01:46", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-290/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ninput_image = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x000001DEB7E1AB30>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(input_image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        \"\"\"\n        Hide a message in an image using LSB steganography.\n    \n        Args:\n            input_image: Path to image file or PIL Image object\n            message: String message to hide\n            generator: Optional generator for pixel selection (default: sequential)\n            shift: Offset for generator sequence\n            encoding: Text encoding (default: UTF-8)\n            auto_convert_rgb: Convert image to RGB if needed\n    \n        Returns:\n            PIL Image object with hidden message\n        \"\"\"\n        if isinstance(input_image, str):\n            img = Image.open(input_image)\n        else:\n            img = input_image.copy()\n    \n        # Convert to RGB if needed\n        if img.mode not in ('RGB', 'RGBA'):\n            if auto_convert_rgb:\n                img = img.convert('RGB')\n            else:\n                raise ValueError(f\"Image mode {img.mode} not supported. Use auto_convert_rgb=True or convert to RGB.\")\n    \n        # Encode message to bytes and add null terminator\n        message_bytes = message.encode(encoding)\n        message_bytes += b'\\x00\\x00\\x00\\x00'  # 4-byte null terminator\n    \n        # Convert bytes to bits\n        bits = []\n        for byte in message_bytes:\n            for i in range(8):\n                bits.append((byte >> (7 - i)) & 1)\n    \n        # Get image dimensions\n        width, height = img.size\n        pixels = img.load()\n    \n        # Create generator for pixel positions\n        if generator is None:\n            # Sequential generator\n            def sequential_gen():\n                idx = 0\n                while True:\n                    yield idx\n                    idx += 1\n            gen = sequential_gen()\n        else:\n>           gen = generator()\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:60: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\n1 failed, 11 passed in 2.89s\n", "stdout_sha1": "e3c48554a97ccb4b53d44a9478dc21d781cf92dd", "stdout_len": 3275, "stdout": ".F..........                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-290/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ninput_image = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x000001DEB7E1AB30>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(input_image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        \"\"\"\n        Hide a message in an image using LSB steganography.\n    \n        Args:\n            input_image: Path to image file or PIL Image object\n            message: String message to hide\n            generator: Optional generator for pixel selection (default: sequential)\n            shift: Offset for generator sequence\n            encoding: Text encoding (default: UTF-8)\n            auto_convert_rgb: Convert image to RGB if needed\n    \n        Returns:\n            PIL Image object with hidden message\n        \"\"\"\n        if isinstance(input_image, str):\n            img = Image.open(input_image)\n        else:\n            img = input_image.copy()\n    \n        # Convert to RGB if needed\n        if img.mode not in ('RGB', 'RGBA'):\n            if auto_convert_rgb:\n                img = img.convert('RGB')\n            else:\n                raise ValueError(f\"Image mode {img.mode} not supported. Use auto_convert_rgb=True or convert to RGB.\")\n    \n        # Encode message to bytes and add null terminator\n        message_bytes = message.encode(encoding)\n        message_bytes += b'\\x00\\x00\\x00\\x00'  # 4-byte null terminator\n    \n        # Convert bytes to bits\n        bits = []\n        for byte in message_bytes:\n            for i in range(8):\n                bits.append((byte >> (7 - i)) & 1)\n    \n        # Get image dimensions\n        width, height = img.size\n        pixels = img.load()\n    \n        # Create generator for pixel positions\n        if generator is None:\n            # Sequential generator\n            def sequential_gen():\n                idx = 0\n                while True:\n                    yield idx\n                    idx += 1\n            gen = sequential_gen()\n        else:\n>           gen = generator()\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:60: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\n1 failed, 11 passed in 2.89s\n"}
{"model": "claude-4.5-sonnet", "project": "Tablib", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Invalid key type: <class 'int'>", "returncode": 1, "elapsed_time_s": 2.219669, "avg_memory_mb": 32.43, "avg_cpu_percent": 94.9, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 14:02:35", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000277FA1EDF10>, fmt = 'tsv'\n\n    def export(self, fmt):\n        \"\"\"Export dataset to a format.\n    \n        Args:\n            fmt: Format string ('csv', 'json', etc.)\n    \n        Returns:\n            String representation in the requested format\n        \"\"\"\n        fmt = fmt.lower()\n    \n        if fmt == 'csv':\n            from tablib.formats import _csv\n            return _csv.export_set(self)\n        elif fmt == 'json':\n            from tablib.formats import _json\n            return _json.export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:157: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence __________________\n\n    def test_dataset_title_and_headers_persistence() -> None:\n        \"\"\"Dataset title and headers should be assignable and remain consistent.\"\"\"\n        data = tablib.Dataset(headers=(\"k\", \"v\"))\n        data.title = \"Config\"\n        data.append((\"a\", 1))\n        data.append((\"b\", 2))\n    \n        assert getattr(data, \"title\") == \"Config\"\n        assert tuple(data.headers) == (\"k\", \"v\")\n        assert data.height == 2\n>       assert data[1][0] == \"b\"\n\ntests\\Tablib\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000277FA268CD0>, key = 1\n\n    def __getitem__(self, key):\n        \"\"\"Get rows by slice or column by name.\n    \n        Args:\n            key: Either a slice for rows or a string for column access\n    \n        Returns:\n            For slice: list of row tuples\n            For string: list of column values\n        \"\"\"\n        if isinstance(key, slice):\n            return self._data[key]\n        elif isinstance(key, str):\n            # Column access by header name\n            if self._headers is None:\n                raise KeyError(f\"No headers defined\")\n            if key not in self._headers:\n                raise KeyError(f\"Column '{key}' not found\")\n    \n            col_index = self._headers.index(key)\n            return [row[col_index] if col_index < len(row) else None for row in self._data]\n        else:\n>           raise TypeError(f\"Invalid key type: {type(key)}\")\nE           TypeError: Invalid key type: <class 'int'>\n\ngeneration\\Tablib\\tablib\\core.py:119: TypeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\fun", "stdout_sha1": "50cc13e09b46ee4465fa744b54fc983cb3c0d787", "stdout_len": 7546, "stdout": ".F..F.F.F.F                                                              [100%]\n================================== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000277FA1EDF10>, fmt = 'tsv'\n\n    def export(self, fmt):\n        \"\"\"Export dataset to a format.\n    \n        Args:\n            fmt: Format string ('csv', 'json', etc.)\n    \n        Returns:\n            String representation in the requested format\n        \"\"\"\n        fmt = fmt.lower()\n    \n        if fmt == 'csv':\n            from tablib.formats import _csv\n            return _csv.export_set(self)\n        elif fmt == 'json':\n            from tablib.formats import _json\n            return _json.export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:157: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence __________________\n\n    def test_dataset_title_and_headers_persistence() -> None:\n        \"\"\"Dataset title and headers should be assignable and remain consistent.\"\"\"\n        data = tablib.Dataset(headers=(\"k\", \"v\"))\n        data.title = \"Config\"\n        data.append((\"a\", 1))\n        data.append((\"b\", 2))\n    \n        assert getattr(data, \"title\") == \"Config\"\n        assert tuple(data.headers) == (\"k\", \"v\")\n        assert data.height == 2\n>       assert data[1][0] == \"b\"\n\ntests\\Tablib\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000277FA268CD0>, key = 1\n\n    def __getitem__(self, key):\n        \"\"\"Get rows by slice or column by name.\n    \n        Args:\n            key: Either a slice for rows or a string for column access\n    \n        Returns:\n            For slice: list of row tuples\n            For string: list of column values\n        \"\"\"\n        if isinstance(key, slice):\n            return self._data[key]\n        elif isinstance(key, str):\n            # Column access by header name\n            if self._headers is None:\n                raise KeyError(f\"No headers defined\")\n            if key not in self._headers:\n                raise KeyError(f\"Column '{key}' not found\")\n    \n            col_index = self._headers.index(key)\n            return [row[col_index] if col_index < len(row) else None for row in self._data]\n        else:\n>           raise TypeError(f\"Invalid key type: {type(key)}\")\nE           TypeError: Invalid key type: <class 'int'>\n\ngeneration\\Tablib\\tablib\\core.py:119: TypeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000277FA2973D0>, fmt = 'html'\n\n    def export(self, fmt):\n        \"\"\"Export dataset to a format.\n    \n        Args:\n            fmt: Format string ('csv', 'json', etc.)\n    \n        Returns:\n            String representation in the requested format\n        \"\"\"\n        fmt = fmt.lower()\n    \n        if fmt == 'csv':\n            from tablib.formats import _csv\n            return _csv.export_set(self)\n        elif fmt == 'json':\n            from tablib.formats import _json\n            return _json.export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:157: ValueError\n_________________ test_databook_add_sheet_and_iteration_order _________________\n\n    def test_databook_add_sheet_and_iteration_order() -> None:\n        \"\"\"Databook should allow adding sheets and preserve the order in iteration.\"\"\"\n        s1 = tablib.Dataset((1, \"x\"), headers=(\"id\", \"val\"))\n        s1.title = \"S1\"\n        s2 = tablib.Dataset((2, \"y\"), headers=(\"id\", \"val\"))\n        s2.title = \"S2\"\n    \n        book = tablib.Databook([s1])\n    \n        if hasattr(book, \"add_sheet\"):\n            book.add_sheet(s2)  # type: ignore[attr-defined]\n        else:\n            # Fallback: reconstruct via the public constructor (still normal usage).\n            book = tablib.Databook([s1, s2])\n    \n        assert book.size == 2\n    \n        sheets = _iter_databook_sheets(book)\n        assert len(sheets) == 2\n        assert sheets[0].title == \"S1\"\n        assert sheets[1].title == \"S2\"\n>       assert sheets[0][0] == (1, \"x\")\n\ntests\\Tablib\\functional_test.py:365: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000277FA211D90>, key = 0\n\n    def __getitem__(self, key):\n        \"\"\"Get rows by slice or column by name.\n    \n        Args:\n            key: Either a slice for rows or a string for column access\n    \n        Returns:\n            For slice: list of row tuples\n            For string: list of column values\n        \"\"\"\n        if isinstance(key, slice):\n            return self._data[key]\n        elif isinstance(key, str):\n            # Column access by header name\n            if self._headers is None:\n                raise KeyError(f\"No headers defined\")\n            if key not in self._headers:\n                raise KeyError(f\"Column '{key}' not found\")\n    \n            col_index = self._headers.index(key)\n            return [row[col_index] if col_index < len(row) else None for row in self._data]\n        else:\n>           raise TypeError(f\"Invalid key type: {type(key)}\")\nE           TypeError: Invalid key type: <class 'int'>\n\ngeneration\\Tablib\\tablib\\core.py:119: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_title_and_headers_persistence\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\nFAILED tests/Tablib/functional_test.py::test_databook_add_sheet_and_iteration_order\n5 failed, 6 passed in 0.70s\n"}
{"model": "claude-4.5-sonnet", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "tabulate() got an unexpected keyword argument 'maxcolwidths'", "returncode": 1, "elapsed_time_s": 2.032719, "avg_memory_mb": 33.12, "avg_cpu_percent": 99.2, "passed": 7, "failed": 5, "skipped": 0, "total": 12, "functional_score": 0.5833, "timestamp": "2025-12-31 14:04:13", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n>       assert lines[0].strip().startswith(\"Name\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000019D3251F470>('Name')\nE        +    where <built-in method startswith of str object at 0x0000019D3251F470> = '-----  ---'.startswith\nE        +      where '-----  ---' = <built-in method strip of str object at 0x0000019D3251F470>()\nE        +        where <built-in method strip of str object at 0x0000019D3251F470> = '-----  ---'.strip\n\ntests\\Tabulate\\functional_test.py:120: AssertionError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in '----------------  --------'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n        out_true = tabulate(table, showindex=True)\n        lines_true = _lines(out_true)\n>       assert any(line.lstrip().startswith(\"0\") for line in lines_true)\nE       assert False\nE        +  where False = any(<generator object test_showindex_variants.<locals>.<genexpr> at 0x0000019D3249B190>)\n\ntests\\Tabulate\\functional_test.py:153: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000019D3249C8B0>('|')\nE        +    where <built-in method startswith of str object at 0x0000019D3249C8B0> = 'item githubqty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - assert False\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Asse...\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n5 failed, 7 passed in 0.62s\n", "stdout_sha1": "727019538e75a4e815f1ab5cbe9bfd1bb28ec1d5", "stdout_len": 3946, "stdout": "..FFFF....F.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n>       assert lines[0].strip().startswith(\"Name\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000019D3251F470>('Name')\nE        +    where <built-in method startswith of str object at 0x0000019D3251F470> = '-----  ---'.startswith\nE        +      where '-----  ---' = <built-in method strip of str object at 0x0000019D3251F470>()\nE        +        where <built-in method strip of str object at 0x0000019D3251F470> = '-----  ---'.strip\n\ntests\\Tabulate\\functional_test.py:120: AssertionError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in '----------------  --------'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n        out_true = tabulate(table, showindex=True)\n        lines_true = _lines(out_true)\n>       assert any(line.lstrip().startswith(\"0\") for line in lines_true)\nE       assert False\nE        +  where False = any(<generator object test_showindex_variants.<locals>.<genexpr> at 0x0000019D3249B190>)\n\ntests\\Tabulate\\functional_test.py:153: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000019D3249C8B0>('|')\nE        +    where <built-in method startswith of str object at 0x0000019D3249C8B0> = 'item githubqty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - assert False\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Asse...\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n5 failed, 7 passed in 0.62s\n"}
{"model": "claude-4.5-sonnet", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'>' not supported between instances of 'str' and 'int'", "returncode": 1, "elapsed_time_s": 55.754068, "avg_memory_mb": 32.64, "avg_cpu_percent": 0.31, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 14:06:02", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B2EAC0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B2EA60>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Test Chart\n\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B7E940>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:177: in draw\n    total = sum(v if v > 0 else 0 for v in values_list)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000021064B7E370>\n\n>   total = sum(v if v > 0 else 0 for v in values_list)\nE   TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:177: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Stacked Chart\n\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B76D60>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B76D90>\n\n    def draw(self):\n        \"\"\"\n        R", "stdout_sha1": "cc739673caa4bd30407025c34772adad90631be9", "stdout_len": 21367, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B2EAC0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B2EA60>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Test Chart\n\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B7E940>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:177: in draw\n    total = sum(v if v > 0 else 0 for v in values_list)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000021064B7E370>\n\n>   total = sum(v if v > 0 else 0 for v in values_list)\nE   TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:177: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Stacked Chart\n\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B76D60>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B76D90>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Bars\n\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B0E340>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B0E6A0>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# No Values\n\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B80A30>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Labels\", width=10, no_labels=True, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B80760>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# No Labels\n\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B916D0>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Suffix\", width=18, suffix=\"%\", format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B91A60>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Suffix\n\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064BD3C70>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Fmt\", width=20, format=\"{:>6.2f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064BD3D00>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Fmt\n\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B92BB0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack Labels\", width=25, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:177: in draw\n    total = sum(v if v > 0 else 0 for v in values_list)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000021064B92550>\n\n>   total = sum(v if v > 0 else 0 for v in values_list)\nE   TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:177: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Stack Labels\n\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064AEFD60>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack No Values\", width=30, no_values=True, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:177: in draw\n    total = sum(v if v > 0 else 0 for v in values_list)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000021064AEF1F0>\n\n>   total = sum(v if v > 0 else 0 for v in values_list)\nE   TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:177: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Stack No Values\n\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064BDE2E0>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=None, width=15, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064BDE700>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000021064B88BB0>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000021064B88C70>\n\n    def draw(self):\n        \"\"\"\n        Render the bar chart to stdout.\n        \"\"\"\n        if self.args.title:\n            print(f\"\\n# {self.args.title}\\n\")\n    \n        # Collect all data and determine if multi-series\n        all_data = []\n        max_label_len = 0\n        is_multi_series = False\n    \n        for label, values in self.data:\n            if not self.args.no_labels and self.args.labels:\n                max_label_len = max(max_label_len, len(str(label)))\n    \n            # Check if values is a list (multi-series) or single value\n            if isinstance(values, (list, tuple)):\n                is_multi_series = True\n                all_data.append((label, list(values)))\n            else:\n                all_data.append((label, [values]))\n    \n        # Find maximum value for scaling\n        if is_multi_series and not self.args.different_scale:\n            # For multi-series, find max across all series\n            max_val = 0\n            for label, values in all_data:\n                max_val = max(max_val, max(values) if values else 0)\n        else:\n            max_val = 0\n            for label, values in all_data:\n>               max_val = max(max_val, max(values) if values else 0)\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:67: TypeError\n---------------------------- Captured stdout call -----------------------------\n\n# Narrow\n\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 27.79s\n"}
{"model": "claude-4.5-sonnet", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'python' in 'pythno -v'", "returncode": 1, "elapsed_time_s": 2.112695, "avg_memory_mb": 31.99, "avg_cpu_percent": 97.7, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 14:07:28", "stdout_excerpt": "==== FAILURES ===================================\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-291/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n        _, get_new_fn = _import_no_command_rule()\n    \n        _make_windows_cmd(tmp_path, \"python\")\n    \n        with _with_temp_path(tmp_path):\n            cmd = FakeCommand(\n                script=\"pythno -V\",\n                stderr=_windows_command_not_found_output(\"pythno\"),\n                returncode=1,\n            )\n            suggestion = _coerce_suggestion(get_new_fn(cmd)).lower()\n>           assert \"python\" in suggestion, f\"expected suggestion to contain 'python', got: {suggestion!r}\"\nE           AssertionError: expected suggestion to contain 'python', got: 'pythno -v'\nE           assert 'python' in 'pythno -v'\n\ntests\\TheFuck\\functional_test.py:195: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\n1 failed, 11 passed in 0.57s\n", "stdout_sha1": "6fec40bd1a466319aaf1331377748027c6dde474", "stdout_len": 1531, "stdout": "......F.....                                                             [100%]\n================================== FAILURES ===================================\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-291/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n        _, get_new_fn = _import_no_command_rule()\n    \n        _make_windows_cmd(tmp_path, \"python\")\n    \n        with _with_temp_path(tmp_path):\n            cmd = FakeCommand(\n                script=\"pythno -V\",\n                stderr=_windows_command_not_found_output(\"pythno\"),\n                returncode=1,\n            )\n            suggestion = _coerce_suggestion(get_new_fn(cmd)).lower()\n>           assert \"python\" in suggestion, f\"expected suggestion to contain 'python', got: {suggestion!r}\"\nE           AssertionError: expected suggestion to contain 'python', got: 'pythno -v'\nE           assert 'python' in 'pythno -v'\n\ntests\\TheFuck\\functional_test.py:195: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\n1 failed, 11 passed in 0.57s\n"}
{"model": "claude-4.5-sonnet", "project": "TinyDB", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "object of type 'Table' has no len()", "returncode": 1, "elapsed_time_s": 2.278858, "avg_memory_mb": 32.48, "avg_cpu_percent": 100.7, "passed": 7, "failed": 5, "skipped": 0, "total": 12, "functional_score": 0.5833, "timestamp": "2025-12-31 14:08:41", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_multiple_tables_isolation ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_multiple_tables_isolation0')\n\n    def test_multiple_tables_isolation(tmp_path: Path) -> None:\n        \"\"\"Data in different tables should be isolated.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"write code\", \"done\": False})\n        tasks.insert({\"title\": \"write tests\", \"done\": False})\n        logs.insert({\"event\": \"created_tasks\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:88: TypeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_contains_and_count0')\n\n    def test_contains_and_count(tmp_path: Path) -> None:\n        \"\"\"contains and count should reflect stored data and queries.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n        db.insert({\"name\": \"Alice\", \"age\": 30})\n        db.insert({\"name\": \"Bob\", \"age\": 25})\n        db.insert({\"name\": \"Charlie\", \"age\": 35})\n    \n>       assert db.contains(User.name == \"Alice\") is True\nE       AttributeError: 'TinyDB' object has no attribute 'contains'\n\ntests\\TinyDB\\functional_test.py:180: AttributeError\n_________________ test_table_truncate_clears_only_that_table __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_table_truncate_clears_onl0')\n\n    def test_table_truncate_clears_only_that_table(tmp_path: Path) -> None:\n        \"\"\"truncate on a table should clear its rows without affecting other tables.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"t1\"})\n        tasks.insert({\"title\": \"t2\"})\n        logs.insert({\"event\": \"created\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:215: TypeError\n____________________________ test_update_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_update_by_doc_id0')\n\n    def test_update_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"update with doc_ids should modify the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        doc_id = table.insert({\"name\": \"ItemA\", \"qty\": 1})\n>       assert len(table) == 1\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:231: TypeError\n____________________________ test_remove_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_remove_by_doc_id0')\n\n    def test_remove_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"remove with doc_ids should delete the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        id1 = table.insert({\"name\": \"A\"})\n        id2 = table.insert({\"name\": \"B\"})\n>       assert len(table) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:249: TypeError\n=========================== short test summary info ===========================\nFAILED tests/TinyDB/functional_test.py::test_multiple_tables_isolation - Type...\nFAILED tests/TinyDB/functional_test.py::test_contains_and_count - AttributeEr...\nFAILED tests/TinyDB/functional_test.py::test_table_truncate_clears_only_that_table\nFAILED tests/TinyDB/functional_test.py::test_update_by_doc_id - TypeError: ob...\nFAILED tests/TinyDB/functional_test.py::test_remove_by_doc_id - TypeError: ob...\n5 failed, 7 passed in 0.76s\n", "stdout_sha1": "56e54f28ec0fdee0da27540b2b29ca0e50bf9ee3", "stdout_len": 4046, "stdout": ".F....F.FFF.                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_multiple_tables_isolation ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_multiple_tables_isolation0')\n\n    def test_multiple_tables_isolation(tmp_path: Path) -> None:\n        \"\"\"Data in different tables should be isolated.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"write code\", \"done\": False})\n        tasks.insert({\"title\": \"write tests\", \"done\": False})\n        logs.insert({\"event\": \"created_tasks\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:88: TypeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_contains_and_count0')\n\n    def test_contains_and_count(tmp_path: Path) -> None:\n        \"\"\"contains and count should reflect stored data and queries.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n        db.insert({\"name\": \"Alice\", \"age\": 30})\n        db.insert({\"name\": \"Bob\", \"age\": 25})\n        db.insert({\"name\": \"Charlie\", \"age\": 35})\n    \n>       assert db.contains(User.name == \"Alice\") is True\nE       AttributeError: 'TinyDB' object has no attribute 'contains'\n\ntests\\TinyDB\\functional_test.py:180: AttributeError\n_________________ test_table_truncate_clears_only_that_table __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_table_truncate_clears_onl0')\n\n    def test_table_truncate_clears_only_that_table(tmp_path: Path) -> None:\n        \"\"\"truncate on a table should clear its rows without affecting other tables.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"t1\"})\n        tasks.insert({\"title\": \"t2\"})\n        logs.insert({\"event\": \"created\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:215: TypeError\n____________________________ test_update_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_update_by_doc_id0')\n\n    def test_update_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"update with doc_ids should modify the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        doc_id = table.insert({\"name\": \"ItemA\", \"qty\": 1})\n>       assert len(table) == 1\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:231: TypeError\n____________________________ test_remove_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-292/test_remove_by_doc_id0')\n\n    def test_remove_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"remove with doc_ids should delete the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        id1 = table.insert({\"name\": \"A\"})\n        id2 = table.insert({\"name\": \"B\"})\n>       assert len(table) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:249: TypeError\n=========================== short test summary info ===========================\nFAILED tests/TinyDB/functional_test.py::test_multiple_tables_isolation - Type...\nFAILED tests/TinyDB/functional_test.py::test_contains_and_count - AttributeEr...\nFAILED tests/TinyDB/functional_test.py::test_table_truncate_clears_only_that_table\nFAILED tests/TinyDB/functional_test.py::test_update_by_doc_id - TypeError: ob...\nFAILED tests/TinyDB/functional_test.py::test_remove_by_doc_id - TypeError: ob...\n5 failed, 7 passed in 0.76s\n"}
{"model": "claude-4.5-sonnet", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where 'TOKEN=Ellipsis\\n' = <typer.testing.Result object at 0x00000246BDAB2610>.stdout", "returncode": 1, "elapsed_time_s": 2.266948, "avg_memory_mb": 32.85, "avg_cpu_percent": 97.1, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 14:09:42", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"World\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000246BDAA1DC0>.exit_code\n\ntests\\Typer\\functional_test.py:199: AssertionError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n        app = _create_greeter_app()\n        # Safer ordering across Click versions: options before args.\n        result = runner.invoke(app, [\"--excited\", \"World\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000246BDAAF700>.exit_code\n\ntests\\Typer\\functional_test.py:207: AssertionError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"--excited\" in out\nE       AssertionError: assert '--excited' in 'Usage: [OPTIONS] COMMAND [ARGS]...\\n'\n\ntests\\Typer\\functional_test.py:216: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000246BDAA8CA0>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'Usage: [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add                  \\n  list                 \\n  remove               \\n' or 'title' in 'Usage: [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add                  \\n  list                 \\n  remove               \\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n        app = _create_prompt_app()\n        # Now stable: \"greet\" always exists as a subcommand (multi-command app).\n        result = runner.invoke(app, [\"greet\"], input=\"Alice\\n\")\n        assert result.exit_code == 0\n>       assert \"Hi Alice\" in result.stdout\nE       AssertionError: assert 'Hi Alice' in 'Hi <typer.params.ParamInfo object at 0x00000246BDAA7EB0>\\n'\nE        +  where 'Hi <typer.params.ParamInfo object at 0x00000246BDAA7EB0>\\n' = <typer.testing.Result object at 0x00000246BDAA7880>.stdout\n\ntests\\Typer\\functional_test.py:284: AssertionError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x00000246BDAB2580>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n        app = _create_env_app()\n        monkeypatch.setenv(\"APP_TOKEN\", \"abc123\")\n    \n        result = runner.invoke(app, [\"show\"])\n        assert result.exit_code == 0\n>       assert \"TOKEN=abc123\" in result.stdout\nE       AssertionError: assert 'TOKEN=abc123' in 'TOKEN=Ellipsis\\n'\nE        +  where 'TOKEN=Ellipsis\\n' = <typer.testing.Result object at 0x00000246BDAB2610>.stdout\n\ntests\\Typer\\functional_test.py:293: Asse", "stdout_sha1": "d8cb29b5455cef2e31acd0d45dd4e7ff890d24af", "stdout_len": 6081, "stdout": "FFF..F.FFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"World\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000246BDAA1DC0>.exit_code\n\ntests\\Typer\\functional_test.py:199: AssertionError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n        app = _create_greeter_app()\n        # Safer ordering across Click versions: options before args.\n        result = runner.invoke(app, [\"--excited\", \"World\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000246BDAAF700>.exit_code\n\ntests\\Typer\\functional_test.py:207: AssertionError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"--excited\" in out\nE       AssertionError: assert '--excited' in 'Usage: [OPTIONS] COMMAND [ARGS]...\\n'\n\ntests\\Typer\\functional_test.py:216: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000246BDAA8CA0>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'Usage: [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add                  \\n  list                 \\n  remove               \\n' or 'title' in 'Usage: [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add                  \\n  list                 \\n  remove               \\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n        app = _create_prompt_app()\n        # Now stable: \"greet\" always exists as a subcommand (multi-command app).\n        result = runner.invoke(app, [\"greet\"], input=\"Alice\\n\")\n        assert result.exit_code == 0\n>       assert \"Hi Alice\" in result.stdout\nE       AssertionError: assert 'Hi Alice' in 'Hi <typer.params.ParamInfo object at 0x00000246BDAA7EB0>\\n'\nE        +  where 'Hi <typer.params.ParamInfo object at 0x00000246BDAA7EB0>\\n' = <typer.testing.Result object at 0x00000246BDAA7880>.stdout\n\ntests\\Typer\\functional_test.py:284: AssertionError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x00000246BDAB2580>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n        app = _create_env_app()\n        monkeypatch.setenv(\"APP_TOKEN\", \"abc123\")\n    \n        result = runner.invoke(app, [\"show\"])\n        assert result.exit_code == 0\n>       assert \"TOKEN=abc123\" in result.stdout\nE       AssertionError: assert 'TOKEN=abc123' in 'TOKEN=Ellipsis\\n'\nE        +  where 'TOKEN=Ellipsis\\n' = <typer.testing.Result object at 0x00000246BDAB2610>.stdout\n\ntests\\Typer\\functional_test.py:293: AssertionError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n        app = _create_callback_app()\n    \n        r1 = runner.invoke(app, [\"run\"])\n        assert r1.exit_code == 0\n        assert \"running\" in r1.stdout\n        assert \"verbose\" not in r1.stdout\n    \n        r2 = runner.invoke(app, [\"--verbose\", \"run\"])\n>       assert r2.exit_code == 0\nE       assert 2 == 0\nE        +  where 2 = <typer.testing.Result object at 0x00000246BDAAF2B0>.exit_code\n\ntests\\Typer\\functional_test.py:305: AssertionError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n        app = _create_types_app()\n        # Now stable: \"calc\" always exists as a subcommand (multi-command app).\n        r = runner.invoke(app, [\"calc\", \"2\", \"3\", \"--scale\", \"2.0\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000246BDB16250>.exit_code\n\ntests\\Typer\\functional_test.py:313: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - assert 1 == 0\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - as...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - Assert...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - Assert...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n9 failed, 3 passed in 0.71s\n"}
{"model": "claude-4.5-sonnet", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 2.19765, "avg_memory_mb": 35.54, "avg_cpu_percent": 99.3, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 14:10:26", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n", "stdout_sha1": "ab9a030ccb03922d0202a790bd63e9a6545205ea", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n"}
{"model": "deepseek-r1", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "update() got an unexpected keyword argument 'task_always_eager'", "returncode": 1, "elapsed_time_s": 30.266594, "avg_memory_mb": 32.4, "avg_cpu_percent": 0.61, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2026-01-01 22:39:13", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            r", "stdout_sha1": "29bf746fa48c678dcdd89e8574dc5469f8c3c972", "stdout_len": 13248, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n>       app = _make_app(\"celery_test_app_2\")\n\ntests\\Celery\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app_2'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.68s\n"}
{"model": "deepseek-r1", "project": "Click", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'echo' from 'click.utils' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Click\\click\\utils.py)", "returncode": 2, "elapsed_time_s": 4.182222, "avg_memory_mb": 34.8, "avg_cpu_percent": 98.5, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 22:43:21", "stdout_excerpt": "====\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:1: in <module>\n    from .core import (\ngeneration\\Click\\click\\core.py:6: in <module>\n    from .utils import echo, get_os_args\nE   ImportError: cannot import name 'echo' from 'click.utils' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Click\\click\\utils.py)\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 2.96s\n", "stdout_sha1": "5f61a395d7bfcc4fc1e773ed64a96f432268295e", "stdout_len": 1118, "stdout": "\n=================================== ERRORS ====================================\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:1: in <module>\n    from .core import (\ngeneration\\Click\\click\\core.py:6: in <module>\n    from .utils import echo, get_os_args\nE   ImportError: cannot import name 'echo' from 'click.utils' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Click\\click\\utils.py)\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 2.96s\n"}
{"model": "deepseek-r1", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 22:55:17", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "deepseek-r1", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('usage' in 'error: requires log file and pattern arguments\\n\\n' or 'options' in 'error: requires log file and pattern arguments\\n\\n' or 'fail2ban-regex' in 'error: requires log file and pattern arguments\\n\\n')", "returncode": 1, "elapsed_time_s": 2.490022, "avg_memory_mb": 32.48, "avg_cpu_percent": 74.5, "passed": 8, "failed": 4, "skipped": 0, "total": 12, "functional_score": 0.6667, "timestamp": "2026-01-01 22:58:25", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in \"import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    try:\\n        ipaddress.ip_address(ip)\\n        return true\\n ...fa-f0-9:]+::?[a-fa-f0-9:]*)\\\\b'\\n    match = re.search(ip_pattern, text)\\n    return match.group(0) if match else none\" or '<host>' in \"import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    try:\\n        ipaddress.ip_address(ip)\\n        return true\\n ...fa-f0-9:]+::?[a-fa-f0-9:]*)\\\\b'\\n    match = re.search(ip_pattern, text)\\n    return match.group(0) if match else none\")\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n_________________ test_011_fail2ban_regex_help_exits_quickly __________________\n\n    def test_011_fail2ban_regex_help_exits_quickly():\n        base = _resolve_repo_root()\n        p = _run_script_help(base / \"bin\" / \"fail2ban-regex\", timeout_s=25)\n        out = _out(p)\n>       assert (\"usage\" in out) or (\"options\" in out) or (\"fail2ban-regex\" in out)\nE       AssertionError: assert ('usage' in 'error: requires log file and pattern arguments\\n\\n' or 'options' in 'error: requires log file and pattern arguments\\n\\n' or 'fail2ban-regex' in 'error: requires log file and pattern arguments\\n\\n')\n\ntests\\Fail2ban\\functional_test.py:202: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                  ", "stdout_sha1": "29065aa53c9625ef34511224cf9fdd2515a0222b", "stdout_len": 6181, "stdout": "...F....F.FF                                                             [100%]\n================================== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in \"import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    try:\\n        ipaddress.ip_address(ip)\\n        return true\\n ...fa-f0-9:]+::?[a-fa-f0-9:]*)\\\\b'\\n    match = re.search(ip_pattern, text)\\n    return match.group(0) if match else none\" or '<host>' in \"import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    try:\\n        ipaddress.ip_address(ip)\\n        return true\\n ...fa-f0-9:]+::?[a-fa-f0-9:]*)\\\\b'\\n    match = re.search(ip_pattern, text)\\n    return match.group(0) if match else none\")\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n_________________ test_011_fail2ban_regex_help_exits_quickly __________________\n\n    def test_011_fail2ban_regex_help_exits_quickly():\n        base = _resolve_repo_root()\n        p = _run_script_help(base / \"bin\" / \"fail2ban-regex\", timeout_s=25)\n        out = _out(p)\n>       assert (\"usage\" in out) or (\"options\" in out) or (\"fail2ban-regex\" in out)\nE       AssertionError: assert ('usage' in 'error: requires log file and pattern arguments\\n\\n' or 'options' in 'error: requires log file and pattern arguments\\n\\n' or 'fail2ban-regex' in 'error: requires log file and pattern arguments\\n\\n')\n\ntests\\Fail2ban\\functional_test.py:202: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           AssertionError: assert ('line' in 'match: failed password for invalid user root from 203.0.113.5 port 2222 ssh2\\nmatch: failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\\nmatch: failed password for invalid user test from 203.0.113.9 port 4444 ssh2\\n\\n' or 'lines' in 'match: failed password for invalid user root from 203.0.113.5 port 2222 ssh2\\nmatch: failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\\nmatch: failed password for invalid user test from 203.0.113.9 port 4444 ssh2\\n\\n')\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\nFAILED tests/Fail2ban/functional_test.py::test_011_fail2ban_regex_help_exits_quickly\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n4 failed, 8 passed in 1.18s\n"}
{"model": "deepseek-r1", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "NameError", "exception_msg": "name 'TileLayer' is not defined", "returncode": 1, "elapsed_time_s": 1.99066, "avg_memory_mb": 32.5, "avg_cpu_percent": 101.7, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 22:59:52", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:46: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE48700>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE689D0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE68280>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:79: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE667C0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n__", "stdout_sha1": "f883ffcba62ce189874f8846b5e2210e0bc6df18", "stdout_len": 10356, "stdout": "..FFFFFFFF.F                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:46: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE48700>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE689D0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE68280>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:79: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE667C0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n>       folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:92: TypeError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:114: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EEA3790>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:140: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EE69880>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-477/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:152: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EEA3EE0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:173: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000002C46EEB19D0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', width = '100%', height = '100%'\n\n    def __init__(self, location=None, zoom_start=10, tiles='OpenStreetMap', width='100%', height='100%'):\n        super().__init__()\n        self.location = location or [0, 0]\n        self.zoom_start = zoom_start\n        self.width = width\n        self.height = height\n        self.tile_layer = None\n        if tiles:\n>           self.tile_layer = TileLayer(tiles).add_to(self)\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:14: NameError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root - NameErro...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - NameE...\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n9 failed, 3 passed in 0.67s\n"}
{"model": "deepseek-r1", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "fit() got an unexpected keyword", "returncode": 1, "elapsed_time_s": 4.970559, "avg_memory_mb": 71.96, "avg_cpu_percent": 104.43, "passed": 0, "failed": 15, "skipped": 0, "total": 15, "functional_score": 0.0, "timestamp": "2026-01-01 23:25:07", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage        0.043368       0.1\\ntreatment -0.027688       0.1.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002424803CAB0>()\nE        +    where <built-in method lower of str object at 0x000002424803CAB0> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x0000024225764670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x0000024225764670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage        0.043368       0.1\\ntreatment -0.027688       0.1.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword ", "stdout_sha1": "144ef41db607f00a0c3366d9db6709837d415d28", "stdout_len": 11861, "stdout": "FFFFFFFFFFFFFFF                                                          [100%]\n================================== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage        0.043368       0.1\\ntreatment -0.027688       0.1.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002424803CAB0>()\nE        +    where <built-in method lower of str object at 0x000002424803CAB0> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x0000024225764670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x0000024225764670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage        0.043368       0.1\\ntreatment -0.027688       0.1.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:169: TypeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:182: TypeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:191: TypeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:204: TypeError\n_________________ test_coxph_params_index_matches_covariates __________________\n\n    def test_coxph_params_index_matches_covariates() -> None:\n        \"\"\"Cox model params_ should be indexed by covariate names.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        params = cph.params_\n>       assert list(params.index) == [\"age\", \"treatment\"]\nE       AttributeError: 'numpy.ndarray' object has no attribute 'index'\n\ntests\\Lifelines\\functional_test.py:216: AttributeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x_low = pd.DataFrame({\"age\": [25], \"treatment\": [0]})\n        x_high = pd.DataFrame({\"age\": [55], \"treatment\": [1]})\n    \n>       h_low = float(cph.predict_partial_hazard(x_low).iloc[0])\nE       AttributeError: 'CoxPHFitter' object has no attribute 'predict_partial_hazard'\n\ntests\\Lifelines\\functional_test.py:240: AttributeError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x = pd.DataFrame({\"age\": [30, 60], \"treatment\": [0, 1]})\n>       sf = cph.predict_survival_function(x)\n\ntests\\Lifelines\\functional_test.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.estimators.coxph.CoxPHFitter object at 0x00000242480D0130>\nrow =    age  treatment\n0   30          0\n1   60          1\n\n    def predict_survival_function(self, row: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Predict survival function for a single observation.\n    \n        Parameters\n        ----------\n        row : pandas.DataFrame\n            Single-row DataFrame with same covariates as training data.\n    \n        Returns\n        -------\n        pandas.DataFrame\n            Survival function with values in [0, 1].\n        \"\"\"\n        if not self._fitted:\n            raise ValueError(\"Model must be fitted before prediction.\")\n    \n        # Extract covariates (exclude duration and event columns if present)\n        covariate_cols = self._summary.index.tolist()\n        covariates = row[covariate_cols].values.astype(np.float64).flatten()\n    \n        # Calculate linear predictor\n>       linear_predictor = np.dot(covariates, self.params_)\nE       ValueError: shapes (4,) and (2,) not aligned: 4 (dim 0) != 2 (dim 0)\n\ngeneration\\Lifelines\\lifelines\\estimators\\coxph.py:147: ValueError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n_____________ test_coxph_fit_on_waltons_with_binary_group_feature _____________\n\n    def test_coxph_fit_on_waltons_with_binary_group_feature() -> None:\n        \"\"\"Fit CoxPH on Waltons dataset using a binary treated indicator derived from group.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        df2 = df.copy()\n        df2[\"treated\"] = (df2[\"group\"] != \"control\").astype(int)\n    \n        model_df = df2[[\"T\", \"E\", \"treated\"]].rename(columns={\"T\": \"duration\", \"E\": \"event\"})\n    \n        cph = CoxPHFitter()\n        cph.fit(model_df, duration_col=\"duration\", event_col=\"event\")\n    \n>       coef = float(cph.params_.loc[\"treated\"])\nE       AttributeError: 'numpy.ndarray' object has no attribute 'loc'\n\ntests\\Lifelines\\functional_test.py:286: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_small_manual_dataset\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_waltons_groups - TypeE...\nFAILED tests/Lifelines/functional_test.py::test_coxph_basic_fit - AssertionEr...\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_at_time_zero_is_one\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_is_non_increasing_over_time\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_params_index_matches_covariates\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\nFAILED tests/Lifelines/functional_test.py::test_coxph_fit_on_waltons_with_binary_group_feature\n15 failed in 3.36s\n"}
{"model": "deepseek-r1", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 3.153057, "avg_memory_mb": 35.49, "avg_cpu_percent": 65.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 23:33:51", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.79s\n", "stdout_sha1": "c24d03cc570d980bb592628977d5149fd1adfbb3", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.79s\n"}
{"model": "deepseek-r1", "project": "Markdown", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.498021, "avg_memory_mb": 31.04, "avg_cpu_percent": 97.8, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 23:35:12", "stdout_excerpt": "\n1 skipped in 0.13s\n", "stdout_sha1": "4c4ceb412a81fcf19d92b45ee51d2d9a1553d8c3", "stdout_len": 20, "stdout": "\n1 skipped in 0.13s\n"}
{"model": "deepseek-r1", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 1.941702, "avg_memory_mb": 32.13, "avg_cpu_percent": 100.0, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2026-01-01 23:36:50", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.54s\n", "stdout_sha1": "f89ee2d6f349f40925e10dca5e471419e6ad4515", "stdout_len": 3013, "stdout": "........FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.54s\n"}
{"model": "deepseek-r1", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.487885, "avg_memory_mb": 31.2, "avg_cpu_percent": 96.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 23:43:02", "stdout_excerpt": "\n1 skipped in 0.12s\n", "stdout_sha1": "2c297eff6659b1c3f522bd1a20de05b2bdd71aca", "stdout_len": 20, "stdout": "\n1 skipped in 0.12s\n"}
{"model": "deepseek-r1", "project": "Pendulum", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 2.107444, "avg_memory_mb": 32.04, "avg_cpu_percent": 72.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 23:49:32", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "deepseek-r1", "project": "Petl", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.522595, "avg_memory_mb": 30.64, "avg_cpu_percent": 96.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 23:52:59", "stdout_excerpt": "\n1 skipped in 0.17s\n", "stdout_sha1": "66bd18a62ec687100e9a9e996a20b12b6bd4dc1e", "stdout_len": 20, "stdout": "\n1 skipped in 0.17s\n"}
{"model": "deepseek-r1", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.424761, "avg_memory_mb": 14.17, "avg_cpu_percent": 100.2, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 23:55:05", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 12, in <module>\n    from pygments import lexers\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 6, in <module>\n    from pygments.lexer import Lexer, RegexLexer\nModuleNotFoundError: No module named 'pygments.lexer'\n", "stdout_sha1": "3458d889f3245b26c4073e38fa3a04cbd5186e1f", "stdout_len": 1687, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 12, in <module>\n    from pygments import lexers\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 6, in <module>\n    from pygments.lexer import Lexer, RegexLexer\nModuleNotFoundError: No module named 'pygments.lexer'\n"}
{"model": "deepseek-r1", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 2.000624, "avg_memory_mb": 33.78, "avg_cpu_percent": 97.5, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 23:56:56", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:28: in encode\n    return _encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:63: in encode\n    signature = _sign(msg, key, algorithm)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nmsg = b'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJzY29wZSI6WyJyZWFkIiwid3JpdGUiXSwiYWN0aXZlIjp0cnVlfQ'\nkey = 'secret', algorithm = 'HS512'\n\n    def _sign(msg: bytes, key: str, algorithm: str) -> str:\n        \"\"\"Create HMAC signature.\"\"\"\n        if algorithm != \"HS256\":\n>           raise DecodeError(\"Algorithm not supported\")\nE           jwt.exceptions.DecodeError: Algorithm not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:31: DecodeError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:28: in encode\n    return _encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000291E4FC7CD0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "69186fe6293d9bad09598f40024432b5502ee4a1", "stdout_len": 7013, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:28: in encode\n    return _encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:63: in encode\n    signature = _sign(msg, key, algorithm)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nmsg = b'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJzY29wZSI6WyJyZWFkIiwid3JpdGUiXSwiYWN0aXZlIjp0cnVlfQ'\nkey = 'secret', algorithm = 'HS512'\n\n    def _sign(msg: bytes, key: str, algorithm: str) -> str:\n        \"\"\"Create HMAC signature.\"\"\"\n        if algorithm != \"HS256\":\n>           raise DecodeError(\"Algorithm not supported\")\nE           jwt.exceptions.DecodeError: Algorithm not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:31: DecodeError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:28: in encode\n    return _encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000291E4FC7CD0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:28: in encode\n    return _encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000291E5035CD0>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - j...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.63s\n"}
{"model": "deepseek-r1", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Job' object has no attribute 'day'", "returncode": 1, "elapsed_time_s": 1.885307, "avg_memory_mb": 32.49, "avg_cpu_percent": 96.5, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-02 00:12:43", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:97: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:148: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"ran\")\n    \n>       j = schedule.every(10).seconds.do(job)\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:184: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().day.at(\"10:30\").do(job)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:210: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().monday.at(\"09:00\").do", "stdout_sha1": "140aca00f290e80b416b1a64b52f66803f416fac", "stdout_len": 7265, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:97: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:148: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"ran\")\n    \n>       j = schedule.every(10).seconds.do(job)\nE       AttributeError: 'function' object has no attribute 'do'\n\ntests\\Schedule\\functional_test.py:184: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().day.at(\"10:30\").do(job)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:210: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().monday.at(\"09:00\").do(job)\nE       AttributeError: 'function' object has no attribute 'at'\n\ntests\\Schedule\\functional_test.py:224: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       schedule.every().hour.do(job)\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:253: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n>       schedule.every().minute.do(a).tag(\"alpha\")\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:269: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:290: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_run_pending_executes_due_job_without_sleep\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_day_at_sets_time_component_in_next_run\nFAILED tests/Schedule/functional_test.py::test_weekday_scheduling_creates_job_and_next_run\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n12 failed in 0.58s\n"}
{"model": "deepseek-r1", "project": "Stegano", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute 'load'", "returncode": 1, "elapsed_time_s": 26.490882, "avg_memory_mb": 36.71, "avg_cpu_percent": 0.8, "passed": 2, "failed": 10, "skipped": 0, "total": 12, "functional_score": 0.1667, "timestamp": "2026-01-02 00:33:49", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x0000025B3B889C80>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'This is a longer secret message with punctuation: 12345, hello-world!'\ngenerator = None, shift = 0, encoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n     ", "stdout_sha1": "c57f2f83a412a425e5cf5d0ae2b590ae14d8a534", "stdout_len": 12195, "stdout": "FFFFFF..FFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x0000025B3B889C80>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'This is a longer secret message with punctuation: 12345, hello-world!'\ngenerator = None, shift = 0, encoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n>       img_obj = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'object input', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\red\\red.py:6: in hide\n    image = convert_image(image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def convert_image(image):\n>       if image.mode not in ('RGB', 'RGBA'):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\tools\\utils.py:4: AttributeError\n________________ test_red_hide_and_reveal_extended_latin_text _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_red_hide_and_reveal_exten0')\n\n    def test_red_hide_and_reveal_extended_latin_text(tmp_path: Path) -> None:\n        \"\"\"Red backend stores per-char ord() into a byte channel; Latin-1 chars like 'é' are valid.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"Café au lait\"\n        output = tmp_path / \"red_latin.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\red\\red.py:6: in hide\n    image = convert_image(image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def convert_image(image):\n>       if image.mode not in ('RGB', 'RGBA'):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\tools\\utils.py:4: AttributeError\n________________________ test_wav_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_wav_hide_and_reveal_text0')\n\n    def test_wav_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"wav.hide writes output WAV; wav.reveal returns the same string.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"wav secret\"\n        output = tmp_path / \"out.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       assert '~j(\\x12.-\\rE...\\x0b{\\x17\\x7f' == 'wav secret'\nE         \nE         - wav secret\nE         + ~j(\u0012.-\nE         + E~\nE         + (\"(\u001f?\u0018}\"+tT\u0013\nE         \nE         + J'y\\xaae^h(\\x08\\x0f\\u04f2\\x08gu9(*g]TW(\"...\nE         \nE         ...Full output truncated (9 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:224: AssertionError\n_____________________ test_wav_hide_and_reveal_short_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_wav_hide_and_reveal_short0')\n\n    def test_wav_hide_and_reveal_short_text(tmp_path: Path) -> None:\n        \"\"\"A short message should also roundtrip.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"ok\"\n        output = tmp_path / \"out_short.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       assert '|(,E\"(\\x15\\x...\\x0b{\\x17\\x7f' == 'ok'\nE         \nE         - ok\nE         + |(,E\"(\u0015\u0010U\u0003|T\u0013\nE         \nE         + J'y\\xaae^h(\\x08\\x0f\\u04f2\\x08gu9(*g]TW(\"\nE         + \u0003ut \u0002_\u0014:5LV{TZ\nE         ...\nE         \nE         ...Full output truncated (7 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:239: AssertionError\n____________________ test_wav_hide_and_reveal_longer_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_wav_hide_and_reveal_longe0')\n\n    def test_wav_hide_and_reveal_longer_text(tmp_path: Path) -> None:\n        \"\"\"Roundtrip a longer ASCII message via WAV backend.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\"\n        output = tmp_path / \"out_long.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       assert 'vj \\x12&-\\rE...(\\x1f=}\"))e\\\\' == 'WAV backend ...nopqrstuvwxyz'\nE         \nE         - WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\nE         + vj \u0012&-\nE         + E|\b(\u0002(\u001f=}\"))e\\\n\ntests\\Stegano\\functional_test.py:254: AssertionError\n_____________________ test_lsb_and_red_outputs_are_files ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-478/test_lsb_and_red_outputs_are_f0')\n\n    def test_lsb_and_red_outputs_are_files(tmp_path: Path) -> None:\n        \"\"\"Ensure image-encoding backends produce files that can be written to disk.\"\"\"\n        _ensure_image_samples_exist()\n    \n        out_lsb = tmp_path / \"lsb_file.png\"\n        out_red = tmp_path / \"red_file.png\"\n    \n>       lsb.hide(str(LENNA_PNG), \"x\").save(str(out_lsb))\n\ntests\\Stegano\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'x', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb:\n            image = convert_image(image)\n>       pixels = image.load()\nE       AttributeError: 'str' object has no attribute 'load'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:9: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_extended_latin_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_text - asse...\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_short_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_longer_text\nFAILED tests/Stegano/functional_test.py::test_lsb_and_red_outputs_are_files\n10 failed, 2 passed in 1.91s\n"}
{"model": "deepseek-r1", "project": "Tablib", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "Unsupported format: html", "returncode": 1, "elapsed_time_s": 2.026849, "avg_memory_mb": 33.18, "avg_cpu_percent": 101.7, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2026-01-02 00:35:47", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3, width=3>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            from .formats._csv import export_csv\n            return export_csv(self)\n        elif fmt == 'json':\n            from .formats._json import export_json\n            return export_json(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:167: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3, width=3>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            from .formats._csv import export_csv\n            return export_csv(self)\n        elif fmt == 'json':\n            from .formats._json import export_json\n            return export_json(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:167: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.54s\n", "stdout_sha1": "b71b36579feba19163055a9e2c8b8ec8f2e4aaf2", "stdout_len": 3234, "stdout": ".F..F...F..                                                              [100%]\n================================== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3, width=3>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            from .formats._csv import export_csv\n            return export_csv(self)\n        elif fmt == 'json':\n            from .formats._json import export_json\n            return export_json(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:167: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3, width=3>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            from .formats._csv import export_csv\n            return export_csv(self)\n        elif fmt == 'json':\n            from .formats._json import export_json\n            return export_json(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:167: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.54s\n"}
{"model": "deepseek-r1", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "sequence item 0: expected str instance, list found", "returncode": 1, "elapsed_time_s": 27.637547, "avg_memory_mb": 32.76, "avg_cpu_percent": 0.65, "passed": 1, "failed": 11, "skipped": 0, "total": 12, "functional_score": 0.0833, "timestamp": "2026-01-02 00:39:55", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_basic_list_of_lists_default_simple ___________________\n\n    def test_basic_list_of_lists_default_simple() -> None:\n        table = [\n            [\"Sun\", 696000, 1.9891e9],\n            [\"Earth\", 6371, 5973.6],\n            [\"Moon\", 1737, 73.5],\n            [\"Mars\", 3390, 641.85],\n        ]\n    \n>       output = tabulate(table)\n\ntests\\Tabulate\\functional_test.py:82: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['Sun', 696000, 1989100000.0], ['Earth', 6371, 5973.6], ['Moon', 1737, 73.5], ['Mars', 3390, 641.85]]\nheaders = None, tablefmt = 'plain', numalign = 'right', stralign = 'left'\n\n    def tabulate(table, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        if tablefmt in PRESET_FORMATS:\n            fmt = PRESET_FORMATS[tablefmt]\n        else:\n            raise ValueError(f\"Table format {tablefmt} not supported\")\n    \n        headers, rows = _normalize_table(table, headers)\n        if not rows:\n            return \"\"\n    \n        widths = _calculate_widths(headers, rows)\n        align_funcs = []\n        for i in range(len(widths)):\n            if headers and i < len(headers) and any(isinstance(row[i], (int, float)) for row in rows if i < len(row)):\n                align = numalign\n            else:\n                align = stralign\n            if align == \"left\":\n                align_funcs.append(str.ljust)\n            elif align == \"right\":\n                align_funcs.append(str.rjust)\n            elif align == \"center\":\n                align_funcs.append(str.center)\n            else:\n                align_funcs.append(str.ljust)\n    \n        output_lines = []\n        if fmt.lineabove and (headers or \"lineabove\" not in fmt.with_header_hide):\n            output_lines.append(fmt.lineabove(widths))\n    \n        if headers:\n            aligned_headers = _align_row(headers, widths, align_funcs)\n            header_line = fmt.headerrow(aligned_headers, widths)\n            output_lines.append(header_line)\n            if fmt.linebelowheader and (headers or \"linebelowheader\" not in fmt.with_header_hide):\n                output_lines.append(fmt.linebelowheader(widths))\n    \n        for i, row in enumerate(rows):\n            if i > 0 and fmt.linebetweenrows:\n                output_lines.append(fmt.linebetweenrows(widths))\n            aligned_row = _align_row(row, widths, align_funcs)\n            output_lines.append(fmt.datarow(aligned_row, widths))\n    \n        if fmt.linebelow and (headers or \"linebelow\" not in fmt.with_header_hide):\n            output_lines.append(fmt.linebelow(widths))\n    \n>       return '\\n'.join(output_lines)\nE       TypeError: sequence item 0: expected str instance, list found\n\ngeneration\\Tabulate\\tabulate\\core.py:103: TypeError\n____________________ test_headers_as_list_and_plain_format ____________________\n\n    def test_headers_as_list_and_plain_format() -> None:\n        table = [\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n        headers = [\"item\", \"qty\"]\n    \n>       output = tabulate(table, headers=headers, tablefmt=\"plain\")\n\ntests\\Tabulate\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['spam', 42], ['eggs', 451], ['bacon', 0]], headers = ['item', 'qty']\ntablefmt = 'plain', numalign = 'right', stralign = 'left'\n\n    def tabulate(table, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        if tablefmt in PRESET_FORMATS:\n            fmt = PRESET_FORMATS[tablefmt]\n        else:\n            raise ValueError(f\"Table format {tablefmt} not supported\")\n    \n        headers, rows = _normalize_table(table, headers)\n        if not rows:\n            return \"\"\n    \n        widths = _calculate_widths(headers, rows)\n        align_funcs = []\n        for i in range(len(widths)):\n            if headers and i < len(headers) and any(isinstance(row[i], (int", "stdout_sha1": "be9f6b7dafd6d1eed113507590fec912ed7837a0", "stdout_len": 14545, "stdout": "FFFFFFFFFFF.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_basic_list_of_lists_default_simple ___________________\n\n    def test_basic_list_of_lists_default_simple() -> None:\n        table = [\n            [\"Sun\", 696000, 1.9891e9],\n            [\"Earth\", 6371, 5973.6],\n            [\"Moon\", 1737, 73.5],\n            [\"Mars\", 3390, 641.85],\n        ]\n    \n>       output = tabulate(table)\n\ntests\\Tabulate\\functional_test.py:82: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['Sun', 696000, 1989100000.0], ['Earth', 6371, 5973.6], ['Moon', 1737, 73.5], ['Mars', 3390, 641.85]]\nheaders = None, tablefmt = 'plain', numalign = 'right', stralign = 'left'\n\n    def tabulate(table, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        if tablefmt in PRESET_FORMATS:\n            fmt = PRESET_FORMATS[tablefmt]\n        else:\n            raise ValueError(f\"Table format {tablefmt} not supported\")\n    \n        headers, rows = _normalize_table(table, headers)\n        if not rows:\n            return \"\"\n    \n        widths = _calculate_widths(headers, rows)\n        align_funcs = []\n        for i in range(len(widths)):\n            if headers and i < len(headers) and any(isinstance(row[i], (int, float)) for row in rows if i < len(row)):\n                align = numalign\n            else:\n                align = stralign\n            if align == \"left\":\n                align_funcs.append(str.ljust)\n            elif align == \"right\":\n                align_funcs.append(str.rjust)\n            elif align == \"center\":\n                align_funcs.append(str.center)\n            else:\n                align_funcs.append(str.ljust)\n    \n        output_lines = []\n        if fmt.lineabove and (headers or \"lineabove\" not in fmt.with_header_hide):\n            output_lines.append(fmt.lineabove(widths))\n    \n        if headers:\n            aligned_headers = _align_row(headers, widths, align_funcs)\n            header_line = fmt.headerrow(aligned_headers, widths)\n            output_lines.append(header_line)\n            if fmt.linebelowheader and (headers or \"linebelowheader\" not in fmt.with_header_hide):\n                output_lines.append(fmt.linebelowheader(widths))\n    \n        for i, row in enumerate(rows):\n            if i > 0 and fmt.linebetweenrows:\n                output_lines.append(fmt.linebetweenrows(widths))\n            aligned_row = _align_row(row, widths, align_funcs)\n            output_lines.append(fmt.datarow(aligned_row, widths))\n    \n        if fmt.linebelow and (headers or \"linebelow\" not in fmt.with_header_hide):\n            output_lines.append(fmt.linebelow(widths))\n    \n>       return '\\n'.join(output_lines)\nE       TypeError: sequence item 0: expected str instance, list found\n\ngeneration\\Tabulate\\tabulate\\core.py:103: TypeError\n____________________ test_headers_as_list_and_plain_format ____________________\n\n    def test_headers_as_list_and_plain_format() -> None:\n        table = [\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n        headers = [\"item\", \"qty\"]\n    \n>       output = tabulate(table, headers=headers, tablefmt=\"plain\")\n\ntests\\Tabulate\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['spam', 42], ['eggs', 451], ['bacon', 0]], headers = ['item', 'qty']\ntablefmt = 'plain', numalign = 'right', stralign = 'left'\n\n    def tabulate(table, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        if tablefmt in PRESET_FORMATS:\n            fmt = PRESET_FORMATS[tablefmt]\n        else:\n            raise ValueError(f\"Table format {tablefmt} not supported\")\n    \n        headers, rows = _normalize_table(table, headers)\n        if not rows:\n            return \"\"\n    \n        widths = _calculate_widths(headers, rows)\n        align_funcs = []\n        for i in range(len(widths)):\n            if headers and i < len(headers) and any(isinstance(row[i], (int, float)) for row in rows if i < len(row)):\n                align = numalign\n            else:\n                align = stralign\n            if align == \"left\":\n                align_funcs.append(str.ljust)\n            elif align == \"right\":\n                align_funcs.append(str.rjust)\n            elif align == \"center\":\n                align_funcs.append(str.center)\n            else:\n                align_funcs.append(str.ljust)\n    \n        output_lines = []\n        if fmt.lineabove and (headers or \"lineabove\" not in fmt.with_header_hide):\n            output_lines.append(fmt.lineabove(widths))\n    \n        if headers:\n            aligned_headers = _align_row(headers, widths, align_funcs)\n            header_line = fmt.headerrow(aligned_headers, widths)\n            output_lines.append(header_line)\n            if fmt.linebelowheader and (headers or \"linebelowheader\" not in fmt.with_header_hide):\n                output_lines.append(fmt.linebelowheader(widths))\n    \n        for i, row in enumerate(rows):\n            if i > 0 and fmt.linebetweenrows:\n                output_lines.append(fmt.linebetweenrows(widths))\n            aligned_row = _align_row(row, widths, align_funcs)\n            output_lines.append(fmt.datarow(aligned_row, widths))\n    \n        if fmt.linebelow and (headers or \"linebelow\" not in fmt.with_header_hide):\n            output_lines.append(fmt.linebelow(widths))\n    \n>       return '\\n'.join(output_lines)\nE       TypeError: sequence item 0: expected str instance, list found\n\ngeneration\\Tabulate\\tabulate\\core.py:103: TypeError\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]], headers = 'firstrow'\ntablefmt = 'simple', numalign = 'right', stralign = 'left'\n\n    def tabulate(table, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        if tablefmt in PRESET_FORMATS:\n            fmt = PRESET_FORMATS[tablefmt]\n        else:\n>           raise ValueError(f\"Table format {tablefmt} not supported\")\nE           ValueError: Table format simple not supported\n\ngeneration\\Tabulate\\tabulate\\core.py:61: ValueError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n>       output = tabulate(table, headers=\"keys\")\n\ntests\\Tabulate\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:63: in tabulate\n    headers, rows = _normalize_table(table, headers)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = {'Age': [24, 19], 'Name': ['Alice', 'Bob']}, headers = 'keys'\n\n    def _normalize_table(table, headers):\n        if not table:\n            return [], []\n    \n>       if isinstance(table[0], dict):\nE       KeyError: 0\n\ngeneration\\Tabulate\\tabulate\\core.py:7: KeyError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n>       out_true = tabulate(table, showindex=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'showindex'\n\ntests\\Tabulate\\functional_test.py:151: TypeError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['spam', 42], ['eggs', 451], ['bacon', 0]], headers = ['item', 'qty']\ntablefmt = 'github', numalign = 'right', stralign = 'left'\n\n    def tabulate(table, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        if tablefmt in PRESET_FORMATS:\n            fmt = PRESET_FORMATS[tablefmt]\n        else:\n>           raise ValueError(f\"Table format {tablefmt} not supported\")\nE           ValueError: Table format github not supported\n\ngeneration\\Tabulate\\tabulate\\core.py:61: ValueError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            {\"name\": \"Alice\", \"score\": 10},\n            {\"name\": \"Bob\", \"score\": 12},\n        ]\n>       output = tabulate(rows, headers=\"keys\", tablefmt=\"plain\")\n\ntests\\Tabulate\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [{'name': 'Alice', 'score': 10}, {'name': 'Bob', 'score': 12}]\nheaders = ['name', 'score'], tablefmt = 'plain', numalign = 'right'\nstralign = 'left'\n\n    def tabulate(table, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        if tablefmt in PRESET_FORMATS:\n            fmt = PRESET_FORMATS[tablefmt]\n        else:\n            raise ValueError(f\"Table format {tablefmt} not supported\")\n    \n        headers, rows = _normalize_table(table, headers)\n        if not rows:\n            return \"\"\n    \n        widths = _calculate_widths(headers, rows)\n        align_funcs = []\n        for i in range(len(widths)):\n            if headers and i < len(headers) and any(isinstance(row[i], (int, float)) for row in rows if i < len(row)):\n                align = numalign\n            else:\n                align = stralign\n            if align == \"left\":\n                align_funcs.append(str.ljust)\n            elif align == \"right\":\n                align_funcs.append(str.rjust)\n            elif align == \"center\":\n                align_funcs.append(str.center)\n            else:\n                align_funcs.append(str.ljust)\n    \n        output_lines = []\n        if fmt.lineabove and (headers or \"lineabove\" not in fmt.with_header_hide):\n            output_lines.append(fmt.lineabove(widths))\n    \n        if headers:\n            aligned_headers = _align_row(headers, widths, align_funcs)\n            header_line = fmt.headerrow(aligned_headers, widths)\n            output_lines.append(header_line)\n            if fmt.linebelowheader and (headers or \"linebelowheader\" not in fmt.with_header_hide):\n                output_lines.append(fmt.linebelowheader(widths))\n    \n        for i, row in enumerate(rows):\n            if i > 0 and fmt.linebetweenrows:\n                output_lines.append(fmt.linebetweenrows(widths))\n            aligned_row = _align_row(row, widths, align_funcs)\n            output_lines.append(fmt.datarow(aligned_row, widths))\n    \n        if fmt.linebelow and (headers or \"linebelow\" not in fmt.with_header_hide):\n            output_lines.append(fmt.linebelow(widths))\n    \n>       return '\\n'.join(output_lines)\nE       TypeError: sequence item 0: expected str instance, list found\n\ngeneration\\Tabulate\\tabulate\\core.py:103: TypeError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\nE       TypeError: tabulate() got an unexpected keyword argument 'missingval'\n\ntests\\Tabulate\\functional_test.py:207: TypeError\n__________________ test_floatfmt_controls_numeric_rendering ___________________\n\n    def test_floatfmt_controls_numeric_rendering() -> None:\n        rows = [\n            [\"pi\", 3.14159],\n            [\"e\", 2.71828],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"value\"], tablefmt=\"plain\", floatfmt=\".2f\")\nE       TypeError: tabulate() got an unexpected keyword argument 'floatfmt'\n\ntests\\Tabulate\\functional_test.py:222: TypeError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_basic_list_of_lists_default_simple\nFAILED tests/Tabulate/functional_test.py::test_headers_as_list_and_plain_format\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - TypeError...\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\nFAILED tests/Tabulate/functional_test.py::test_list_of_dicts_headers_keys_plain\nFAILED tests/Tabulate/functional_test.py::test_missingval_renders_placeholder\nFAILED tests/Tabulate/functional_test.py::test_floatfmt_controls_numeric_rendering\nFAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n11 failed, 1 passed in 0.69s\n"}
{"model": "deepseek-r1", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Query' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 2.012428, "avg_memory_mb": 36.12, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 00:58:14", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Query' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n", "stdout_sha1": "f98a593813157c61e0b9c8c5589b3b959272e171", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Query' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n"}
{"model": "deepseek-r1", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "KeyError", "exception_msg": "'root'", "returncode": 1, "elapsed_time_s": 27.765308, "avg_memory_mb": 32.71, "avg_cpu_percent": 0.59, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-02 01:15:15", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n>       assert \"root\" in data\nE       AssertionError: assert 'root' in {'message': 'Hello'}\n\ntests\\Xmltodict\\functional_test.py:79: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n>       items = data[\"root\"][\"item\"]\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:88: KeyError\n_______________________ test_parse_attributes_and_text ________________________\n\n    def test_parse_attributes_and_text() -> None:\n        \"\"\"Attributes and text content should be exposed using @attr and #text keys.\"\"\"\n        xml = '<user id=\"123\">Alice</user>'\n        data = _parse(xml)\n    \n>       user = data[\"user\"]\nE       KeyError: 'user'\n\ntests\\Xmltodict\\functional_test.py:98: KeyError\n___________________ test_unparse_roundtrip_basic_structure ____________________\n\n    def test_unparse_roundtrip_basic_structure() -> None:\n        \"\"\"unparse() followed by parse() should preserve the logical structure.\"\"\"\n        original = {\n            \"root\": {\n                \"item\": [\n                    {\"@id\": \"1\", \"#text\": \"A\"},\n                    {\"@id\": \"2\", \"#text\": \"B\"},\n                ]\n            }\n        }\n    \n        xml = _unparse(original)\n        round_tripped = _parse(xml)\n    \n>       assert round_tripped == original\nE       AssertionError: assert {'item': [{'#... '@id': '2'}]} == {'root': {'it...'@id': '2'}]}}\nE         \nE         Left contains 1 more item:\nE         {'item': [{'#text': 'A', '@id': '1'}, {'#text': 'B', '@id': '2'}]}\nE         Right contains 1 more item:\nE         {'root': {'item': [{'#text': 'A', '@id': '1'}, {'#text': 'B', '@id': '2'}]}}\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:117: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n>       root = data[\"root\"]\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:129: KeyError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:151: KeyError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n>       item = data[\"root\"][\"item\"]\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:163: KeyError\n_____________ test_custom_attr_prefix_and_cdata_key_if_supported ______________\n\n    def ", "stdout_sha1": "cd5f75b74e212730d7a5e3dca14f83720b857a27", "stdout_len": 12169, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n>       assert \"root\" in data\nE       AssertionError: assert 'root' in {'message': 'Hello'}\n\ntests\\Xmltodict\\functional_test.py:79: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n>       items = data[\"root\"][\"item\"]\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:88: KeyError\n_______________________ test_parse_attributes_and_text ________________________\n\n    def test_parse_attributes_and_text() -> None:\n        \"\"\"Attributes and text content should be exposed using @attr and #text keys.\"\"\"\n        xml = '<user id=\"123\">Alice</user>'\n        data = _parse(xml)\n    \n>       user = data[\"user\"]\nE       KeyError: 'user'\n\ntests\\Xmltodict\\functional_test.py:98: KeyError\n___________________ test_unparse_roundtrip_basic_structure ____________________\n\n    def test_unparse_roundtrip_basic_structure() -> None:\n        \"\"\"unparse() followed by parse() should preserve the logical structure.\"\"\"\n        original = {\n            \"root\": {\n                \"item\": [\n                    {\"@id\": \"1\", \"#text\": \"A\"},\n                    {\"@id\": \"2\", \"#text\": \"B\"},\n                ]\n            }\n        }\n    \n        xml = _unparse(original)\n        round_tripped = _parse(xml)\n    \n>       assert round_tripped == original\nE       AssertionError: assert {'item': [{'#... '@id': '2'}]} == {'root': {'it...'@id': '2'}]}}\nE         \nE         Left contains 1 more item:\nE         {'item': [{'#text': 'A', '@id': '1'}, {'#text': 'B', '@id': '2'}]}\nE         Right contains 1 more item:\nE         {'root': {'item': [{'#text': 'A', '@id': '1'}, {'#text': 'B', '@id': '2'}]}}\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:117: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n>       root = data[\"root\"]\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:129: KeyError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:151: KeyError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n>       item = data[\"root\"][\"item\"]\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:163: KeyError\n_____________ test_custom_attr_prefix_and_cdata_key_if_supported ______________\n\n    def test_custom_attr_prefix_and_cdata_key_if_supported() -> None:\n        \"\"\"attr_prefix / cdata_key customization should reflect in output when supported.\"\"\"\n        xml = '<user id=\"7\">Bob</user>'\n    \n        data = _parse(xml, attr_prefix=\"$\", cdata_key=\"text\")\n>       user = data[\"user\"]\nE       KeyError: 'user'\n\ntests\\Xmltodict\\functional_test.py:177: KeyError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n>       user = data[\"user\"]\nE       KeyError: 'user'\n\ntests\\Xmltodict\\functional_test.py:192: KeyError\n______________________ test_dict_constructor_ordereddict ______________________\n\n    def test_dict_constructor_ordereddict() -> None:\n        \"\"\"dict_constructor should allow choosing mapping type (e.g., OrderedDict) when supported.\"\"\"\n        xml = \"<root><a>1</a><b>2</b></root>\"\n        data = _parse(xml, dict_constructor=OrderedDict)\n    \n        if \"dict_constructor\" in _PARSE_PARAMS:\n            assert isinstance(data, OrderedDict)\n            assert isinstance(data[\"root\"], OrderedDict)\n        else:\n            assert isinstance(data, dict)\n    \n>       assert data[\"root\"][\"a\"] == \"1\"\nE       KeyError: 'root'\n\ntests\\Xmltodict\\functional_test.py:215: KeyError\n_____________________ test_unparse_pretty_and_parse_back ______________________\n\n    def test_unparse_pretty_and_parse_back() -> None:\n        \"\"\"Pretty/full_document knobs should not break roundtrip of basic structure.\"\"\"\n        original: Dict[str, Any] = {\"root\": {\"x\": \"1\", \"y\": \"2\"}}\n    \n        xml = _unparse(original, pretty=True, full_document=True)\n        assert \"<root>\" in xml or \"<root\" in xml\n    \n        round_tripped = _parse(xml)\n>       assert round_tripped == original\nE       AssertionError: assert {'x': '1', 'y': '2'} == {'root': {'x': '1', 'y': '2'}}\nE         \nE         Left contains 2 more items:\nE         {'x': '1', 'y': '2'}\nE         Right contains 1 more item:\nE         {'root': {'x': '1', 'y': '2'}}\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:227: AssertionError\n______________ test_postprocessor_transforms_value_if_supported _______________\n\n    def test_postprocessor_transforms_value_if_supported() -> None:\n        \"\"\"postprocessor can transform values in a happy-path parse when supported.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n    \n        def _pp(path: Any, key: str, value: Any) -> Any:\n            if key == \"message\" and isinstance(value, str):\n                return key, value.upper()\n            return key, value\n    \n>       data = _parse(xml, postprocessor=_pp)\n\ntests\\Xmltodict\\functional_test.py:239: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:70: in parse\n    return _element_to_dict(\ngeneration\\Xmltodict\\xmltodict.py:116: in _element_to_dict\n    child_dict = _element_to_dict(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nelement = <Element 'message' at 0x0000029B4CAA7860>, process_namespaces = False\nnamespace_separator = ':', force_list = []\npostprocessor = <function test_postprocessor_transforms_value_if_supported.<locals>._pp at 0x0000029B4CB23F70>\n\n    def _element_to_dict(\n        element: ET.Element,\n        process_namespaces: bool,\n        namespace_separator: str,\n        force_list: List[str],\n        postprocessor: Any\n    ) -> Union[XMLDict, str]:\n        \"\"\"Convert XML element to dictionary.\"\"\"\n    \n        # Handle tag name\n        tag = element.tag\n        if process_namespaces and '}' in tag:\n            # Extract namespace and local name\n            namespace_match = re.match(r'\\{.*?\\}', tag)\n            if namespace_match:\n                namespace = namespace_match.group(0)[1:-1]\n                local_name = tag[namespace_match.end():]\n                tag = f\"{namespace}{namespace_separator}{local_name}\"\n    \n        # Start with attributes\n        result: XMLDict = {}\n        if element.attrib:\n            for key, value in element.attrib.items():\n                attr_key = f\"@{key}\"\n                if process_namespaces and '}' in key:\n                    namespace_match = re.match(r'\\{.*?\\}', key)\n                    if namespace_match:\n                        namespace = namespace_match.group(0)[1:-1]\n                        local_name = key[namespace_match.end():]\n                        attr_key = f\"@{namespace}{namespace_separator}{local_name}\"\n                result[attr_key] = value\n    \n        # Handle children\n        children_by_tag: Dict[str, List[Any]] = {}\n        text_parts: List[str] = []\n    \n        for child in element:\n            if isinstance(child, ET.Element):\n                child_dict = _element_to_dict(\n                    child,\n                    process_namespaces,\n                    namespace_separator,\n                    force_list,\n                    postprocessor\n                )\n    \n                child_tag = child.tag\n                if process_namespaces and '}' in child_tag:\n                    namespace_match = re.match(r'\\{.*?\\}', child_tag)\n                    if namespace_match:\n                        namespace = namespace_match.group(0)[1:-1]\n                        local_name = child_tag[namespace_match.end():]\n                        child_tag = f\"{namespace}{namespace_separator}{local_name}\"\n    \n                if child_tag not in children_by_tag:\n                    children_by_tag[child_tag] = []\n                children_by_tag[child_tag].append(child_dict)\n            elif child.tail:\n                text_parts.append(child.tail)\n    \n        # Add children to result\n        for child_tag, children in children_by_tag.items():\n            if len(children) == 1 and child_tag not in force_list:\n                result[child_tag] = children[0]\n            else:\n                result[child_tag] = children\n    \n        # Handle text\n        if element.text and element.text.strip():\n            text = element.text.strip()\n            if text_parts:\n                text = text + ''.join(text_parts)\n    \n            if '#text' in result:\n                if isinstance(result['#text'], list):\n                    result['#text'].append(text)\n                else:\n                    result['#text'] = [result['#text'], text]\n            else:\n                result['#text'] = text\n    \n        # Apply postprocessor\n        if postprocessor:\n>           result = postprocessor(tag, result)\nE           TypeError: _pp() missing 1 required positional argument: 'value'\n\ngeneration\\Xmltodict\\xmltodict.py:161: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_parse_simple_element - Assert...\nFAILED tests/Xmltodict/functional_test.py::test_parse_repeated_elements_as_list\nFAILED tests/Xmltodict/functional_test.py::test_parse_attributes_and_text - K...\nFAILED tests/Xmltodict/functional_test.py::test_unparse_roundtrip_basic_structure\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\nFAILED tests/Xmltodict/functional_test.py::test_parse_nested_structure - KeyE...\nFAILED tests/Xmltodict/functional_test.py::test_force_list_option_for_single_element\nFAILED tests/Xmltodict/functional_test.py::test_custom_attr_prefix_and_cdata_key_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_xml_attribs_false_drops_attributes_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_dict_constructor_ordereddict\nFAILED tests/Xmltodict/functional_test.py::test_unparse_pretty_and_parse_back\nFAILED tests/Xmltodict/functional_test.py::test_postprocessor_transforms_value_if_supported\n12 failed in 0.68s\n"}
{"model": "deepseek-v3", "project": "Astral", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'moon' from partially initialized module 'astral' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Astral\\astral\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.740976, "avg_memory_mb": 35.97, "avg_cpu_percent": 98.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 14:20:00", "stdout_excerpt": "====\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Astral\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\ngeneration\\Astral\\astral\\__init__.py:3: in <module>\n    from astral import sun, moon\nE   ImportError: cannot import name 'moon' from partially initialized module 'astral' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Astral\\astral\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.54s\n", "stdout_sha1": "7ea6ec466fd634243720fdf50ca40e5317ecea17", "stdout_len": 1123, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Astral\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\ngeneration\\Astral\\astral\\__init__.py:3: in <module>\n    from astral import sun, moon\nE   ImportError: cannot import name 'moon' from partially initialized module 'astral' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Astral\\astral\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.54s\n"}
{"model": "deepseek-v3", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "update() got an unexpected keyword argument 'task_always_eager'", "returncode": 1, "elapsed_time_s": 29.303983, "avg_memory_mb": 32.8, "avg_cpu_percent": 0.54, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2025-12-31 14:28:44", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            r", "stdout_sha1": "71c42ae08cc41de15c9e0c82e11ad04b5fef9c4d", "stdout_len": 13248, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n>       app = _make_app(\"celery_test_app_2\")\n\ntests\\Celery\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app_2'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.67s\n"}
{"model": "deepseek-v3", "project": "Click", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'click.decorators'", "returncode": 2, "elapsed_time_s": 5.517443, "avg_memory_mb": 35.5, "avg_cpu_percent": 98.8, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 14:30:58", "stdout_excerpt": "====\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:15: in <module>\n    from .decorators import (\nE   ModuleNotFoundError: No module named 'click.decorators'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.04s\n", "stdout_sha1": "8fd90f29fa8c03ae323526985cbc913e7c466210", "stdout_len": 966, "stdout": "\n=================================== ERRORS ====================================\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:15: in <module>\n    from .decorators import (\nE   ModuleNotFoundError: No module named 'click.decorators'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.04s\n"}
{"model": "deepseek-v3", "project": "Dataset", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "sqlite3.OperationalError: unable to open database file", "returncode": 1, "elapsed_time_s": 5.497633, "avg_memory_mb": 32.84, "avg_cpu_percent": 98.5, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 14:35:28", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5648CB80>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5651AEB0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-296/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n>       db = dataset.connect(db_url)\n\ntests\\Dataset\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B56540FD0>\nurl = 'sqlite:///C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-296\\\\test_transactions_commit_and_r0\\\\tx_sample.db'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5651DFA0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "dc68adfe046d452625124fbb9ab037d62042e799", "stdout_len": 11315, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5648CB80>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5651AEB0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-296/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n>       db = dataset.connect(db_url)\n\ntests\\Dataset\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B56540FD0>\nurl = 'sqlite:///C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-296\\\\test_transactions_commit_and_r0\\\\tx_sample.db'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5651DFA0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B56447F10>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:243: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B56509310>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B564928E0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_______________________ test_delete_and_clear_all_rows ________________________\n\n    def test_delete_and_clear_all_rows() -> None:\n        \"\"\"\n        Older dataset.Table may not expose truncate().\n        Clear a table and end at 0 rows without relying on result iteration for DML.\n        \"\"\"\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5650CC70>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B56525BB0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_____________________ test_raw_sql_query_with_parameters ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-296/test_raw_sql_query_with_parame0')\n\n    def test_raw_sql_query_with_parameters(tmp_path: Path) -> None:\n        db_path = tmp_path / \"param.db\"\n>       db = dataset.connect(\"sqlite:///%s\" % str(db_path))\n\ntests\\Dataset\\functional_test.py:317: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B5650DB20>\nurl = 'sqlite:///C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-296\\\\test_raw_sql_query_with_parame0\\\\param.db'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:52: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000019B564AE9A0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        self.url = url\n>       self.conn = sqlite3.connect(url)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:8: OperationalError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - sql...\nFAILED tests/Dataset/functional_test.py::test_transactions_commit_and_rollback\nFAILED tests/Dataset/functional_test.py::test_insert_many_returns_ids_and_count\nFAILED tests/Dataset/functional_test.py::test_find_one_missing_returns_none\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_table_all_iteration_and_row_shape\nFAILED tests/Dataset/functional_test.py::test_delete_and_clear_all_rows - sql...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_raw_sql_query_with_parameters\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n11 failed in 4.16s\n"}
{"model": "deepseek-v3", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 14:41:44", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "deepseek-v3", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('line' in 'error: file not found: failed password\\n\\n' or 'lines' in 'error: file not found: failed password\\n\\n')", "returncode": 1, "elapsed_time_s": 2.696906, "avg_memory_mb": 32.57, "avg_cpu_percent": 71.5, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 14:43:54", "stdout_excerpt": "==== FAILURES ===================================\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           AssertionError: assert ('line' in 'error: file not found: failed password\\n\\n' or 'lines' in 'error: file not found: failed password\\n\\n')\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n1 failed, 11 passed in 1.24s\n", "stdout_sha1": "88374bc5e1ac474f0f3d2c9bb0d3ddd45c7c97bc", "stdout_len": 2430, "stdout": "...........F                                                             [100%]\n================================== FAILURES ===================================\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           AssertionError: assert ('line' in 'error: file not found: failed password\\n\\n' or 'lines' in 'error: file not found: failed password\\n\\n')\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n1 failed, 11 passed in 1.24s\n"}
{"model": "deepseek-v3", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "naturaltime() got an unexpected keyword argument 'when'", "returncode": 1, "elapsed_time_s": 2.077669, "avg_memory_mb": 32.09, "avg_cpu_percent": 98.5, "passed": 4, "failed": 6, "skipped": 5, "total": 15, "functional_score": 0.2667, "timestamp": "2025-12-31 14:52:43", "stdout_excerpt": "==== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n>       d = humanize.precisedelta(3661)  # seconds\n\ntests\\Humanize\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndelta = 3661, minimum_unit = 'seconds', format = '%0.2f'\n\n    def precisedelta(delta, minimum_unit='seconds', format='%0.2f'):\n        \"\"\"Format a timedelta into a human-readable string with precision control.\"\"\"\n        if not isinstance(delta, timedelta):\n>           raise TypeError(\"precisedelta() argument must be a timedelta\")\nE           TypeError: precisedelta() argument must be a timedelta\n\ngeneration\\Humanize\\humanize\\time.py:7: TypeError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n_________________________ test_naturalsize_binary_kib _________________________\n\n    def test_naturalsize_binary_kib() -> None:\n        s = humanize.naturalsize(1536, binary=True)\n        assert isinstance(s, str)\n        assert s\n        # Compatible across versions: \"KiB\" (common) or any case variant.\n>       assert (\"KiB\" in s) or (\"kib\" in s.lower())\nE       AssertionError: assert ('KiB' in '1.5 KB' or 'kib' in '1.5 kb')\nE        +  where '1.5 kb' = <built-in method lower of str object at 0x0000026A33DBBA30>()\nE        +    where <built-in method lower of str object at 0x0000026A33DBBA30> = '1.5 KB'.lower\n\ntests\\Humanize\\functional_test.py:148: AssertionError\n______________________ test_precisedelta_timedelta_input ______________________\n\n    def test_precisedelta_timedelta_input() -> None:\n        td = timedelta(days=2, hours=1, minutes=1, seconds=1)\n        s = humanize.precisedelta(td)\n        assert isinstance(s, str)\n        assert s\n>       assert \"day\" in s\nE       AssertionError: assert 'day' in '1 seconds'\n\ntests\\Humanize\\functional_test.py:156: AssertionError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - TypeErr...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturalsize_binary_kib - Asser...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_timedelta_input\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n6 failed, 4 passed, 5 skipped in 0.58s\n", "stdout_sha1": "42afbde6b0b22be0b44a6e717bd4e327e01b2b32", "stdout_len": 3769, "stdout": "..FF.F.FFFsssss                                                          [100%]\n================================== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n>       d = humanize.precisedelta(3661)  # seconds\n\ntests\\Humanize\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndelta = 3661, minimum_unit = 'seconds', format = '%0.2f'\n\n    def precisedelta(delta, minimum_unit='seconds', format='%0.2f'):\n        \"\"\"Format a timedelta into a human-readable string with precision control.\"\"\"\n        if not isinstance(delta, timedelta):\n>           raise TypeError(\"precisedelta() argument must be a timedelta\")\nE           TypeError: precisedelta() argument must be a timedelta\n\ngeneration\\Humanize\\humanize\\time.py:7: TypeError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n_________________________ test_naturalsize_binary_kib _________________________\n\n    def test_naturalsize_binary_kib() -> None:\n        s = humanize.naturalsize(1536, binary=True)\n        assert isinstance(s, str)\n        assert s\n        # Compatible across versions: \"KiB\" (common) or any case variant.\n>       assert (\"KiB\" in s) or (\"kib\" in s.lower())\nE       AssertionError: assert ('KiB' in '1.5 KB' or 'kib' in '1.5 kb')\nE        +  where '1.5 kb' = <built-in method lower of str object at 0x0000026A33DBBA30>()\nE        +    where <built-in method lower of str object at 0x0000026A33DBBA30> = '1.5 KB'.lower\n\ntests\\Humanize\\functional_test.py:148: AssertionError\n______________________ test_precisedelta_timedelta_input ______________________\n\n    def test_precisedelta_timedelta_input() -> None:\n        td = timedelta(days=2, hours=1, minutes=1, seconds=1)\n        s = humanize.precisedelta(td)\n        assert isinstance(s, str)\n        assert s\n>       assert \"day\" in s\nE       AssertionError: assert 'day' in '1 seconds'\n\ntests\\Humanize\\functional_test.py:156: AssertionError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - TypeErr...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturalsize_binary_kib - Asser...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_timedelta_input\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n6 failed, 4 passed, 5 skipped in 0.58s\n"}
{"model": "deepseek-v3", "project": "Imageio", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "Use -v to get more diff", "returncode": 1, "elapsed_time_s": 2.59291, "avg_memory_mb": 45.86, "avg_cpu_percent": 100.0, "passed": 2, "failed": 8, "skipped": 0, "total": 10, "functional_score": 0.2, "timestamp": "2025-12-31 14:54:06", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_png_roundtrip_with_imread_and_imwrite __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_png_roundtrip_with_imread0')\n\n    def test_png_roundtrip_with_imread_and_imwrite(tmp_path: Path) -> None:\n        \"\"\"Exercise a simple PNG roundtrip and verify image shape and data.\"\"\"\n        img = _make_color_image()\n        path = tmp_path / \"test.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape == img.shape\nE       assert (48, 3, 3) == (32, 48, 3)\nE         \nE         At index 0 diff: 48 != 32\nE         Use -v to get more diff\n\ntests\\Imageio\\functional_test.py:90: AssertionError\n____________________ test_improps_and_immeta_basic_fields _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_improps_and_immeta_basic_0')\n\n    def test_improps_and_immeta_basic_fields(tmp_path: Path) -> None:\n        \"\"\"Check that improps and immeta expose basic metadata for a PNG image.\"\"\"\n        img = _make_color_image(height=40, width=50)\n        path = tmp_path / \"meta_test.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        props = iio.improps(path)\n>       assert tuple(props.shape) == img.shape\nE       assert (40, 50, 3, 3) == (40, 50, 3)\nE         \nE         Left contains one more item: 3\nE         Use -v to get more diff\n\ntests\\Imageio\\functional_test.py:122: AssertionError\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n_____________ test_png_imiter_yields_single_frame_equal_to_image ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_png_imiter_yields_single_0')\n\n    def test_png_imiter_yields_single_frame_equal_to_image(tmp_path: Path) -> None:\n        \"\"\"For a single-image PNG, imiter should yield exactly one frame.\"\"\"\n        img = _make_color_image(height=18, width=22)\n        path = tmp_path / \"single.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        frames = list(iio.imiter(path))\n>       assert len(frames) == 1\nE       assert 18 == 1\nE        +  where 18 = len([array([[[157, 157, 157],\\n        [193, 193, 193],\\n        [255, 255, 255]],\\n\\n       [[178, 178, 178],\\n        [141, 1...     [228, 228, 228]],\\n\\n       [[154, 154, 154],\\n        [109, 109, 109],\\n        [  6,   6,   6]]], dtype=uint8), ...])\n\ntests\\Imageio\\functional_test.py:159: AssertionError\n______________ test_png_imread_accepts_path_and_str_equivalently ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_png_imread_accepts_path_a0')\n\n    def test_png_imread_accepts_path_and_str_equivalently(tmp_path: Path) -> None:\n        \"\"\"Read the same PNG via Path and str(path) and verify identical content.\"\"\"\n        img = _make_color_image(height=25, width=27)\n        path = tmp_path / \"path_vs_str.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        a = iio.imread(path)\n        b = iio.imread(str(path))\n    \n        assert isinstance(a, np.ndarray)\n        assert isinstance(b, np.ndarray)\n>       assert a.shape == b.shape == img.shape\nE       assert (27, 3, 3) == (25, 27, 3)\nE         \nE         At index 0 diff: 27 != 25\nE         Use -v to get more diff\n\ntests\\Imageio\\functional_test.py:178: AssertionError\n___________ test_gif_imread_returns_stack_with_expected_", "stdout_sha1": "ff488ad262954ed4efacbc64343bfe5bb14d9211", "stdout_len": 6995, "stdout": "F.FFFFFFF.                                                               [100%]\n================================== FAILURES ===================================\n_________________ test_png_roundtrip_with_imread_and_imwrite __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_png_roundtrip_with_imread0')\n\n    def test_png_roundtrip_with_imread_and_imwrite(tmp_path: Path) -> None:\n        \"\"\"Exercise a simple PNG roundtrip and verify image shape and data.\"\"\"\n        img = _make_color_image()\n        path = tmp_path / \"test.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape == img.shape\nE       assert (48, 3, 3) == (32, 48, 3)\nE         \nE         At index 0 diff: 48 != 32\nE         Use -v to get more diff\n\ntests\\Imageio\\functional_test.py:90: AssertionError\n____________________ test_improps_and_immeta_basic_fields _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_improps_and_immeta_basic_0')\n\n    def test_improps_and_immeta_basic_fields(tmp_path: Path) -> None:\n        \"\"\"Check that improps and immeta expose basic metadata for a PNG image.\"\"\"\n        img = _make_color_image(height=40, width=50)\n        path = tmp_path / \"meta_test.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        props = iio.improps(path)\n>       assert tuple(props.shape) == img.shape\nE       assert (40, 50, 3, 3) == (40, 50, 3)\nE         \nE         Left contains one more item: 3\nE         Use -v to get more diff\n\ntests\\Imageio\\functional_test.py:122: AssertionError\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n_____________ test_png_imiter_yields_single_frame_equal_to_image ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_png_imiter_yields_single_0')\n\n    def test_png_imiter_yields_single_frame_equal_to_image(tmp_path: Path) -> None:\n        \"\"\"For a single-image PNG, imiter should yield exactly one frame.\"\"\"\n        img = _make_color_image(height=18, width=22)\n        path = tmp_path / \"single.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        frames = list(iio.imiter(path))\n>       assert len(frames) == 1\nE       assert 18 == 1\nE        +  where 18 = len([array([[[157, 157, 157],\\n        [193, 193, 193],\\n        [255, 255, 255]],\\n\\n       [[178, 178, 178],\\n        [141, 1...     [228, 228, 228]],\\n\\n       [[154, 154, 154],\\n        [109, 109, 109],\\n        [  6,   6,   6]]], dtype=uint8), ...])\n\ntests\\Imageio\\functional_test.py:159: AssertionError\n______________ test_png_imread_accepts_path_and_str_equivalently ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_png_imread_accepts_path_a0')\n\n    def test_png_imread_accepts_path_and_str_equivalently(tmp_path: Path) -> None:\n        \"\"\"Read the same PNG via Path and str(path) and verify identical content.\"\"\"\n        img = _make_color_image(height=25, width=27)\n        path = tmp_path / \"path_vs_str.png\"\n    \n        iio.imwrite(path, img)\n        assert path.exists()\n    \n        a = iio.imread(path)\n        b = iio.imread(str(path))\n    \n        assert isinstance(a, np.ndarray)\n        assert isinstance(b, np.ndarray)\n>       assert a.shape == b.shape == img.shape\nE       assert (27, 3, 3) == (25, 27, 3)\nE         \nE         At index 0 diff: 27 != 25\nE         Use -v to get more diff\n\ntests\\Imageio\\functional_test.py:178: AssertionError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape[0] == frames.shape[0]\nE       assert 20 == 5\n\ntests\\Imageio\\functional_test.py:194: AssertionError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-299/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_with_imread_and_imwrite\nFAILED tests/Imageio/functional_test.py::test_improps_and_immeta_basic_fields\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_png_imiter_yields_single_frame_equal_to_image\nFAILED tests/Imageio/functional_test.py::test_png_imread_accepts_path_and_str_equivalently\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n8 failed, 2 passed in 1.19s\n"}
{"model": "deepseek-v3", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "fit() got an unexpected keyword", "returncode": 1, "elapsed_time_s": 23.661012, "avg_memory_mb": 101.37, "avg_cpu_percent": 2.3, "passed": 0, "failed": 15, "skipped": 0, "total": 15, "functional_score": 0.0, "timestamp": "2025-12-31 14:55:57", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051458\\ntreatment  0.593058  0.944088.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002397F8978F0>()\nE        +    where <built-in method lower of str object at 0x000002397F8978F0> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x0000023948204670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x0000023948204670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051458\\ntreatment  0.593058  0.944088.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword ", "stdout_sha1": "3d3f6876a2f5c4c64b7f9da9f362b4f44297ed61", "stdout_len": 12716, "stdout": "FFFFFFFFFFFFFFF                                                          [100%]\n================================== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051458\\ntreatment  0.593058  0.944088.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002397F8978F0>()\nE        +    where <built-in method lower of str object at 0x000002397F8978F0> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x0000023948204670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x0000023948204670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051458\\ntreatment  0.593058  0.944088.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:169: TypeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:182: TypeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:191: TypeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:204: TypeError\n_________________ test_coxph_params_index_matches_covariates __________________\n\n    def test_coxph_params_index_matches_covariates() -> None:\n        \"\"\"Cox model params_ should be indexed by covariate names.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       params = cph.params_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'params_'\n\ntests\\Lifelines\\functional_test.py:215: AttributeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x_low = pd.DataFrame({\"age\": [25], \"treatment\": [0]})\n        x_high = pd.DataFrame({\"age\": [55], \"treatment\": [1]})\n    \n>       h_low = float(cph.predict_partial_hazard(x_low).iloc[0])\nE       AttributeError: 'CoxPHFitter' object has no attribute 'predict_partial_hazard'\n\ntests\\Lifelines\\functional_test.py:240: AttributeError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x = pd.DataFrame({\"age\": [30, 60], \"treatment\": [0, 1]})\n>       sf = cph.predict_survival_function(x)\n\ntests\\Lifelines\\functional_test.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Lifelines\\lifelines\\fitters\\coxph_fitter.py:80: in predict_survival_function\n    cumulative_hazard = self._baseline_hazard['baseline_hazard'].cumsum() * risk_score\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\common.py:76: in new_method\n    return method(self, other)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:202: in __mul__\n    return self._arith_method(other, operator.mul)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:6135: in _arith_method\n    return base.IndexOpsMixin._arith_method(self, other, op)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\base.py:1382: in _arith_method\n    result = ops.arithmetic_op(lvalues, rvalues, op)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283: in arithmetic_op\n    res_values = _na_arithmetic_op(left, right, op)  # type: ignore[arg-type]\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218: in _na_arithmetic_op\n    result = func(left, right)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:242: in evaluate\n    return _evaluate(op, op_str, a, b)  # type: ignore[misc]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nop = <built-in function mul>, op_str = '*'\na = array([ 0.46172058,  1.31518588,  2.28390238,  3.60886592,  6.3867767 ,\n       10.16608587])\nb = array([0.27755601, 0.13940004])\n\n    def _evaluate_standard(op, op_str, a, b):\n        \"\"\"\n        Standard evaluation.\n        \"\"\"\n        if _TEST_MODE:\n            _store_test_result(False)\n>       return op(a, b)\nE       ValueError: operands could not be broadcast together with shapes (6,) (2,)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: ValueError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n_____________ test_coxph_fit_on_waltons_with_binary_group_feature _____________\n\n    def test_coxph_fit_on_waltons_with_binary_group_feature() -> None:\n        \"\"\"Fit CoxPH on Waltons dataset using a binary treated indicator derived from group.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        df2 = df.copy()\n        df2[\"treated\"] = (df2[\"group\"] != \"control\").astype(int)\n    \n        model_df = df2[[\"T\", \"E\", \"treated\"]].rename(columns={\"T\": \"duration\", \"E\": \"event\"})\n    \n        cph = CoxPHFitter()\n        cph.fit(model_df, duration_col=\"duration\", event_col=\"event\")\n    \n>       coef = float(cph.params_.loc[\"treated\"])\nE       AttributeError: 'CoxPHFitter' object has no attribute 'params_'\n\ntests\\Lifelines\\functional_test.py:286: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_small_manual_dataset\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_waltons_groups - TypeE...\nFAILED tests/Lifelines/functional_test.py::test_coxph_basic_fit - AssertionEr...\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_at_time_zero_is_one\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_is_non_increasing_over_time\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_params_index_matches_covariates\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\nFAILED tests/Lifelines/functional_test.py::test_coxph_fit_on_waltons_with_binary_group_feature\n15 failed in 3.76s\n"}
{"model": "deepseek-v3", "project": "Loguru", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "remove() missing 1 required positional argument: 'sink_id'", "returncode": 1, "elapsed_time_s": 1.935375, "avg_memory_mb": 32.27, "avg_cpu_percent": 100.9, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 14:56:52", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "1f3878670f5fe247717620041bb81023f416a757", "stdout_len": 9962, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} user={extra[user]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n__________________ test_multiple_sinks_receive_same_message ___________________\n\n    def test_multiple_sinks_receive_same_message() -> None:\n        buf1 = io.StringIO()\n        buf2 = io.StringIO()\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:161: TypeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-300/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:178: TypeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n>       log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n\ntests\\Loguru\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n>       log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n\ntests\\Loguru\\functional_test.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} patched={extra[patched]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n\ntests\\Loguru\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format() -> None:\n        # Default format should include some timestamp-like content, level, and message.\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:237: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - Ty...\nFAILED tests/Loguru/functional_test.py::test_level_filtering - TypeError: rem...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Typ...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Type...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_multiple_sinks_receive_same_message\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Typ...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n11 failed in 0.57s\n"}
{"model": "deepseek-v3", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<p>``` literal &lt;b&gt; tag in code block ```</p>'", "returncode": 1, "elapsed_time_s": 4.721936, "avg_memory_mb": 32.64, "avg_cpu_percent": 42.2, "passed": 9, "failed": 1, "skipped": 9, "total": 19, "functional_score": 0.4737, "timestamp": "2025-12-31 15:04:53", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<p>``` literal &lt;b&gt; tag in code block ```</p>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\n1 failed, 9 passed, 9 skipped in 0.61s\n", "stdout_sha1": "b6bc99d692e25cc0bf56f6d9d31d2b946b411058", "stdout_len": 999, "stdout": "......F...sssssssss                                                      [100%]\n================================== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<p>``` literal &lt;b&gt; tag in code block ```</p>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\n1 failed, 9 passed, 9 skipped in 0.61s\n"}
{"model": "deepseek-v3", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 1.888234, "avg_memory_mb": 32.2, "avg_cpu_percent": 100.0, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 15:06:17", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.54s\n", "stdout_sha1": "f89ee2d6f349f40925e10dca5e471419e6ad4515", "stdout_len": 3013, "stdout": "........FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.54s\n"}
{"model": "deepseek-v3", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.483086, "avg_memory_mb": 31.5, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 15:07:46", "stdout_excerpt": "\n1 skipped in 0.14s\n", "stdout_sha1": "95c5fda1107f8078c182653b3ba949fc343f3984", "stdout_len": 20, "stdout": "\n1 skipped in 0.14s\n"}
{"model": "deepseek-v3", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "time data '2020-01-01T12:00:00+00:00' does not match format '%Y-%m-%dT%H:%M:%S.%f'", "returncode": 1, "elapsed_time_s": 41.189378, "avg_memory_mb": 33.4, "avg_cpu_percent": 0.45, "passed": 1, "failed": 11, "skipped": 1, "total": 13, "functional_score": 0.0769, "timestamp": "2025-12-31 15:14:03", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\ncls = <class 'pendulum.datetime.DateTime'>, text = '2020-01-01T12:00:00+00:00'\ntz = None\n\n    @classmethod\n    def parse(cls, text, tz=None):\n        try:\n>           dt_naive = dt.datetime.strptime(text, '%Y-%m-%dT%H:%M:%S.%f')\n\ngeneration\\Pendulum\\pendulum\\datetime.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata_string = '2020-01-01T12:00:00+00:00', format = '%Y-%m-%dT%H:%M:%S.%f'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n>           raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\nE           ValueError: time data '2020-01-01T12:00:00+00:00' does not match format '%Y-%m-%dT%H:%M:%S.%f'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:349: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncls = <class 'pendulum.datetime.DateTime'>, text = '2020-01-01T12:00:00+00:00'\ntz = None\n\n    @classmethod\n    def parse(cls, text, tz=None):\n        try:\n            dt_naive = dt.datetime.strptime(text, '%Y-%m-%dT%H:%M:%S.%f')\n        except ValueError:\n            try:\n>               dt_naive = dt.datetime.strptime(text, '%Y-%m-%dT%H:%M:%S')\n\ngeneration\\Pendulum\\pendulum\\datetime.py:34: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata_string = '2020-01-01T12:00:00+00:00', format = '%Y-%m-%dT%H:%M:%S'\n\n    def _strptime(data_str", "stdout_sha1": "650d1d4b4607fb959bd79bde4d5b6609f21554a6", "stdout_len": 20612, "stdout": "FFFFFFFF.sFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\ncls = <class 'pendulum.datetime.DateTime'>, text = '2020-01-01T12:00:00+00:00'\ntz = None\n\n    @classmethod\n    def parse(cls, text, tz=None):\n        try:\n>           dt_naive = dt.datetime.strptime(text, '%Y-%m-%dT%H:%M:%S.%f')\n\ngeneration\\Pendulum\\pendulum\\datetime.py:31: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata_string = '2020-01-01T12:00:00+00:00', format = '%Y-%m-%dT%H:%M:%S.%f'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n>           raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\nE           ValueError: time data '2020-01-01T12:00:00+00:00' does not match format '%Y-%m-%dT%H:%M:%S.%f'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:349: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncls = <class 'pendulum.datetime.DateTime'>, text = '2020-01-01T12:00:00+00:00'\ntz = None\n\n    @classmethod\n    def parse(cls, text, tz=None):\n        try:\n            dt_naive = dt.datetime.strptime(text, '%Y-%m-%dT%H:%M:%S.%f')\n        except ValueError:\n            try:\n>               dt_naive = dt.datetime.strptime(text, '%Y-%m-%dT%H:%M:%S')\n\ngeneration\\Pendulum\\pendulum\\datetime.py:34: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata_string = '2020-01-01T12:00:00+00:00', format = '%Y-%m-%dT%H:%M:%S'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n            raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\n        if len(data_string) != found.end():\n>           raise ValueError(\"unconverted data remains: %s\" %\n                              data_string[found.end():])\nE           ValueError: unconverted data remains: +00:00\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:352: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n>       dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n\ntests\\Pendulum\\functional_test.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:11: in parse\n    return DateTime.parse(text, tz=tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:36: in parse\n    dt_naive = dt.datetime.strptime(text, '%Y-%m-%d')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:568: in _strptime_datetime\n    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata_string = '2020-01-01T12:00:00+00:00', format = '%Y-%m-%d'\n\n    def _strptime(data_string, format=\"%a %b %d %H:%M:%S %Y\"):\n        \"\"\"Return a 2-tuple consisting of a time struct and an int containing\n        the number of microseconds based on the input string and the\n        format string.\"\"\"\n    \n        for index, arg in enumerate([data_string, format]):\n            if not isinstance(arg, str):\n                msg = \"strptime() argument {} must be str, not {}\"\n                raise TypeError(msg.format(index, type(arg)))\n    \n        global _TimeRE_cache, _regex_cache\n        with _cache_lock:\n            locale_time = _TimeRE_cache.locale_time\n            if (_getlang() != locale_time.lang or\n                time.tzname != locale_time.tzname or\n                time.daylight != locale_time.daylight):\n                _TimeRE_cache = TimeRE()\n                _regex_cache.clear()\n                locale_time = _TimeRE_cache.locale_time\n            if len(_regex_cache) > _CACHE_MAX_SIZE:\n                _regex_cache.clear()\n            format_regex = _regex_cache.get(format)\n            if not format_regex:\n                try:\n                    format_regex = _TimeRE_cache.compile(format)\n                # KeyError raised when a bad format is found; can be specified as\n                # \\\\, in which case it was a stray % but with a space after it\n                except KeyError as err:\n                    bad_directive = err.args[0]\n                    if bad_directive == \"\\\\\":\n                        bad_directive = \"%\"\n                    del err\n                    raise ValueError(\"'%s' is a bad directive in format '%s'\" %\n                                        (bad_directive, format)) from None\n                # IndexError only occurs when the format string is \"%\"\n                except IndexError:\n                    raise ValueError(\"stray %% in format '%s'\" % format) from None\n                _regex_cache[format] = format_regex\n        found = format_regex.match(data_string)\n        if not found:\n            raise ValueError(\"time data %r does not match format %r\" %\n                             (data_string, format))\n        if len(data_string) != found.end():\n>           raise ValueError(\"unconverted data remains: %s\" %\n                              data_string[found.end():])\nE           ValueError: unconverted data remains: T12:00:00+00:00\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py:352: ValueError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n>       base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:8: in datetime\n    return DateTime(year, month, day, hour, minute, second, microsecond, tz=tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <class 'pendulum.datetime.DateTime'>, year = 2021, month = 3, day = 15\nhour = 10, minute = 30, second = 0, microsecond = 0, tz = Timezone('UTC')\n\n    def __new__(cls, year, month, day, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is not None:\n            if isinstance(tz, str):\n                tz = Timezone(tz)\n            elif not isinstance(tz, (Timezone, FixedTimezone)):\n                raise ValueError('tz argument must be a timezone instance or string')\n    \n>       self = super().__new__(\n            cls, year, month, day, hour, minute, second, microsecond, tz\n        )\nE       TypeError: tzinfo argument must be None or of a tzinfo subclass, not type 'Timezone'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:53: TypeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n>       start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:8: in datetime\n    return DateTime(year, month, day, hour, minute, second, microsecond, tz=tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <class 'pendulum.datetime.DateTime'>, year = 2011, month = 8, day = 1\nhour = 0, minute = 0, second = 0, microsecond = 0, tz = Timezone('UTC')\n\n    def __new__(cls, year, month, day, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is not None:\n            if isinstance(tz, str):\n                tz = Timezone(tz)\n            elif not isinstance(tz, (Timezone, FixedTimezone)):\n                raise ValueError('tz argument must be a timezone instance or string')\n    \n>       self = super().__new__(\n            cls, year, month, day, hour, minute, second, microsecond, tz\n        )\nE       TypeError: tzinfo argument must be None or of a tzinfo subclass, not type 'Timezone'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:53: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n>       dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:8: in datetime\n    return DateTime(year, month, day, hour, minute, second, microsecond, tz=tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <class 'pendulum.datetime.DateTime'>, year = 2020, month = 1, day = 1\nhour = 12, minute = 0, second = 0, microsecond = 0, tz = Timezone('UTC')\n\n    def __new__(cls, year, month, day, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is not None:\n            if isinstance(tz, str):\n                tz = Timezone(tz)\n            elif not isinstance(tz, (Timezone, FixedTimezone)):\n                raise ValueError('tz argument must be a timezone instance or string')\n    \n>       self = super().__new__(\n            cls, year, month, day, hour, minute, second, microsecond, tz\n        )\nE       TypeError: tzinfo argument must be None or of a tzinfo subclass, not type 'Timezone'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:53: TypeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n>       dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:135: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:8: in datetime\n    return DateTime(year, month, day, hour, minute, second, microsecond, tz=tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <class 'pendulum.datetime.DateTime'>, year = 2021, month = 12, day = 31\nhour = 23, minute = 59, second = 58, microsecond = 0, tz = Timezone('UTC')\n\n    def __new__(cls, year, month, day, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is not None:\n            if isinstance(tz, str):\n                tz = Timezone(tz)\n            elif not isinstance(tz, (Timezone, FixedTimezone)):\n                raise ValueError('tz argument must be a timezone instance or string')\n    \n>       self = super().__new__(\n            cls, year, month, day, hour, minute, second, microsecond, tz\n        )\nE       TypeError: tzinfo argument must be None or of a tzinfo subclass, not type 'Timezone'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:53: TypeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n>       dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:8: in datetime\n    return DateTime(year, month, day, hour, minute, second, microsecond, tz=tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <class 'pendulum.datetime.DateTime'>, year = 2020, month = 5, day = 20\nhour = 13, minute = 14, second = 15, microsecond = 0, tz = Timezone('UTC')\n\n    def __new__(cls, year, month, day, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is not None:\n            if isinstance(tz, str):\n                tz = Timezone(tz)\n            elif not isinstance(tz, (Timezone, FixedTimezone)):\n                raise ValueError('tz argument must be a timezone instance or string')\n    \n>       self = super().__new__(\n            cls, year, month, day, hour, minute, second, microsecond, tz\n        )\nE       TypeError: tzinfo argument must be None or of a tzinfo subclass, not type 'Timezone'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:53: TypeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n>       dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:8: in datetime\n    return DateTime(year, month, day, hour, minute, second, microsecond, tz=tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <class 'pendulum.datetime.DateTime'>, year = 2020, month = 6, day = 1\nhour = 0, minute = 0, second = 0, microsecond = 0, tz = Timezone('UTC')\n\n    def __new__(cls, year, month, day, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is not None:\n            if isinstance(tz, str):\n                tz = Timezone(tz)\n            elif not isinstance(tz, (Timezone, FixedTimezone)):\n                raise ValueError('tz argument must be a timezone instance or string')\n    \n>       self = super().__new__(\n            cls, year, month, day, hour, minute, second, microsecond, tz\n        )\nE       TypeError: tzinfo argument must be None or of a tzinfo subclass, not type 'Timezone'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:53: TypeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_datetime_arithmetic_and_duration\nFAILED tests/Pendulum/functional_test.py::test_diff_for_humans_months - TypeE...\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - TypeErro...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n11 failed, 1 passed, 1 skipped in 20.68s\n"}
{"model": "deepseek-v3", "project": "Petl", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Use -v to get more diff", "returncode": 1, "elapsed_time_s": 2.041365, "avg_memory_mb": 32.5, "avg_cpu_percent": 101.6, "passed": 3, "failed": 3, "skipped": 6, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 15:15:44", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:12: in _select_rows\n    for row in it:\ngeneration\\Petl\\petl\\transform\\conversions.py:43: in _addfield_rows\n    new_value = func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = [1, 10]\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: list indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-302/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n3 failed, 3 passed, 6 skipped in 0.61s\n", "stdout_sha1": "545d62f4ca30b37f96b2975121f909be446e9082", "stdout_len": 3404, "stdout": ".F.ss.FsFsss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:12: in _select_rows\n    for row in it:\ngeneration\\Petl\\petl\\transform\\conversions.py:43: in _addfield_rows\n    new_value = func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = [1, 10]\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: list indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-302/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n3 failed, 3 passed, 6 skipped in 0.61s\n"}
{"model": "deepseek-v3", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.374489, "avg_memory_mb": 14.23, "avg_cpu_percent": 94.5, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 15:17:44", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 3, in <module>\n    from pygments.lex import lex\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py\", line 4, in <module>\n    from pygments.token import Token\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\token.py\", line 18, in <module>\n    Token = _TokenType()\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\token.py\", line 5, in __init__\n    super(_TokenType, self).__init__(args)\nTypeError: object.__init__() takes exactly one argument (the instance to initialize)\n", "stdout_sha1": "401101d5557a01ed7a493bfdf39cc0f0220d6a17", "stdout_len": 1971, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 3, in <module>\n    from pygments.lex import lex\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py\", line 4, in <module>\n    from pygments.token import Token\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\token.py\", line 18, in <module>\n    Token = _TokenType()\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\token.py\", line 5, in __init__\n    super(_TokenType, self).__init__(args)\nTypeError: object.__init__() takes exactly one argument (the instance to initialize)\n"}
{"model": "deepseek-v3", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.932499, "avg_memory_mb": 33.29, "avg_cpu_percent": 98.3, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 15:18:40", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x000001A6350FFF10>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(self, payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm not in self.algorithms:\n>           raise ValueError(f\"Algorithm {algorithm} is not supported\")\nE           ValueError: Algorithm HS512 is not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: ValueError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:30: in encode\n    payload_encoded = self._base64url_encode(json.dumps(payload, separators=(\",\", \":\")).encode())\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001A6351009A0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:30: in encode\n    payload_encoded = self._base6", "stdout_sha1": "b15e6b7f88fb3caee91ad876397d2257c4b01ac6", "stdout_len": 6671, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x000001A6350FFF10>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(self, payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm not in self.algorithms:\n>           raise ValueError(f\"Algorithm {algorithm} is not supported\")\nE           ValueError: Algorithm HS512 is not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: ValueError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:30: in encode\n    payload_encoded = self._base64url_encode(json.dumps(payload, separators=(\",\", \":\")).encode())\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001A6351009A0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:30: in encode\n    payload_encoded = self._base64url_encode(json.dumps(payload, separators=(\",\", \":\")).encode())\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001A63517BA60>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - V...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.57s\n"}
{"model": "deepseek-v3", "project": "PyPDF", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "IndexError", "exception_msg": "list index out of range", "returncode": 1, "elapsed_time_s": 1.966224, "avg_memory_mb": 32.32, "avg_cpu_percent": 97.5, "passed": 1, "failed": 10, "skipped": 1, "total": 12, "functional_score": 0.0833, "timestamp": "2025-12-31 15:19:54", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=3)\n    \n        reader = PdfReader(str(pdf_path))\n>       assert len(reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf._reader.PdfReader object at 0x000001E05093FEB0>.pages\n\ntests\\PyPDF\\functional_test.py:137: AssertionError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n        reader = PdfReader(str(pdf_path))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:146: IndexError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n        _create_simple_pdf(pdf1, num_pages=1)\n        _create_simple_pdf(pdf2, num_pages=2)\n    \n        _write_pdf_with_pages([pdf1, pdf2], merged)\n    \n        merged_reader = PdfReader(str(merged))\n>       assert len(merged_reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf._reader.PdfReader object at 0x000001E05094E910>.pages\n\ntests\\PyPDF\\functional_test.py:165: AssertionError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n        _create_simple_pdf(src, num_pages=4)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for page in reader.pages:\n            writer.add_page(page)\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n>       assert len(reader2.pages) == 4\nE       assert 0 == 4\nE        +  where 0 = len([])\nE        +    where [] = <pypdf._reader.PdfReader object at 0x000001E050950FA0>.pages\n\ntests\\PyPDF\\functional_test.py:183: AssertionError\n______________________________ test_rotate_page _______________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_rotate_page0')\n\n    def test_rotate_page(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        rotated = tmp_path / \"rotated.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:192: IndexError\n_______________________ test_rotate_preserves_page_size _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_rotate_preserves_page_siz0')\n\n    def test_rotate_preserves_page_size(tmp_path: Path) -> None:\n        \"\"\"Rotating a blank page should keep a valid mediabox size.\"\"\"\n        src = tmp_path / \"src_size.pdf\"\n        rotated = tmp_path / \"rot_size.pdf\"\n        _create_simpl", "stdout_sha1": "22d7fdae0e22ea6df1a3f19e22175c31e59e6df7", "stdout_len": 8686, "stdout": "FFFFFF.FFFsF                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=3)\n    \n        reader = PdfReader(str(pdf_path))\n>       assert len(reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf._reader.PdfReader object at 0x000001E05093FEB0>.pages\n\ntests\\PyPDF\\functional_test.py:137: AssertionError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n        reader = PdfReader(str(pdf_path))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:146: IndexError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n        _create_simple_pdf(pdf1, num_pages=1)\n        _create_simple_pdf(pdf2, num_pages=2)\n    \n        _write_pdf_with_pages([pdf1, pdf2], merged)\n    \n        merged_reader = PdfReader(str(merged))\n>       assert len(merged_reader.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf._reader.PdfReader object at 0x000001E05094E910>.pages\n\ntests\\PyPDF\\functional_test.py:165: AssertionError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n        _create_simple_pdf(src, num_pages=4)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for page in reader.pages:\n            writer.add_page(page)\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n>       assert len(reader2.pages) == 4\nE       assert 0 == 4\nE        +  where 0 = len([])\nE        +    where [] = <pypdf._reader.PdfReader object at 0x000001E050950FA0>.pages\n\ntests\\PyPDF\\functional_test.py:183: AssertionError\n______________________________ test_rotate_page _______________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_rotate_page0')\n\n    def test_rotate_page(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        rotated = tmp_path / \"rotated.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:192: IndexError\n_______________________ test_rotate_preserves_page_size _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_rotate_preserves_page_siz0')\n\n    def test_rotate_preserves_page_size(tmp_path: Path) -> None:\n        \"\"\"Rotating a blank page should keep a valid mediabox size.\"\"\"\n        src = tmp_path / \"src_size.pdf\"\n        rotated = tmp_path / \"rot_size.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n>       page = reader.pages[0]\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:213: IndexError\n_____________ test_encrypted_pdf_allows_page_access_after_decrypt _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_encrypted_pdf_allows_page0')\n\n    def test_encrypted_pdf_allows_page_access_after_decrypt(tmp_path: Path) -> None:\n        \"\"\"After decrypting, basic page access should succeed and page size is valid.\"\"\"\n        src = tmp_path / \"plain2.pdf\"\n        enc = tmp_path / \"encrypted2.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n>       writer.add_page(reader.pages[0])\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:260: IndexError\n___________________________ test_metadata_roundtrip ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_metadata_roundtrip0')\n\n    def test_metadata_roundtrip(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"meta.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for page in reader.pages:\n            writer.add_page(page)\n    \n        writer.add_metadata(\n            {\n                \"/Title\": \"PyPDF Benchmark Document\",\n                \"/Author\": \"RealAppCodeBench\",\n            }\n        )\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n        meta = reader2.metadata\n        assert meta is not None\n>       assert meta.get(\"/Title\") == \"PyPDF Benchmark Document\"\nE       AssertionError: assert 'Document Title' == 'PyPDF Benchmark Document'\nE         \nE         - PyPDF Benchmark Document\nE         + Document Title\n\ntests\\PyPDF\\functional_test.py:298: AssertionError\n___________________ test_metadata_multiple_fields_roundtrip ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_metadata_multiple_fields_0')\n\n    def test_metadata_multiple_fields_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Add several info dict fields and ensure they can be read back.\"\"\"\n        src = tmp_path / \"src_info.pdf\"\n        dst = tmp_path / \"info.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n>       writer.add_page(reader.pages[0])\nE       IndexError: list index out of range\n\ntests\\PyPDF\\functional_test.py:310: IndexError\n_________________ test_clone_document_by_writing_reader_pages _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-303/test_clone_document_by_writing0')\n\n    def test_clone_document_by_writing_reader_pages(tmp_path: Path) -> None:\n        \"\"\"Clone a document by copying pages and verify page count matches.\"\"\"\n        src = tmp_path / \"orig.pdf\"\n        dst = tmp_path / \"clone.pdf\"\n        _create_simple_pdf(src, num_pages=3)\n    \n        reader = PdfReader(str(src))\n        writer = PdfWriter()\n        for p in reader.pages:\n            writer.add_page(p)\n    \n        with dst.open(\"wb\") as fp:\n            writer.write(fp)\n    \n        reader2 = PdfReader(str(dst))\n>       assert len(reader2.pages) == 3\nE       assert 0 == 3\nE        +  where 0 = len([])\nE        +    where [] = <pypdf._reader.PdfReader object at 0x000001E05093F8B0>.pages\n\ntests\\PyPDF\\functional_test.py:372: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/PyPDF/functional_test.py::test_create_and_read_blank_pdf - asser...\nFAILED tests/PyPDF/functional_test.py::test_blank_page_has_expected_size - In...\nFAILED tests/PyPDF/functional_test.py::test_merge_two_pdfs - assert 0 == 3\nFAILED tests/PyPDF/functional_test.py::test_writer_add_page_preserves_page_count\nFAILED tests/PyPDF/functional_test.py::test_rotate_page - IndexError: list in...\nFAILED tests/PyPDF/functional_test.py::test_rotate_preserves_page_size - Inde...\nFAILED tests/PyPDF/functional_test.py::test_encrypted_pdf_allows_page_access_after_decrypt\nFAILED tests/PyPDF/functional_test.py::test_metadata_roundtrip - AssertionErr...\nFAILED tests/PyPDF/functional_test.py::test_metadata_multiple_fields_roundtrip\nFAILED tests/PyPDF/functional_test.py::test_clone_document_by_writing_reader_pages\n10 failed, 1 passed, 1 skipped in 0.74s\n"}
{"model": "deepseek-v3", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.648851, "avg_memory_mb": 31.59, "avg_cpu_percent": 99.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 15:23:31", "stdout_excerpt": "\n1 skipped in 0.17s\n", "stdout_sha1": "66bd18a62ec687100e9a9e996a20b12b6bd4dc1e", "stdout_len": 20, "stdout": "\n1 skipped in 0.17s\n"}
{"model": "deepseek-v3", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Job' object has no attribute 'day'", "returncode": 1, "elapsed_time_s": 1.953658, "avg_memory_mb": 32.41, "avg_cpu_percent": 95.8, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 15:24:54", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       AttributeError: 'Job' object has no attribute 'seconds'\n\ntests\\Schedule\\functional_test.py:97: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:148: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"ran\")\n    \n>       j = schedule.every(10).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'seconds'\n\ntests\\Schedule\\functional_test.py:184: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().day.at(\"10:30\").do(job)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:210: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().monday.at(\"09:00\").do", "stdout_sha1": "661a2c89aa0153d4ef7094586308c18ef031182b", "stdout_len": 7264, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       AttributeError: 'Job' object has no attribute 'seconds'\n\ntests\\Schedule\\functional_test.py:97: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:148: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"ran\")\n    \n>       j = schedule.every(10).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'seconds'\n\ntests\\Schedule\\functional_test.py:184: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().day.at(\"10:30\").do(job)\nE       AttributeError: 'Job' object has no attribute 'day'\n\ntests\\Schedule\\functional_test.py:210: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().monday.at(\"09:00\").do(job)\nE       AttributeError: 'Job' object has no attribute 'monday'\n\ntests\\Schedule\\functional_test.py:224: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       schedule.every().hour.do(job)\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:253: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n>       schedule.every().minute.do(a).tag(\"alpha\")\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:269: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:290: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_run_pending_executes_due_job_without_sleep\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_day_at_sets_time_component_in_next_run\nFAILED tests/Schedule/functional_test.py::test_weekday_scheduling_creates_job_and_next_run\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n12 failed in 0.64s\n"}
{"model": "deepseek-v3", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute 'sub'", "returncode": 1, "elapsed_time_s": 24.506327, "avg_memory_mb": 34.71, "avg_cpu_percent": 0.65, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 15:26:54", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n>       result_default_sep = slugify(text, regex_pattern=regex_pattern)\n\ntests\\Slugify\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = '___this is a test___', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = '[^-a-z0-9_]+'\nstopwords = None, lowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text: str,\n        allow_unicode: bool = False,\n        max_length: Optional[int] = None,\n        word_boundary: bool = False,\n        separator: str = '-',\n        regex_pattern: Optional[Pattern] = None,\n        stopwords: Optional[List[str]] = None,\n        lowercase: bool = True,\n        replacements: Optional[List[List[str]]] = None,\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Convert text to a URL-friendly slug.\n    \n        Args:\n            text: Input text to slugify\n            allow_unicode: Allow unicode characters in the slug\n            max_length: Maximum length of the slug\n            word_boundary: Truncate at word boundary when max_length is reached\n            separator: Separator character (default: '-')\n            regex_pattern: Custom regex pattern for character filtering\n            stopwords: List of words to remove from the slug\n            lowercase: Convert to lowercase (default: True)\n            replacements: List of [pattern, replacement] pairs for custom replacements\n            **kwargs: Additional arguments (ignored for compatibility)\n    \n        Returns:\n            Slugified string\n        \"\"\"\n        if text is None:\n            return \"\"\n    \n        # Apply custom replacements first\n        if replacements:\n            for pattern, replacement in replacements:\n                text = re.sub(pattern, replacement, text)\n    \n        # Normalize unicode\n        text = unicodedata.normalize('NFKC', str(text))\n    \n        # Handle unicode characters\n        if allow_unicode:\n            # Keep unicode characters, remove unwanted ones\n            text = re.sub(r'[^\\w\\s\\-_]', '', text, flags=re.UNICODE)\n        else:\n            # Transliterate unicode characters to ASCII\n            text = _transliterate_unicode(text)\n            # Remove non-ASCII characters\n            text = re.sub(r'[^\\w\\s\\-]', '', text)\n    \n        # Convert to lowercase if requested\n        if lowercase:\n            text = text.lower()\n    \n        # Remove stopwords\n        if stopwords is not None:\n            text = _remove_stopwords(text, stopwords)\n    \n        # Apply custom regex pattern if provided\n        if regex_pattern is not None:\n>           text = regex_pattern.sub('', text)\nE           AttributeError: 'str' object has no attribute 'sub'\n\ngeneration\\Slugify\\slugify\\slugify.py:115: AttributeError\n___________________ test_replacements_apply_before_slugging ___________________\n\n    def test_replacements_apply_before_slugging() -> None:\n        \"\"\"replacements should transform substrings before final slug is produced.\"\"\"\n        text = \"C# is not C++\"\n>       result = slugify(text, replacements=[[\"C#\", \"Csharp\"], [\"C++\", \"Cpp\"]])\n\ntests\\Slugify\\functional_test.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Slugify\\slugify\\slugify.py:90: in slugify\n    text = re.sub(pattern, replacement, text)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:210: in sub\n    return _compile(pattern, flags).sub(repl, string, count)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:304: in _compile\n    p = sre_compile.compile(pattern, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\", "stdout_sha1": "fec3d6ebbf24ecbc242acda56fe1aaba6d3cf1d7", "stdout_len": 12921, "stdout": ".......F..F.                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n>       result_default_sep = slugify(text, regex_pattern=regex_pattern)\n\ntests\\Slugify\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = '___this is a test___', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = '[^-a-z0-9_]+'\nstopwords = None, lowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text: str,\n        allow_unicode: bool = False,\n        max_length: Optional[int] = None,\n        word_boundary: bool = False,\n        separator: str = '-',\n        regex_pattern: Optional[Pattern] = None,\n        stopwords: Optional[List[str]] = None,\n        lowercase: bool = True,\n        replacements: Optional[List[List[str]]] = None,\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Convert text to a URL-friendly slug.\n    \n        Args:\n            text: Input text to slugify\n            allow_unicode: Allow unicode characters in the slug\n            max_length: Maximum length of the slug\n            word_boundary: Truncate at word boundary when max_length is reached\n            separator: Separator character (default: '-')\n            regex_pattern: Custom regex pattern for character filtering\n            stopwords: List of words to remove from the slug\n            lowercase: Convert to lowercase (default: True)\n            replacements: List of [pattern, replacement] pairs for custom replacements\n            **kwargs: Additional arguments (ignored for compatibility)\n    \n        Returns:\n            Slugified string\n        \"\"\"\n        if text is None:\n            return \"\"\n    \n        # Apply custom replacements first\n        if replacements:\n            for pattern, replacement in replacements:\n                text = re.sub(pattern, replacement, text)\n    \n        # Normalize unicode\n        text = unicodedata.normalize('NFKC', str(text))\n    \n        # Handle unicode characters\n        if allow_unicode:\n            # Keep unicode characters, remove unwanted ones\n            text = re.sub(r'[^\\w\\s\\-_]', '', text, flags=re.UNICODE)\n        else:\n            # Transliterate unicode characters to ASCII\n            text = _transliterate_unicode(text)\n            # Remove non-ASCII characters\n            text = re.sub(r'[^\\w\\s\\-]', '', text)\n    \n        # Convert to lowercase if requested\n        if lowercase:\n            text = text.lower()\n    \n        # Remove stopwords\n        if stopwords is not None:\n            text = _remove_stopwords(text, stopwords)\n    \n        # Apply custom regex pattern if provided\n        if regex_pattern is not None:\n>           text = regex_pattern.sub('', text)\nE           AttributeError: 'str' object has no attribute 'sub'\n\ngeneration\\Slugify\\slugify\\slugify.py:115: AttributeError\n___________________ test_replacements_apply_before_slugging ___________________\n\n    def test_replacements_apply_before_slugging() -> None:\n        \"\"\"replacements should transform substrings before final slug is produced.\"\"\"\n        text = \"C# is not C++\"\n>       result = slugify(text, replacements=[[\"C#\", \"Csharp\"], [\"C++\", \"Cpp\"]])\n\ntests\\Slugify\\functional_test.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Slugify\\slugify\\slugify.py:90: in slugify\n    text = re.sub(pattern, replacement, text)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:210: in sub\n    return _compile(pattern, flags).sub(repl, string, count)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:304: in _compile\n    p = sre_compile.compile(pattern, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_compile.py:764: in compile\n    p = sre_parse.parse(p, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:948: in parse\n    p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:443: in _parse_sub\n    itemsappend(_parse(source, state, verbose, nested + 1,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsource = <sre_parse.Tokenizer object at 0x0000028A0F249FD0>\nstate = <sre_parse.State object at 0x0000028A0F249880>, verbose = 0, nested = 1\nfirst = True\n\n    def _parse(source, state, verbose, nested, first=False):\n        # parse a simple pattern\n        subpattern = SubPattern(state)\n    \n        # precompute constants into local variables\n        subpatternappend = subpattern.append\n        sourceget = source.get\n        sourcematch = source.match\n        _len = len\n        _ord = ord\n    \n        while True:\n    \n            this = source.next\n            if this is None:\n                break # end of pattern\n            if this in \"|)\":\n                break # end of subpattern\n            sourceget()\n    \n            if verbose:\n                # skip whitespace and comments\n                if this in WHITESPACE:\n                    continue\n                if this == \"#\":\n                    while True:\n                        this = sourceget()\n                        if this is None or this == \"\\n\":\n                            break\n                    continue\n    \n            if this[0] == \"\\\\\":\n                code = _escape(source, this, state)\n                subpatternappend(code)\n    \n            elif this not in SPECIAL_CHARS:\n                subpatternappend((LITERAL, _ord(this)))\n    \n            elif this == \"[\":\n                here = source.tell() - 1\n                # character set\n                set = []\n                setappend = set.append\n    ##          if sourcematch(\":\"):\n    ##              pass # handle character classes\n                if source.next == '[':\n                    import warnings\n                    warnings.warn(\n                        'Possible nested set at position %d' % source.tell(),\n                        FutureWarning, stacklevel=nested + 6\n                    )\n                negate = sourcematch(\"^\")\n                # check remaining characters\n                while True:\n                    this = sourceget()\n                    if this is None:\n                        raise source.error(\"unterminated character set\",\n                                           source.tell() - here)\n                    if this == \"]\" and set:\n                        break\n                    elif this[0] == \"\\\\\":\n                        code1 = _class_escape(source, this)\n                    else:\n                        if set and this in '-&~|' and source.next == this:\n                            import warnings\n                            warnings.warn(\n                                'Possible set %s at position %d' % (\n                                    'difference' if this == '-' else\n                                    'intersection' if this == '&' else\n                                    'symmetric difference' if this == '~' else\n                                    'union',\n                                    source.tell() - 1),\n                                FutureWarning, stacklevel=nested + 6\n                            )\n                        code1 = LITERAL, _ord(this)\n                    if sourcematch(\"-\"):\n                        # potential range\n                        that = sourceget()\n                        if that is None:\n                            raise source.error(\"unterminated character set\",\n                                               source.tell() - here)\n                        if that == \"]\":\n                            if code1[0] is IN:\n                                code1 = code1[1][0]\n                            setappend(code1)\n                            setappend((LITERAL, _ord(\"-\")))\n                            break\n                        if that[0] == \"\\\\\":\n                            code2 = _class_escape(source, that)\n                        else:\n                            if that == '-':\n                                import warnings\n                                warnings.warn(\n                                    'Possible set difference at position %d' % (\n                                        source.tell() - 2),\n                                    FutureWarning, stacklevel=nested + 6\n                                )\n                            code2 = LITERAL, _ord(that)\n                        if code1[0] != LITERAL or code2[0] != LITERAL:\n                            msg = \"bad character range %s-%s\" % (this, that)\n                            raise source.error(msg, len(this) + 1 + len(that))\n                        lo = code1[1]\n                        hi = code2[1]\n                        if hi < lo:\n                            msg = \"bad character range %s-%s\" % (this, that)\n                            raise source.error(msg, len(this) + 1 + len(that))\n                        setappend((RANGE, (lo, hi)))\n                    else:\n                        if code1[0] is IN:\n                            code1 = code1[1][0]\n                        setappend(code1)\n    \n                set = _uniq(set)\n                # XXX: <fl> should move set optimization to compiler!\n                if _len(set) == 1 and set[0][0] is LITERAL:\n                    # optimization\n                    if negate:\n                        subpatternappend((NOT_LITERAL, set[0][1]))\n                    else:\n                        subpatternappend(set[0])\n                else:\n                    if negate:\n                        set.insert(0, (NEGATE, None))\n                    # charmap optimization can't be added here because\n                    # global flags still are not known\n                    subpatternappend((IN, set))\n    \n            elif this in REPEAT_CHARS:\n                # repeat previous item\n                here = source.tell()\n                if this == \"?\":\n                    min, max = 0, 1\n                elif this == \"*\":\n                    min, max = 0, MAXREPEAT\n    \n                elif this == \"+\":\n                    min, max = 1, MAXREPEAT\n                elif this == \"{\":\n                    if source.next == \"}\":\n                        subpatternappend((LITERAL, _ord(this)))\n                        continue\n    \n                    min, max = 0, MAXREPEAT\n                    lo = hi = \"\"\n                    while source.next in DIGITS:\n                        lo += sourceget()\n                    if sourcematch(\",\"):\n                        while source.next in DIGITS:\n                            hi += sourceget()\n                    else:\n                        hi = lo\n                    if not sourcematch(\"}\"):\n                        subpatternappend((LITERAL, _ord(this)))\n                        source.seek(here)\n                        continue\n    \n                    if lo:\n                        min = int(lo)\n                        if min >= MAXREPEAT:\n                            raise OverflowError(\"the repetition number is too large\")\n                    if hi:\n                        max = int(hi)\n                        if max >= MAXREPEAT:\n                            raise OverflowError(\"the repetition number is too large\")\n                        if max < min:\n                            raise source.error(\"min repeat greater than max repeat\",\n                                               source.tell() - here)\n                else:\n                    raise AssertionError(\"unsupported quantifier %r\" % (char,))\n                # figure out which item to repeat\n                if subpattern:\n                    item = subpattern[-1:]\n                else:\n                    item = None\n                if not item or item[0][0] is AT:\n                    raise source.error(\"nothing to repeat\",\n                                       source.tell() - here + len(this))\n                if item[0][0] in _REPEATCODES:\n>                   raise source.error(\"multiple repeat\",\n                                       source.tell() - here + len(this))\nE                   re.error: multiple repeat at position 2\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:671: error\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_replacements_apply_before_slugging\n2 failed, 10 passed in 0.61s\n"}
{"model": "deepseek-v3", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "TypeError", "exception_msg": "function() argument 'code' must be code, not str", "returncode": 2, "elapsed_time_s": 2.219437, "avg_memory_mb": 41.54, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 15:30:44", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:26: in <module>\n    class Field(PydanticField):\nE   TypeError: function() argument 'code' must be code, not str\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - TypeError: function() argument 'cod...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.86s\n", "stdout_sha1": "743216cf555001ece027fd7c6ffcd3b70de58fd3", "stdout_len": 679, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:26: in <module>\n    class Field(PydanticField):\nE   TypeError: function() argument 'code' must be code, not str\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - TypeError: function() argument 'cod...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.86s\n"}
{"model": "deepseek-v3", "project": "Tablib", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Use -v to get more diff", "returncode": 1, "elapsed_time_s": 1.860452, "avg_memory_mb": 32.91, "avg_cpu_percent": 98.2, "passed": 7, "failed": 4, "skipped": 0, "total": 11, "functional_score": 0.6364, "timestamp": "2025-12-31 15:38:26", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001AECEAAF610>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:120: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001AECEAB0A90>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:120: ValueError\n_________________ test_databook_add_sheet_and_iteration_order _________________\n\n    def test_databook_add_sheet_and_iteration_order() -> None:\n        \"\"\"Databook should allow adding sheets and preserve the order in iteration.\"\"\"\n        s1 = tablib.Dataset((1, \"x\"), headers=(\"id\", \"val\"))\n        s1.title = \"S1\"\n        s2 = tablib.Dataset((2, \"y\"), headers=(\"id\", \"val\"))\n        s2.title = \"S2\"\n    \n        book = tablib.Databook([s1])\n    \n        if hasattr(book, \"add_sheet\"):\n            book.add_sheet(s2)  # type: ignore[attr-defined]\n        else:\n            # Fallback: reconstruct via the public constructor (still normal usage).\n            book = tablib.Databook([s1, s2])\n    \n        assert book.size == 2\n    \n        sheets = _iter_databook_sheets(book)\n        assert len(sheets) == 2\n        assert sheets[0].title == \"S1\"\n        assert sheets[1].title == \"S2\"\n>       assert sheets[0][0] == (1, \"x\")\nE       AssertionError: assert ('1', 'x') == (1, 'x')\nE         \nE         At index 0 diff: '1' != 1\nE         Use -v to get more diff\n\ntests\\Tablib\\functional_test.py:365: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_", "stdout_sha1": "226bc3c539c578b20d89cd226cedde48fdc9a62f", "stdout_len": 4247, "stdout": ".F..F...F.F                                                              [100%]\n================================== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001AECEAAF610>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:120: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001AECEAB0A90>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:120: ValueError\n_________________ test_databook_add_sheet_and_iteration_order _________________\n\n    def test_databook_add_sheet_and_iteration_order() -> None:\n        \"\"\"Databook should allow adding sheets and preserve the order in iteration.\"\"\"\n        s1 = tablib.Dataset((1, \"x\"), headers=(\"id\", \"val\"))\n        s1.title = \"S1\"\n        s2 = tablib.Dataset((2, \"y\"), headers=(\"id\", \"val\"))\n        s2.title = \"S2\"\n    \n        book = tablib.Databook([s1])\n    \n        if hasattr(book, \"add_sheet\"):\n            book.add_sheet(s2)  # type: ignore[attr-defined]\n        else:\n            # Fallback: reconstruct via the public constructor (still normal usage).\n            book = tablib.Databook([s1, s2])\n    \n        assert book.size == 2\n    \n        sheets = _iter_databook_sheets(book)\n        assert len(sheets) == 2\n        assert sheets[0].title == \"S1\"\n        assert sheets[1].title == \"S2\"\n>       assert sheets[0][0] == (1, \"x\")\nE       AssertionError: assert ('1', 'x') == (1, 'x')\nE         \nE         At index 0 diff: '1' != 1\nE         Use -v to get more diff\n\ntests\\Tablib\\functional_test.py:365: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\nFAILED tests/Tablib/functional_test.py::test_databook_add_sheet_and_iteration_order\n4 failed, 7 passed in 0.52s\n"}
{"model": "deepseek-v3", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "tabulate() got an unexpected keyword argument 'missingval'", "returncode": 1, "elapsed_time_s": 2.034597, "avg_memory_mb": 33.04, "avg_cpu_percent": 99.2, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 15:40:07", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:175: in tabulate\n    row = [format_spec[\"sep_char\"] * width for width in widths]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000018C07DAE8E0>\n\n>   row = [format_spec[\"sep_char\"] * width for width in widths]\nE   KeyError: 'sep_char'\n\ngeneration\\Tabulate\\tabulate\\core.py:175: KeyError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n>       output = tabulate(table, headers=\"keys\")\n\ntests\\Tabulate\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:149: in tabulate\n    if any(re.search(r\"^-?\\d+\\.\\d+$\", cell) for cell in col):\ngeneration\\Tabulate\\tabulate\\core.py:149: in <genexpr>\n    if any(re.search(r\"^-?\\d+\\.\\d+$\", cell) for cell in col):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npattern = '^-?\\\\d+\\\\.\\\\d+$', string = 24, flags = 0\n\n    def search(pattern, string, flags=0):\n        \"\"\"Scan through string looking for a match to the pattern, returning\n        a Match object, or None if no match was found.\"\"\"\n>       return _compile(pattern, flags).search(string)\nE       TypeError: expected string or bytes-like object\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:201: TypeError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n        out_true = tabulate(table, showindex=True)\n        lines_true = _lines(out_true)\n        assert any(line.lstrip().startswith(\"0\") for line in lines_true)\n>       assert any(line.lstrip().startswith(\"1\") for line in lines_true)\nE       assert False\nE        +  where False = any(<generator object test_showindex_variants.<locals>.<genexpr> at 0x0000018C07E36F20>)\n\ntests\\Tabulate\\functional_test.py:154: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:175: in tabulate\n    row = [format_spec[\"sep_char\"] * width for width in widths]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000018C07EBC490>\n\n>   row = [format_spec[\"sep_char\"] * width for width in widths]\nE   KeyError: 'sep_char'\n\ngeneration\\Tabulate\\tabulate\\core.py:175: KeyError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\nE       TypeError: tabulate() got an unexpected keyword argument 'missingval'\n\ntests\\Tabulate\\functional_test.py:207: TypeError\n__________________ test_floatfmt_con", "stdout_sha1": "9123a2ee4085a2c670909a608f78974e23a14d8f", "stdout_len": 8581, "stdout": "..FFFF.FFFFF                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:175: in tabulate\n    row = [format_spec[\"sep_char\"] * width for width in widths]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000018C07DAE8E0>\n\n>   row = [format_spec[\"sep_char\"] * width for width in widths]\nE   KeyError: 'sep_char'\n\ngeneration\\Tabulate\\tabulate\\core.py:175: KeyError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n>       output = tabulate(table, headers=\"keys\")\n\ntests\\Tabulate\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:149: in tabulate\n    if any(re.search(r\"^-?\\d+\\.\\d+$\", cell) for cell in col):\ngeneration\\Tabulate\\tabulate\\core.py:149: in <genexpr>\n    if any(re.search(r\"^-?\\d+\\.\\d+$\", cell) for cell in col):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npattern = '^-?\\\\d+\\\\.\\\\d+$', string = 24, flags = 0\n\n    def search(pattern, string, flags=0):\n        \"\"\"Scan through string looking for a match to the pattern, returning\n        a Match object, or None if no match was found.\"\"\"\n>       return _compile(pattern, flags).search(string)\nE       TypeError: expected string or bytes-like object\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:201: TypeError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n        out_true = tabulate(table, showindex=True)\n        lines_true = _lines(out_true)\n        assert any(line.lstrip().startswith(\"0\") for line in lines_true)\n>       assert any(line.lstrip().startswith(\"1\") for line in lines_true)\nE       assert False\nE        +  where False = any(<generator object test_showindex_variants.<locals>.<genexpr> at 0x0000018C07E36F20>)\n\ntests\\Tabulate\\functional_test.py:154: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:175: in tabulate\n    row = [format_spec[\"sep_char\"] * width for width in widths]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000018C07EBC490>\n\n>   row = [format_spec[\"sep_char\"] * width for width in widths]\nE   KeyError: 'sep_char'\n\ngeneration\\Tabulate\\tabulate\\core.py:175: KeyError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\nE       TypeError: tabulate() got an unexpected keyword argument 'missingval'\n\ntests\\Tabulate\\functional_test.py:207: TypeError\n__________________ test_floatfmt_controls_numeric_rendering ___________________\n\n    def test_floatfmt_controls_numeric_rendering() -> None:\n        rows = [\n            [\"pi\", 3.14159],\n            [\"e\", 2.71828],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"value\"], tablefmt=\"plain\", floatfmt=\".2f\")\n\ntests\\Tabulate\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:177: in tabulate\n    formatted_row = _format_row(\ngeneration\\Tabulate\\tabulate\\core.py:87: in _format_row\n    aligned_lines = _align_column(cell_lines, align, width)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncolumn = ['value'], align = 'decimal', minwidth = 7\n\n    def _align_column(\n        column: List[str], align: Optional[str], minwidth: int = 0\n    ) -> List[str]:\n        \"\"\"Align all cells in a column according to the specified alignment.\"\"\"\n        if not column:\n            return column\n    \n        if align is None:\n            return column\n    \n        max_len = max(len(cell) for cell in column)\n        max_len = max(max_len, minwidth)\n    \n        aligned = []\n        for cell in column:\n            if align == \"left\":\n                aligned.append(cell.ljust(max_len))\n            elif align == \"right\":\n                aligned.append(cell.rjust(max_len))\n            elif align == \"center\":\n                aligned.append(cell.center(max_len))\n            elif align == \"decimal\":\n                parts = re.split(r\"(\\d+\\.\\d+)\", cell)\n>               aligned.append(parts[0].ljust(max_len - len(parts[1])) + parts[1])\nE               IndexError: list index out of range\n\ngeneration\\Tabulate\\tabulate\\core.py:47: IndexError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n___________________ test_pipe_format_has_pipes_and_headers ____________________\n\n    def test_pipe_format_has_pipes_and_headers() -> None:\n        rows = [\n            [\"name\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"pipe\")\n\ntests\\Tabulate\\functional_test.py:274: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:175: in tabulate\n    row = [format_spec[\"sep_char\"] * width for width in widths]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000018C07DC2520>\n\n>   row = [format_spec[\"sep_char\"] * width for width in widths]\nE   KeyError: 'sep_char'\n\ngeneration\\Tabulate\\tabulate\\core.py:175: KeyError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - assert False\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - KeyE...\nFAILED tests/Tabulate/functional_test.py::test_missingval_renders_placeholder\nFAILED tests/Tabulate/functional_test.py::test_floatfmt_controls_numeric_rendering\nFAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\nFAILED tests/Tabulate/functional_test.py::test_pipe_format_has_pipes_and_headers\n9 failed, 3 passed in 0.66s\n"}
{"model": "deepseek-v3", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for +: 'int' and 'str'", "returncode": 1, "elapsed_time_s": 26.965474, "avg_memory_mb": 33.16, "avg_cpu_percent": 0.51, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 15:41:39", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209EEE80>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD209EEFD0>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n[3]: \n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD20A4FA90>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001AD20A4F9A0>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n[1, 2]: \n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209E4400>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD209E4340>\n\n    def _draw_horizontal(self)", "stdout_sha1": "62c682ebd73b0b4295822fd41184c1fe68072361", "stdout_len": 18127, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209EEE80>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD209EEFD0>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n[3]: \n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD20A4FA90>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001AD20A4F9A0>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n[1, 2]: \n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209E4400>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD209E4340>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nBars\n[4]: \n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209E8D60>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD209E8B20>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Values\n[2]: \n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209E2B20>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Labels\", width=10, no_labels=True, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD209E28E0>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Labels\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD20A60C10>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Suffix\", width=18, suffix=\"%\", format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD20A60F10>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nSuffix\n[12.5]: \n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD20A778E0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Fmt\", width=20, format=\"{:>6.2f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD20A77B80>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nFmt\n[3.14159]: \n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD20A54940>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack Labels\", width=25, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001AD20A54BB0>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack Labels\n[1, 1]: \n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209E4C70>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack No Values\", width=30, no_values=True, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x000001AD209E4880>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack No Values\n[1, 2, 3]: \n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD209D0370>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=None, width=15, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD209C0700>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\n[4]: \n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001AD20A72BB0>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:14: in draw\n    self._draw_horizontal()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001AD20A72B20>\n\n    def _draw_horizontal(self):\n        if self.args.title:\n            print(self.args.title)\n    \n        max_value = max(max(series) for series in self.data.data) if self.data.data else 0\n        if max_value == 0:\n            max_value = 1\n    \n        for i, label in enumerate(self.data.labels):\n            if not self.args.no_labels:\n                print(f\"{label}: \", end=\"\")\n    \n            values = [series[i] for series in self.data.data]\n>           total = sum(values)\nE           TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:29: TypeError\n---------------------------- Captured stdout call -----------------------------\nNarrow\n[9]: \n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 25.60s\n"}
{"model": "deepseek-v3", "project": "Typer", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "attempted relative import beyond top-level package", "returncode": 2, "elapsed_time_s": 1.958747, "avg_memory_mb": 36.36, "avg_cpu_percent": 96.7, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 15:51:13", "stdout_excerpt": "====\n_______________ ERROR collecting tests/Typer/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Typer\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Typer\\functional_test.py:53: in <module>\n    import typer  # type: ignore  # noqa: E402\ngeneration\\Typer\\typer\\__init__.py:8: in <module>\n    from . import testing\ngeneration\\Typer\\typer\\testing.py:5: in <module>\n    from ..core import Typer\nE   ImportError: attempted relative import beyond top-level package\n=========================== short test summary info ===========================\nERROR tests/Typer/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.63s\n", "stdout_sha1": "f8d0380aa62acc7a6487b4fa7abfca70e997252c", "stdout_len": 1046, "stdout": "\n=================================== ERRORS ====================================\n_______________ ERROR collecting tests/Typer/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Typer\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Typer\\functional_test.py:53: in <module>\n    import typer  # type: ignore  # noqa: E402\ngeneration\\Typer\\typer\\__init__.py:8: in <module>\n    from . import testing\ngeneration\\Typer\\typer\\testing.py:5: in <module>\n    from ..core import Typer\nE   ImportError: attempted relative import beyond top-level package\n=========================== short test summary info ===========================\nERROR tests/Typer/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.63s\n"}
{"model": "deepseek-v3", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.949484, "avg_memory_mb": 35.81, "avg_cpu_percent": 97.4, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 15:52:24", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n", "stdout_sha1": "d4bb50f171ace793db32b44ef1161ab7b4cfaad5", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n"}
{"model": "deepseek-v3", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "read() did not return a bytes object (type=str)", "returncode": 124, "elapsed_time_s": 60.053072, "avg_memory_mb": 32.61, "avg_cpu_percent": 0.2, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 15:54:42", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271FFFC8E50>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x00000271817BFF10>\nparser = <pyexpat.xmlparser object at 0x00000271FFFAF340>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271817AFE50>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x00000271FFFD89D0>\nparser = <pyexpat.xmlparser object at 0x000002718180B1C0>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the gi", "stdout_sha1": "eb127b9550b524ec5f93b9feacf0cf2237d67720", "stdout_len": 22448, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271FFFC8E50>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x00000271817BFF10>\nparser = <pyexpat.xmlparser object at 0x00000271FFFAF340>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271817AFE50>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x00000271FFFD89D0>\nparser = <pyexpat.xmlparser object at 0x000002718180B1C0>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n_______________________ test_parse_attributes_and_text ________________________\n\n    def test_parse_attributes_and_text() -> None:\n        \"\"\"Attributes and text content should be exposed using @attr and #text keys.\"\"\"\n        xml = '<user id=\"123\">Alice</user>'\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271FFFF2040>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x00000271817BEBE0>\nparser = <pyexpat.xmlparser object at 0x000002718180B040>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n___________________ test_unparse_roundtrip_basic_structure ____________________\n\n    def test_unparse_roundtrip_basic_structure() -> None:\n        \"\"\"unparse() followed by parse() should preserve the logical structure.\"\"\"\n        original = {\n            \"root\": {\n                \"item\": [\n                    {\"@id\": \"1\", \"#text\": \"A\"},\n                    {\"@id\": \"2\", \"#text\": \"B\"},\n                ]\n            }\n        }\n    \n        xml = _unparse(original)\n>       round_tripped = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x0000027181801D30>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x00000271FFFF0730>\nparser = <pyexpat.xmlparser object at 0x0000027181807B80>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x0000027181801EE0>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x000002718180D4F0>\nparser = <pyexpat.xmlparser object at 0x00000271FFFF55E0>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:150: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271FFFF2280>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x000002718183A7F0>\nparser = <pyexpat.xmlparser object at 0x00000271FFFF57C0>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n>       data = _parse(xml, force_list=(\"item\",))\n\ntests\\Xmltodict\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271FFFF23A0>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x0000027181828370>\nparser = <pyexpat.xmlparser object at 0x00000271FFFAF820>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n>       parser.ParseFile(xml_input)\nE       TypeError: read() did not return a bytes object (type=str)\n\ngeneration\\Xmltodict\\xmltodict.py:54: TypeError\n_____________ test_custom_attr_prefix_and_cdata_key_if_supported ______________\n\n    def test_custom_attr_prefix_and_cdata_key_if_supported() -> None:\n        \"\"\"attr_prefix / cdata_key customization should reflect in output when supported.\"\"\"\n        xml = '<user id=\"7\">Bob</user>'\n    \n>       data = _parse(xml, attr_prefix=\"$\", cdata_key=\"text\")\n\ntests\\Xmltodict\\functional_test.py:176: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nxml_input = <_io.StringIO object at 0x00000271FFFF2040>, encoding = None\nexpat = <module 'xml.parsers.expat' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\xml\\\\parsers\\\\expat.py'>\nprocess_namespaces = False, namespace_separator = ':', disable_entities = True\nkwargs = {}, handler = <xmltodict._DictSAXHandler object at 0x0000027181823EE0>\nparser = <pyexpat.xmlparser object at 0x0000027181807FA0>\n\n    def parse(xml_input, encoding=None, expat=expat, process_namespaces=False,\n              namespace_separator=':', disable_entities=True, **kwargs):\n        \"\"\"\n        Parse the given XML input and convert it into a dictionary.\n    \n        :param xml_input: XML string or file-like object\n        :param encoding: XML encoding (default: autodetect)\n        :param expat: expat parser to use\n        :param process_namespaces: whether to process namespaces\n        :param namespace_separator: namespace separator character\n        :param disable_entities: whether to disable entity expansion\n        :return: dictionary representation of XML\n        \"\"\"\n        if isinstance(xml_input, basestring):\n            xml_input = StringIO(xml_input)\n    \n        handler = _DictSAXHandler(\n            process_namespaces=process_namespaces,\n            namespace_separator=namespace_separator,\n            **kwargs\n        )\n    \n        parser = expat.ParserCreate(encoding, namespace_separator if process_namespaces else '')\n    \n        if disable_entities:\n            try:\n                # Disable entity expansion to prevent XML bomb attacks\n                parser.SetParamEntityParsing(expat.XML_PARAM_ENTITY_PARSING_NEVER)\n            except AttributeError:\n                # Python 2.6 and earlier don't have this method\n                pass\n    \n        parser.StartElementHandler = handler.start_element\n        parser.EndElementHandler = handler.end_element\n        parser.CharacterDataHandler = handler.characters\n    \n"}
{"model": "deepseek-v3.2", "project": "Astral", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'astral.sun'", "returncode": 2, "elapsed_time_s": 1.992516, "avg_memory_mb": 34.66, "avg_cpu_percent": 98.4, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 19:12:44", "stdout_excerpt": "====\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Astral\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\ngeneration\\Astral\\astral\\__init__.py:6: in <module>\n    from astral.sun import (\nE   ModuleNotFoundError: No module named 'astral.sun'\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.57s\n", "stdout_sha1": "6873e60ab8c78b41d4803faf262fba6f13ede1e3", "stdout_len": 973, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Astral\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\ngeneration\\Astral\\astral\\__init__.py:6: in <module>\n    from astral.sun import (\nE   ModuleNotFoundError: No module named 'astral.sun'\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.57s\n"}
{"model": "deepseek-v3.2", "project": "Click", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'click.core'", "returncode": 2, "elapsed_time_s": 6.176581, "avg_memory_mb": 35.43, "avg_cpu_percent": 97.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 19:18:32", "stdout_excerpt": "====\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:5: in <module>\n    from .core import (\nE   ModuleNotFoundError: No module named 'click.core'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.75s\n", "stdout_sha1": "b11479523e36de239552a29134ce786e5c6e050b", "stdout_len": 953, "stdout": "\n=================================== ERRORS ====================================\n_______________ ERROR collecting tests/Click/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Click\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:5: in <module>\n    from .core import (\nE   ModuleNotFoundError: No module named 'click.core'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.75s\n"}
{"model": "deepseek-v3.2", "project": "Dataset", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "", "exception_msg": "sqlite3.OperationalError: unable to open database file", "returncode": 1, "elapsed_time_s": 30.343323, "avg_memory_mb": 34.39, "avg_cpu_percent": 0.5, "passed": 1, "failed": 10, "skipped": 0, "total": 11, "functional_score": 0.0909, "timestamp": "2025-12-31 19:23:12", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E756F8E0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E7612AC0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-324/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n>       table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n\ntests\\Dataset\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:103: in insert\n    return self.find_one(id=row_id)\ngeneration\\Dataset\\dataset\\table.py:286: in find_one\n    for row in self.find(**filters):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x00000226E75F1B80>, filters = {'id': 1}\nwhere_parts = ['\"id\" = ?'], params = [1], ", "stdout_sha1": "71e6a508cb26a668e018ad22eeaf18f2d845bbef", "stdout_len": 16458, "stdout": "FFFFFFFFF.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E756F8E0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E7612AC0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-324/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n>       table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n\ntests\\Dataset\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:103: in insert\n    return self.find_one(id=row_id)\ngeneration\\Dataset\\dataset\\table.py:286: in find_one\n    for row in self.find(**filters):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x00000226E75F1B80>, filters = {'id': 1}\nwhere_parts = ['\"id\" = ?'], params = [1], key = 'id', value = 1\nsql = 'SELECT * FROM \"events\" WHERE \"id\" = ?'\n\n    def find(self, **filters: Any) -> Iterator[Dict[str, Any]]:\n        \"\"\"\n        Find rows matching the filters.\n    \n        Args:\n            **filters: Filter conditions\n    \n        Yields:\n            Matching rows as dictionaries\n        \"\"\"\n        if not filters:\n            yield from self.all()\n            return\n    \n        where_parts = []\n        params = []\n    \n        for key, value in filters.items():\n            if value is None:\n                where_parts.append(f\"{self._quote(key)} IS NULL\")\n            else:\n                where_parts.append(f\"{self._quote(key)} = ?\")\n                params.append(value)\n    \n        sql = f\"SELECT * FROM {self._quote(self.name)} WHERE {' AND '.join(where_parts)}\"\n>       yield from self.db.query(sql, *params)\nE       TypeError: query() takes 2 positional arguments but 3 were given\n\ngeneration\\Dataset\\dataset\\table.py:274: TypeError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E760E970>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E7646BB0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:243: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E7627CD0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E75F1370>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_______________________ test_delete_and_clear_all_rows ________________________\n\n    def test_delete_and_clear_all_rows() -> None:\n        \"\"\"\n        Older dataset.Table may not expose truncate().\n        Clear a table and end at 0 rows without relying on result iteration for DML.\n        \"\"\"\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E7563F70>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E760BB20>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\__init__.py:22: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000226E753D460>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url: str):\n        \"\"\"\n        Initialize database connection.\n    \n        Args:\n            url: Database URL (only sqlite:// is supported)\n        \"\"\"\n        parsed = urlparse(url)\n        if parsed.scheme != \"sqlite\":\n            raise ValueError(f\"Unsupported database scheme: {parsed.scheme}\")\n    \n        # Extract database path (remove leading //)\n        db_path = parsed.netloc + parsed.path\n        if db_path.startswith(\"//\"):\n            db_path = db_path[2:]\n        if db_path == \":memory:\":\n            db_path = \":memory:\"\n    \n        self.url = url\n        self.db_path = db_path\n>       self._conn = sqlite3.connect(db_path, check_same_thread=False)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - sql...\nFAILED tests/Dataset/functional_test.py::test_transactions_commit_and_rollback\nFAILED tests/Dataset/functional_test.py::test_insert_many_returns_ids_and_count\nFAILED tests/Dataset/functional_test.py::test_find_one_missing_returns_none\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_table_all_iteration_and_row_shape\nFAILED tests/Dataset/functional_test.py::test_delete_and_clear_all_rows - sql...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n10 failed, 1 passed in 29.03s\n"}
{"model": "deepseek-v3.2", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 19:27:29", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "deepseek-v3.2", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('line' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\" or 'lines' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\")", "returncode": 1, "elapsed_time_s": 2.640886, "avg_memory_mb": 32.29, "avg_cpu_percent": 72.2, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 19:31:57", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_006_bin_scripts_exist __________________________\n\n    def test_006_bin_scripts_exist():\n        base = _resolve_repo_root()\n        b = base / \"bin\"\n        assert b.is_dir(), \"Expected bin/ directory\"\n        assert (b / \"fail2ban-client\").is_file(), \"Expected bin/fail2ban-client\"\n>       assert (b / \"fail2ban-server\").is_file(), \"Expected bin/fail2ban-server\"\nE       AssertionError: Expected bin/fail2ban-server\nE       assert False\nE        +  where False = is_file()\nE        +    where is_file = (WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Fail2ban/bin') / 'fail2ban-server').is_file\n\ntests\\Fail2ban\\functional_test.py:143: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           assert ('line' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\" or 'lines' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\")\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_006_bin_scripts_exist - Assert...\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n2 failed, 10 passed in 1.28s\n", "stdout_sha1": "ed47a53658d9b884d6435b0c63e68b154f20f4a5", "stdout_len": 3534, "stdout": ".....F.....F                                                             [100%]\n================================== FAILURES ===================================\n_________________________ test_006_bin_scripts_exist __________________________\n\n    def test_006_bin_scripts_exist():\n        base = _resolve_repo_root()\n        b = base / \"bin\"\n        assert b.is_dir(), \"Expected bin/ directory\"\n        assert (b / \"fail2ban-client\").is_file(), \"Expected bin/fail2ban-client\"\n>       assert (b / \"fail2ban-server\").is_file(), \"Expected bin/fail2ban-server\"\nE       AssertionError: Expected bin/fail2ban-server\nE       assert False\nE        +  where False = is_file()\nE        +    where is_file = (WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Fail2ban/bin') / 'fail2ban-server').is_file\n\ntests\\Fail2ban\\functional_test.py:143: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           assert ('line' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\" or 'lines' in \"\\nc:\\\\users\\\\86152\\\\appdata\\\\local\\\\programs\\\\python\\\\python39\\\\python.exe: can't open file 'd:\\\\妗岄潰\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2ban-regex': [errno 2] no such file or directory\\n\")\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_006_bin_scripts_exist - Assert...\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n2 failed, 10 passed in 1.28s\n"}
{"model": "deepseek-v3.2", "project": "Folium", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "assert ('featurecollection' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n", "returncode": 1, "elapsed_time_s": 2.149846, "avg_memory_mb": 32.06, "avg_cpu_percent": 100.0, "passed": 4, "failed": 8, "skipped": 0, "total": 12, "functional_score": 0.3333, "timestamp": "2025-12-31 19:34:08", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n        folium.Marker([0, 0], tooltip=\"t\").add_to(m)\n        html = m.get_root().render()\n>       assert len(html) > len(base)\nE       assert 1201 > 1201\nE        +  where 1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\nE        +  and   1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:71: AssertionError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n        folium.CircleMarker([0, 0], radius=5).add_to(m)\n        html = m.get_root().render()\n>       assert len(html) > len(base)\nE       assert 1201 > 1201\nE        +  where 1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\nE        +  and   1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:84: AssertionError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n        folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\n        folium.LayerControl().add_to(m)\n    \n        html = m.get_root().render().lower()\n>       assert \"layercontrol\" in html or \"layers\" in html\nE       assert ('layercontrol' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ' or 'layers' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:96: AssertionError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        folium.GeoJson(gj, name=\"g\").add_to(m)\n    \n        html = m.get_root().render().lower()\n>       assert \"featurecollection\" in html or \"geojson\" in html\nE       assert ('featurecollection' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n   ", "stdout_sha1": "7e4f4f97ba5c28c4dd16672885bc81b8130f42fa", "stdout_len": 9984, "stdout": "....FFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n        folium.Marker([0, 0], tooltip=\"t\").add_to(m)\n        html = m.get_root().render()\n>       assert len(html) > len(base)\nE       assert 1201 > 1201\nE        +  where 1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\nE        +  and   1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:71: AssertionError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n        folium.CircleMarker([0, 0], radius=5).add_to(m)\n        html = m.get_root().render()\n>       assert len(html) > len(base)\nE       assert 1201 > 1201\nE        +  where 1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\nE        +  and   1201 = len('\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = L.map(\"map\").setView([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:84: AssertionError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n        folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\n        folium.LayerControl().add_to(m)\n    \n        html = m.get_root().render().lower()\n>       assert \"layercontrol\" in html or \"layers\" in html\nE       assert ('layercontrol' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ' or 'layers' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:96: AssertionError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        folium.GeoJson(gj, name=\"g\").add_to(m)\n    \n        html = m.get_root().render().lower()\n>       assert \"featurecollection\" in html or \"geojson\" in html\nE       assert ('featurecollection' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ' or 'geojson' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:118: AssertionError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        folium.GeoJson(gj, style_function=style_fn).add_to(m)\n    \n        html = m.get_root().render().lower()\n>       assert \"color\" in html or \"weight\" in html\nE       assert ('color' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ' or 'weight' in '\\n        <!doctype html>\\n        <html>\\n        <head>\\n            <meta http-equiv=\"content-type\" content=\"text/...></div>\\n<script>\\nvar map = l.map(\"map\").setview([0, 0], 2);\\n</script>\\n\\n        </body>\\n        </html>\\n        ')\n\ntests\\Folium\\functional_test.py:144: AssertionError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-325/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n______________ test_010_plugins_markercluster_module_importable _______________\n\n    def test_010_plugins_markercluster_module_importable():\n        _prepend_import_path()\n>       plugins = _plugins_module()\n\ntests\\Folium\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Folium\\functional_test.py:29: in _plugins_module\n    return importlib.import_module(\"folium.plugins\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Plugins for folium.\n    \"\"\"\n    \n>   from folium.plugins.marker_cluster import MarkerCluster\nE   ModuleNotFoundError: No module named 'folium.plugins.marker_cluster'\n\ngeneration\\Folium\\folium\\plugins\\__init__.py:5: ModuleNotFoundError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n>       plugins = _plugins_module()\n\ntests\\Folium\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Folium\\functional_test.py:29: in _plugins_module\n    return importlib.import_module(\"folium.plugins\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Plugins for folium.\n    \"\"\"\n    \n>   from folium.plugins.marker_cluster import MarkerCluster\nE   ModuleNotFoundError: No module named 'folium.plugins.marker_cluster'\n\ngeneration\\Folium\\folium\\plugins\\__init__.py:5: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\nFAILED tests/Folium/functional_test.py::test_010_plugins_markercluster_module_importable\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n8 failed, 4 passed in 0.65s\n"}
{"model": "deepseek-v3.2", "project": "Humanize", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.584546, "avg_memory_mb": 30.87, "avg_cpu_percent": 96.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 19:37:59", "stdout_excerpt": "\n1 skipped in 0.16s\n", "stdout_sha1": "a1849a7e09f94d0f14b1c3622e0bedba158ebbdf", "stdout_len": 20, "stdout": "\n1 skipped in 0.16s\n"}
{"model": "deepseek-v3.2", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "", "exception_msg": "", "returncode": 124, "elapsed_time_s": 60.05296, "avg_memory_mb": 44.97, "avg_cpu_percent": 0.22, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 19:41:14", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_png_roundtrip_with_imread_and_imwrite __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_png_roundtrip_with_imread0')\n\n    def test_png_roundtrip_with_imread_and_imwrite(tmp_path: Path) -> None:\n        \"\"\"Exercise a simple PNG roundtrip and verify image shape and data.\"\"\"\n        img = _make_color_image()\n        path = tmp_path / \"test.png\"\n    \n>       iio.imwrite(path, img)\n\ntests\\Imageio\\functional_test.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Imageio\\imageio\\v3.py:139: in imwrite\n    with imopen(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_png_roundtrip_with_imread0/test.png')\nio_mode = 'w', plugin = None, extension = None, format_hint = None\nlegacy_mode = False, kwargs = {}\nrequest = <imageio.core.request.Request object at 0x000001E57FECE430>\nsource = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_png_roundtrip_with_imread0/test.png')\n\n    def imopen(\n        uri,\n        io_mode,\n        *,\n        plugin=None,\n        extension=None,\n        format_hint=None,\n        legacy_mode=False,\n        **kwargs,\n    ):\n        \"\"\"Open an ImageResource.\n    \n        .. warning::\n            This warning is for pypy users. If you are not using a context manager,\n            remember to deconstruct the returned plugin to avoid leaking the file\n            handle to an unclosed file.\n    \n        Parameters\n        ----------\n        uri : str or pathlib.Path or bytes or file or Request\n            The :doc:`ImageResource <../../user_guide/requests>` to load the\n            image from.\n        io_mode : str\n            The mode in which the file is opened. Possible values are::\n    \n                ``r`` - open the file for reading\n                ``w`` - open the file for writing\n    \n            Depreciated since v2.9:\n            A second character can be added to give the reader a hint on what\n            the user expects. This will be ignored by new plugins and will\n            only have an effect on legacy plugins. Possible values are::\n    \n                ``i`` for a single image,\n                ``I`` for multiple images,\n                ``v`` for a single volume,\n                ``V`` for multiple volumes,\n                ``?`` for don't care\n    \n        plugin : str, Plugin, or None\n            The plugin to use. If set to None imopen will perform a\n            search for a matching plugin. If not None, this takes priority over\n            the provided format hint.\n        extension : str\n            If not None, treat the provided ImageResource as if it had the given\n            extension. This affects the order in which backends are considered, and\n            when writing this may also influence the format used when encoding.\n        format_hint : str\n            Deprecated. Use `extension` instead.\n        legacy_mode : bool\n            If true use the v2 behavior when searching for a suitable\n            plugin. This will ignore v3 plugins and will check ``plugin``\n            against known extensions if no plugin with the given name can be found.\n        **kwargs : Any\n            Additional keyword arguments will be passed to the plugin upon\n            construction.\n    \n        Notes\n        -----\n        Registered plugins are controlled via the ``known_plugins`` dict in\n        ``imageio.config``.\n    \n        Passing a ``Request`` as the uri is only supported if ``legacy_mode``\n        is ``True``. In this case ``io_mode`` is ignored.\n    \n        Using the kwarg ``format_hint`` does not enforce the given format. It merely\n        provides a `hint` to the selection process and plugin. The selection\n        processes uses this hint for optimization; however, a plugin's", "stdout_sha1": "2919766f3b2bfc01d432de89ccfe1e872ea343e6", "stdout_len": 18669, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n_________________ test_png_roundtrip_with_imread_and_imwrite __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_png_roundtrip_with_imread0')\n\n    def test_png_roundtrip_with_imread_and_imwrite(tmp_path: Path) -> None:\n        \"\"\"Exercise a simple PNG roundtrip and verify image shape and data.\"\"\"\n        img = _make_color_image()\n        path = tmp_path / \"test.png\"\n    \n>       iio.imwrite(path, img)\n\ntests\\Imageio\\functional_test.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Imageio\\imageio\\v3.py:139: in imwrite\n    with imopen(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_png_roundtrip_with_imread0/test.png')\nio_mode = 'w', plugin = None, extension = None, format_hint = None\nlegacy_mode = False, kwargs = {}\nrequest = <imageio.core.request.Request object at 0x000001E57FECE430>\nsource = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_png_roundtrip_with_imread0/test.png')\n\n    def imopen(\n        uri,\n        io_mode,\n        *,\n        plugin=None,\n        extension=None,\n        format_hint=None,\n        legacy_mode=False,\n        **kwargs,\n    ):\n        \"\"\"Open an ImageResource.\n    \n        .. warning::\n            This warning is for pypy users. If you are not using a context manager,\n            remember to deconstruct the returned plugin to avoid leaking the file\n            handle to an unclosed file.\n    \n        Parameters\n        ----------\n        uri : str or pathlib.Path or bytes or file or Request\n            The :doc:`ImageResource <../../user_guide/requests>` to load the\n            image from.\n        io_mode : str\n            The mode in which the file is opened. Possible values are::\n    \n                ``r`` - open the file for reading\n                ``w`` - open the file for writing\n    \n            Depreciated since v2.9:\n            A second character can be added to give the reader a hint on what\n            the user expects. This will be ignored by new plugins and will\n            only have an effect on legacy plugins. Possible values are::\n    \n                ``i`` for a single image,\n                ``I`` for multiple images,\n                ``v`` for a single volume,\n                ``V`` for multiple volumes,\n                ``?`` for don't care\n    \n        plugin : str, Plugin, or None\n            The plugin to use. If set to None imopen will perform a\n            search for a matching plugin. If not None, this takes priority over\n            the provided format hint.\n        extension : str\n            If not None, treat the provided ImageResource as if it had the given\n            extension. This affects the order in which backends are considered, and\n            when writing this may also influence the format used when encoding.\n        format_hint : str\n            Deprecated. Use `extension` instead.\n        legacy_mode : bool\n            If true use the v2 behavior when searching for a suitable\n            plugin. This will ignore v3 plugins and will check ``plugin``\n            against known extensions if no plugin with the given name can be found.\n        **kwargs : Any\n            Additional keyword arguments will be passed to the plugin upon\n            construction.\n    \n        Notes\n        -----\n        Registered plugins are controlled via the ``known_plugins`` dict in\n        ``imageio.config``.\n    \n        Passing a ``Request`` as the uri is only supported if ``legacy_mode``\n        is ``True``. In this case ``io_mode`` is ignored.\n    \n        Using the kwarg ``format_hint`` does not enforce the given format. It merely\n        provides a `hint` to the selection process and plugin. The selection\n        processes uses this hint for optimization; however, a plugin's decision how\n        to read a ImageResource will - typically - still be based on the content of\n        the resource.\n    \n    \n        Examples\n        --------\n    \n        >>> import imageio.v3 as iio\n        >>> with iio.imopen(\"/path/to/image.png\", \"r\") as file:\n        >>>     im = file.read()\n    \n        >>> with iio.imopen(\"/path/to/output.jpg\", \"w\") as file:\n        >>>     file.write(im)\n    \n        \"\"\"\n    \n        if isinstance(uri, Request) and legacy_mode:\n            warnings.warn(\n                \"`iio.core.Request` is a low-level object and using it\"\n                \" directly as input to `imopen` is discouraged. This will raise\"\n                \" an exception in ImageIO v3.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n    \n            request = uri\n            uri = request.raw_uri\n            io_mode = request.mode.io_mode\n            request.format_hint = format_hint\n        else:\n            request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n    \n        source = \"<bytes>\" if isinstance(uri, bytes) else uri\n    \n        # fast-path based on plugin\n        # (except in legacy mode)\n        if plugin is not None:\n            if isinstance(plugin, str):\n                try:\n                    config = known_plugins[plugin]\n                except KeyError:\n                    request.finish()\n                    raise ValueError(\n                        f\"`{plugin}` is not a registered plugin name.\"\n                    ) from None\n    \n                def loader(request, **kwargs):\n                    return config.plugin_class(request, **kwargs)\n    \n            else:\n    \n                def loader(request, **kwargs):\n                    return plugin(request, **kwargs)\n    \n            try:\n                return loader(request, **kwargs)\n            except InitializationError as class_specific:\n                err_from = class_specific\n                err_type = RuntimeError if legacy_mode else IOError\n                err_msg = f\"`{plugin}` can not handle the given uri.\"\n            except ImportError:\n                err_from = None\n                err_type = ImportError\n                err_msg = (\n                    f\"The `{config.name}` plugin is not installed. \"\n                    f\"Use `pip install imageio[{config.install_name}]` to install it.\"\n                )\n            except Exception as generic_error:\n                err_from = generic_error\n                err_type = IOError\n                err_msg = f\"An unknown error occurred while initializing plugin `{plugin}`.\"\n    \n            request.finish()\n            raise err_type(err_msg) from err_from\n    \n        # fast-path based on format_hint\n        if request.format_hint is not None:\n            for candidate_format in known_extensions[format_hint]:\n                for plugin_name in candidate_format.priority:\n                    config = known_plugins[plugin_name]\n    \n                    try:\n                        candidate_plugin = config.plugin_class\n                    except ImportError:\n                        # not installed\n                        continue\n    \n                    try:\n                        plugin_instance = candidate_plugin(request, **kwargs)\n                    except InitializationError:\n                        # file extension doesn't match file type\n                        continue\n    \n                    return plugin_instance\n            else:\n                resource = (\n                    \"<bytes>\" if isinstance(request.raw_uri, bytes) else request.raw_uri\n                )\n                warnings.warn(f\"`{resource}` can not be opened as a `{format_hint}` file.\")\n    \n        # fast-path based on file extension\n        if request.extension in known_extensions:\n            for candidate_format in known_extensions[request.extension]:\n                for plugin_name in candidate_format.priority:\n                    config = known_plugins[plugin_name]\n    \n                    try:\n                        candidate_plugin = config.plugin_class\n                    except ImportError:\n                        # not installed\n                        continue\n    \n                    try:\n                        plugin_instance = candidate_plugin(request, **kwargs)\n                    except InitializationError:\n                        # file extension doesn't match file type\n                        continue\n    \n                    return plugin_instance\n    \n        # error out for read-only special targets\n        # this is hacky; can we come up with a better solution for this?\n        if request.mode.io_mode == IOMode.write:\n            if isinstance(uri, str) and uri.startswith(SPECIAL_READ_URIS):\n                request.finish()\n                err_type = ValueError if legacy_mode else IOError\n                err_msg = f\"`{source}` is read-only.\"\n                raise err_type(err_msg)\n    \n        # error out for directories\n        # this is a bit hacky and should be cleaned once we decide\n        # how to gracefully handle DICOM\n        if request._uri_type == URI_FILENAME and Path(request.raw_uri).is_dir():\n            request.finish()\n            err_type = ValueError if legacy_mode else IOError\n            err_msg = (\n                \"ImageIO does not generally support reading folders. \"\n                \"Limited support may be available via specific plugins. \"\n                \"Specify the plugin explicitly using the `plugin` kwarg, e.g. `plugin='DICOM'`\"\n            )\n            raise err_type(err_msg)\n    \n        # close the current request here and use fresh/new ones while trying each\n        # plugin This is slow (means potentially reopening a resource several\n        # times), but should only happen rarely because this is the fallback if all\n        # else fails.\n        request.finish()\n    \n        # fallback option: try all plugins\n        for config in known_plugins.values():\n            # each plugin gets its own request\n            request = Request(uri, io_mode, format_hint=format_hint)\n    \n            try:\n                plugin_instance = config.plugin_class(request, **kwargs)\n            except InitializationError:\n                continue\n            except ImportError:\n                continue\n            else:\n                return plugin_instance\n    \n        err_type = ValueError if legacy_mode else IOError\n        err_msg = f\"Could not find a backend to open `{source}`` with iomode `{io_mode}`.\"\n    \n        # check if a missing plugin could help\n        if request.extension in known_extensions:\n            missing_plugins = list()\n    \n            formats = known_extensions[request.extension]\n            plugin_names = [\n                plugin for file_format in formats for plugin in file_format.priority\n            ]\n            for name in plugin_names:\n                config = known_plugins[name]\n    \n                try:\n                    config.plugin_class\n                    continue\n                except ImportError:\n                    missing_plugins.append(config)\n    \n            if len(missing_plugins) > 0:\n                install_candidates = \"\\n\".join(\n                    [\n                        (\n                            f\"  {config.name}:  \"\n                            f\"pip install imageio[{config.install_name}]\"\n                        )\n                        for config in missing_plugins\n                    ]\n                )\n                err_msg += (\n                    \"\\nBased on the extension, the following plugins might add capable backends:\\n\"\n                    f\"{install_candidates}\"\n                )\n    \n        request.finish()\n>       raise err_type(err_msg)\nE       OSError: Could not find a backend to open `C:\\Users\\86152\\AppData\\Local\\Temp\\pytest-of-86152\\pytest-328\\test_png_roundtrip_with_imread0\\test.png`` with iomode `w`.\nE       Based on the extension, the following plugins might add capable backends:\nE         pillow:  pip install imageio[pillow]\nE         PNG-PIL:  pip install imageio[pillow]\nE         PNG-FI:  pip install imageio[freeimage]\nE         ITK:  pip install imageio[simpleitk]\nE         pyav:  pip install imageio[pyav]\nE         opencv:  pip install imageio[opencv]\n\nrepositories\\Imageio\\imageio\\core\\imopen.py:281: OSError\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepositories\\Imageio\\imageio\\v3.py:139: in imwrite\n    with imopen(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_gif_multiframe_roundtrip_0/anim.gif')\nio_mode = 'w', plugin = None, extension = None, format_hint = None\nlegacy_mode = False, kwargs = {}\nrequest = <imageio.core.request.Request object at 0x000001E57FF69B20>\nsource = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-328/test_gif_multiframe_roundtrip_0/anim.gif')\n\n    def imopen(\n        uri,\n        io_mode,\n        *,\n        plugin=None,\n        extension=None,\n        format_hint=None,\n        legacy_mode=False,\n        **kwargs,\n    ):\n        \"\"\"Open an ImageResource.\n    \n        .. warning::\n            This warning is for pypy users. If you are not using a context manager,\n            remember to deconstruct the returned plugin to avoid leaking the file\n            handle to an unclosed file.\n    \n        Parameters\n        ----------\n        uri : str or pathlib.Path or bytes or file or Request\n            The :doc:`ImageResource <../../user_guide/requests>` to load the\n            image from.\n        io_mode : str\n            The mode in which the file is opened. Possible values are::\n    \n                ``r`` - open the file for reading\n                ``w`` - open the file for writing\n    \n            Depreciated since v2.9:\n            A second character can be added to give the reader a hint on what\n            the user expects. This will be ignored by new plugins and will\n            only have an effect on legacy plugins. Possible values are::\n    \n                ``i`` for a single image,\n                ``I`` for multiple images,\n                ``v`` for a single volume,\n                ``V`` for multiple volumes,\n                ``?`` for don't care\n    \n        plugin : str, Plugin, or None\n            The plugin to use. If set to None imopen will perform a\n            search for a matching plugin. If not None, this takes priority over\n            the provided format hint.\n        extension : str\n            If not None, treat the provided ImageResource as if it had the given\n            extension. This affects the order in which backends are considered, and\n            when writing this may also influence the format used when encoding.\n        format_hint : str\n            Deprecated. Use `extension` instead.\n        legacy_mode : bool\n            If true use the v2 behavior when searching for a suitable\n            plugin. This will ignore v3 plugins and will check ``plugin``\n            against known extensions if no plugin with the given name can be found.\n        **kwargs : Any\n            Additional keyword arguments will be passed to the plugin upon\n            construction.\n    \n        Notes\n        -----\n        Registered plugins are controlled via the ``known_plugins`` dict in\n        ``imageio.config``.\n    \n        Passing a ``Request`` as the uri is only supported if ``legacy_mode``\n        is ``True``. In this case ``io_mode`` is ignored.\n    \n        Using the kwarg ``format_hint`` does not enforce the given format. It merely\n        provides a `hint` to the selection process and plugin. The selection\n        processes uses this hint for optimization; however, a plugin's decision how\n        to read a ImageResource will - typically - still be based on the content of\n        the resource.\n    \n    \n        Examples\n        --------\n    \n        >>> import imageio.v3 as iio\n        >>> with iio.imopen(\"/path/to/image.png\", \"r\") as file:\n        >>>     im = file.read()\n    \n        >>> with iio.imopen(\"/path/to/output.jpg\", \"w\") as file:\n        >>>     file.write(im)\n    \n        \"\"\"\n    \n        if isinstance(uri, Request) and legacy_mode:\n            warnings.warn(\n                \"`iio.core.Request` is a low-level object and using it\"\n                \" directly as input to `imopen` is discouraged. This will raise\"\n                \" an exception in ImageIO v3.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n    \n            request = uri\n            uri = request.raw_uri\n            io_mode = request.mode.io_mode\n            request.format_hint = format_hint\n        else:\n            request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n    \n        source = \"<bytes>\" if isinstance(uri, bytes) else uri\n    \n        # fast-path based on plugin\n        # (except in legacy mode)\n        if plugin is not None:\n            if isinstance(plugin, str):\n                try:\n                    config = known_plugins[plugin]\n                except KeyError:\n                    request.finish()\n                    raise ValueError(\n                        f\"`{plugin}` is not a registered plugin name.\"\n                    ) from None\n    \n                def loader(request, **kwargs):\n                    return config.plugin_class(request, **kwargs)\n    \n            else:\n    \n                def loader(request, **kwargs):\n                    return plugin(request, **kwargs)\n    \n            try:\n                return loader(request, **kwargs)\n            except InitializationError as class_specific:\n                err_from = class_specific\n                err_type = RuntimeError if legacy_mode else IOError\n                err_msg = f\"`{plugin}` can not handle the given uri.\"\n            except ImportError:\n                err_from = None\n                err_type = ImportError\n"}
{"model": "deepseek-v3.2", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "KeyError", "exception_msg": "'test'", "returncode": 1, "elapsed_time_s": 4.739532, "avg_memory_mb": 78.57, "avg_cpu_percent": 99.77, "passed": 5, "failed": 10, "skipped": 0, "total": 15, "functional_score": 0.3333, "timestamp": "2025-12-31 19:45:46", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\nself = Index(['KM_estimate'], dtype='object'), key = 'test'\n\n    def get_loc(self, key):\n        \"\"\"\n        Get integer location, slice or boolean mask for requested label.\n    \n        Parameters\n        ----------\n        key : label\n    \n        Returns\n        -------\n        int if unique index, slice if monotonic index, else mask\n    \n        Examples\n        --------\n        >>> unique_index = pd.Index(list('abc'))\n        >>> unique_index.get_loc('b')\n        1\n    \n        >>> monotonic_index = pd.Index(list('abbc'))\n        >>> monotonic_index.get_loc('b')\n        slice(1, 3, None)\n    \n        >>> non_monotonic_index = pd.Index(list('abcb'))\n        >>> non_monotonic_index.get_loc('b')\n        array([False,  True, False,  True])\n        \"\"\"\n        casted_key = self._maybe_cast_indexer(key)\n        try:\n>           return self._engine.get_loc(casted_key)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nindex.pyx:167: in pandas._libs.index.IndexEngine.get_loc\n    ???\nindex.pyx:196: in pandas._libs.index.IndexEngine.get_loc\n    ???\npandas\\\\_libs\\\\hashtable_class_helper.pxi:7081: in pandas._libs.hashtable.PyObjectHashTable.get_item\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   ???\nE   KeyError: 'test'\n\npandas\\\\_libs\\\\hashtable_class_helper.pxi:7089: KeyError\n\nThe above exception was the direct cause of the following exception:\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n        kmf.fit(durations=durations, event_observed=events, label=\"test\")\n        sf = kmf.survival_function_\n    \n>       values = sf[\"test\"].values\n\ntests\\Lifelines\\functional_test.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4102: in __getitem__\n    indexer = self.columns.get_loc(key)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Index(['KM_estimate'], dtype='object'), key = 'test'\n\n    def get_loc(self, key):\n        \"\"\"\n        Get integer location, slice or boolean mask for requested label.\n    \n        Parameters\n        ----------\n        key : label\n    \n        Returns\n        -------\n        int if unique index, slice if monotonic index, else mask\n    \n        Examples\n        --------\n        >>> unique_index = pd.Index(list('abc'))\n        >>> unique_index.get_loc('b')\n        1\n    \n        >>> monotonic_index = pd.Index(list('abbc'))\n        >>> monotonic_index.get_loc('b')\n        slice(1, 3, None)\n    \n        >>> non_monotonic_index = pd.Index(list('abcb'))\n        >>> non_monotonic_index.get_loc('b')\n        array([False,  True, False,  True])\n        \"\"\"\n        casted_key = self._maybe_cast_indexer(key)\n        try:\n            return self._engine.get_loc(casted_key)\n        except KeyError as err:\n            if isinstance(casted_key, slice) or (\n                isinstance(casted_key, abc.Iterable)\n                and any(isinstance(x, slice) for x in casted_key)\n            ):\n                raise InvalidIndexError(key)\n>           raise KeyError(key) from err\nE           KeyError: 'test'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812: KeyError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n      ", "stdout_sha1": "45c6b9b134f0578d43d1cb19acda61af64a54e0c", "stdout_len": 11870, "stdout": "FF..FFFFF.F.FF.                                                          [100%]\n================================== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\nself = Index(['KM_estimate'], dtype='object'), key = 'test'\n\n    def get_loc(self, key):\n        \"\"\"\n        Get integer location, slice or boolean mask for requested label.\n    \n        Parameters\n        ----------\n        key : label\n    \n        Returns\n        -------\n        int if unique index, slice if monotonic index, else mask\n    \n        Examples\n        --------\n        >>> unique_index = pd.Index(list('abc'))\n        >>> unique_index.get_loc('b')\n        1\n    \n        >>> monotonic_index = pd.Index(list('abbc'))\n        >>> monotonic_index.get_loc('b')\n        slice(1, 3, None)\n    \n        >>> non_monotonic_index = pd.Index(list('abcb'))\n        >>> non_monotonic_index.get_loc('b')\n        array([False,  True, False,  True])\n        \"\"\"\n        casted_key = self._maybe_cast_indexer(key)\n        try:\n>           return self._engine.get_loc(casted_key)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nindex.pyx:167: in pandas._libs.index.IndexEngine.get_loc\n    ???\nindex.pyx:196: in pandas._libs.index.IndexEngine.get_loc\n    ???\npandas\\\\_libs\\\\hashtable_class_helper.pxi:7081: in pandas._libs.hashtable.PyObjectHashTable.get_item\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   ???\nE   KeyError: 'test'\n\npandas\\\\_libs\\\\hashtable_class_helper.pxi:7089: KeyError\n\nThe above exception was the direct cause of the following exception:\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n        kmf.fit(durations=durations, event_observed=events, label=\"test\")\n        sf = kmf.survival_function_\n    \n>       values = sf[\"test\"].values\n\ntests\\Lifelines\\functional_test.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4102: in __getitem__\n    indexer = self.columns.get_loc(key)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Index(['KM_estimate'], dtype='object'), key = 'test'\n\n    def get_loc(self, key):\n        \"\"\"\n        Get integer location, slice or boolean mask for requested label.\n    \n        Parameters\n        ----------\n        key : label\n    \n        Returns\n        -------\n        int if unique index, slice if monotonic index, else mask\n    \n        Examples\n        --------\n        >>> unique_index = pd.Index(list('abc'))\n        >>> unique_index.get_loc('b')\n        1\n    \n        >>> monotonic_index = pd.Index(list('abbc'))\n        >>> monotonic_index.get_loc('b')\n        slice(1, 3, None)\n    \n        >>> non_monotonic_index = pd.Index(list('abcb'))\n        >>> non_monotonic_index.get_loc('b')\n        array([False,  True, False,  True])\n        \"\"\"\n        casted_key = self._maybe_cast_indexer(key)\n        try:\n            return self._engine.get_loc(casted_key)\n        except KeyError as err:\n            if isinstance(casted_key, slice) or (\n                isinstance(casted_key, abc.Iterable)\n                and any(isinstance(x, slice) for x in casted_key)\n            ):\n                raise InvalidIndexError(key)\n>           raise KeyError(key) from err\nE           KeyError: 'test'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812: KeyError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n        kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\n        kmf_treated.fit(treated[\"T\"], treated[\"E\"], label=\"treated\")\n    \n        t = 10.0\n        s_control = float(kmf_control.predict(t))\n        s_treated = float(kmf_treated.predict(t))\n    \n        assert 0.0 <= s_control <= 1.0\n        assert 0.0 <= s_treated <= 1.0\n>       assert abs(s_control - s_treated) > 1e-3\nE       assert 0.0 > 0.001\nE        +  where 0.0 = abs((1.0 - 1.0))\n\ntests\\Lifelines\\functional_test.py:114: AssertionError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n        s1 = float(kmf.predict(1.0))\n        s3 = float(kmf.predict(3.0))\n        s10 = float(kmf.predict(10.0))\n    \n        eps = 1e-8\n    \n        # Bounds (avoid chaining eps into the hard upper bound 1.0)\n        assert 0.0 <= s1 <= 1.0\n        assert 0.0 <= s3 <= 1.0\n        assert 0.0 <= s10 <= 1.0\n    \n        # Monotonic non-increasing (allow tiny numerical wiggle)\n        assert s3 <= s1 + eps\n>       assert s10 <= s3 + eps\nE       assert 0.19999999999999996 <= (0.0 + 1e-08)\n\ntests\\Lifelines\\functional_test.py:163: AssertionError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x = pd.DataFrame({\"age\": [30, 60], \"treatment\": [0, 1]})\n>       sf = cph.predict_survival_function(x)\n\ntests\\Lifelines\\functional_test.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.coxph_fitter.CoxPHFitter object at 0x000001D1B688D5E0>\nrow =    age  treatment\n0   30          0\n1   60          1\n\n    def predict_survival_function(self, row: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Predict survival function for a single observation.\n    \n        Parameters\n        ----------\n        row : DataFrame\n            Single-row DataFrame with same covariates as training data.\n    \n        Returns\n        -------\n        DataFrame\n            Survival function over time.\n        \"\"\"\n        if not self._fitted:\n            raise ValueError(\"Model must be fitted before prediction.\")\n    \n        if self._baseline_cumulative_hazard is None:\n            raise ValueError(\"Baseline hazard not calculated.\")\n    \n        # Get linear predictor for this row\n        covariate_cols = self.params_.index.tolist()\n        missing_cols = [col for col in covariate_cols if col not in row.columns]\n        if missing_cols:\n            raise ValueError(f\"Missing columns in row: {missing_cols}\")\n    \n        X_row = row[covariate_cols].values.astype(float).flatten()\n>       linear_predictor = np.dot(X_row, self.params_.values)\nE       ValueError: shapes (4,) and (2,) not aligned: 4 (dim 0) != 2 (dim 0)\n\ngeneration\\Lifelines\\lifelines\\fitters\\coxph_fitter.py:171: ValueError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_small_manual_dataset\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_waltons_groups - asser...\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_is_non_increasing_over_time\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\n10 failed, 5 passed in 3.14s\n"}
{"model": "deepseek-v3.2", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 3.017522, "avg_memory_mb": 35.3, "avg_cpu_percent": 68.3, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 19:56:37", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.62s\n", "stdout_sha1": "80350b3a454e82dffb6f2740319b8650fdf0eb7e", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.62s\n"}
{"model": "deepseek-v3.2", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 2.019287, "avg_memory_mb": 32.46, "avg_cpu_percent": 95.9, "passed": 7, "failed": 3, "skipped": 9, "total": 19, "functional_score": 0.3684, "timestamp": "2025-12-31 19:58:09", "stdout_excerpt": "==== FAILURES ===================================\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<a \" in norm and \"</a>\" in norm\n        assert 'href=\"https://example.com\"' in norm\n>       assert \"<img \" in norm\nE       assert '<img ' in '<p>A <a href=\"https://example.com\">link</a> and an image: !<a href=\"https://example.com/image.png\">alt text</a></p>'\n\ntests\\Markdown\\functional_test.py:191: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_links_and_images - assert '<im...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.64s\n", "stdout_sha1": "354de87958e577a9b7d2bb4d9195851208d4d6dd", "stdout_len": 2438, "stdout": ".....FF..Fsssssssss                                                      [100%]\n================================== FAILURES ===================================\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<a \" in norm and \"</a>\" in norm\n        assert 'href=\"https://example.com\"' in norm\n>       assert \"<img \" in norm\nE       assert '<img ' in '<p>A <a href=\"https://example.com\">link</a> and an image: !<a href=\"https://example.com/image.png\">alt text</a></p>'\n\ntests\\Markdown\\functional_test.py:191: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_links_and_images - assert '<im...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.64s\n"}
{"model": "deepseek-v3.2", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 1.970716, "avg_memory_mb": 31.73, "avg_cpu_percent": 99.2, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 19:59:38", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.59s\n", "stdout_sha1": "5b3c6a492145975a9ac14c499d122f075f606ea5", "stdout_len": 3013, "stdout": "........FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.59s\n"}
{"model": "deepseek-v3.2", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.563405, "avg_memory_mb": 31.84, "avg_cpu_percent": 96.8, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:01:43", "stdout_excerpt": "\n1 skipped in 0.16s\n", "stdout_sha1": "a1849a7e09f94d0f14b1c3622e0bedba158ebbdf", "stdout_len": 20, "stdout": "\n1 skipped in 0.16s\n"}
{"model": "deepseek-v3.2", "project": "Pendulum", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.620816, "avg_memory_mb": 30.64, "avg_cpu_percent": 99.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:04:01", "stdout_excerpt": "\n1 skipped in 0.17s\n", "stdout_sha1": "66bd18a62ec687100e9a9e996a20b12b6bd4dc1e", "stdout_len": 20, "stdout": "\n1 skipped in 0.17s\n"}
{"model": "deepseek-v3.2", "project": "Petl", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "sort() got an unexpected keyword argument 'reverse'", "returncode": 1, "elapsed_time_s": 1.559995, "avg_memory_mb": 32.45, "avg_cpu_percent": 98.9, "passed": 4, "failed": 2, "skipped": 6, "total": 12, "functional_score": 0.3333, "timestamp": "2025-12-31 20:05:28", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:25: in source\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\conversions.py:59: in source\n    new_value = func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = (1, 10)\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: tuple indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n2 failed, 4 passed, 6 skipped in 0.43s\n", "stdout_sha1": "9a2f23f9e17979baa6cdfd23a1ede3d1a37acc65", "stdout_len": 2456, "stdout": ".F.ss.Fs.sss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:25: in source\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\conversions.py:59: in source\n    new_value = func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = (1, 10)\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: tuple indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n2 failed, 4 passed, 6 skipped in 0.43s\n"}
{"model": "deepseek-v3.2", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.396122, "avg_memory_mb": 14.91, "avg_cpu_percent": 89.4, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:09:42", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 14, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\formatters\\__init__.py\", line 6, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\nModuleNotFoundError: No module named 'pygments.formatters.terminal'\n", "stdout_sha1": "777f861fa960de43dfa3ec8d9327ebf0b6276cca", "stdout_len": 1622, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 14, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\formatters\\__init__.py\", line 6, in <module>\n    from pygments.formatters.terminal import TerminalFormatter\nModuleNotFoundError: No module named 'pygments.formatters.terminal'\n"}
{"model": "deepseek-v3.2", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.937778, "avg_memory_mb": 32.99, "avg_cpu_percent": 98.3, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 20:10:41", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        \"\"\"\n        Encode a payload into a JWT token\n    \n        Args:\n            payload: Dictionary containing the claims\n            key: Secret key for signing\n            algorithm: Signing algorithm (only HS256 supported)\n            **kwargs: Additional options\n    \n        Returns:\n            str: Encoded JWT token\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise ValueError(f\"Algorithm {algorithm} not supported\")\nE           ValueError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:47: ValueError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:68: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000025A71CC4C10>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "0b21f7ca62b5bf51b35bba06f2e862d806cd1dae", "stdout_len": 6892, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        \"\"\"\n        Encode a payload into a JWT token\n    \n        Args:\n            payload: Dictionary containing the claims\n            key: Secret key for signing\n            algorithm: Signing algorithm (only HS256 supported)\n            **kwargs: Additional options\n    \n        Returns:\n            str: Encoded JWT token\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise ValueError(f\"Algorithm {algorithm} not supported\")\nE           ValueError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:47: ValueError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:68: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000025A71CC4C10>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:68: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000025A71D34C40>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - V...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.58s\n"}
{"model": "deepseek-v3.2", "project": "PyPDF", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.627537, "avg_memory_mb": 31.34, "avg_cpu_percent": 97.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:13:02", "stdout_excerpt": "\n1 skipped in 0.16s\n", "stdout_sha1": "a1849a7e09f94d0f14b1c3622e0bedba158ebbdf", "stdout_len": 20, "stdout": "\n1 skipped in 0.16s\n"}
{"model": "deepseek-v3.2", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.588839, "avg_memory_mb": 31.81, "avg_cpu_percent": 102.2, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:17:35", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "deepseek-v3.2", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Job' object has no attribute 'to'", "returncode": 1, "elapsed_time_s": 1.490587, "avg_memory_mb": 32.32, "avg_cpu_percent": 102.3, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 20:19:14", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\n2 failed, 10 passed in 0.35s\n", "stdout_sha1": "4c475a6bf0423f6e60eeefeb9413688fddbd227e", "stdout_len": 1402, "stdout": "...F....F...                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\n2 failed, 10 passed in 0.35s\n"}
{"model": "deepseek-v3.2", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "?                     ++++++++", "returncode": 1, "elapsed_time_s": 1.52367, "avg_memory_mb": 31.73, "avg_cpu_percent": 96.8, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 20:20:54", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___hisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n__________ test_lowercase_false_preserves_case_for_remaining_tokens ___________\n\n    def test_lowercase_false_preserves_case_for_remaining_tokens() -> None:\n        \"\"\"lowercase=False should preserve original case for non-removed words.\"\"\"\n        mixed = \"thIs Has a stopword Stopword\"\n        result = slugify(mixed, stopwords=[\"Stopword\"], lowercase=False)\n    \n        assert \"thIs\" in result\n        assert \"Has\" in result\n>       assert \"Stopword\" not in result\nE       AssertionError: assert 'Stopword' not in 'thIs-Has-a-...ord-Stopword'\nE         \nE         'Stopword' is contained here:\nE           thIs-Has-a-stopword-Stopword\nE         ?                     ++++++++\n\ntests\\Slugify\\functional_test.py:202: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_lowercase_false_preserves_case_for_remaining_tokens\n2 failed, 10 passed in 0.38s\n", "stdout_sha1": "c5487defef19c115c4526e19dcdaddcc45c1797e", "stdout_len": 1786, "stdout": ".......F.F..                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___hisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n__________ test_lowercase_false_preserves_case_for_remaining_tokens ___________\n\n    def test_lowercase_false_preserves_case_for_remaining_tokens() -> None:\n        \"\"\"lowercase=False should preserve original case for non-removed words.\"\"\"\n        mixed = \"thIs Has a stopword Stopword\"\n        result = slugify(mixed, stopwords=[\"Stopword\"], lowercase=False)\n    \n        assert \"thIs\" in result\n        assert \"Has\" in result\n>       assert \"Stopword\" not in result\nE       AssertionError: assert 'Stopword' not in 'thIs-Has-a-...ord-Stopword'\nE         \nE         'Stopword' is contained here:\nE           thIs-Has-a-stopword-Stopword\nE         ?                     ++++++++\n\ntests\\Slugify\\functional_test.py:202: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_lowercase_false_preserves_case_for_remaining_tokens\n2 failed, 10 passed in 0.38s\n"}
{"model": "deepseek-v3.2", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "SQLModel requires sqlalchemy to be installed", "returncode": 2, "elapsed_time_s": 2.244146, "avg_memory_mb": 54.58, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:24:28", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ngeneration\\SQLModel\\sqlmodel\\__init__.py:50: in <module>\n    from sqlalchemy.orm import (\nE   ImportError: cannot import name 'mapped_column' from 'sqlalchemy.orm' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\orm\\__init__.py)\n\nDuring handling of the above exception, another exception occurred:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:62: in <module>\n    raise ImportError(\"SQLModel requires sqlalchemy to be installed\")\nE   ImportError: SQLModel requires sqlalchemy to be installed\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.07s\n", "stdout_sha1": "f5353d093bb9f03b33ba2a3f0152718fa33cec43", "stdout_len": 1366, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ngeneration\\SQLModel\\sqlmodel\\__init__.py:50: in <module>\n    from sqlalchemy.orm import (\nE   ImportError: cannot import name 'mapped_column' from 'sqlalchemy.orm' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\orm\\__init__.py)\n\nDuring handling of the above exception, another exception occurred:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:62: in <module>\n    raise ImportError(\"SQLModel requires sqlalchemy to be installed\")\nE   ImportError: SQLModel requires sqlalchemy to be installed\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.07s\n"}
{"model": "deepseek-v3.2", "project": "Stegano", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.279926, "avg_memory_mb": 32.5, "avg_cpu_percent": 98.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:26:34", "stdout_excerpt": "\n1 skipped in 0.16s\n", "stdout_sha1": "a1849a7e09f94d0f14b1c3622e0bedba158ebbdf", "stdout_len": 20, "stdout": "\n1 skipped in 0.16s\n"}
{"model": "deepseek-v3.2", "project": "Tablib", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "ValueError", "exception_msg": "Unsupported format: html", "returncode": 1, "elapsed_time_s": 1.884144, "avg_memory_mb": 32.67, "avg_cpu_percent": 100.9, "passed": 7, "failed": 4, "skipped": 0, "total": 11, "functional_score": 0.6364, "timestamp": "2025-12-31 20:28:05", "stdout_excerpt": "==== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n>       assert loaded_csv.height == data.height\nE       assert 4 == 3\nE        +  where 4 = <Dataset height=4 width=3>.height\nE        +  and   3 = <Dataset height=3 width=3>.height\n\ntests\\Tablib\\functional_test.py:134: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3 width=3>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:152: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3 width=3>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:152: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_csv_and_json_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n4 failed, 7 passed in 0.53s\n", "stdout_sha1": "894644cc125c09f88c8eb150133f707add962b5d", "stdout_len": 3858, "stdout": "FF..F...F..                                                              [100%]\n================================== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n>       assert loaded_csv.height == data.height\nE       assert 4 == 3\nE        +  where 4 = <Dataset height=4 width=3>.height\nE        +  and   3 = <Dataset height=3 width=3>.height\n\ntests\\Tablib\\functional_test.py:134: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3 width=3>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:152: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset height=3 width=3>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt == 'csv':\n            return self.csv\n        elif fmt == 'json':\n            return self.json\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:152: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_csv_and_json_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n4 failed, 7 passed in 0.53s\n"}
{"model": "deepseek-v3.2", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "Number of data points must match number of labels", "returncode": 1, "elapsed_time_s": 26.621252, "avg_memory_mb": 32.86, "avg_cpu_percent": 0.47, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 20:39:07", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF24130>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF24220>\nlabels = [[3], [5], [2]], data = ['A', 'B', 'C']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF93670>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF93700>\nlabels = [[1, 2], [3, 4]], data = ['X', 'Y']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF24850>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF24DC0>, labels = [[4], [1]]\ndata = ['D', 'E']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series)", "stdout_sha1": "2748f2290281bebb1163de4044db5eeee7e01466", "stdout_len": 17443, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF24130>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF24220>\nlabels = [[3], [5], [2]], data = ['A', 'B', 'C']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF93670>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF93700>\nlabels = [[1, 2], [3, 4]], data = ['X', 'Y']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF24850>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF24DC0>, labels = [[4], [1]]\ndata = ['D', 'E']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF92C40>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF929D0>, labels = [[2], [7]]\ndata = ['A', 'B']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF1A5B0>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF1A3D0>\nlabels = [[1], [2], [3]], data = ['L1', 'L2', 'L3']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF81070>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF81A60>\nlabels = [[12.5], [7.0]], data = ['CPU', 'RAM']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF116A0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF112B0>\nlabels = [[3.14159], [2.71828]], data = ['P', 'Q']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCED63A0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCED6FA0>\nlabels = [[1, 1], [2, 1], [1, 3]], data = ['S1', 'S2', 'S3']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF809A0>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF80610>\nlabels = [[1, 2, 3], [3, 2, 1]], data = ['A', 'B']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCEED490>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCEED4C0>, labels = [[4], [6]]\ndata = ['U', 'V']\n\n    def __init__(self, labels: List[str], data: List[List[Union[int, float]]]):\n        \"\"\"\n        Initialize Data object.\n    \n        Args:\n            labels: List of label strings\n            data: List of data series, each series is a list of numeric values\n        \"\"\"\n        self.labels = labels\n        self.data = data\n    \n        # Validate data dimensions\n        if len(data) > 0:\n            series_length = len(data[0])\n            for series in data:\n                if len(series) != series_length:\n                    raise ValueError(\"All data series must have the same length\")\n                if len(series) != len(labels):\n>                   raise ValueError(\"Number of data points must match number of labels\")\nE                   ValueError: Number of data points must match number of labels\n\ngeneration\\Termgraph\\termgraph\\data.py:31: ValueError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000246BCF14640>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:54: in draw\n    self._draw_horizontal()\ngeneration\\Termgraph\\termgraph\\charts.py:63: in _draw_horizontal\n    max_val = self.data.get_max_value()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000246BCF14460>, series_idx = None\n\n    def get_max_value(self, series_idx: Optional[int] = None) -> Union[int, float]:\n        \"\"\"\n        Get maximum value across all series or in a specific series.\n    \n        Args:\n            series_idx: Optional index of specific series, None for all series\n    \n        Returns:\n            Maximum value\n        \"\"\"\n        if series_idx is not None:\n            return max(self.data[series_idx])\n    \n        max_val = float('-inf')\n        for series in self.data:\n            series_max = max(series)\n>           if series_max > max_val:\nE           TypeError: '>' not supported between instances of 'str' and 'float'\n\ngeneration\\Termgraph\\termgraph\\data.py:59: TypeError\n---------------------------- Captured stdout call -----------------------------\nNarrow\n\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 25.31s\n"}
{"model": "deepseek-v3.2", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 1.994566, "avg_memory_mb": 32.84, "avg_cpu_percent": 98.3, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 20:43:25", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "722735942fe80378f49af6789a4b2b3a9e1778b2", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-331/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-331/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-331/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000025F1BBA1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.73s\n"}
{"model": "deepseek-v3.2", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.840722, "avg_memory_mb": 35.94, "avg_cpu_percent": 98.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:45:30", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.57s\n", "stdout_sha1": "f2e0f976bd9592e314fe1512e65b54bb51872b1d", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.57s\n"}
{"model": "deepseek-v3.2", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "__init__() got an un", "returncode": 1, "elapsed_time_s": 1.99642, "avg_memory_mb": 32.54, "avg_cpu_percent": 98.3, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 20:47:13", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000231FB060640>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'usage: __main__.py add [-h]\\n\\noptional arguments:\\n  -h, --help  show this help message and exit\\n' or 'title' in 'usage: __main__.py add [-h]\\n\\noptional arguments:\\n  -h, --help  show this help message and exit\\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an un", "stdout_sha1": "6dda34a5527793f1fc0ccca36fccd1d006c41d54", "stdout_len": 7014, "stdout": "FFF..F.FFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000231FB060640>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'usage: __main__.py add [-h]\\n\\noptional arguments:\\n  -h, --help  show this help message and exit\\n' or 'title' in 'usage: __main__.py add [-h]\\n\\noptional arguments:\\n  -h, --help  show this help message and exit\\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x00000231FB059970>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:159: AttributeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n        app = _create_types_app()\n        # Now stable: \"calc\" always exists as a subcommand (multi-command app).\n        r = runner.invoke(app, [\"calc\", \"2\", \"3\", \"--scale\", \"2.0\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x00000231FB0C2B20>.exit_code\n\ntests\\Typer\\functional_test.py:313: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AttributeE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - At...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n9 failed, 3 passed in 0.72s\n"}
{"model": "deepseek-v3.2", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'watchdog.observers.api'", "returncode": 2, "elapsed_time_s": 2.010667, "avg_memory_mb": 36.3, "avg_cpu_percent": 95.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:49:22", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:54: in <module>\n    from watchdog.observers import Observer  # type: ignore  # noqa: E402\ngeneration\\Watchdog\\watchdog\\__init__.py:35: in <module>\n    from watchdog.observers.api import BaseObserver, Observer\ngeneration\\Watchdog\\watchdog\\observers\\__init__.py:4: in <module>\n    from watchdog.observers.api import BaseObserver, Observer\nE   ModuleNotFoundError: No module named 'watchdog.observers.api'\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n", "stdout_sha1": "de4b3d78538fdffb5bcf2eabe4b8392083b9daf6", "stdout_len": 1173, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:54: in <module>\n    from watchdog.observers import Observer  # type: ignore  # noqa: E402\ngeneration\\Watchdog\\watchdog\\__init__.py:35: in <module>\n    from watchdog.observers.api import BaseObserver, Observer\ngeneration\\Watchdog\\watchdog\\observers\\__init__.py:4: in <module>\n    from watchdog.observers.api import BaseObserver, Observer\nE   ModuleNotFoundError: No module named 'watchdog.observers.api'\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n"}
{"model": "deepseek-v3.2", "project": "Xmltodict", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "NameError", "exception_msg": "name 'NAMESPACE_SEPARATOR' is not defined", "returncode": 2, "elapsed_time_s": 1.935921, "avg_memory_mb": 36.24, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 20:51:21", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Xmltodict/functional_test.py _____________\ntests\\Xmltodict\\functional_test.py:49: in <module>\n    import xmltodict  # type: ignore  # noqa: E402\ngeneration\\Xmltodict\\xmltodict.py:30: in <module>\n    DEFAULT_NAMESPACE_SEPARATOR = NAMESPACE_SEPARATOR\nE   NameError: name 'NAMESPACE_SEPARATOR' is not defined\n=========================== short test summary info ===========================\nERROR tests/Xmltodict/functional_test.py - NameError: name 'NAMESPACE_SEPARAT...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.63s\n", "stdout_sha1": "6de2fc1a9d8f2304694d151b9d224de2e0e41531", "stdout_len": 682, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Xmltodict/functional_test.py _____________\ntests\\Xmltodict\\functional_test.py:49: in <module>\n    import xmltodict  # type: ignore  # noqa: E402\ngeneration\\Xmltodict\\xmltodict.py:30: in <module>\n    DEFAULT_NAMESPACE_SEPARATOR = NAMESPACE_SEPARATOR\nE   NameError: name 'NAMESPACE_SEPARATOR' is not defined\n=========================== short test summary info ===========================\nERROR tests/Xmltodict/functional_test.py - NameError: name 'NAMESPACE_SEPARAT...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.63s\n"}
{"model": "gemini-2.5-pro", "project": "Cachetools", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "KeyError", "exception_msg": "'c'", "returncode": 1, "elapsed_time_s": 3.378116, "avg_memory_mb": 32.75, "avg_cpu_percent": 54.7, "passed": 11, "failed": 2, "skipped": 0, "total": 13, "functional_score": 0.8462, "timestamp": "2026-01-01 01:09:44", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_lru_cache_eviction ________________________\n\nself = LRUCache(LRUCache([('a', 1), ('c', 3)]), maxsize=2, currsize=3)\nkey = 'b'\n\n    def __getitem__(self, key):\n        try:\n            value = super().__getitem__(key)\n>           self.move_to_end(key)\nE           KeyError: 'b'\n\ngeneration\\Cachetools\\cachetools\\cache.py:47: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_basic_lru_cache_eviction():\n        cache = LRUCache(maxsize=2)\n    \n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n    \n        # Touch \"a\" so it becomes most recently used\n        _ = cache[\"a\"]\n    \n        # Adding \"c\" should evict the least recently used entry (\"b\")\n>       cache[\"c\"] = 3\n\ntests\\Cachetools\\functional_test.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Cachetools\\cachetools\\cache.py:55: in __setitem__\n    self.popitem(last=False)\ngeneration\\Cachetools\\cachetools\\cache.py:50: in __getitem__\n    return self.__missing__(key)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache(LRUCache([('a', 1), ('c', 3)]), maxsize=2, currsize=3)\nkey = 'b'\n\n    def __missing__(self, key):\n        \"\"\"Called by __getitem__ when a key is not in the cache.\"\"\"\n>       raise KeyError(key)\nE       KeyError: 'b'\n\ngeneration\\Cachetools\\cachetools\\cache.py:30: KeyError\n__________________ test_lru_cache_popitem_removes_one_entry ___________________\n\nself = LRUCache(LRUCache([('a', 1), ('b', 2)]), maxsize=3, currsize=3)\nkey = 'c'\n\n    def __getitem__(self, key):\n        try:\n            value = super().__getitem__(key)\n>           self.move_to_end(key)\nE           KeyError: 'c'\n\ngeneration\\Cachetools\\cachetools\\cache.py:47: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_lru_cache_popitem_removes_one_entry():\n        cache = LRUCache(maxsize=3)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n        cache[\"c\"] = 3\n        assert len(cache) == 3\n    \n>       k, v = cache.popitem()\n\ntests\\Cachetools\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Cachetools\\cachetools\\cache.py:50: in __getitem__\n    return self.__missing__(key)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache(LRUCache([('a', 1), ('b', 2)]), maxsize=3, currsize=3)\nkey = 'c'\n\n    def __missing__(self, key):\n        \"\"\"Called by __getitem__ when a key is not in the cache.\"\"\"\n>       raise KeyError(key)\nE       KeyError: 'c'\n\ngeneration\\Cachetools\\cachetools\\cache.py:30: KeyError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_basic_lru_cache_eviction - K...\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_popitem_removes_one_entry\n2 failed, 11 passed in 2.01s\n", "stdout_sha1": "56afd5ac022fb1da6190f25d7770587042a61669", "stdout_len": 3105, "stdout": "F......F.....                                                            [100%]\n================================== FAILURES ===================================\n________________________ test_basic_lru_cache_eviction ________________________\n\nself = LRUCache(LRUCache([('a', 1), ('c', 3)]), maxsize=2, currsize=3)\nkey = 'b'\n\n    def __getitem__(self, key):\n        try:\n            value = super().__getitem__(key)\n>           self.move_to_end(key)\nE           KeyError: 'b'\n\ngeneration\\Cachetools\\cachetools\\cache.py:47: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_basic_lru_cache_eviction():\n        cache = LRUCache(maxsize=2)\n    \n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n    \n        # Touch \"a\" so it becomes most recently used\n        _ = cache[\"a\"]\n    \n        # Adding \"c\" should evict the least recently used entry (\"b\")\n>       cache[\"c\"] = 3\n\ntests\\Cachetools\\functional_test.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Cachetools\\cachetools\\cache.py:55: in __setitem__\n    self.popitem(last=False)\ngeneration\\Cachetools\\cachetools\\cache.py:50: in __getitem__\n    return self.__missing__(key)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache(LRUCache([('a', 1), ('c', 3)]), maxsize=2, currsize=3)\nkey = 'b'\n\n    def __missing__(self, key):\n        \"\"\"Called by __getitem__ when a key is not in the cache.\"\"\"\n>       raise KeyError(key)\nE       KeyError: 'b'\n\ngeneration\\Cachetools\\cachetools\\cache.py:30: KeyError\n__________________ test_lru_cache_popitem_removes_one_entry ___________________\n\nself = LRUCache(LRUCache([('a', 1), ('b', 2)]), maxsize=3, currsize=3)\nkey = 'c'\n\n    def __getitem__(self, key):\n        try:\n            value = super().__getitem__(key)\n>           self.move_to_end(key)\nE           KeyError: 'c'\n\ngeneration\\Cachetools\\cachetools\\cache.py:47: KeyError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_lru_cache_popitem_removes_one_entry():\n        cache = LRUCache(maxsize=3)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n        cache[\"c\"] = 3\n        assert len(cache) == 3\n    \n>       k, v = cache.popitem()\n\ntests\\Cachetools\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Cachetools\\cachetools\\cache.py:50: in __getitem__\n    return self.__missing__(key)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = LRUCache(LRUCache([('a', 1), ('b', 2)]), maxsize=3, currsize=3)\nkey = 'c'\n\n    def __missing__(self, key):\n        \"\"\"Called by __getitem__ when a key is not in the cache.\"\"\"\n>       raise KeyError(key)\nE       KeyError: 'c'\n\ngeneration\\Cachetools\\cachetools\\cache.py:30: KeyError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_basic_lru_cache_eviction - K...\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_popitem_removes_one_entry\n2 failed, 11 passed in 2.01s\n"}
{"model": "gemini-2.5-pro", "project": "Click", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "__click_params__", "returncode": 1, "elapsed_time_s": 26.940921, "avg_memory_mb": 33.5, "avg_cpu_percent": 0.84, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 01:22:29", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n>       def greet(count: int, name: str) -> None:\n\ntests\\Click\\functional_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:17: in _make_command\n    params.append(Option(['--help'], is_flag=True, help='Show this message and exit.'))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D38F9D30>\nparam_decls = ['--help']\nattrs = {'help': 'Show this message and exit.', 'is_flag': True}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'is_flag'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n>       def cli(flag: bool) -> None:\n\ntests\\Click\\functional_test.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:17: in _make_command\n    params.append(Option(['--help'], is_flag=True, help='Show this message and exit.'))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D3897E80>\nparam_decls = ['--help']\nattrs = {'help': 'Show this message and exit.', 'is_flag': True}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'is_flag'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_group_with_subcommands.<locals>.cli at 0x00000260D38D8700>\nname = 'cli', cls = <class 'click.core.Group'>, attrs = {}, params = []\n\n    def _make_command(f, name, cls, **attrs):\n        if name is None:\n            name = f.__name__.lower().replace('_', '-')\n    \n        # Get params attached by decorators, in reverse order of application\n        params = getattr(f, '__click_params__', [])\n        params.reverse()\n>       delattr(f, '__click_params__')\nE       AttributeError: __click_params__\n\ngeneration\\Click\\click\\decorators.py:13: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    ", "stdout_sha1": "ae610506b14247533965c10851386529dfb8072c", "stdout_len": 12980, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n>       def greet(count: int, name: str) -> None:\n\ntests\\Click\\functional_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:17: in _make_command\n    params.append(Option(['--help'], is_flag=True, help='Show this message and exit.'))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D38F9D30>\nparam_decls = ['--help']\nattrs = {'help': 'Show this message and exit.', 'is_flag': True}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'is_flag'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n>       def cli(flag: bool) -> None:\n\ntests\\Click\\functional_test.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:17: in _make_command\n    params.append(Option(['--help'], is_flag=True, help='Show this message and exit.'))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D3897E80>\nparam_decls = ['--help']\nattrs = {'help': 'Show this message and exit.', 'is_flag': True}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'is_flag'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_group_with_subcommands.<locals>.cli at 0x00000260D38D8700>\nname = 'cli', cls = <class 'click.core.Group'>, attrs = {}, params = []\n\n    def _make_command(f, name, cls, **attrs):\n        if name is None:\n            name = f.__name__.lower().replace('_', '-')\n    \n        # Get params attached by decorators, in reverse order of application\n        params = getattr(f, '__click_params__', [])\n        params.reverse()\n>       delattr(f, '__click_params__')\nE       AttributeError: __click_params__\n\ngeneration\\Click\\click\\decorators.py:13: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_help_output_for_command_and_group.<locals>.cli at 0x00000260D38D8310>\nname = 'cli', cls = <class 'click.core.Group'>\nattrs = {'help': 'Top level group'}, params = []\n\n    def _make_command(f, name, cls, **attrs):\n        if name is None:\n            name = f.__name__.lower().replace('_', '-')\n    \n        # Get params attached by decorators, in reverse order of application\n        params = getattr(f, '__click_params__', [])\n        params.reverse()\n>       delattr(f, '__click_params__')\nE       AttributeError: __click_params__\n\ngeneration\\Click\\click\\decorators.py:13: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:17: in _make_command\n    params.append(Option(['--help'], is_flag=True, help='Show this message and exit.'))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D39B8FA0>\nparam_decls = ['--help']\nattrs = {'help': 'Show this message and exit.', 'is_flag': True}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'is_flag'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n>       def boom() -> None:\n\ntests\\Click\\functional_test.py:244: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_command_exception_is_exposed_in_result.<locals>.boom at 0x00000260D38D8310>\nname = 'boom', cls = <class 'click.core.Command'>, attrs = {}, params = []\n\n    def _make_command(f, name, cls, **attrs):\n        if name is None:\n            name = f.__name__.lower().replace('_', '-')\n    \n        # Get params attached by decorators, in reverse order of application\n        params = getattr(f, '__click_params__', [])\n        params.reverse()\n>       delattr(f, '__click_params__')\nE       AttributeError: __click_params__\n\ngeneration\\Click\\click\\decorators.py:13: AttributeError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n>       def cli(name: str) -> None:\n\ntests\\Click\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:43: in decorator\n    param = param_cls(param_decls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D38F3490>\nparam_decls = ('--name',)\nattrs = {'default': 'fallback', 'envvar': 'CLICK_TEST_NAME'}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n>       def cli(token: str) -> None:\n\ntests\\Click\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:43: in decorator\n    param = param_cls(param_decls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D38E7B50>\nparam_decls = ('--token',), attrs = {'prompt': True}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:291: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_default_map_provides_default_option_value.<locals>.cli at 0x00000260D39A7700>\nname = 'cli', cls = <class 'click.core.Group'>, attrs = {}, params = []\n\n    def _make_command(f, name, cls, **attrs):\n        if name is None:\n            name = f.__name__.lower().replace('_', '-')\n    \n        # Get params attached by decorators, in reverse order of application\n        params = getattr(f, '__click_params__', [])\n        params.reverse()\n>       delattr(f, '__click_params__')\nE       AttributeError: __click_params__\n\ngeneration\\Click\\click\\decorators.py:13: AttributeError\n_______________ test_parameter_type_validation_error_exit_code ________________\n\n    def test_parameter_type_validation_error_exit_code():\n        @click.command()\n        @click.option(\"--count\", type=int, required=True)\n>       def cli(count: int) -> None:\n\ntests\\Click\\functional_test.py:308: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:27: in decorator\n    cmd = _make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:73: in _make_command\n    return original_make_command(f, name, cls, **attrs)\ngeneration\\Click\\click\\decorators.py:17: in _make_command\n    params.append(Option(['--help'], is_flag=True, help='Show this message and exit.'))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000260D38D0160>\nparam_decls = ['--help']\nattrs = {'help': 'Show this message and exit.', 'is_flag': True}\n\n    def __init__(self, param_decls, **attrs):\n>       super(Option, self).__init__(param_decls, **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'is_flag'\n\ngeneration\\Click\\click\\core.py:189: TypeError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - TypeEr...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - Attribut...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_command_exception_is_exposed_in_result\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - T...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n11 failed in 3.96s\n"}
{"model": "gemini-2.5-pro", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "sqlite3.ProgrammingError: Binding 1 has no name, but you supplied a dictionary (which has only names).", "returncode": 1, "elapsed_time_s": 5.145192, "avg_memory_mb": 34.12, "avg_cpu_percent": 98.7, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 01:26:24", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n>       alice = table.find_one(name=\"Alice\")\n\ntests\\Dataset\\functional_test.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:215: in find_one\n    return next(iter(self.find(**filters)))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Database(connection=<sqlite3.Connection object at 0x0000029F82061E40>)>\nsql = 'SELECT * FROM \"users\" WHERE \"name\" = ?', params = {'name': 'Alice'}\ncursor = <sqlite3.Cursor object at 0x0000029F820EC9D0>\n\n    def query(self, sql, **params):\n        \"\"\"\n        Execute a raw SQL query and yield rows as dictionaries.\n    \n        :param sql: The SQL query string.\n        :param params: A dictionary of parameters to bind to the query.\n        \"\"\"\n        cursor = self.conn.cursor()\n>       cursor.execute(sql, params)\nE       sqlite3.ProgrammingError: Binding 1 has no name, but you supplied a dictionary (which has only names).\n\ngeneration\\Dataset\\dataset\\database.py:89: ProgrammingError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n>       updated = table.find_one(account_id=1)\n\ntests\\Dataset\\functional_test.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:215: in find_one\n    return next(iter(self.find(**filters)))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Database(connection=<sqlite3.Connection object at 0x0000029F82061990>)>\nsql = 'SELECT * FROM \"accounts\" WHERE \"account_id\" = ?'\nparams = {'account_id': 1}\ncursor = <sqlite3.Cursor object at 0x0000029F821531F0>\n\n    def query(self, sql, **params):\n        \"\"\"\n        Execute a raw SQL query and yield rows as dictionaries.\n    \n        :param sql: The SQL query string.\n        :param params: A dictionary of parameters to bind to the query.\n        \"\"\"\n        cursor = self.conn.cursor()\n>       cursor.execute(sql, params)\nE       sqlite3.ProgrammingError: Binding 1 has no name, but you supplied a dictionary (which has only names).\n\ngeneration\\Dataset\\dataset\\database.py:89: ProgrammingError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n        db = create_in_memory_db()\n        table = db[\"t\"]\n        table.insert({\"name\": \"only\"})\n>       missing = table.find_one(name=\"absent\")\n\ntests\\Dataset\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:215: in find_one\n    return next(iter(self.find(**filters)))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _", "stdout_sha1": "1bd18abd45156bea198c51ace3d2fde2e9f82d25", "stdout_len": 7060, "stdout": "FF..FF..F..                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n>       alice = table.find_one(name=\"Alice\")\n\ntests\\Dataset\\functional_test.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:215: in find_one\n    return next(iter(self.find(**filters)))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Database(connection=<sqlite3.Connection object at 0x0000029F82061E40>)>\nsql = 'SELECT * FROM \"users\" WHERE \"name\" = ?', params = {'name': 'Alice'}\ncursor = <sqlite3.Cursor object at 0x0000029F820EC9D0>\n\n    def query(self, sql, **params):\n        \"\"\"\n        Execute a raw SQL query and yield rows as dictionaries.\n    \n        :param sql: The SQL query string.\n        :param params: A dictionary of parameters to bind to the query.\n        \"\"\"\n        cursor = self.conn.cursor()\n>       cursor.execute(sql, params)\nE       sqlite3.ProgrammingError: Binding 1 has no name, but you supplied a dictionary (which has only names).\n\ngeneration\\Dataset\\dataset\\database.py:89: ProgrammingError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n>       updated = table.find_one(account_id=1)\n\ntests\\Dataset\\functional_test.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:215: in find_one\n    return next(iter(self.find(**filters)))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Database(connection=<sqlite3.Connection object at 0x0000029F82061990>)>\nsql = 'SELECT * FROM \"accounts\" WHERE \"account_id\" = ?'\nparams = {'account_id': 1}\ncursor = <sqlite3.Cursor object at 0x0000029F821531F0>\n\n    def query(self, sql, **params):\n        \"\"\"\n        Execute a raw SQL query and yield rows as dictionaries.\n    \n        :param sql: The SQL query string.\n        :param params: A dictionary of parameters to bind to the query.\n        \"\"\"\n        cursor = self.conn.cursor()\n>       cursor.execute(sql, params)\nE       sqlite3.ProgrammingError: Binding 1 has no name, but you supplied a dictionary (which has only names).\n\ngeneration\\Dataset\\dataset\\database.py:89: ProgrammingError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n        db = create_in_memory_db()\n        table = db[\"t\"]\n        table.insert({\"name\": \"only\"})\n>       missing = table.find_one(name=\"absent\")\n\ntests\\Dataset\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:215: in find_one\n    return next(iter(self.find(**filters)))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Database(connection=<sqlite3.Connection object at 0x0000029F82061D50>)>\nsql = 'SELECT * FROM \"t\" WHERE \"name\" = ?', params = {'name': 'absent'}\ncursor = <sqlite3.Cursor object at 0x0000029F821536C0>\n\n    def query(self, sql, **params):\n        \"\"\"\n        Execute a raw SQL query and yield rows as dictionaries.\n    \n        :param sql: The SQL query string.\n        :param params: A dictionary of parameters to bind to the query.\n        \"\"\"\n        cursor = self.conn.cursor()\n>       cursor.execute(sql, params)\nE       sqlite3.ProgrammingError: Binding 1 has no name, but you supplied a dictionary (which has only names).\n\ngeneration\\Dataset\\dataset\\database.py:89: ProgrammingError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n>       rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n\ntests\\Dataset\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Database(connection=<sqlite3.Connection object at 0x0000029F82061C60>)>\nsql = 'SELECT * FROM \"nums\" WHERE \"order_by\" = ? AND \"_limit\" = ? AND \"_offset\" = ?'\nparams = {'_limit': 3, '_offset': 4, 'order_by': 'n'}\ncursor = <sqlite3.Cursor object at 0x0000029F820EC9D0>\n\n    def query(self, sql, **params):\n        \"\"\"\n        Execute a raw SQL query and yield rows as dictionaries.\n    \n        :param sql: The SQL query string.\n        :param params: A dictionary of parameters to bind to the query.\n        \"\"\"\n        cursor = self.conn.cursor()\n>       cursor.execute(sql, params)\nE       sqlite3.ProgrammingError: Binding 1 has no name, but you supplied a dictionary (which has only names).\n\ngeneration\\Dataset\\dataset\\database.py:89: ProgrammingError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<Database(connection=<sqlite3.Connection object at 0x0000029F82061A80>)>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - sql...\nFAILED tests/Dataset/functional_test.py::test_find_one_missing_returns_none\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\n5 failed, 6 passed in 3.78s\n"}
{"model": "gemini-2.5-pro", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "NameError", "exception_msg": "name 'TileLayer' is not defined", "returncode": 1, "elapsed_time_s": 2.099642, "avg_memory_mb": 32.67, "avg_cpu_percent": 100.45, "passed": 4, "failed": 8, "skipped": 0, "total": 12, "functional_score": 0.3333, "timestamp": "2026-01-01 01:35:28", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:46: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85756A0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85AACD0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85FF2B0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:79: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF8601B50>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n ", "stdout_sha1": "e9e7a9259944f64cec1a3a7cf1ad64053681f925", "stdout_len": 10793, "stdout": "..FFFF.FFF.F                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:46: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85756A0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85AACD0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:66: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85FF2B0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:79: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF8601B50>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:114: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF6F7F730>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:140: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85A3A00>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-383/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:152: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF859C8B0>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n>       m = folium.Map(location=[0, 0], zoom_start=2)\n\ntests\\Folium\\functional_test.py:173: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.map.Map object at 0x000001DCF85EB160>, location = [0, 0]\nzoom_start = 2, tiles = 'OpenStreetMap', kwargs = {}\n\n    def __init__(self, location=None, zoom_start=10, tiles=\"OpenStreetMap\", **kwargs):\n        super().__init__()\n        self._name = \"map\"\n        self.location = location if location is not None else [0, 0]\n        self.zoom_start = zoom_start\n        self.js = []\n        self.css = []\n    \n        # Add default Leaflet JS/CSS\n        self.js.append((\"leaflet\", templates.LEAFLET_JS))\n        self.css.append((\"leaflet\", templates.LEAFLET_CSS))\n    \n        if tiles:\n>           self.add_child(TileLayer(tiles))\nE           NameError: name 'TileLayer' is not defined\n\ngeneration\\Folium\\folium\\map.py:97: NameError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root - NameErro...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - NameE...\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n8 failed, 4 passed in 0.70s\n"}
{"model": "gemini-2.5-pro", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '1 second' in '1 hour, 1 minute, and 1.00 second'", "returncode": 1, "elapsed_time_s": 1.864399, "avg_memory_mb": 31.92, "avg_cpu_percent": 98.2, "passed": 8, "failed": 2, "skipped": 5, "total": 15, "functional_score": 0.5333, "timestamp": "2026-01-01 01:38:28", "stdout_excerpt": "==== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n        d = humanize.precisedelta(3661)  # seconds\n        assert \"1 hour\" in d\n        assert \"1 minute\" in d\n>       assert \"1 second\" in d\nE       AssertionError: assert '1 second' in '1 hour, 1 minute, and 1.00 second'\n\ntests\\Humanize\\functional_test.py:115: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - Asserti...\n2 failed, 8 passed, 5 skipped in 0.51s\n", "stdout_sha1": "87c40a8fb7de2657cc6b45c8130d5afa3a560343", "stdout_len": 1208, "stdout": "..FF......sssss                                                          [100%]\n================================== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n        d = humanize.precisedelta(3661)  # seconds\n        assert \"1 hour\" in d\n        assert \"1 minute\" in d\n>       assert \"1 second\" in d\nE       AssertionError: assert '1 second' in '1 hour, 1 minute, and 1.00 second'\n\ntests\\Humanize\\functional_test.py:115: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - Asserti...\n2 failed, 8 passed, 5 skipped in 0.51s\n"}
{"model": "gemini-2.5-pro", "project": "Loguru", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "ValueError", "exception_msg": "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)", "returncode": 1, "elapsed_time_s": 1.933372, "avg_memory_mb": 33.23, "avg_cpu_percent": 98.3, "passed": 5, "failed": 6, "skipped": 0, "total": 11, "functional_score": 0.4545, "timestamp": "2026-01-01 01:53:33", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n>       log.log(\"INFO\", \"hello-info\")\nE       AttributeError: 'Logger' object has no attribute 'log'\n\ntests\\Loguru\\functional_test.py:125: AttributeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-386/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n        logger.remove()\n>       logger.add(log_path, format=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <loguru._logger.Logger object at 0x00000252BFF1EFD0>\nsink = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-386/test_add_file_sink_writes_line0/loguru_test.log')\nlevel = 'INFO', format = '{level}:{message}', filter = None, kwargs = {}\nlevel_no = 20, writer = None\n\n    def add(self, sink, *, level=\"DEBUG\", format=\"{message}\\n\", filter=None, **kwargs):\n        level_no = self._level_name_to_no[level].no if isinstance(level, str) else level\n    \n        writer = None\n        if isinstance(sink, str):\n            writer = open(sink, \"a\", encoding=\"utf-8\")\n        elif hasattr(sink, 'write'):\n            writer = sink\n        elif callable(sink):\n            # For callable sinks, the writer is a wrapper\n            writer = lambda msg: sink(msg)\n    \n        if writer is None:\n>           raise ValueError(\"Invalid sink specified\")\nE           ValueError: Invalid sink specified\n\ngeneration\\Loguru\\loguru\\_logger.py:168: ValueError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x00000252BDD4BCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\j", "stdout_sha1": "8df5832c3aa44a7847fad5dfff51d9a4d126860c", "stdout_len": 5766, "stdout": "..F.F.FFF.F                                                              [100%]\n================================== FAILURES ===================================\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n>       log.log(\"INFO\", \"hello-info\")\nE       AttributeError: 'Logger' object has no attribute 'log'\n\ntests\\Loguru\\functional_test.py:125: AttributeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-386/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n        logger.remove()\n>       logger.add(log_path, format=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <loguru._logger.Logger object at 0x00000252BFF1EFD0>\nsink = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-386/test_add_file_sink_writes_line0/loguru_test.log')\nlevel = 'INFO', format = '{level}:{message}', filter = None, kwargs = {}\nlevel_no = 20, writer = None\n\n    def add(self, sink, *, level=\"DEBUG\", format=\"{message}\\n\", filter=None, **kwargs):\n        level_no = self._level_name_to_no[level].no if isinstance(level, str) else level\n    \n        writer = None\n        if isinstance(sink, str):\n            writer = open(sink, \"a\", encoding=\"utf-8\")\n        elif hasattr(sink, 'write'):\n            writer = sink\n        elif callable(sink):\n            # For callable sinks, the writer is a wrapper\n            writer = lambda msg: sink(msg)\n    \n        if writer is None:\n>           raise ValueError(\"Invalid sink specified\")\nE           ValueError: Invalid sink specified\n\ngeneration\\Loguru\\loguru\\_logger.py:168: ValueError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x00000252BDD4BCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\ntests\\Loguru\\functional_test.py:211: AttributeError\n____________________ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format() -> None:\n        # Default format should include some timestamp-like content, level, and message.\n        buf = io.StringIO()\n        logger.remove()\n        logger.add(buf)\n    \n        logger.info(\"default-format-test\")\n    \n        output = buf.getvalue()\n>       assert \"INFO\" in output\nE       AssertionError: assert 'INFO' in 'default-format-test\\n'\n\ntests\\Loguru\\functional_test.py:243: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Att...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Val...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n6 failed, 5 passed in 0.56s\n"}
{"model": "gemini-2.5-pro", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 1.948102, "avg_memory_mb": 31.96, "avg_cpu_percent": 98.3, "passed": 7, "failed": 4, "skipped": 0, "total": 11, "functional_score": 0.6364, "timestamp": "2026-01-01 02:03:23", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n4 failed, 7 passed in 0.59s\n", "stdout_sha1": "b8b23caa770543c57b2ee4c71d2ee22351ecfd01", "stdout_len": 3587, "stdout": ".....F..FFF                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n4 failed, 7 passed in 0.59s\n"}
{"model": "gemini-2.5-pro", "project": "Pendulum", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.500442, "avg_memory_mb": 31.38, "avg_cpu_percent": 101.2, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 02:11:25", "stdout_excerpt": "\n1 skipped in 0.19s\n", "stdout_sha1": "defdb7f46dcd131fbdba9b7d779dbe0528dfb2bd", "stdout_len": 20, "stdout": "\n1 skipped in 0.19s\n"}
{"model": "gemini-2.5-pro", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.918454, "avg_memory_mb": 32.98, "avg_cpu_percent": 100.9, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 02:25:31", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        \"\"\"\n        Encodes a payload into a JSON Web Token (JWT).\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported\")\nE           NotImplementedError: Only HS256 algorithm is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:36: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:46: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001DBD19C6B80>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:46: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Pyth", "stdout_sha1": "b6487ac898b51aa2efc5144fbb1e2c1e0e49cdc3", "stdout_len": 6564, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        \"\"\"\n        Encodes a payload into a JSON Web Token (JWT).\n        \"\"\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported\")\nE           NotImplementedError: Only HS256 algorithm is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:36: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:46: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001DBD19C6B80>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:46: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001DBD19E5D90>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.58s\n"}
{"model": "gemini-2.5-pro", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'this-is-a-test' in '___thisisatest___'", "returncode": 1, "elapsed_time_s": 1.761509, "avg_memory_mb": 31.83, "avg_cpu_percent": 98.1, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 02:48:00", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.46s\n", "stdout_sha1": "4a13c6b360d2717657a7a8398973608a5efac044", "stdout_len": 956, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.46s\n"}
{"model": "gemini-2.5-pro", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "+  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode", "returncode": 1, "elapsed_time_s": 3.719603, "avg_memory_mb": 31.68, "avg_cpu_percent": 49.4, "passed": 7, "failed": 2, "skipped": 0, "total": 9, "functional_score": 0.7778, "timestamp": "2026-01-01 02:49:29", "stdout_excerpt": "==== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000001E23BE399D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: python sqlmap.py [options]\\nsqlmap.py: error: unrecognized argument: --batch\\n')\nE        +    where <function search at 0x000001E23BE399D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n2 failed, 7 passed in 2.00s\n", "stdout_sha1": "a75376ed180a489933e4e100badde3ab5fd0584c", "stdout_len": 2309, "stdout": "....F...F                                                                [100%]\n================================== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000001E23BE399D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: python sqlmap.py [options]\\nsqlmap.py: error: unrecognized argument: --batch\\n')\nE        +    where <function search at 0x000001E23BE399D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n2 failed, 7 passed in 2.00s\n"}
{"model": "gemini-2.5-pro", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "pydantic is required to use this mock sqlmodel. Please `pip install pydantic`.", "returncode": 2, "elapsed_time_s": 2.128819, "avg_memory_mb": 40.93, "avg_cpu_percent": 98.5, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 02:51:36", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ngeneration\\SQLModel\\sqlmodel\\__init__.py:11: in <module>\n    from pydantic.fields import FieldInfo, Undefined\nE   ImportError: cannot import name 'Undefined' from 'pydantic.fields' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\fields.py)\n\nDuring handling of the above exception, another exception occurred:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:14: in <module>\n    raise ImportError(\"pydantic is required to use this mock sqlmodel. Please `pip install pydantic`.\")\nE   ImportError: pydantic is required to use this mock sqlmodel. Please `pip install pydantic`.\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.78s\n", "stdout_sha1": "62753f459e94dc387fa42d46b0f0e47ab89fd691", "stdout_len": 1443, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\ngeneration\\SQLModel\\sqlmodel\\__init__.py:11: in <module>\n    from pydantic.fields import FieldInfo, Undefined\nE   ImportError: cannot import name 'Undefined' from 'pydantic.fields' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\fields.py)\n\nDuring handling of the above exception, another exception occurred:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:14: in <module>\n    raise ImportError(\"pydantic is required to use this mock sqlmodel. Please `pip install pydantic`.\")\nE   ImportError: pydantic is required to use this mock sqlmodel. Please `pip install pydantic`.\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.78s\n"}
{"model": "gemini-2.5-pro", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "The length of the bit list must be a multiple of 8.", "returncode": 124, "elapsed_time_s": 60.073578, "avg_memory_mb": 41.73, "avg_cpu_percent": 0.21, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 02:54:44", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-387\\\\test_lsb_hide_and_reveal_text0\\\\lsb_lenna.png'\ngenerator = None, shift = 0, encoding = 'UTF-8'\n\n    def reveal(image, generator=None, shift=0, encoding=\"UTF-8\"):\n        \"\"\"\n        Reveals a message hidden in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        pixel_gen = _get_pixel_generator(img, generator, shift)\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for x, y in pixel_gen:\n            pixel = pixels[x, y]\n            for i in range(3): # R, G, B channels\n                extracted_bits.append(pixel[i] & 1)\n                if len(extracted_bits) >= 8 and extracted_bits[-8:] == utils.DELIMITER:\n                    delimiter_found = True\n                    break\n            if delimiter_found:\n                break\n    \n        if not delimiter_found:\n            raise ValueError(\"No hidden message found or delimiter is missing.\")\n    \n        # Remove the delimiter\n        message_bits = extracted_bits[:-8]\n    \n        try:\n>           message_bytes = utils.bits_to_bytes(message_bits)\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nbit_list = [0, 1, 1, 0, 1, 0, ...]\n\n    def bits_to_bytes(bit_list):\n        \"\"\"Convert a list of bits to a byte string.\"\"\"\n        if len(bit_list) % 8 != 0:\n>           raise ValueError(\"The length of the bit list must be a multiple of 8.\")\nE           ValueError: The length of the bit list must be a multiple of 8.\n\ngeneration\\Stegano\\stegano\\tools\\utils.py:11: ValueError\n\nThe above exception was the direct cause of the following exception:\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-387/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n>       revealed = lsb.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:93: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-387\\\\test_lsb_hide_and_reveal_text0\\\\lsb_lenna.png'\ngenerator = None, shift = 0, encoding = 'UTF-8'\n\n    def reveal(image, generator=None, shift=0, encoding=\"UTF-8\"):\n        \"\"\"\n        Reveals a message hidden in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        pixel_gen = _get_pixel_generator(img, generator, shift)\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for x, y in pixel_gen:\n            pixel = pixels[x, y]\n            for i in range(3): # R, G, B channels\n                extracted_bits.append(pixel[i] & 1)\n", "stdout_sha1": "a4218eba7ef8e5e69cc2f51c1fd3e7ec80b49781", "stdout_len": 18770, "stdout": "FF.FFF..F.F.                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-387\\\\test_lsb_hide_and_reveal_text0\\\\lsb_lenna.png'\ngenerator = None, shift = 0, encoding = 'UTF-8'\n\n    def reveal(image, generator=None, shift=0, encoding=\"UTF-8\"):\n        \"\"\"\n        Reveals a message hidden in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        pixel_gen = _get_pixel_generator(img, generator, shift)\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for x, y in pixel_gen:\n            pixel = pixels[x, y]\n            for i in range(3): # R, G, B channels\n                extracted_bits.append(pixel[i] & 1)\n                if len(extracted_bits) >= 8 and extracted_bits[-8:] == utils.DELIMITER:\n                    delimiter_found = True\n                    break\n            if delimiter_found:\n                break\n    \n        if not delimiter_found:\n            raise ValueError(\"No hidden message found or delimiter is missing.\")\n    \n        # Remove the delimiter\n        message_bits = extracted_bits[:-8]\n    \n        try:\n>           message_bytes = utils.bits_to_bytes(message_bits)\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nbit_list = [0, 1, 1, 0, 1, 0, ...]\n\n    def bits_to_bytes(bit_list):\n        \"\"\"Convert a list of bits to a byte string.\"\"\"\n        if len(bit_list) % 8 != 0:\n>           raise ValueError(\"The length of the bit list must be a multiple of 8.\")\nE           ValueError: The length of the bit list must be a multiple of 8.\n\ngeneration\\Stegano\\stegano\\tools\\utils.py:11: ValueError\n\nThe above exception was the direct cause of the following exception:\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-387/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n>       revealed = lsb.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:93: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-387\\\\test_lsb_hide_and_reveal_text0\\\\lsb_lenna.png'\ngenerator = None, shift = 0, encoding = 'UTF-8'\n\n    def reveal(image, generator=None, shift=0, encoding=\"UTF-8\"):\n        \"\"\"\n        Reveals a message hidden in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        pixel_gen = _get_pixel_generator(img, generator, shift)\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for x, y in pixel_gen:\n            pixel = pixels[x, y]\n            for i in range(3): # R, G, B channels\n                extracted_bits.append(pixel[i] & 1)\n                if len(extracted_bits) >= 8 and extracted_bits[-8:] == utils.DELIMITER:\n                    delimiter_found = True\n                    break\n            if delimiter_found:\n                break\n    \n        if not delimiter_found:\n            raise ValueError(\"No hidden message found or delimiter is missing.\")\n    \n        # Remove the delimiter\n        message_bits = extracted_bits[:-8]\n    \n        try:\n            message_bytes = utils.bits_to_bytes(message_bits)\n            return message_bytes.decode(encoding)\n        except UnicodeDecodeError as e:\n            raise ValueError(\"Failed to decode message. The encoding might be incorrect.\") from e\n        except ValueError as e:\n            # This can happen if bits_to_bytes gets a non-multiple of 8 length\n>           raise ValueError(\"Failed to reconstruct message from bits. Data may be corrupt.\") from e\nE           ValueError: Failed to reconstruct message from bits. Data may be corrupt.\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:117: ValueError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x0000016F417C5900>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        \"\"\"\n        Hides a message in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode != 'RGB' and auto_convert_rgb:\n            img = img.convert('RGB')\n        elif img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        new_img = img.copy()\n        pixels = new_img.load()\n    \n        message_bits = utils.get_bit_generator(message, encoding)\n        pixel_gen = _get_pixel_generator(new_img, generator, shift)\n    \n        try:\n>           for x, y in pixel_gen:\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimg = <PIL.Image.Image image mode=RGB size=512x512 at 0x16F417CB310>\ngenerator = <generator object eratosthenes at 0x0000016F417C5900>, shift = 0\n\n    def _get_pixel_generator(img, generator=None, shift=0):\n        \"\"\"\n        Returns a generator for pixel coordinates (x, y).\n        If a generator is provided, it yields indices which are then converted to (x, y).\n        Otherwise, it yields sequential (x, y) coordinates.\n        \"\"\"\n        width, height = img.size\n        max_pixels = width * height\n    \n        if generator:\n            # Use the provided prime number generator\n            # Skip 'shift' number of primes\n>           gen = itertools.islice(generator(), shift, None)\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:19: TypeError\n\nThe above exception was the direct cause of the following exception:\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-387/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x0000016F417C5900>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        \"\"\"\n        Hides a message in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode != 'RGB' and auto_convert_rgb:\n            img = img.convert('RGB')\n        elif img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        new_img = img.copy()\n        pixels = new_img.load()\n    \n        message_bits = utils.get_bit_generator(message, encoding)\n        pixel_gen = _get_pixel_generator(new_img, generator, shift)\n    \n        try:\n            for x, y in pixel_gen:\n                pixel = list(pixels[x, y])\n                for i in range(3): # R, G, B channels\n                    try:\n                        bit = next(message_bits)\n                        pixel[i] = (pixel[i] & 0xFE) | bit\n                    except StopIteration:\n                        # No more bits to hide\n                        pixels[x, y] = tuple(pixel)\n                        return new_img\n                pixels[x, y] = tuple(pixel)\n        except Exception as e:\n>           raise ValueError(\"The message is too long to be hidden in the image.\") from e\nE           ValueError: The message is too long to be hidden in the image.\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:67: ValueError\n______________________ test_lsb_reveal_from_image_object ______________________\n\nimage = <PIL.Image.Image image mode=RGB size=512x512 at 0x16F41237A60>\ngenerator = None, shift = 0, encoding = 'UTF-8'\n\n    def reveal(image, generator=None, shift=0, encoding=\"UTF-8\"):\n        \"\"\"\n        Reveals a message hidden in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        pixel_gen = _get_pixel_generator(img, generator, shift)\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for x, y in pixel_gen:\n            pixel = pixels[x, y]\n            for i in range(3): # R, G, B channels\n                extracted_bits.append(pixel[i] & 1)\n                if len(extracted_bits) >= 8 and extracted_bits[-8:] == utils.DELIMITER:\n                    delimiter_found = True\n                    break\n            if delimiter_found:\n                break\n    \n        if not delimiter_found:\n            raise ValueError(\"No hidden message found or delimiter is missing.\")\n    \n        # Remove the delimiter\n        message_bits = extracted_bits[:-8]\n    \n        try:\n>           message_bytes = utils.bits_to_bytes(message_bits)\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nbit_list = [0, 1, 1, 0, 1, 1, ...]\n\n    def bits_to_bytes(bit_list):\n        \"\"\"Convert a list of bits to a byte string.\"\"\"\n        if len(bit_list) % 8 != 0:\n>           raise ValueError(\"The length of the bit list must be a multiple of 8.\")\nE           ValueError: The length of the bit list must be a multiple of 8.\n\ngeneration\\Stegano\\stegano\\tools\\utils.py:11: ValueError\n\nThe above exception was the direct cause of the following exception:\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n        img_obj = lsb.hide(str(LENNA_PNG), secret)\n>       revealed = lsb.reveal(img_obj)\n\ntests\\Stegano\\functional_test.py:133: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = <PIL.Image.Image image mode=RGB size=512x512 at 0x16F41237A60>\ngenerator = None, shift = 0, encoding = 'UTF-8'\n\n    def reveal(image, generator=None, shift=0, encoding=\"UTF-8\"):\n        \"\"\"\n        Reveals a message hidden in the LSB of an image.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        pixel_gen = _get_pixel_generator(img, generator, shift)\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for x, y in pixel_gen:\n            pixel = pixels[x, y]\n            for i in range(3): # R, G, B channels\n                extracted_bits.append(pixel[i] & 1)\n                if len(extracted_bits) >= 8 and extracted_bits[-8:] == utils.DELIMITER:\n                    delimiter_found = True\n                    break\n            if delimiter_found:\n                break\n    \n        if not delimiter_found:\n            raise ValueError(\"No hidden message found or delimiter is missing.\")\n    \n        # Remove the delimiter\n        message_bits = extracted_bits[:-8]\n    \n        try:\n            message_bytes = utils.bits_to_bytes(message_bits)\n            return message_bytes.decode(encoding)\n        except UnicodeDecodeError as e:\n            raise ValueError(\"Failed to decode message. The encoding might be incorrect.\") from e\n        except ValueError as e:\n            # This can happen if bits_to_bytes gets a non-multiple of 8 length\n>           raise ValueError(\"Failed to reconstruct message from bits. Data may be corrupt.\") from e\nE           ValueError: Failed to reconstruct message from bits. Data may be corrupt.\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:117: ValueError\n________________________ test_red_hide_and_reveal_text ________________________\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-387\\\\test_red_hide_and_reveal_text0\\\\red_lenna.png'\n\n    def reveal(image):\n        \"\"\"\n        Reveals a message hidden in the LSB of the red channel of an image.\n        \"\"\"\n        encoding = \"UTF-8\" # Default encoding\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        width, height = img.size\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for y in range(height):\n            for x in range(width):\n                pixel = pixels[x, y]\n                extracted_bits.append(pixel[0] & 1)\n    \n                if len(extracted_bits) >= 8 and extracted_bits[-8:] == utils.DELIMITER:\n                    delimiter_found = True\n                    break\n            if delimiter_found:\n                break\n    \n        if not delimiter_found:\n            raise ValueError(\"No hidden message found or delimiter is missing.\")\n    \n        message_bits = extracted_bits[:-8]\n    \n        try:\n>           message_bytes = utils.bits_to_bytes(message_bits)\n\ngeneration\\Stegano\\stegano\\red\\red.py:84: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nbit_list = [0, 1, 1, 1, 0, 0, ...]\n\n    def bits_to_bytes(bit_list):\n        \"\"\"Convert a list of bits to a byte string.\"\"\"\n        if len(bit_list) % 8 != 0:\n>           raise ValueError(\"The length of the bit list must be a multiple of 8.\")\nE           ValueError: The length of the bit list must be a multiple of 8.\n\ngeneration\\Stegano\\stegano\\tools\\utils.py:11: ValueError\n\nThe above exception was the direct cause of the following exception:\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-387/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n        encoded_img = red.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n>       revealed = red.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-387\\\\test_red_hide_and_reveal_text0\\\\red_lenna.png'\n\n    def reveal(image):\n        \"\"\"\n        Reveals a message hidden in the LSB of the red channel of an image.\n        \"\"\"\n        encoding = \"UTF-8\" # Default encoding\n        if not isinstance(image, Image.Image):\n            try:\n                img = Image.open(image)\n            except Exception as e:\n                raise TypeError(\"The 'image' parameter must be a PIL.Image.Image object or a file path.\") from e\n        else:\n            img = image\n    \n        if img.mode not in ['RGB', 'RGBA']:\n            raise ValueError(\"Steganography is only supported for RGB or RGBA images.\")\n    \n        pixels = img.load()\n        width, height = img.size\n    \n        extracted_bits = []\n        delimiter_found = False\n    \n        for y in range(height):\n            for x in range(width):\n                pixel = pixels[x, y]\n                extracted_bits.append(pixel[0] & 1)\n    \n                if len(extracted_bits) >= 8 and extracted_bits[-8:] == utils.DELIMITER:\n                    delimiter_found = True\n                    break\n            if delimiter_found:\n                break\n    \n        if not delimiter_found:\n            raise ValueError(\"No hidden message found or delimiter is missing.\")\n    \n        message_bits = extracted_bits[:-8]\n    \n"}
{"model": "gemini-2.5-pro", "project": "Tablib", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "NotImplementedError", "exception_msg": "Format 'html' is not supported for export.", "returncode": 1, "elapsed_time_s": 2.37908, "avg_memory_mb": 32.27, "avg_cpu_percent": 25.38, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2026-01-01 02:56:25", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E57C28E280>, fmt = 'tsv'\n\n    def export(self, fmt):\n        fmt = fmt.lower()\n        if fmt == 'csv':\n            from .formats import _csv\n            return _csv.export_set(self)\n        elif fmt == 'json':\n            from .formats import _json\n            return _json.export_set(self)\n        else:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported for export.\")\nE           NotImplementedError: Format 'tsv' is not supported for export.\n\ngeneration\\Tablib\\tablib\\core.py:96: NotImplementedError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E57C25A910>, fmt = 'html'\n\n    def export(self, fmt):\n        fmt = fmt.lower()\n        if fmt == 'csv':\n            from .formats import _csv\n            return _csv.export_set(self)\n        elif fmt == 'json':\n            from .formats import _json\n            return _json.export_set(self)\n        else:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported for export.\")\nE           NotImplementedError: Format 'html' is not supported for export.\n\ngeneration\\Tablib\\tablib\\core.py:96: NotImplementedError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.55s\n", "stdout_sha1": "650ad555fb0f9de20d363903cda743a8ca50e520", "stdout_len": 3306, "stdout": ".F..F...F..                                                              [100%]\n================================== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E57C28E280>, fmt = 'tsv'\n\n    def export(self, fmt):\n        fmt = fmt.lower()\n        if fmt == 'csv':\n            from .formats import _csv\n            return _csv.export_set(self)\n        elif fmt == 'json':\n            from .formats import _json\n            return _json.export_set(self)\n        else:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported for export.\")\nE           NotImplementedError: Format 'tsv' is not supported for export.\n\ngeneration\\Tablib\\tablib\\core.py:96: NotImplementedError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E57C25A910>, fmt = 'html'\n\n    def export(self, fmt):\n        fmt = fmt.lower()\n        if fmt == 'csv':\n            from .formats import _csv\n            return _csv.export_set(self)\n        elif fmt == 'json':\n            from .formats import _json\n            return _json.export_set(self)\n        else:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported for export.\")\nE           NotImplementedError: Format 'html' is not supported for export.\n\ngeneration\\Tablib\\tablib\\core.py:96: NotImplementedError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.55s\n"}
{"model": "gemini-2.5-pro", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "All data series must have the same length as the labels list.", "returncode": 1, "elapsed_time_s": 25.370243, "avg_memory_mb": 33.03, "avg_cpu_percent": 0.64, "passed": 2, "failed": 9, "skipped": 0, "total": 11, "functional_score": 0.1818, "timestamp": "2026-01-01 03:07:03", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E11280>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E11430>\ndata = [[3], [5], [2]], labels = ['A', 'B', 'C']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E00700>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E005B0>, data = [[4], [1]]\nlabels = ['D', 'E']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E7F970>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E7F9D0>, data = [[2], [7]]\nlabels = ['A', 'B']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data p", "stdout_sha1": "051658950c529c211e2fa3a888f032aca73a8948", "stdout_len": 15130, "stdout": "F.FFFFFFFF.                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E11280>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E11430>\ndata = [[3], [5], [2]], labels = ['A', 'B', 'C']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E00700>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E005B0>, data = [[4], [1]]\nlabels = ['D', 'E']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E7F970>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E7F9D0>, data = [[2], [7]]\nlabels = ['A', 'B']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779DFA520>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779DFA9D0>\ndata = [[1], [2], [3]], labels = ['L1', 'L2', 'L3']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E7E460>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E7E8E0>\ndata = [[12.5], [7.0]], labels = ['CPU', 'RAM']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779DDE5E0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779DDEB20>\ndata = [[3.14159], [2.71828]], labels = ['P', 'Q']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E045B0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E04D60>\ndata = [[1, 1], [2, 1], [1, 3]], labels = ['S1', 'S2', 'S3']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E733D0>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E73CA0>\ndata = [[1, 2, 3], [3, 2, 1]], labels = ['A', 'B']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000022779E00F70>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x0000022779E00820>, data = [[4], [6]]\nlabels = ['U', 'V']\n\n    def __init__(self, data, labels):\n        \"\"\"\n        Initializes the Data object.\n    \n        Args:\n            data (list of list of floats): The numeric data series.\n                Example: [[10, 20, 30], [5, 15, 25]]\n            labels (list of str): The labels for each data point.\n                Example: ['A', 'B', 'C']\n        \"\"\"\n        if not isinstance(data, list) or not all(isinstance(s, list) for s in data):\n            raise TypeError(\"data must be a list of lists\")\n        if not isinstance(labels, list) or not all(isinstance(l, str) for l in labels):\n            raise TypeError(\"labels must be a list of strings\")\n    \n        num_points = len(labels)\n        for s in data:\n            if len(s) != num_points:\n>               raise ValueError(\"All data series must have the same length as the labels list.\")\nE               ValueError: All data series must have the same length as the labels list.\n\ngeneration\\Termgraph\\termgraph\\data.py:24: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\n9 failed, 2 passed in 0.64s\n"}
{"model": "gemini-2.5-pro", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 2.027687, "avg_memory_mb": 35.98, "avg_cpu_percent": 97.6, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 03:11:02", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.70s\n", "stdout_sha1": "35a02dff0ed7dd3498914c8d80f0685b9b5a153b", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.70s\n"}
{"model": "gemini-2.5-pro", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.939758, "avg_memory_mb": 36.23, "avg_cpu_percent": 98.3, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 03:21:40", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n", "stdout_sha1": "d4bb50f171ace793db32b44ef1161ab7b4cfaad5", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ImportError", "exception_msg": "cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)", "returncode": 1, "elapsed_time_s": 1.641349, "avg_memory_mb": 32.74, "avg_cpu_percent": 100.0, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2026-01-01 19:49:11", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.add\")\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_002_create_app_and_register_task_runs_delay.<locals>.add at 0x000001ADC41099D0>\n\n    def decorator(func):\n        base = opts.pop('base', Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.mul\")\n>       def mul(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager.<locals>.mul at 0x000001ADC41098B0>\n\n    def decorator(func):\n        base = opts.pop('base', Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n        app = _make_app()\n>       from celery import group\nE       ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:90: ImportError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n        app = _make_app()\n>       from celery import chain\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:104: ImportError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n        app = _make_app()\n>       from celery import chord, group\nE       ImportError: cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:117: ImportError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n ", "stdout_sha1": "9f0ea384348e66b7e128765994236cdeb1a7aef7", "stdout_len": 7814, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.add\")\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_002_create_app_and_register_task_runs_delay.<locals>.add at 0x000001ADC41099D0>\n\n    def decorator(func):\n        base = opts.pop('base', Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.mul\")\n>       def mul(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager.<locals>.mul at 0x000001ADC41098B0>\n\n    def decorator(func):\n        base = opts.pop('base', Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n        app = _make_app()\n>       from celery import group\nE       ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:90: ImportError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n        app = _make_app()\n>       from celery import chain\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:104: ImportError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n        app = _make_app()\n>       from celery import chord, group\nE       ImportError: cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:117: ImportError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n        app = _make_app()\n    \n        @app.task(name=\"celery_test.boom\")\n>       def boom() -> None:\n\ntests\\Celery\\functional_test.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_007_task_exception_propagates_in_eager_mode.<locals>.boom at 0x000001ADC40973A0>\n\n    def decorator(func):\n        base = opts.pop('base', Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n        app = _make_app()\n>       app.conf.task_eager_propagates = False\nE       AttributeError: 'dict' object has no attribute 'task_eager_propagates'\n\ntests\\Celery\\functional_test.py:166: AttributeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n        app = _make_app()\n>       from celery import signature\nE       ImportError: cannot import name 'signature' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:191: ImportError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n        app = _make_app(\"celery_test_app_2\")\n    \n        @app.task(name=\"celery_test_app_2.add\")\n>       def add(x: int, y: int) -> int:\n\ntests\\Celery\\functional_test.py:210: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfunc = <function test_010_default_app_does_not_break_custom_app_usage.<locals>.add at 0x000001ADC4109EE0>\n\n    def decorator(func):\n        base = opts.pop('base', Task)\n        name = opts.get('name') or self.gen_task_name(func.__name__, func.__module__)\n>       task_instance = base(func, self, name=name, **opts)\nE       TypeError: celery.app.task.Task() got multiple values for keyword argument 'name'\n\ngeneration\\Celery\\celery\\app\\base.py:51: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.50s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "", "returncode": 1, "elapsed_time_s": 5.554229, "avg_memory_mb": 33.29, "avg_cpu_percent": 98.8, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 19:51:00", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n>       def greet(count: int, name: str) -> None:\n\ntests\\Click\\functional_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E7914790>\ndecls = ('--count', '-c')\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n>       def cli(flag: bool) -> None:\n\ntests\\Click\\functional_test.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E78D1250>\ndecls = ('--flag/--no-flag',)\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'function' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'function' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E79D9A60>, decls = ('--config',)\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE     ", "stdout_sha1": "8ebaa3165b328517ba4925ccd730f11ce0861370", "stdout_len": 9985, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n>       def greet(count: int, name: str) -> None:\n\ntests\\Click\\functional_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E7914790>\ndecls = ('--count', '-c')\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n>       def cli(flag: bool) -> None:\n\ntests\\Click\\functional_test.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E78D1250>\ndecls = ('--flag/--no-flag',)\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'function' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'function' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E79D9A60>, decls = ('--config',)\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert result.exit_code != 0\n>       assert isinstance(result.exception, CustomError)\nE       AssertionError: assert False\nE        +  where False = isinstance(AttributeError('__enter__'), <class 'functional_test.test_command_exception_is_exposed_in_result.<locals>.CustomError'>)\nE        +    where AttributeError('__enter__') = <Result exit_code=1>.exception\n\ntests\\Click\\functional_test.py:251: AssertionError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n>       def cli(name: str) -> None:\n\ntests\\Click\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E7962D60>, decls = ('--name',)\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n>       def cli(token: str) -> None:\n\ntests\\Click\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E79CAFD0>, decls = ('--token',)\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'function' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:294: AttributeError\n_______________ test_parameter_type_validation_error_exit_code ________________\n\n    def test_parameter_type_validation_error_exit_code():\n        @click.command()\n        @click.option(\"--count\", type=int, required=True)\n>       def cli(count: int) -> None:\n\ntests\\Click\\functional_test.py:308: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:44: in decorator\n    f.__click_params__.append(param_cls(param_decls, **attrs))\ngeneration\\Click\\click\\core.py:88: in __init__\n    super().__init__(param_decls, **attrs)\ngeneration\\Click\\click\\core.py:63: in __init__\n    self.opts, self.name = self._parse_decls(param_decls)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000250E79143D0>, decls = ('--count',)\n\n    def _parse_decls(self, decls):\n        opts = [d for d in decls if d.startswith(\"-\")]\n>       name = [d for d in decls if not d.startswith(\"-\")][0]\nE       IndexError: list index out of range\n\ngeneration\\Click\\click\\core.py:71: IndexError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - IndexE...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - Attribut...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_command_exception_is_exposed_in_result\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - I...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n11 failed in 4.14s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 50.304026, "avg_memory_mb": 51.56, "avg_cpu_percent": 0.61, "passed": 3, "failed": 8, "skipped": 0, "total": 11, "functional_score": 0.2727, "timestamp": "2026-01-01 19:54:13", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\nself = <sqlalchemy.engine.base.Connection object at 0x0000020C88193B20>\ndialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x0000020C88193760>\nconstructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>\nstatement = 'SELECT users.id, users.name, users.age, users.country, users.active \\nFROM users \\nWHERE users.age = ?'\nparameters = ({'>=': 40},), execution_options = immutabledict({})\nargs = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x0000020C88A6BDC0>, [], <sqlalchemy.sql.selectable.Select object at 0x0000020C88A6BDF0>, [BindParameter('%(2252855490208 age)s', {'>=': 40}, type_=INTEGER())])\nkw = {'cache_hit': symbol('CACHE_MISS')}\nbranched = <sqlalchemy.engine.base.Connection object at 0x0000020C88193B20>\nconn = <sqlalchemy.pool.base._ConnectionFairy object at 0x0000020C87F45B50>\ncontext = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x0000020C88A6BD90>\ncursor = <sqlite3.Cursor object at 0x0000020C889DBB20>, evt_handled = False\n\n    def _execute_context(\n        self,\n        dialect,\n        constructor,\n        statement,\n        parameters,\n        execution_options,\n        *args,\n        **kw\n    ):\n        \"\"\"Create an :class:`.ExecutionContext` and execute, returning\n        a :class:`_engine.CursorResult`.\"\"\"\n    \n        branched = self\n        if self.__branch_from:\n            # if this is a \"branched\" connection, do everything in terms\n            # of the \"root\" connection, *except* for .close(), which is\n            # the only feature that branching provides\n            self = self.__branch_from\n    \n        if execution_options:\n            yp = execution_options.get(\"yield_per\", None)\n            if yp:\n                execution_options = execution_options.union(\n                    {\"stream_results\": True, \"max_row_buffer\": yp}\n                )\n    \n        try:\n            conn = self._dbapi_connection\n            if conn is None:\n                conn = self._revalidate_connection()\n    \n            context = constructor(\n                dialect, self, conn, execution_options, *args, **kw\n            )\n        except (exc.PendingRollbackError, exc.ResourceClosedError):\n            raise\n        except BaseException as e:\n            self._handle_dbapi_exception(\n                e, util.text_type(statement), parameters, None, None\n            )\n    \n        if (\n            self._transaction\n            and not self._transaction.is_active\n            or (\n                self._nested_transaction\n                and not self._nested_transaction.is_active\n            )\n        ):\n            self._invalid_transaction()\n    \n        elif self._trans_context_manager:\n            TransactionalContext._trans_ctx_check(self)\n    \n        if self._is_future and self._transaction is None:\n            self._autobegin()\n    \n        context.pre_exec()\n    \n        if dialect.use_setinputsizes:\n            context._set_input_sizes()\n    \n        cursor, statement, parameters = (\n            context.cursor,\n            context.statement,\n            context.parameters,\n        )\n    \n        if not context.executemany:\n            parameters = parameters[0]\n    \n        if self._has_events or self.engine._has_events:\n            for fn in self.dispatch.before_cursor_execute:\n                statement, parameters = fn(\n                    self,\n                    cursor,\n                    statement,\n                    parameters,\n                    context,\n                    context.executemany,\n                )\n    \n        if self._echo:\n    \n            self._log_info(statement)\n    \n            stats = context._get_cache_stats()\n    \n            if not self.engine.hide_parameters:\n                self._log_info(\n                    \"[%s] %r\",\n ", "stdout_sha1": "d95afca10251b456a3a59cdc12fa04a97f625100", "stdout_len": 25546, "stdout": "FF.F.F.FFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\nself = <sqlalchemy.engine.base.Connection object at 0x0000020C88193B20>\ndialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x0000020C88193760>\nconstructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>\nstatement = 'SELECT users.id, users.name, users.age, users.country, users.active \\nFROM users \\nWHERE users.age = ?'\nparameters = ({'>=': 40},), execution_options = immutabledict({})\nargs = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x0000020C88A6BDC0>, [], <sqlalchemy.sql.selectable.Select object at 0x0000020C88A6BDF0>, [BindParameter('%(2252855490208 age)s', {'>=': 40}, type_=INTEGER())])\nkw = {'cache_hit': symbol('CACHE_MISS')}\nbranched = <sqlalchemy.engine.base.Connection object at 0x0000020C88193B20>\nconn = <sqlalchemy.pool.base._ConnectionFairy object at 0x0000020C87F45B50>\ncontext = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x0000020C88A6BD90>\ncursor = <sqlite3.Cursor object at 0x0000020C889DBB20>, evt_handled = False\n\n    def _execute_context(\n        self,\n        dialect,\n        constructor,\n        statement,\n        parameters,\n        execution_options,\n        *args,\n        **kw\n    ):\n        \"\"\"Create an :class:`.ExecutionContext` and execute, returning\n        a :class:`_engine.CursorResult`.\"\"\"\n    \n        branched = self\n        if self.__branch_from:\n            # if this is a \"branched\" connection, do everything in terms\n            # of the \"root\" connection, *except* for .close(), which is\n            # the only feature that branching provides\n            self = self.__branch_from\n    \n        if execution_options:\n            yp = execution_options.get(\"yield_per\", None)\n            if yp:\n                execution_options = execution_options.union(\n                    {\"stream_results\": True, \"max_row_buffer\": yp}\n                )\n    \n        try:\n            conn = self._dbapi_connection\n            if conn is None:\n                conn = self._revalidate_connection()\n    \n            context = constructor(\n                dialect, self, conn, execution_options, *args, **kw\n            )\n        except (exc.PendingRollbackError, exc.ResourceClosedError):\n            raise\n        except BaseException as e:\n            self._handle_dbapi_exception(\n                e, util.text_type(statement), parameters, None, None\n            )\n    \n        if (\n            self._transaction\n            and not self._transaction.is_active\n            or (\n                self._nested_transaction\n                and not self._nested_transaction.is_active\n            )\n        ):\n            self._invalid_transaction()\n    \n        elif self._trans_context_manager:\n            TransactionalContext._trans_ctx_check(self)\n    \n        if self._is_future and self._transaction is None:\n            self._autobegin()\n    \n        context.pre_exec()\n    \n        if dialect.use_setinputsizes:\n            context._set_input_sizes()\n    \n        cursor, statement, parameters = (\n            context.cursor,\n            context.statement,\n            context.parameters,\n        )\n    \n        if not context.executemany:\n            parameters = parameters[0]\n    \n        if self._has_events or self.engine._has_events:\n            for fn in self.dispatch.before_cursor_execute:\n                statement, parameters = fn(\n                    self,\n                    cursor,\n                    statement,\n                    parameters,\n                    context,\n                    context.executemany,\n                )\n    \n        if self._echo:\n    \n            self._log_info(statement)\n    \n            stats = context._get_cache_stats()\n    \n            if not self.engine.hide_parameters:\n                self._log_info(\n                    \"[%s] %r\",\n                    stats,\n                    sql_util._repr_params(\n                        parameters, batches=10, ismulti=context.executemany\n                    ),\n                )\n            else:\n                self._log_info(\n                    \"[%s] [SQL parameters hidden due to hide_parameters=True]\"\n                    % (stats,)\n                )\n    \n        evt_handled = False\n        try:\n            if context.executemany:\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_executemany:\n                        if fn(cursor, statement, parameters, context):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n                    self.dialect.do_executemany(\n                        cursor, statement, parameters, context\n                    )\n            elif not parameters and context.no_parameters:\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_execute_no_params:\n                        if fn(cursor, statement, context):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n                    self.dialect.do_execute_no_params(\n                        cursor, statement, context\n                    )\n            else:\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_execute:\n                        if fn(cursor, statement, parameters, context):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n>                   self.dialect.do_execute(\n                        cursor, statement, parameters, context\n                    )\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1910: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x0000020C88193760>\ncursor = <sqlite3.Cursor object at 0x0000020C889DBB20>\nstatement = 'SELECT users.id, users.name, users.age, users.country, users.active \\nFROM users \\nWHERE users.age = ?'\nparameters = ({'>=': 40},)\ncontext = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x0000020C88A6BD90>\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n>       cursor.execute(statement, parameters)\nE       sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\default.py:736: InterfaceError\n\nThe above exception was the direct cause of the following exception:\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:200: in find\n    result = conn.execute(stmt)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1385: in execute\n    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:334: in _execute_on_connection\n    return connection._execute_clauseelement(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1577: in _execute_clauseelement\n    ret = self._execute_context(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1953: in _execute_context\n    self._handle_dbapi_exception(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2134: in _handle_dbapi_exception\n    util.raise_(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\util\\compat.py:211: in raise_\n    raise exception\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1910: in _execute_context\n    self.dialect.do_execute(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x0000020C88193760>\ncursor = <sqlite3.Cursor object at 0x0000020C889DBB20>\nstatement = 'SELECT users.id, users.name, users.age, users.country, users.active \\nFROM users \\nWHERE users.age = ?'\nparameters = ({'>=': 40},)\ncontext = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x0000020C88A6BD90>\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n>       cursor.execute(statement, parameters)\nE       sqlalchemy.exc.InterfaceError: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.\nE       [SQL: SELECT users.id, users.name, users.age, users.country, users.active \nE       FROM users \nE       WHERE users.age = ?]\nE       [parameters: ({'>=': 40},)]\nE       (Background on this error at: https://sqlalche.me/e/14/rvf5)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\default.py:736: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n>           table.create_index([\"owner\", \"currency\"])\n\ntests\\Dataset\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Table('accounts')>, columns = ['owner', 'currency'], unique = False\n_conn = None\n\n    def create_index(self, columns, unique=False, _conn=None):\n        \"\"\"Create an index on one or more columns.\"\"\"\n        columns = [columns] if not isinstance(columns, (list, tuple)) else columns\n        conn = _conn or self.database._get_connection()\n        try:\n            sa_table = self._get_sa_table(conn)\n            if sa_table is None:\n>               raise RuntimeError(\"Table does not exist, cannot create index.\")\nE               RuntimeError: Table does not exist, cannot create index.\n\ngeneration\\Dataset\\dataset\\table.py:264: RuntimeError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n        db = create_in_memory_db()\n        table = db[\"items\"]\n    \n        rows = [{\"name\": \"A\"}, {\"name\": \"B\"}, {\"name\": \"C\"}]\n        ret = table.insert_many(rows)\n    \n>       assert len(table) == 3\nE       AssertionError: assert 0 == 3\nE        +  where 0 = len(<Table('items')>)\n\ntests\\Dataset\\functional_test.py:225: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n>       rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n\ntests\\Dataset\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:197: in find\n    stmt = self._build_select_query(conn, **filters)\ngeneration\\Dataset\\dataset\\table.py:185: in _build_select_query\n    clauses = [sa_table.c[k] == v for k, v in filters.items()]\ngeneration\\Dataset\\dataset\\table.py:185: in <listcomp>\n    clauses = [sa_table.c[k] == v for k, v in filters.items()]\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlalchemy.sql.base.ImmutableColumnCollection object at 0x0000020C88F44AE0>\nkey = 'order_by'\n\n    def __getitem__(self, key):\n        try:\n>           return self._index[key]\nE           KeyError: 'order_by'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\sql\\base.py:1214: KeyError\n_______________________ test_delete_and_clear_all_rows ________________________\n\n    def test_delete_and_clear_all_rows() -> None:\n        \"\"\"\n        Older dataset.Table may not expose truncate().\n        Clear a table and end at 0 rows without relying on result iteration for DML.\n        \"\"\"\n        db = create_in_memory_db()\n        table = db[\"logs\"]\n        table.insert_many([{\"kind\": \"a\"}, {\"kind\": \"b\"}, {\"kind\": \"b\"}])\n    \n>       assert len(table) == 3\nE       AssertionError: assert 0 == 3\nE        +  where 0 = len(<Table('logs')>)\n\ntests\\Dataset\\functional_test.py:272: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<Database(sqlite:///:memory:)>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_raw_sql_query_with_parameters ______________________\n\nself = <sqlalchemy.engine.base.Connection object at 0x0000020C879CAA90>\ndialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x0000020C879F02B0>\nconstructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>\nstatement = 'SELECT k, v FROM kv WHERE v >= ? ORDER BY v', parameters = (2,)\nexecution_options = immutabledict({'autocommit': symbol('PARSE_AUTOCOMMIT')})\nargs = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x0000020C879CACA0>, [{'min_v': 2}], <sqlalchemy.sql.elements.TextClause object at 0x0000020C879CAAF0>, [BindParameter('min_v', None, type_=NullType())])\nkw = {'cache_hit': symbol('CACHE_MISS')}\nbranched = <sqlalchemy.engine.base.Connection object at 0x0000020C879CAA90>\nyp = None\nconn = <sqlalchemy.pool.base._ConnectionFairy object at 0x0000020C879CA8B0>\ncontext = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x0000020C879CA7F0>\ncursor = <sqlite3.Cursor object at 0x0000020C88A7AB90>, evt_handled = False\n\n    def _execute_context(\n        self,\n        dialect,\n        constructor,\n        statement,\n        parameters,\n        execution_options,\n        *args,\n        **kw\n    ):\n        \"\"\"Create an :class:`.ExecutionContext` and execute, returning\n        a :class:`_engine.CursorResult`.\"\"\"\n    \n        branched = self\n        if self.__branch_from:\n            # if this is a \"branched\" connection, do everything in terms\n            # of the \"root\" connection, *except* for .close(), which is\n            # the only feature that branching provides\n            self = self.__branch_from\n    \n        if execution_options:\n            yp = execution_options.get(\"yield_per\", None)\n            if yp:\n                execution_options = execution_options.union(\n                    {\"stream_results\": True, \"max_row_buffer\": yp}\n                )\n    \n        try:\n            conn = self._dbapi_connection\n            if conn is None:\n                conn = self._revalidate_connection()\n    \n            context = constructor(\n                dialect, self, conn, execution_options, *args, **kw\n            )\n        except (exc.PendingRollbackError, exc.ResourceClosedError):\n            raise\n        except BaseException as e:\n            self._handle_dbapi_exception(\n                e, util.text_type(statement), parameters, None, None\n            )\n    \n        if (\n            self._transaction\n            and not self._transaction.is_active\n            or (\n                self._nested_transaction\n                and not self._nested_transaction.is_active\n            )\n        ):\n            self._invalid_transaction()\n    \n        elif self._trans_context_manager:\n            TransactionalContext._trans_ctx_check(self)\n    \n        if self._is_future and self._transaction is None:\n            self._autobegin()\n    \n        context.pre_exec()\n    \n        if dialect.use_setinputsizes:\n            context._set_input_sizes()\n    \n        cursor, statement, parameters = (\n            context.cursor,\n            context.statement,\n            context.parameters,\n        )\n    \n        if not context.executemany:\n            parameters = parameters[0]\n    \n        if self._has_events or self.engine._has_events:\n            for fn in self.dispatch.before_cursor_execute:\n                statement, parameters = fn(\n                    self,\n                    cursor,\n                    statement,\n                    parameters,\n                    context,\n                    context.executemany,\n                )\n    \n        if self._echo:\n    \n            self._log_info(statement)\n    \n            stats = context._get_cache_stats()\n    \n            if not self.engine.hide_parameters:\n                self._log_info(\n                    \"[%s] %r\",\n                    stats,\n                    sql_util._repr_params(\n                        parameters, batches=10, ismulti=context.executemany\n                    ),\n                )\n            else:\n                self._log_info(\n                    \"[%s] [SQL parameters hidden due to hide_parameters=True]\"\n                    % (stats,)\n                )\n    \n        evt_handled = False\n        try:\n            if context.executemany:\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_executemany:\n                        if fn(cursor, statement, parameters, context):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n                    self.dialect.do_executemany(\n                        cursor, statement, parameters, context\n                    )\n            elif not parameters and context.no_parameters:\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_execute_no_params:\n                        if fn(cursor, statement, context):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n                    self.dialect.do_execute_no_params(\n                        cursor, statement, context\n                    )\n            else:\n                if self.dialect._has_events:\n                    for fn in self.dialect.dispatch.do_execute:\n                        if fn(cursor, statement, parameters, context):\n                            evt_handled = True\n                            break\n                if not evt_handled:\n>                   self.dialect.do_execute(\n                        cursor, statement, parameters, context\n                    )\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1910: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x0000020C879F02B0>\ncursor = <sqlite3.Cursor object at 0x0000020C88A7AB90>\nstatement = 'SELECT k, v FROM kv WHERE v >= ? ORDER BY v', parameters = (2,)\ncontext = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x0000020C879CA7F0>\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n>       cursor.execute(statement, parameters)\nE       sqlite3.OperationalError: no such table: kv\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\default.py:736: OperationalError\n\nThe above exception was the direct cause of the following exception:\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-447/test_raw_sql_query_with_parame0')\n\n    def test_raw_sql_query_with_parameters(tmp_path: Path) -> None:\n        db_path = tmp_path / \"param.db\"\n        db = dataset.connect(\"sqlite:///%s\" % str(db_path))\n        table = db[\"kv\"]\n        table.insert_many([{\"k\": \"a\", \"v\": 1}, {\"k\": \"b\", \"v\": 2}])\n    \n>       rows = list(db.query(\"SELECT k, v FROM kv WHERE v >= :min_v ORDER BY v\", min_v=2))\n\ntests\\Dataset\\functional_test.py:321: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\database.py:77: in query\n    result = conn.execute(sqlalchemy.text(sql), params)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1385: in execute\n    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\sql\\elements.py:334: in _execute_on_connection\n    return connection._execute_clauseelement(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1577: in _execute_clauseelement\n    ret = self._execute_context(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1953: in _execute_context\n    self._handle_dbapi_exception(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2134: in _handle_dbapi_exception\n    util.raise_(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\util\\compat.py:211: in raise_\n    raise exception\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1910: in _execute_context\n    self.dialect.do_execute(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x0000020C879F02B0>\ncursor = <sqlite3.Cursor object at 0x0000020C88A7AB90>\nstatement = 'SELECT k, v FROM kv WHERE v >= ? ORDER BY v', parameters = (2,)\ncontext = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x0000020C879CA7F0>\n\n    def do_execute(self, cursor, statement, parameters, context=None):\n>       cursor.execute(statement, parameters)\nE       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: kv\nE       [SQL: SELECT k, v FROM kv WHERE v >= ? ORDER BY v]\nE       [parameters: (2,)]\nE       (Background on this error at: https://sqlalche.me/e/14/e3q8)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sqlalchemy\\engine\\default.py:736: OperationalError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n        values = {r[\"c\"] for r in distinct}\n>       assert values == {\"red\", \"blue\"}\nE       AssertionError: assert set() == {'blue', 'red'}\nE         \nE         Extra items in the right set:\nE         'red'\nE         'blue'\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:334: AssertionError\n============================== warnings summary ===============================\ntests/Dataset/functional_test.py::test_insert_and_query_basic_rows\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Dataset\\dataset\\table.py:55: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n    table.create(conn)\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - Run...\nFAILED tests/Dataset/functional_test.py::test_insert_many_returns_ids_and_count\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - Ke...\nFAILED tests/Dataset/functional_test.py::test_delete_and_clear_all_rows - Ass...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_raw_sql_query_with_parameters\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n8 failed, 3 passed, 1 warning in 48.87s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 19:56:16", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "gemini-2.5-pro-thinking", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "sequence item 0: expected str in", "returncode": 1, "elapsed_time_s": 2.17931, "avg_memory_mb": 31.97, "avg_cpu_percent": 105.6, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 19:59:59", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       html = m.get_root().render()\n\ntests\\Folium\\functional_test.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B4358580>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        root = m.get_root()\n        assert hasattr(root, \"render\")\n>       html = root.render().lower()\n\ntests\\Folium\\functional_test.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B43841C0>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B43F9880>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B431A910>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n        folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\n        folium.LayerControl().add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:95: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B43ED6D0>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str in", "stdout_sha1": "d7e0769379f7d7b8b1f27b8a1d85e9fa347a0880", "stdout_len": 8945, "stdout": "..FFFFFFFF.F                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       html = m.get_root().render()\n\ntests\\Folium\\functional_test.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B4358580>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        root = m.get_root()\n        assert hasattr(root, \"render\")\n>       html = root.render().lower()\n\ntests\\Folium\\functional_test.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B43841C0>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B43F9880>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B431A910>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n        folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\n        folium.LayerControl().add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:95: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B43ED6D0>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        folium.GeoJson(gj, name=\"g\").add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B4400D90>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        folium.GeoJson(gj, style_function=style_fn).add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B43E5910>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-448/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        mc = MarkerCluster(name=\"mc\").add_to(m)\n        assert mc is not None\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:177: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <folium.elements.Figure object at 0x00000218B28B0D60>, kwargs = {}\n\n    def render(self, **kwargs):\n        \"\"\"Render the full HTML page.\"\"\"\n>       header = \"\".join(child.render(**kwargs) for child in self.header._children.values())\nE       TypeError: sequence item 0: expected str instance, NoneType found\n\ngeneration\\Folium\\folium\\elements.py:83: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root - TypeErro...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n9 failed, 3 passed in 0.75s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where <built-in method lower of str object at 0x0000015BF435CF70> = '12000'.lower", "returncode": 1, "elapsed_time_s": 1.910844, "avg_memory_mb": 32.04, "avg_cpu_percent": 99.1, "passed": 12, "failed": 1, "skipped": 2, "total": 15, "functional_score": 0.8, "timestamp": "2026-01-01 20:03:00", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_intword_thousand_scale _________________________\n\n    def test_intword_thousand_scale() -> None:\n        if not hasattr(humanize, \"intword\"):\n            pytest.skip(\"humanize.intword is not available in this repository/version.\")\n        s = humanize.intword(12_000)\n        assert isinstance(s, str)\n        assert s\n>       assert \"thousand\" in s.lower()\nE       AssertionError: assert 'thousand' in '12000'\nE        +  where '12000' = <built-in method lower of str object at 0x0000015BF435CF70>()\nE        +    where <built-in method lower of str object at 0x0000015BF435CF70> = '12000'.lower\n\ntests\\Humanize\\functional_test.py:195: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_intword_thousand_scale - Asser...\n1 failed, 12 passed, 2 skipped in 0.54s\n", "stdout_sha1": "792d7afa2f22fa7f06ccc6046ce6bdf0eeaa869f", "stdout_len": 1044, "stdout": "............Fss                                                          [100%]\n================================== FAILURES ===================================\n_________________________ test_intword_thousand_scale _________________________\n\n    def test_intword_thousand_scale() -> None:\n        if not hasattr(humanize, \"intword\"):\n            pytest.skip(\"humanize.intword is not available in this repository/version.\")\n        s = humanize.intword(12_000)\n        assert isinstance(s, str)\n        assert s\n>       assert \"thousand\" in s.lower()\nE       AssertionError: assert 'thousand' in '12000'\nE        +  where '12000' = <built-in method lower of str object at 0x0000015BF435CF70>()\nE        +    where <built-in method lower of str object at 0x0000015BF435CF70> = '12000'.lower\n\ntests\\Humanize\\functional_test.py:195: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_intword_thousand_scale - Asser...\n1 failed, 12 passed, 2 skipped in 0.54s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "", "exception_msg": "struct.error: bad char in struct format", "returncode": 1, "elapsed_time_s": 23.272221, "avg_memory_mb": 45.05, "avg_cpu_percent": 0.85, "passed": 4, "failed": 6, "skipped": 0, "total": 10, "functional_score": 0.4, "timestamp": "2026-01-01 20:05:33", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:64: in imwrite\n    _gif_write(path, image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_multiframe_roundtrip_0/anim.gif')\nimages = array([[[175,  48,   5, ..., 108, 239,  95],\n        [239,  95,  27, ..., 228,  72, 250],\n        [155, 220,  51, ...,...99, 236, 251],\n        [120, 166, 247, ..., 100, 131,  54],\n        [ 79, 139,  45, ..., 112, 215,  45]]], dtype=uint8)\n\n    def _gif_write(path: pathlib.Path, images: np.ndarray):\n        # images shape: (N, H, W) or (N, H, W, 1) or (N, H, W, 3)\n        n, h, w = images.shape[:3]\n    \n        is_grayscale = images.ndim == 3 or (images.ndim == 4 and images.shape[3] == 1)\n    \n        with open(path, \"wb\") as f:\n            # Header\n            f.write(b\"GIF89a\")\n    \n            # Logical Screen Descriptor\n            palette: Optional[np.ndarray] = None\n            if is_grayscale:\n                palette = np.arange(256, dtype=np.uint8)[:, np.newaxis].repeat(3, axis=1)\n            else: # RGB\n                # Simple palette generation from first frame\n                pixels = images[0].reshape(-1, 3)\n                unique_colors, inverse = np.unique(pixels, axis=0, return_inverse=True)\n                if len(unique_colors) > 256:\n                    raise ValueError(\"GIF supports a maximum of 256 colors per frame.\")\n                palette = np.zeros((256, 3), dtype=np.uint8)\n                palette[:len(unique_colors)] = unique_colors\n    \n            palette_size_log2 = (len(palette) - 1).bit_length() - 1\n            packed = 0x80 | 0x70 | palette_size_log2 # GCT, 8-bit color, sorted, size\n>           f.write(struct.pack(\"<HHB_B\", w, h, packed, 0))\nE           struct.error: bad char in struct format\n\ngeneration\\Imageio\\imageio\\v3.py:526: error\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\n\ntests\\Imageio\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = '<bytes>'\nimage = array([[[157, 193, 255],\n        [178, 141, 177],\n        [ 50,  58, 222],\n        ...,\n        [249,   7, 141],\n     ...[  9, 234,  27],\n        ...,\n        [219, 110, 131],\n        [255, 135, 132],\n        [203,  36, 116]]], dtype=uint8)\nkwargs = {'extension': '.png'}, path = WindowsPath('<bytes>'), ext = ''\n\n    def imwrite(uri: Union[str, pathlib.Path], image: np.ndarray, **kwargs):\n        \"\"\"\n        Writes an image to the given path.\n        \"\"\"\n        path = pathlib.Path(uri)\n        image = np.asarray(image)\n        ext = path.suffix.lower()\n    \n        if image.dtype != np.uint8:\n            raise TypeError(\"Only uint8 images are supported.\")\n    \n        if ext == \".png\":\n            is_sequence = (image.ndim == 3 and image.shape[2] not in (1, 3, 4)) or image.ndim >= 4\n            if is_sequence:\n                raise ValueError(\"PNG format does not support image sequences.\")\n            _png_write(path, image)\n        elif ext == \".gif\":\n ", "stdout_sha1": "4570c09443005280790df17ff83eba20d0c04330", "stdout_len": 13727, "stdout": ".F.F..FFFF                                                               [100%]\n================================== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:64: in imwrite\n    _gif_write(path, image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_multiframe_roundtrip_0/anim.gif')\nimages = array([[[175,  48,   5, ..., 108, 239,  95],\n        [239,  95,  27, ..., 228,  72, 250],\n        [155, 220,  51, ...,...99, 236, 251],\n        [120, 166, 247, ..., 100, 131,  54],\n        [ 79, 139,  45, ..., 112, 215,  45]]], dtype=uint8)\n\n    def _gif_write(path: pathlib.Path, images: np.ndarray):\n        # images shape: (N, H, W) or (N, H, W, 1) or (N, H, W, 3)\n        n, h, w = images.shape[:3]\n    \n        is_grayscale = images.ndim == 3 or (images.ndim == 4 and images.shape[3] == 1)\n    \n        with open(path, \"wb\") as f:\n            # Header\n            f.write(b\"GIF89a\")\n    \n            # Logical Screen Descriptor\n            palette: Optional[np.ndarray] = None\n            if is_grayscale:\n                palette = np.arange(256, dtype=np.uint8)[:, np.newaxis].repeat(3, axis=1)\n            else: # RGB\n                # Simple palette generation from first frame\n                pixels = images[0].reshape(-1, 3)\n                unique_colors, inverse = np.unique(pixels, axis=0, return_inverse=True)\n                if len(unique_colors) > 256:\n                    raise ValueError(\"GIF supports a maximum of 256 colors per frame.\")\n                palette = np.zeros((256, 3), dtype=np.uint8)\n                palette[:len(unique_colors)] = unique_colors\n    \n            palette_size_log2 = (len(palette) - 1).bit_length() - 1\n            packed = 0x80 | 0x70 | palette_size_log2 # GCT, 8-bit color, sorted, size\n>           f.write(struct.pack(\"<HHB_B\", w, h, packed, 0))\nE           struct.error: bad char in struct format\n\ngeneration\\Imageio\\imageio\\v3.py:526: error\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\n\ntests\\Imageio\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = '<bytes>'\nimage = array([[[157, 193, 255],\n        [178, 141, 177],\n        [ 50,  58, 222],\n        ...,\n        [249,   7, 141],\n     ...[  9, 234,  27],\n        ...,\n        [219, 110, 131],\n        [255, 135, 132],\n        [203,  36, 116]]], dtype=uint8)\nkwargs = {'extension': '.png'}, path = WindowsPath('<bytes>'), ext = ''\n\n    def imwrite(uri: Union[str, pathlib.Path], image: np.ndarray, **kwargs):\n        \"\"\"\n        Writes an image to the given path.\n        \"\"\"\n        path = pathlib.Path(uri)\n        image = np.asarray(image)\n        ext = path.suffix.lower()\n    \n        if image.dtype != np.uint8:\n            raise TypeError(\"Only uint8 images are supported.\")\n    \n        if ext == \".png\":\n            is_sequence = (image.ndim == 3 and image.shape[2] not in (1, 3, 4)) or image.ndim >= 4\n            if is_sequence:\n                raise ValueError(\"PNG format does not support image sequences.\")\n            _png_write(path, image)\n        elif ext == \".gif\":\n            is_single_frame = (image.ndim == 2) or (image.ndim == 3 and image.shape[2] in (1, 3, 4))\n            if is_single_frame:\n                image = image[np.newaxis, ...]\n            _gif_write(path, image)\n        else:\n>           raise ValueError(f\"Unsupported file extension for writing: {ext}\")\nE           ValueError: Unsupported file extension for writing:\n\ngeneration\\Imageio\\imageio\\v3.py:66: ValueError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:64: in imwrite\n    _gif_write(path, image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_imread_returns_stack_0/stack.gif')\nimages = array([[[175,  48,   5, ..., 173,  66,  93],\n        [108, 239,  95, ...,  84,  50,  73],\n        [  3,  59, 140, ...,...18,  26, 217],\n        [255, 220, 204, ...,  46,  65,  79],\n        [235, 162, 251, ..., 155,  10, 108]]], dtype=uint8)\n\n    def _gif_write(path: pathlib.Path, images: np.ndarray):\n        # images shape: (N, H, W) or (N, H, W, 1) or (N, H, W, 3)\n        n, h, w = images.shape[:3]\n    \n        is_grayscale = images.ndim == 3 or (images.ndim == 4 and images.shape[3] == 1)\n    \n        with open(path, \"wb\") as f:\n            # Header\n            f.write(b\"GIF89a\")\n    \n            # Logical Screen Descriptor\n            palette: Optional[np.ndarray] = None\n            if is_grayscale:\n                palette = np.arange(256, dtype=np.uint8)[:, np.newaxis].repeat(3, axis=1)\n            else: # RGB\n                # Simple palette generation from first frame\n                pixels = images[0].reshape(-1, 3)\n                unique_colors, inverse = np.unique(pixels, axis=0, return_inverse=True)\n                if len(unique_colors) > 256:\n                    raise ValueError(\"GIF supports a maximum of 256 colors per frame.\")\n                palette = np.zeros((256, 3), dtype=np.uint8)\n                palette[:len(unique_colors)] = unique_colors\n    \n            palette_size_log2 = (len(palette) - 1).bit_length() - 1\n            packed = 0x80 | 0x70 | palette_size_log2 # GCT, 8-bit color, sorted, size\n>           f.write(struct.pack(\"<HHB_B\", w, h, packed, 0))\nE           struct.error: bad char in struct format\n\ngeneration\\Imageio\\imageio\\v3.py:526: error\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:64: in imwrite\n    _gif_write(path, image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_gif_imread_index0_matches0/index0.gif')\nimages = array([[[175,  48,   5, ...,  93, 108, 239],\n        [ 95, 239,  95, ...,  59, 140, 228],\n        [ 72, 250, 155, ...,...57, 165, 255],\n        [ 18,  28,  29, ..., 155, 216, 213],\n        [219, 124,  59, ..., 250, 200, 138]]], dtype=uint8)\n\n    def _gif_write(path: pathlib.Path, images: np.ndarray):\n        # images shape: (N, H, W) or (N, H, W, 1) or (N, H, W, 3)\n        n, h, w = images.shape[:3]\n    \n        is_grayscale = images.ndim == 3 or (images.ndim == 4 and images.shape[3] == 1)\n    \n        with open(path, \"wb\") as f:\n            # Header\n            f.write(b\"GIF89a\")\n    \n            # Logical Screen Descriptor\n            palette: Optional[np.ndarray] = None\n            if is_grayscale:\n                palette = np.arange(256, dtype=np.uint8)[:, np.newaxis].repeat(3, axis=1)\n            else: # RGB\n                # Simple palette generation from first frame\n                pixels = images[0].reshape(-1, 3)\n                unique_colors, inverse = np.unique(pixels, axis=0, return_inverse=True)\n                if len(unique_colors) > 256:\n                    raise ValueError(\"GIF supports a maximum of 256 colors per frame.\")\n                palette = np.zeros((256, 3), dtype=np.uint8)\n                palette[:len(unique_colors)] = unique_colors\n    \n            palette_size_log2 = (len(palette) - 1).bit_length() - 1\n            packed = 0x80 | 0x70 | palette_size_log2 # GCT, 8-bit color, sorted, size\n>           f.write(struct.pack(\"<HHB_B\", w, h, packed, 0))\nE           struct.error: bad char in struct format\n\ngeneration\\Imageio\\imageio\\v3.py:526: error\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n____________ test_improps_for_gif_has_expected_spatial_dimensions _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_improps_for_gif_has_expec0')\n\n    def test_improps_for_gif_has_expected_spatial_dimensions(tmp_path: Path) -> None:\n        \"\"\"improps on a GIF should include the written frame height/width in its reported shape.\n    \n        In practice, different plugins/paths can report shapes like:\n          - (T, H, W)\n          - (T, H, W, C)\n          - (H, W, C)\n          - (W, H, C)\n        Therefore we validate that the expected H and W appear somewhere in props.shape,\n        without assuming their exact positions.\n        \"\"\"\n        frames = _make_grayscale_frames(num_frames=3, height=17, width=19)\n        path = tmp_path / \"props.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:64: in imwrite\n    _gif_write(path, image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-451/test_improps_for_gif_has_expec0/props.gif')\nimages = array([[[175,  48,   5,  97, 162,  98,  32, 180, 237, 234,  27, 119,\n         129, 130, 192, 109,  49,  37, 173],\n    ...193, 108,  94, 224, 102,  31,  61, 217, 175, 231, 194, 199,\n          97, 107,  97,  61, 152,  69, 111]]], dtype=uint8)\n\n    def _gif_write(path: pathlib.Path, images: np.ndarray):\n        # images shape: (N, H, W) or (N, H, W, 1) or (N, H, W, 3)\n        n, h, w = images.shape[:3]\n    \n        is_grayscale = images.ndim == 3 or (images.ndim == 4 and images.shape[3] == 1)\n    \n        with open(path, \"wb\") as f:\n            # Header\n            f.write(b\"GIF89a\")\n    \n            # Logical Screen Descriptor\n            palette: Optional[np.ndarray] = None\n            if is_grayscale:\n                palette = np.arange(256, dtype=np.uint8)[:, np.newaxis].repeat(3, axis=1)\n            else: # RGB\n                # Simple palette generation from first frame\n                pixels = images[0].reshape(-1, 3)\n                unique_colors, inverse = np.unique(pixels, axis=0, return_inverse=True)\n                if len(unique_colors) > 256:\n                    raise ValueError(\"GIF supports a maximum of 256 colors per frame.\")\n                palette = np.zeros((256, 3), dtype=np.uint8)\n                palette[:len(unique_colors)] = unique_colors\n    \n            palette_size_log2 = (len(palette) - 1).bit_length() - 1\n            packed = 0x80 | 0x70 | palette_size_log2 # GCT, 8-bit color, sorted, size\n>           f.write(struct.pack(\"<HHB_B\", w, h, packed, 0))\nE           struct.error: bad char in struct format\n\ngeneration\\Imageio\\imageio\\v3.py:526: error\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_gif_multiframe_roundtrip_with_imiter\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\nFAILED tests/Imageio/functional_test.py::test_improps_for_gif_has_expected_spatial_dimensions\n6 failed, 4 passed in 1.08s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "", "exception_msg": "pandas.errors.MergeError: incompatible merge keys [0] dtype('float64') and dtype('int64'), must be the same type", "returncode": 124, "elapsed_time_s": 60.079529, "avg_memory_mb": 91.37, "avg_cpu_percent": 0.22, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 20:12:43", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n        kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\n        kmf_treated.fit(treated[\"T\"], treated[\"E\"], label=\"treated\")\n    \n        t = 10.0\n>       s_control = float(kmf_control.predict(t))\n\ntests\\Lifelines\\functional_test.py:109: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Lifelines\\lifelines\\fitters\\kaplan_meier_fitter.py:80: in predict\n    merged = pd.merge_asof(predict_df, sf_df, on='timeline')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:691: in merge_asof\n    op = _AsOfMerge(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1999: in __init__\n    _OrderedMerge.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1911: in __init__\n    _MergeOperation.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:802: in __init__\n    self._maybe_require_matching_dtypes(self.left_join_keys, self.right_join_keys)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2124: in _maybe_require_matching_dtypes\n    _check_dtype_match(lk, rk, i)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nleft = array([10.]), right = array([ 0,  6,  9, 13, 19, 26, 33, 40]), i = 0\n\n    def _check_dtype_match(left: ArrayLike, right: ArrayLike, i: int):\n        if left.dtype != right.dtype:\n            if isinstance(left.dtype, CategoricalDtype) and isinstance(\n                right.dtype, CategoricalDtype\n            ):\n                # The generic error message is confusing for categoricals.\n                #\n                # In this function, the join keys include both the original\n                # ones of the merge_asof() call, and also the keys passed\n                # to its by= argument. Unordered but equal categories\n                # are not supported for the former, but will fail\n                # later with a ValueError, so we don't *need* to check\n                # for them here.\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, both sides category, but not equal ones\"\n                )\n            else:\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, must be the same type\"\n                )\n>           raise MergeError(msg)\nE           pandas.errors.MergeError: incompatible merge keys [0] dtype('float64') and dtype('int64'), must be the same type\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2120: MergeError\n____________________________ test_coxph_basic_fit _____________________________\n\nself = <lifelines.fitters.coxph_fitter.CoxPHFitter object at 0x00000237B170AB50>\nX = array([[30,  0],\n       [40,  0],\n       [50,  1],\n       [20,  1],\n       [60,  1],\n       [35,  0],\n       [45,  1],\n       [55,  0]])\nT = array([5, 6, 6, 2, 4, 3, 8, 7]), E = array([1, 0, 1, 1, 1, 0, 1, 1])\ninitial_beta = array([0., 0.]), max_iter = 50, tol = 1e-09\n\n    def _newton_rhapson(self, X, T, E, initial_beta, max_iter=50, tol=1e-9):\n        n_features = X.shape[1]\n        beta = np.array(initial_beta, dtype=float)\n    \n        for i in range(max_iter):\n", "stdout_sha1": "3ce7b1b74e565d9290d05bdeee9f752e79f95160", "stdout_len": 21460, "stdout": ".FFFFFFFFFFFFFF                                                          [100%]\n================================== FAILURES ===================================\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n        kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\n        kmf_treated.fit(treated[\"T\"], treated[\"E\"], label=\"treated\")\n    \n        t = 10.0\n>       s_control = float(kmf_control.predict(t))\n\ntests\\Lifelines\\functional_test.py:109: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Lifelines\\lifelines\\fitters\\kaplan_meier_fitter.py:80: in predict\n    merged = pd.merge_asof(predict_df, sf_df, on='timeline')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:691: in merge_asof\n    op = _AsOfMerge(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1999: in __init__\n    _OrderedMerge.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1911: in __init__\n    _MergeOperation.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:802: in __init__\n    self._maybe_require_matching_dtypes(self.left_join_keys, self.right_join_keys)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2124: in _maybe_require_matching_dtypes\n    _check_dtype_match(lk, rk, i)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nleft = array([10.]), right = array([ 0,  6,  9, 13, 19, 26, 33, 40]), i = 0\n\n    def _check_dtype_match(left: ArrayLike, right: ArrayLike, i: int):\n        if left.dtype != right.dtype:\n            if isinstance(left.dtype, CategoricalDtype) and isinstance(\n                right.dtype, CategoricalDtype\n            ):\n                # The generic error message is confusing for categoricals.\n                #\n                # In this function, the join keys include both the original\n                # ones of the merge_asof() call, and also the keys passed\n                # to its by= argument. Unordered but equal categories\n                # are not supported for the former, but will fail\n                # later with a ValueError, so we don't *need* to check\n                # for them here.\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, both sides category, but not equal ones\"\n                )\n            else:\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, must be the same type\"\n                )\n>           raise MergeError(msg)\nE           pandas.errors.MergeError: incompatible merge keys [0] dtype('float64') and dtype('int64'), must be the same type\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2120: MergeError\n____________________________ test_coxph_basic_fit _____________________________\n\nself = <lifelines.fitters.coxph_fitter.CoxPHFitter object at 0x00000237B170AB50>\nX = array([[30,  0],\n       [40,  0],\n       [50,  1],\n       [20,  1],\n       [60,  1],\n       [35,  0],\n       [45,  1],\n       [55,  0]])\nT = array([5, 6, 6, 2, 4, 3, 8, 7]), E = array([1, 0, 1, 1, 1, 0, 1, 1])\ninitial_beta = array([0., 0.]), max_iter = 50, tol = 1e-09\n\n    def _newton_rhapson(self, X, T, E, initial_beta, max_iter=50, tol=1e-9):\n        n_features = X.shape[1]\n        beta = np.array(initial_beta, dtype=float)\n    \n        for i in range(max_iter):\n            risk_scores = np.exp(X @ beta)\n            unique_event_times = np.unique(T[E == 1])\n    \n            gradient = np.zeros(n_features)\n            hessian = np.zeros((n_features, n_features))\n            log_likelihood = 0.0\n    \n            for t in sorted(unique_event_times):\n                at_risk_mask = T >= t\n                event_mask = (T == t) & (E == 1)\n                d_i = np.sum(event_mask)\n    \n                if d_i == 0: continue\n    \n                risk_set_X = X[at_risk_mask]\n                risk_set_scores = risk_scores[at_risk_mask]\n    \n                S0 = np.sum(risk_set_scores)\n                if S0 == 0: continue\n    \n                S1 = np.sum(risk_set_X * risk_set_scores[:, np.newaxis], axis=0)\n                S2 = np.sum(np.einsum('ij,ik->ijk', risk_set_X, risk_set_X) * risk_set_scores[:, np.newaxis, np.newaxis], axis=0)\n    \n                event_X_sum = np.sum(X[event_mask], axis=0)\n    \n                log_likelihood += np.sum(X[event_mask] @ beta) - d_i * np.log(S0)\n                gradient += event_X_sum - d_i * (S1 / S0)\n                hessian -= d_i * ((S2 / S0) - np.outer(S1, S1) / (S0 ** 2))\n    \n            try:\n>               inv_hessian = linalg.inv(-hessian)\n\ngeneration\\Lifelines\\lifelines\\fitters\\coxph_fitter.py:53: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\linalg\\_basic.py:940: in inv\n    a1 = _asarray_validated(a, check_finite=check_finite)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\_lib\\_util.py:321: in _asarray_validated\n    a = toarray(a)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\na = array([[nan, nan],\n       [nan, nan]]), dtype = None, order = None\n\n    @set_module('numpy')\n    def asarray_chkfinite(a, dtype=None, order=None):\n        \"\"\"Convert the input to an array, checking for NaNs or Infs.\n    \n        Parameters\n        ----------\n        a : array_like\n            Input data, in any form that can be converted to an array.  This\n            includes lists, lists of tuples, tuples, tuples of tuples, tuples\n            of lists and ndarrays.  Success requires no NaNs or Infs.\n        dtype : data-type, optional\n            By default, the data-type is inferred from the input data.\n        order : {'C', 'F', 'A', 'K'}, optional\n            Memory layout.  'A' and 'K' depend on the order of input array a.\n            'C' row-major (C-style),\n            'F' column-major (Fortran-style) memory representation.\n            'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n            'K' (keep) preserve input order\n            Defaults to 'C'.\n    \n        Returns\n        -------\n        out : ndarray\n            Array interpretation of `a`.  No copy is performed if the input\n            is already an ndarray.  If `a` is a subclass of ndarray, a base\n            class ndarray is returned.\n    \n        Raises\n        ------\n        ValueError\n            Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).\n    \n        See Also\n        --------\n        asarray : Create and array.\n        asanyarray : Similar function which passes through subclasses.\n        ascontiguousarray : Convert input to a contiguous array.\n        asfortranarray : Convert input to an ndarray with column-major\n                         memory order.\n        fromiter : Create an array from an iterator.\n        fromfunction : Construct an array by executing a function on grid\n                       positions.\n    \n        Examples\n        --------\n        Convert a list into an array.  If all elements are finite\n        ``asarray_chkfinite`` is identical to ``asarray``.\n    \n        >>> a = [1, 2]\n        >>> np.asarray_chkfinite(a, dtype=float)\n        array([1., 2.])\n    \n        Raises ValueError if array_like contains Nans or Infs.\n    \n        >>> a = [1, 2, np.inf]\n        >>> try:\n        ...     np.asarray_chkfinite(a)\n        ... except ValueError:\n        ...     print('ValueError')\n        ...\n        ValueError\n    \n        \"\"\"\n        a = asarray(a, dtype=dtype, order=order)\n        if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():\n>           raise ValueError(\n                \"array must not contain infs or NaNs\")\nE           ValueError: array must not contain infs or NaNs\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:649: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n>       cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Lifelines\\lifelines\\fitters\\coxph_fitter.py:95: in fit\n    final_beta, final_hessian = self._newton_rhapson(X, T, E, initial_beta)\ngeneration\\Lifelines\\lifelines\\fitters\\coxph_fitter.py:56: in _newton_rhapson\n    inv_hessian = linalg.pinv(-hessian)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\_lib\\deprecation.py:213: in inner_f\n    return f(*args, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\linalg\\_basic.py:1422: in pinv\n    a = _asarray_validated(a, check_finite=check_finite)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\_lib\\_util.py:321: in _asarray_validated\n    a = toarray(a)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\na = array([[nan, nan],\n       [nan, nan]]), dtype = None, order = None\n\n    @set_module('numpy')\n    def asarray_chkfinite(a, dtype=None, order=None):\n        \"\"\"Convert the input to an array, checking for NaNs or Infs.\n    \n        Parameters\n        ----------\n        a : array_like\n            Input data, in any form that can be converted to an array.  This\n            includes lists, lists of tuples, tuples, tuples of tuples, tuples\n            of lists and ndarrays.  Success requires no NaNs or Infs.\n        dtype : data-type, optional\n            By default, the data-type is inferred from the input data.\n        order : {'C', 'F', 'A', 'K'}, optional\n            Memory layout.  'A' and 'K' depend on the order of input array a.\n            'C' row-major (C-style),\n            'F' column-major (Fortran-style) memory representation.\n            'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n            'K' (keep) preserve input order\n            Defaults to 'C'.\n    \n        Returns\n        -------\n        out : ndarray\n            Array interpretation of `a`.  No copy is performed if the input\n            is already an ndarray.  If `a` is a subclass of ndarray, a base\n            class ndarray is returned.\n    \n        Raises\n        ------\n        ValueError\n            Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).\n    \n        See Also\n        --------\n        asarray : Create and array.\n        asanyarray : Similar function which passes through subclasses.\n        ascontiguousarray : Convert input to a contiguous array.\n        asfortranarray : Convert input to an ndarray with column-major\n                         memory order.\n        fromiter : Create an array from an iterator.\n        fromfunction : Construct an array by executing a function on grid\n                       positions.\n    \n        Examples\n        --------\n        Convert a list into an array.  If all elements are finite\n        ``asarray_chkfinite`` is identical to ``asarray``.\n    \n        >>> a = [1, 2]\n        >>> np.asarray_chkfinite(a, dtype=float)\n        array([1., 2.])\n    \n        Raises ValueError if array_like contains Nans or Infs.\n    \n        >>> a = [1, 2, np.inf]\n        >>> try:\n        ...     np.asarray_chkfinite(a)\n        ... except ValueError:\n        ...     print('ValueError')\n        ...\n        ValueError\n    \n        \"\"\"\n        a = asarray(a, dtype=dtype, order=order)\n        if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():\n>           raise ValueError(\n                \"array must not contain infs or NaNs\")\nE           ValueError: array must not contain infs or NaNs\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:649: ValueError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       s0 = float(kmf.predict(0.0))\n\ntests\\Lifelines\\functional_test.py:141: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Lifelines\\lifelines\\fitters\\kaplan_meier_fitter.py:80: in predict\n    merged = pd.merge_asof(predict_df, sf_df, on='timeline')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:691: in merge_asof\n    op = _AsOfMerge(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1999: in __init__\n    _OrderedMerge.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1911: in __init__\n    _MergeOperation.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:802: in __init__\n    self._maybe_require_matching_dtypes(self.left_join_keys, self.right_join_keys)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2124: in _maybe_require_matching_dtypes\n    _check_dtype_match(lk, rk, i)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nleft = array([0.]), right = array([0, 2, 4, 5, 6]), i = 0\n\n    def _check_dtype_match(left: ArrayLike, right: ArrayLike, i: int):\n        if left.dtype != right.dtype:\n            if isinstance(left.dtype, CategoricalDtype) and isinstance(\n                right.dtype, CategoricalDtype\n            ):\n                # The generic error message is confusing for categoricals.\n                #\n                # In this function, the join keys include both the original\n                # ones of the merge_asof() call, and also the keys passed\n                # to its by= argument. Unordered but equal categories\n                # are not supported for the former, but will fail\n                # later with a ValueError, so we don't *need* to check\n                # for them here.\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, both sides category, but not equal ones\"\n                )\n            else:\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, must be the same type\"\n                )\n>           raise MergeError(msg)\nE           pandas.errors.MergeError: incompatible merge keys [0] dtype('float64') and dtype('int64'), must be the same type\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2120: MergeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       s1 = float(kmf.predict(1.0))\n\ntests\\Lifelines\\functional_test.py:150: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Lifelines\\lifelines\\fitters\\kaplan_meier_fitter.py:80: in predict\n    merged = pd.merge_asof(predict_df, sf_df, on='timeline')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:691: in merge_asof\n    op = _AsOfMerge(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1999: in __init__\n    _OrderedMerge.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1911: in __init__\n    _MergeOperation.__init__(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:802: in __init__\n    self._maybe_require_matching_dtypes(self.left_join_keys, self.right_join_keys)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2124: in _maybe_require_matching_dtypes\n    _check_dtype_match(lk, rk, i)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nleft = array([1.]), right = array([0, 2, 4, 5, 6]), i = 0\n\n    def _check_dtype_match(left: ArrayLike, right: ArrayLike, i: int):\n        if left.dtype != right.dtype:\n            if isinstance(left.dtype, CategoricalDtype) and isinstance(\n                right.dtype, CategoricalDtype\n            ):\n                # The generic error message is confusing for categoricals.\n                #\n                # In this function, the join keys include both the original\n                # ones of the merge_asof() call, and also the keys passed\n                # to its by= argument. Unordered but equal categories\n                # are not supported for the former, but will fail\n                # later with a ValueError, so we don't *need* to check\n                # for them here.\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, both sides category, but not equal ones\"\n                )\n            else:\n                msg = (\n                    f\"incompatible merge keys [{i}] {repr(left.dtype)} and \"\n                    f\"{repr(right.dtype)}, must be the same type\"\n                )\n>           raise MergeError(msg)\nE           pandas.errors.MergeError: incompatible merge keys [0] dtype('float64') and dtype('int64'), must be the same type\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:2120: MergeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n_________________ test_coxph_params_index_matches_covariates __________________\n\nself = <lifelines.fitters.coxph_fitter.CoxPHFitter object at 0x00000237F0717F10>\nX = array([[30,  0],\n       [40,  0],\n       [50,  1],\n       [20,  1],\n       [60,  1],\n       [35,  0],\n       [45,  1],\n       [55,  0]])\nT = array([5, 6, 6, 2, 4, 3, 8, 7]), E = array([1, 0, 1, 1, 1, 0, 1, 1])\ninitial_beta = array([0., 0.]), max_iter = 50, tol = 1e-09\n\n    def _newton_rhapson(self, X, T, E, initial_beta, max_iter=50, tol=1e-9):\n        n_features = X.shape[1]\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Loguru", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'INFO:file-line-1' in ''", "returncode": 1, "elapsed_time_s": 1.964796, "avg_memory_mb": 33.55, "avg_cpu_percent": 100.9, "passed": 2, "failed": 9, "skipped": 0, "total": 11, "functional_score": 0.1818, "timestamp": "2026-01-01 20:15:14", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n        log.debug(\"debug-msg\")\n        log.info(\"info-msg\")\n        log.warning(\"warn-msg\")\n    \n        lines = _lines(buf)\n>       assert len(lines) >= 3\nE       assert 1 >= 3\nE        +  where 1 = len([\"Level(name='DEBUG', no=10, color='<blue>', icon=' '):debug-msgLevel(name='INFO', no=20, color='<green>', icon=' '):info-msgLevel(name='WARNING', no=30, color='<yellow>', icon=' '):warn-msg\"])\n\ntests\\Loguru\\functional_test.py:105: AssertionError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n>       log.log(\"INFO\", \"hello-info\")\nE       AttributeError: 'Logger' object has no attribute 'log'\n\ntests\\Loguru\\functional_test.py:125: AttributeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n    \n        bound = log.bind(user=\"alice\", request_id=\"req-123\")\n        bound.info(\"hello\")\n    \n        out = buf.getvalue()\n>       assert \"INFO:\" in out\nE       assert 'INFO:' in \"Level(name='INFO', no=20, color='<green>', icon=' '):hello user= req=\"\n\ntests\\Loguru\\functional_test.py:140: AssertionError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-452/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n        logger.remove()\n        logger.add(log_path, format=\"{level}:{message}\", level=\"INFO\")\n    \n        logger.info(\"file-line-1\")\n        logger.warning(\"file-line-2\")\n    \n        assert log_path.exists()\n        text = log_path.read_text(encoding=\"utf-8\")\n>       assert \"INFO:file-line-1\" in text\nE       AssertionError: assert 'INFO:file-line-1' in ''\n\ntests\\Loguru\\functional_test.py:186: AssertionError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x00000207CDB2BCD0>\ns = \"Level(name='INFO', no=20, color='<green>', icon=' '):json-msg\", idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the in", "stdout_sha1": "8e64917d9f4742f7a3fe7a92fe862091d9931cb1", "stdout_len": 7193, "stdout": "F.FFF.FFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n        log.debug(\"debug-msg\")\n        log.info(\"info-msg\")\n        log.warning(\"warn-msg\")\n    \n        lines = _lines(buf)\n>       assert len(lines) >= 3\nE       assert 1 >= 3\nE        +  where 1 = len([\"Level(name='DEBUG', no=10, color='<blue>', icon=' '):debug-msgLevel(name='INFO', no=20, color='<green>', icon=' '):info-msgLevel(name='WARNING', no=30, color='<yellow>', icon=' '):warn-msg\"])\n\ntests\\Loguru\\functional_test.py:105: AssertionError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n    \n>       log.log(\"INFO\", \"hello-info\")\nE       AttributeError: 'Logger' object has no attribute 'log'\n\ntests\\Loguru\\functional_test.py:125: AttributeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n    \n        bound = log.bind(user=\"alice\", request_id=\"req-123\")\n        bound.info(\"hello\")\n    \n        out = buf.getvalue()\n>       assert \"INFO:\" in out\nE       assert 'INFO:' in \"Level(name='INFO', no=20, color='<green>', icon=' '):hello user= req=\"\n\ntests\\Loguru\\functional_test.py:140: AssertionError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-452/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n        logger.remove()\n        logger.add(log_path, format=\"{level}:{message}\", level=\"INFO\")\n    \n        logger.info(\"file-line-1\")\n        logger.warning(\"file-line-2\")\n    \n        assert log_path.exists()\n        text = log_path.read_text(encoding=\"utf-8\")\n>       assert \"INFO:file-line-1\" in text\nE       AssertionError: assert 'INFO:file-line-1' in ''\n\ntests\\Loguru\\functional_test.py:186: AssertionError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x00000207CDB2BCD0>\ns = \"Level(name='INFO', no=20, color='<green>', icon=' '):json-msg\", idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n        patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\n>       patched.info(\"hello\")\nE       AttributeError: 'NoneType' object has no attribute 'info'\n\ntests\\Loguru\\functional_test.py:212: AttributeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n    \n        log.debug(\"nope\")\n        log.info(\"yep\")\n    \n        out = buf.getvalue()\n        assert \"nope\" not in out\n        assert \"yep\" in out\n>       assert \"INFO:\" in out\nE       assert 'INFO:' in \"Level(name='INFO', no=20, color='<green>', icon=' '):yep\"\n\ntests\\Loguru\\functional_test.py:231: AssertionError\n____________________ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format() -> None:\n        # Default format should include some timestamp-like content, level, and message.\n        buf = io.StringIO()\n        logger.remove()\n        logger.add(buf)\n    \n        logger.info(\"default-format-test\")\n    \n        output = buf.getvalue()\n>       assert \"INFO\" in output\nE       AssertionError: assert 'INFO' in 'default-format-test\\n'\n\ntests\\Loguru\\functional_test.py:243: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - as...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Att...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - asse...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Ass...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n9 failed, 2 passed in 0.61s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 2.887382, "avg_memory_mb": 36.47, "avg_cpu_percent": 69.7, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 20:16:52", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.49s\n", "stdout_sha1": "15d2106617b14cec6b53ef8fa582355f3a3d8679", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.49s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 1.884046, "avg_memory_mb": 33.02, "avg_cpu_percent": 98.3, "passed": 7, "failed": 3, "skipped": 9, "total": 19, "functional_score": 0.3684, "timestamp": "2026-01-01 20:18:48", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_inline_code_and_code_block _______________________\n\n    def test_inline_code_and_code_block() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use `code()` inline.\n    \n            ```\n            def foo():\n                return 42\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<code>\" in norm and \"</code>\" in norm\n>       assert \"code()\" in norm\nE       AssertionError: assert 'code()' in '<p>Use <strong>CODE<em>PLACEHOLDER</em>0</strong> inline.</p>\\n<pre><code>def foo():\\nreturn 42\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:143: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_inline_code_and_code_block - A...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.53s\n", "stdout_sha1": "2d3cf2a1e7d564acb885f54c5be89796be70e90b", "stdout_len": 2423, "stdout": "..F...F..Fsssssssss                                                      [100%]\n================================== FAILURES ===================================\n_______________________ test_inline_code_and_code_block _______________________\n\n    def test_inline_code_and_code_block() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use `code()` inline.\n    \n            ```\n            def foo():\n                return 42\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<code>\" in norm and \"</code>\" in norm\n>       assert \"code()\" in norm\nE       AssertionError: assert 'code()' in '<p>Use <strong>CODE<em>PLACEHOLDER</em>0</strong> inline.</p>\\n<pre><code>def foo():\\nreturn 42\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:143: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_inline_code_and_code_block - A...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.53s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 1.972484, "avg_memory_mb": 32.02, "avg_cpu_percent": 96.7, "passed": 7, "failed": 4, "skipped": 0, "total": 11, "functional_score": 0.6364, "timestamp": "2026-01-01 20:19:52", "stdout_excerpt": "==== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n        assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\n    \n        text = \"\\n\".join(_file(p).lower() for p in existing)\n    \n        # Accept multiple common patterns.\n        # Examples: __version__ = \"10.0.0\", VERSION = \"10.0.0\", version = \"10.0.0\"\n        import re\n    \n>       assert (\n            re.search(r\"__version__\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\b\", text)\n        ), \"Expected a version-like assignment or token in version source files.\"\nE       AssertionError: Expected a version-like assignment or token in version source files.\nE       assert (None or None or None)\nE        +  where None = <function search at 0x0000017F0D6E99D0>('__version__\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '# this file is intentionally left blank.')\nE        +    where <function search at 0x0000017F0D6E99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000017F0D6E99D0>('\\\\bversion\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '# this file is intentionally left blank.')\nE        +    where <function search at 0x0000017F0D6E99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000017F0D6E99D0>('\\\\bversion\\\\b', '# this file is intentionally left blank.')\nE        +    where <function search at 0x0000017F0D6E99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\n\ntests\\Mitmproxy\\functional_test.py:103: AssertionError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools", "stdout_sha1": "3098ccc0ee17c4bd4b7c227974309ff8800d96da", "stdout_len": 5504, "stdout": "..F.....FFF                                                              [100%]\n================================== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n        assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\n    \n        text = \"\\n\".join(_file(p).lower() for p in existing)\n    \n        # Accept multiple common patterns.\n        # Examples: __version__ = \"10.0.0\", VERSION = \"10.0.0\", version = \"10.0.0\"\n        import re\n    \n>       assert (\n            re.search(r\"__version__\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\b\", text)\n        ), \"Expected a version-like assignment or token in version source files.\"\nE       AssertionError: Expected a version-like assignment or token in version source files.\nE       assert (None or None or None)\nE        +  where None = <function search at 0x0000017F0D6E99D0>('__version__\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '# this file is intentionally left blank.')\nE        +    where <function search at 0x0000017F0D6E99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000017F0D6E99D0>('\\\\bversion\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '# this file is intentionally left blank.')\nE        +    where <function search at 0x0000017F0D6E99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000017F0D6E99D0>('\\\\bversion\\\\b', '# this file is intentionally left blank.')\nE        +    where <function search at 0x0000017F0D6E99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\n\ntests\\Mitmproxy\\functional_test.py:103: AssertionError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_003_version_source_file_exists_and_has_version_like_token\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n4 failed, 7 passed in 0.62s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Mutagen", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "KeyError", "exception_msg": "\"No frame with ID '0'\"", "returncode": 1, "elapsed_time_s": 1.934385, "avg_memory_mb": 33.25, "avg_cpu_percent": 98.3, "passed": 8, "failed": 4, "skipped": 0, "total": 12, "functional_score": 0.6667, "timestamp": "2026-01-01 20:24:28", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_easyid3_genre_and_albumartist_roundtrip _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-454/test_easyid3_genre_and_albumar0')\n\n    def test_easyid3_genre_and_albumartist_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common optional fields via EasyID3 (genre/albumartist).\"\"\"\n        audio_path = tmp_path / \"genre_albumartist.mp3\"\n    \n        tags = EasyID3()\n        tags[\"title\"] = [\"Tagged Song\"]\n        tags[\"artist\"] = [\"Main Artist\"]\n>       tags[\"albumartist\"] = [\"Album Artist\"]\n\ntests\\Mutagen\\functional_test.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.easyid3.EasyID3 object at 0x00000205BD126C70>\nkey = 'albumartist', value = ['Album Artist']\n\n    def __setitem__(self, key, value):\n        key = key.lower()\n        if key not in self._EASY_MAP:\n>           raise KeyError(f\"EasyID3 key '{key}' not recognized\")\nE           KeyError: \"EasyID3 key 'albumartist' not recognized\"\n\ngeneration\\Mutagen\\mutagen\\easyid3.py:42: KeyError\n_______________ test_low_level_id3_frames_with_comment_and_apic _______________\n\nself = <mutagen.id3.ID3 object at 0x00000205BBB0AF40>, key = 0\n\n    def __getitem__(self, key):\n        try:\n>           return self.frames[key][0]\nE           IndexError: list index out of range\n\ngeneration\\Mutagen\\mutagen\\id3.py:240: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-454/test_low_level_id3_frames_with0')\n\n    def test_low_level_id3_frames_with_comment_and_apic(tmp_path: Path) -> None:\n        \"\"\"Use low-level ID3 frames to store text and embedded artwork.\"\"\"\n        audio_path = tmp_path / \"id3_frames.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Frame Title\"))\n        tags.add(TPE1(encoding=3, text=\"Frame Artist\"))\n        tags.add(\n            COMM(\n                encoding=3,\n                lang=\"eng\",\n                desc=\"Comment\",\n                text=\"This is a test comment.\",\n            )\n        )\n    \n        image_data = b\"\\xff\\xd8\\xff\\x00FAKEJPEGDATA\"\n        tags.add(\n            APIC(\n                encoding=3,\n                mime=\"image/jpeg\",\n                type=3,\n                desc=\"Cover\",\n                data=image_data,\n            )\n        )\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n    \n>       assert \"TIT2\" in loaded\n\ntests\\Mutagen\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3.ID3 object at 0x00000205BBB0AF40>, key = 0\n\n    def __getitem__(self, key):\n        try:\n            return self.frames[key][0]\n        except (KeyError, IndexError):\n>           raise KeyError(f\"No frame with ID '{key}'\")\nE           KeyError: \"No frame with ID '0'\"\n\ngeneration\\Mutagen\\mutagen\\id3.py:242: KeyError\n_______________________ test_id3_overwrite_title_frame ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-454/test_id3_overwrite_title_frame0')\n\n    def test_id3_overwrite_title_frame(tmp_path: Path) -> None:\n        \"\"\"Overwrite an existing ID3 title frame and ensure the latest text remains.\"\"\"\n        audio_path = tmp_path / \"overwrite_title.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Old Title\"))\n        tags.save(str(audio_path))\n    \n        tags2 = ID3(str(audio_path))\n        tags2[\"TIT2\"].text = [\"New Title\"]\n>       tags2.save()\n\ntests\\Mutagen\\functional_test.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Mutagen\\mutagen\\id3.py:214: in save\n    all_frames_data += frame.serialize()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3._create_text_frame.<locals>.", "stdout_sha1": "280a1ab0a317e27cdd529d0a19bc99d14b603c28", "stdout_len": 5823, "stdout": ".....F.FF..F                                                             [100%]\n================================== FAILURES ===================================\n________________ test_easyid3_genre_and_albumartist_roundtrip _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-454/test_easyid3_genre_and_albumar0')\n\n    def test_easyid3_genre_and_albumartist_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common optional fields via EasyID3 (genre/albumartist).\"\"\"\n        audio_path = tmp_path / \"genre_albumartist.mp3\"\n    \n        tags = EasyID3()\n        tags[\"title\"] = [\"Tagged Song\"]\n        tags[\"artist\"] = [\"Main Artist\"]\n>       tags[\"albumartist\"] = [\"Album Artist\"]\n\ntests\\Mutagen\\functional_test.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.easyid3.EasyID3 object at 0x00000205BD126C70>\nkey = 'albumartist', value = ['Album Artist']\n\n    def __setitem__(self, key, value):\n        key = key.lower()\n        if key not in self._EASY_MAP:\n>           raise KeyError(f\"EasyID3 key '{key}' not recognized\")\nE           KeyError: \"EasyID3 key 'albumartist' not recognized\"\n\ngeneration\\Mutagen\\mutagen\\easyid3.py:42: KeyError\n_______________ test_low_level_id3_frames_with_comment_and_apic _______________\n\nself = <mutagen.id3.ID3 object at 0x00000205BBB0AF40>, key = 0\n\n    def __getitem__(self, key):\n        try:\n>           return self.frames[key][0]\nE           IndexError: list index out of range\n\ngeneration\\Mutagen\\mutagen\\id3.py:240: IndexError\n\nDuring handling of the above exception, another exception occurred:\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-454/test_low_level_id3_frames_with0')\n\n    def test_low_level_id3_frames_with_comment_and_apic(tmp_path: Path) -> None:\n        \"\"\"Use low-level ID3 frames to store text and embedded artwork.\"\"\"\n        audio_path = tmp_path / \"id3_frames.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Frame Title\"))\n        tags.add(TPE1(encoding=3, text=\"Frame Artist\"))\n        tags.add(\n            COMM(\n                encoding=3,\n                lang=\"eng\",\n                desc=\"Comment\",\n                text=\"This is a test comment.\",\n            )\n        )\n    \n        image_data = b\"\\xff\\xd8\\xff\\x00FAKEJPEGDATA\"\n        tags.add(\n            APIC(\n                encoding=3,\n                mime=\"image/jpeg\",\n                type=3,\n                desc=\"Cover\",\n                data=image_data,\n            )\n        )\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n    \n>       assert \"TIT2\" in loaded\n\ntests\\Mutagen\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3.ID3 object at 0x00000205BBB0AF40>, key = 0\n\n    def __getitem__(self, key):\n        try:\n            return self.frames[key][0]\n        except (KeyError, IndexError):\n>           raise KeyError(f\"No frame with ID '{key}'\")\nE           KeyError: \"No frame with ID '0'\"\n\ngeneration\\Mutagen\\mutagen\\id3.py:242: KeyError\n_______________________ test_id3_overwrite_title_frame ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-454/test_id3_overwrite_title_frame0')\n\n    def test_id3_overwrite_title_frame(tmp_path: Path) -> None:\n        \"\"\"Overwrite an existing ID3 title frame and ensure the latest text remains.\"\"\"\n        audio_path = tmp_path / \"overwrite_title.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Old Title\"))\n        tags.save(str(audio_path))\n    \n        tags2 = ID3(str(audio_path))\n        tags2[\"TIT2\"].text = [\"New Title\"]\n>       tags2.save()\n\ntests\\Mutagen\\functional_test.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Mutagen\\mutagen\\id3.py:214: in save\n    all_frames_data += frame.serialize()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3._create_text_frame.<locals>.TextFrame object at 0x00000205BD127CA0>\n\n    def serialize(self):\n        name = _get_encoding_name(self.encoding)\n>       payload = self.encoding.to_bytes(1, 'big') + self.text.encode(name, errors='replace')\nE       AttributeError: 'list' object has no attribute 'encode'\n\ngeneration\\Mutagen\\mutagen\\id3.py:57: AttributeError\n_______________ test_id3_text_frames_album_and_genre_roundtrip ________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-454/test_id3_text_frames_album_and0')\n\n    def test_id3_text_frames_album_and_genre_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common text frames (album/genre) using low-level ID3.\"\"\"\n        audio_path = tmp_path / \"album_genre.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Song X\"))\n        tags.add(TALB(encoding=3, text=\"Album Y\"))\n        tags.add(TCON(encoding=3, text=\"Jazz\"))\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n>       assert loaded[\"TIT2\"].text == [\"Song X\"]\nE       AssertionError: assert 'Song X' == ['Song X']\nE        +  where 'Song X' = <mutagen.id3._create_text_frame.<locals>.TextFrame object at 0x00000205BD101E80>.text\n\ntests\\Mutagen\\functional_test.py:346: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Mutagen/functional_test.py::test_easyid3_genre_and_albumartist_roundtrip\nFAILED tests/Mutagen/functional_test.py::test_low_level_id3_frames_with_comment_and_apic\nFAILED tests/Mutagen/functional_test.py::test_id3_overwrite_title_frame - Att...\nFAILED tests/Mutagen/functional_test.py::test_id3_text_frames_album_and_genre_roundtrip\n4 failed, 8 passed in 0.58s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'DateTime' object has no attribute 'timedelta'", "returncode": 1, "elapsed_time_s": 2.021308, "avg_memory_mb": 32.9, "avg_cpu_percent": 97.6, "passed": 1, "failed": 11, "skipped": 1, "total": 13, "functional_score": 0.0769, "timestamp": "2026-01-01 20:28:45", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n        assert offset_tokyo.total_seconds() == 9 * 60 * 60\n    \n>       as_str = dt_tokyo.to_datetime_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_datetime_string'\n\ntests\\Pendulum\\functional_test.py:81: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n>       shifted = base.add(days=2, hours=5, minutes=15)\n\ntests\\Pendulum\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DateTime(2021, 3, 15, 10, 30, tzinfo=Timezone('UTC')), years = 0\nmonths = 0, weeks = 0, days = 2, hours = 5, minutes = 15, seconds = 0\nmicroseconds = 0\n\n    def add(\n        self,\n        years: int = 0,\n        months: int = 0,\n        weeks: int = 0,\n        days: int = 0,\n        hours: int = 0,\n        minutes: int = 0,\n        seconds: int = 0,\n        microseconds: int = 0,\n    ) -> DateTime:\n        \"\"\"\n        Adds a duration to the datetime.\n        \"\"\"\n        dt = self\n        if years:\n            dt = _add_months(dt, years * MONTHS_PER_YEAR)\n        if months:\n            dt = _add_months(dt, months)\n    \n>       duration = dt.timedelta(\n            weeks=weeks,\n            days=days,\n            hours=hours,\n            minutes=minutes,\n            seconds=seconds,\n            microseconds=microseconds,\n        )\nE       AttributeError: 'DateTime' object has no attribute 'timedelta'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:80: AttributeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\n\ntests\\Pendulum\\functional_test.py:104: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DateTime(2011, 8, 1, 0, 0, tzinfo=Timezone('UTC')), years = 0, months = 1\nweeks = 0, days = 0, hours = 0, minutes = 0, seconds = 0, microseconds = 0\n\n    def add(\n        self,\n        years: int = 0,\n        months: int = 0,\n        weeks: int = 0,\n        days: int = 0,\n        hours: int = 0,\n        minutes: int = 0,\n        seconds: int = 0,\n        microseconds: int = 0,\n    ) -> DateTime:\n        \"\"\"\n        Adds a duration to the datetime.\n        \"\"\"\n        dt = self\n        if years:\n            dt = _add_months(dt, years * MONTHS_PER_YEAR)\n        if months:\n            dt = _add_months(dt, months)\n    \n>       duration = dt.timedelta(\n            weeks=weeks,\n            days=days,\n            hours=hours,\n            minutes=minutes,\n            seconds=seconds,\n            microseconds=microseconds,\n        )\nE       AttributeError: 'DateTime' object has no attribute 'timedelta'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:80: AttributeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29", "stdout_sha1": "6150de41c6713ccf8d02e18d8c008a57c6ec110e", "stdout_len": 8387, "stdout": "FFFFFFFF.sFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n        assert offset_tokyo.total_seconds() == 9 * 60 * 60\n    \n>       as_str = dt_tokyo.to_datetime_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_datetime_string'\n\ntests\\Pendulum\\functional_test.py:81: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n>       shifted = base.add(days=2, hours=5, minutes=15)\n\ntests\\Pendulum\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DateTime(2021, 3, 15, 10, 30, tzinfo=Timezone('UTC')), years = 0\nmonths = 0, weeks = 0, days = 2, hours = 5, minutes = 15, seconds = 0\nmicroseconds = 0\n\n    def add(\n        self,\n        years: int = 0,\n        months: int = 0,\n        weeks: int = 0,\n        days: int = 0,\n        hours: int = 0,\n        minutes: int = 0,\n        seconds: int = 0,\n        microseconds: int = 0,\n    ) -> DateTime:\n        \"\"\"\n        Adds a duration to the datetime.\n        \"\"\"\n        dt = self\n        if years:\n            dt = _add_months(dt, years * MONTHS_PER_YEAR)\n        if months:\n            dt = _add_months(dt, months)\n    \n>       duration = dt.timedelta(\n            weeks=weeks,\n            days=days,\n            hours=hours,\n            minutes=minutes,\n            seconds=seconds,\n            microseconds=microseconds,\n        )\nE       AttributeError: 'DateTime' object has no attribute 'timedelta'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:80: AttributeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\n\ntests\\Pendulum\\functional_test.py:104: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DateTime(2011, 8, 1, 0, 0, tzinfo=Timezone('UTC')), years = 0, months = 1\nweeks = 0, days = 0, hours = 0, minutes = 0, seconds = 0, microseconds = 0\n\n    def add(\n        self,\n        years: int = 0,\n        months: int = 0,\n        weeks: int = 0,\n        days: int = 0,\n        hours: int = 0,\n        minutes: int = 0,\n        seconds: int = 0,\n        microseconds: int = 0,\n    ) -> DateTime:\n        \"\"\"\n        Adds a duration to the datetime.\n        \"\"\"\n        dt = self\n        if years:\n            dt = _add_months(dt, years * MONTHS_PER_YEAR)\n        if months:\n            dt = _add_months(dt, months)\n    \n>       duration = dt.timedelta(\n            weeks=weeks,\n            days=days,\n            hours=hours,\n            minutes=minutes,\n            seconds=seconds,\n            microseconds=microseconds,\n        )\nE       AttributeError: 'DateTime' object has no attribute 'timedelta'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:80: AttributeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n        dt_ny = dt_utc.in_timezone(\"America/New_York\")\n    \n        assert int(dt_utc.timestamp()) == int(dt_ny.timestamp())\n>       assert dt_ny.to_date_string() in (\"2020-05-31\", \"2020-06-01\")\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:202: AttributeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_datetime_arithmetic_and_duration\nFAILED tests/Pendulum/functional_test.py::test_diff_for_humans_months - Attri...\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n11 failed, 1 passed, 1 skipped in 0.70s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Petl", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Use -v to get more diff", "returncode": 1, "elapsed_time_s": 1.942469, "avg_memory_mb": 32.41, "avg_cpu_percent": 97.4, "passed": 4, "failed": 2, "skipped": 6, "total": 12, "functional_score": 0.3333, "timestamp": "2026-01-01 20:30:13", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-455/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n2 failed, 4 passed, 6 skipped in 0.58s\n", "stdout_sha1": "0f3f32dee31b3f3ad2dd641ce878f4dd286a0f8e", "stdout_len": 1990, "stdout": "...ss.FsFsss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-455/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n2 failed, 4 passed, 6 skipped in 0.58s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Pygments", "failure_stage": "pre-test", "failure_type": "syntax_error", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.407595, "avg_memory_mb": 14.56, "avg_cpu_percent": 95.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 20:36:17", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 17, in <module>\n    from pygments.lex import lex\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py\", line 11, in <module>\n    from pygments.lexers import get_lexer_by_name\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 27, in <module>\n    _import_lexers()\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 23, in _import_lexers\n    from . import python, json, ini\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\python.py\", line 40\n    ![sra])\n           ^\nSyntaxError: EOL while scanning string literal\n", "stdout_sha1": "006506c7a5702b63b72a73ba33e060bfc028b2c5", "stdout_len": 2089, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 17, in <module>\n    from pygments.lex import lex\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py\", line 11, in <module>\n    from pygments.lexers import get_lexer_by_name\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 27, in <module>\n    _import_lexers()\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 23, in _import_lexers\n    from . import python, json, ini\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\python.py\", line 40\n    ![sra])\n           ^\nSyntaxError: EOL while scanning string literal\n"}
{"model": "gemini-2.5-pro-thinking", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.901365, "avg_memory_mb": 33.87, "avg_cpu_percent": 95.6, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 20:37:46", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported\")\nE           NotImplementedError: Only HS256 algorithm is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:31: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:37: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001F6C4D76C10>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:37: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\A", "stdout_sha1": "8c55577744d0159b4b02b121c2a14ff97e5ab9d0", "stdout_len": 6485, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported\")\nE           NotImplementedError: Only HS256 algorithm is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:31: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:37: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001F6C4D76C10>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:37: in encode\n    json_payload = json.dumps(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000001F6C4DEB670>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.52s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.523578, "avg_memory_mb": 31.45, "avg_cpu_percent": 101.1, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 20:48:14", "stdout_excerpt": "\n1 skipped in 0.14s\n", "stdout_sha1": "95c5fda1107f8078c182653b3ba949fc343f3984", "stdout_len": 20, "stdout": "\n1 skipped in 0.14s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'property' object is not callable", "returncode": 1, "elapsed_time_s": 1.790669, "avg_memory_mb": 32.94, "avg_cpu_percent": 99.1, "passed": 8, "failed": 4, "skipped": 0, "total": 12, "functional_score": 0.6667, "timestamp": "2026-01-01 20:50:21", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\n\ntests\\Schedule\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Schedule\\schedule\\__init__.py:200: in do\n    self._schedule_next_run()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Job(interval=1, unit=days, do=job1, args=(), kwargs={}, last_run=[never], next_run=[never])\n\n    def _schedule_next_run(self):\n        \"\"\"\n        Compute the instant when this job should run next.\n        \"\"\"\n        if self.unit is None:\n            raise ScheduleValueError(\"Job is not scheduled. Add a unit \"\n                                     \"(.seconds, .minutes, etc.)\")\n    \n        self.period = datetime.timedelta(**{self.unit: self.interval})\n        now = datetime.datetime.now()\n    \n        if self.unit in ('seconds', 'minutes', 'hours'):\n            self.next_run = now + self.period\n            return\n    \n        if self.unit == 'days':\n            if self.at_time is None:\n>               raise ScheduleValueError('.at() must be used with .day(s)')\nE               schedule.ScheduleValueError: .at() must be used with .day(s)\n\ngeneration\\Schedule\\schedule\\__init__.py:249: ScheduleValueError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n        schedule.every().hour.do(job)\n>       idle = schedule.idle_seconds()\nE       TypeError: 'property' object is not callable\n\ntests\\Schedule\\functional_test.py:254: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\n4 failed, 8 passed in 0.50s\n", "stdout_sha1": "8ffc667cef3b47591f71652842f5e0f95fe76ffc", "stdout_len": 3657, "stdout": "..FF....FF..                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       j1 = schedule.every().day.do(job1)\n\ntests\\Schedule\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Schedule\\schedule\\__init__.py:200: in do\n    self._schedule_next_run()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Job(interval=1, unit=days, do=job1, args=(), kwargs={}, last_run=[never], next_run=[never])\n\n    def _schedule_next_run(self):\n        \"\"\"\n        Compute the instant when this job should run next.\n        \"\"\"\n        if self.unit is None:\n            raise ScheduleValueError(\"Job is not scheduled. Add a unit \"\n                                     \"(.seconds, .minutes, etc.)\")\n    \n        self.period = datetime.timedelta(**{self.unit: self.interval})\n        now = datetime.datetime.now()\n    \n        if self.unit in ('seconds', 'minutes', 'hours'):\n            self.next_run = now + self.period\n            return\n    \n        if self.unit == 'days':\n            if self.at_time is None:\n>               raise ScheduleValueError('.at() must be used with .day(s)')\nE               schedule.ScheduleValueError: .at() must be used with .day(s)\n\ngeneration\\Schedule\\schedule\\__init__.py:249: ScheduleValueError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n        schedule.every().hour.do(job)\n>       idle = schedule.idle_seconds()\nE       TypeError: 'property' object is not callable\n\ntests\\Schedule\\functional_test.py:254: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\n4 failed, 8 passed in 0.50s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'this-is-a-test' in '___thisisatest___'", "returncode": 1, "elapsed_time_s": 1.717449, "avg_memory_mb": 31.96, "avg_cpu_percent": 100.0, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 20:51:41", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.41s\n", "stdout_sha1": "89faf545b916353bffb5b0e7f3ed51902ec7a936", "stdout_len": 956, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.41s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "'MetaData' object has no attribute 'clear'", "returncode": 2, "elapsed_time_s": 1.880075, "avg_memory_mb": 36.62, "avg_cpu_percent": 97.3, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 20:57:08", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: 'MetaData' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: 'MetaData' object h...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.54s\n", "stdout_sha1": "863bd0f349ff764d123fc7ea8614b0ab8f5054eb", "stdout_len": 562, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: 'MetaData' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: 'MetaData' object h...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.54s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Stegano", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "?", "returncode": 1, "elapsed_time_s": 3.148552, "avg_memory_mb": 36.8, "avg_cpu_percent": 98.5, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 20:59:23", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = lsb.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'hello worl' == 'hello world'\nE         \nE         - hello world\nE         ?           -\nE         + hello worl\n\ntests\\Stegano\\functional_test.py:94: AssertionError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:86: in hide\n    x, y, channel_index = next(coord_generator)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimg = <PIL.Image.Image image mode=RGB size=512x512 at 0x152E7A3FC10>\ngenerator = <generator object eratosthenes at 0x00000152E7C8A740>, shift = 0\n\n    def _get_coords(img, generator=None, shift=0):\n        \"\"\"\n        Generates pixel coordinates (x, y, channel_index) for embedding data.\n        \"\"\"\n        width, height = img.size\n    \n        if img.mode == 'RGB':\n            num_channels = 3\n        elif img.mode == 'RGBA':\n            num_channels = 4\n        elif img.mode == 'L':\n            num_channels = 1\n        else:\n            raise ValueError(f\"Unsupported image mode: {img.mode}\")\n    \n        total_positions = width * height * num_channels\n    \n        if generator:\n>           indices = itertools.islice(generator(), shift, None)\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:23: TypeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n        img_obj = lsb.hide(str(LENNA_PNG), secret)\n        revealed = lsb.reveal(img_obj)\n>       assert revealed == secret\nE       AssertionError: assert 'object inpu' == 'object input'\nE         \nE         - object input\nE         ?            -\nE         + object inpu\n\ntests\\Stegano\\functional_test.py:134: AssertionError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n        encoded_img = red.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = red.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'red secre' == 'red secret'\nE         \nE         - red secret\nE         ?       ", "stdout_sha1": "d181310a32d04a3b2c62b4e7bc16e73ba51ab967", "stdout_len": 7625, "stdout": "FF.FFF..F.F.                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = lsb.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'hello worl' == 'hello world'\nE         \nE         - hello world\nE         ?           -\nE         + hello worl\n\ntests\\Stegano\\functional_test.py:94: AssertionError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:86: in hide\n    x, y, channel_index = next(coord_generator)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimg = <PIL.Image.Image image mode=RGB size=512x512 at 0x152E7A3FC10>\ngenerator = <generator object eratosthenes at 0x00000152E7C8A740>, shift = 0\n\n    def _get_coords(img, generator=None, shift=0):\n        \"\"\"\n        Generates pixel coordinates (x, y, channel_index) for embedding data.\n        \"\"\"\n        width, height = img.size\n    \n        if img.mode == 'RGB':\n            num_channels = 3\n        elif img.mode == 'RGBA':\n            num_channels = 4\n        elif img.mode == 'L':\n            num_channels = 1\n        else:\n            raise ValueError(f\"Unsupported image mode: {img.mode}\")\n    \n        total_positions = width * height * num_channels\n    \n        if generator:\n>           indices = itertools.islice(generator(), shift, None)\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:23: TypeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n        img_obj = lsb.hide(str(LENNA_PNG), secret)\n        revealed = lsb.reveal(img_obj)\n>       assert revealed == secret\nE       AssertionError: assert 'object inpu' == 'object input'\nE         \nE         - object input\nE         ?            -\nE         + object inpu\n\ntests\\Stegano\\functional_test.py:134: AssertionError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n        encoded_img = red.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = red.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'red secre' == 'red secret'\nE         \nE         - red secret\nE         ?          -\nE         + red secre\n\ntests\\Stegano\\functional_test.py:152: AssertionError\n________________ test_red_hide_and_reveal_extended_latin_text _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_red_hide_and_reveal_exten0')\n\n    def test_red_hide_and_reveal_extended_latin_text(tmp_path: Path) -> None:\n        \"\"\"Red backend stores per-char ord() into a byte channel; Latin-1 chars like 'é' are valid.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"Café au lait\"\n        output = tmp_path / \"red_latin.png\"\n    \n        encoded_img = red.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n        revealed = red.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'Café au lai' == 'Café au lait'\nE         \nE         - Café au lait\nE         ?            -\nE         + Café au lai\n\ntests\\Stegano\\functional_test.py:166: AssertionError\n________________________ test_wav_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_wav_hide_and_reveal_text0')\n\n    def test_wav_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"wav.hide writes output WAV; wav.reveal returns the same string.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"wav secret\"\n        output = tmp_path / \"out.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'wav secre' == 'wav secret'\nE         \nE         - wav secret\nE         ?          -\nE         + wav secre\n\ntests\\Stegano\\functional_test.py:224: AssertionError\n____________________ test_wav_hide_and_reveal_longer_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-457/test_wav_hide_and_reveal_longe0')\n\n    def test_wav_hide_and_reveal_longer_text(tmp_path: Path) -> None:\n        \"\"\"Roundtrip a longer ASCII message via WAV backend.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\"\n        output = tmp_path / \"out_long.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       AssertionError: assert 'WAV backend ...mnopqrstuvwxy' == 'WAV backend ...nopqrstuvwxyz'\nE         \nE         Skipping 51 identical leading characters in diff, use -v to show\nE         - opqrstuvwxyz\nE         ?            -\nE         + opqrstuvwxy\n\ntests\\Stegano\\functional_test.py:254: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Asse...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_text - Asse...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_extended_latin_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_text - Asse...\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_longer_text\n7 failed, 5 passed in 1.79s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Tablib", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "NotImplementedError", "exception_msg": "Format 'html' is not supported.", "returncode": 1, "elapsed_time_s": 1.784532, "avg_memory_mb": 32.74, "avg_cpu_percent": 99.1, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2026-01-01 21:01:11", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset headers=['first_name', 'last_name', 'age'] rows=3>, fmt = 'tsv'\n\n    def export(self, fmt):\n        \"\"\"Exports the dataset to a given format.\"\"\"\n        if fmt not in _formats:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported.\")\nE           NotImplementedError: Format 'tsv' is not supported.\n\ngeneration\\Tablib\\tablib\\core.py:100: NotImplementedError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset headers=['first_name', 'last_name', 'age'] rows=3>, fmt = 'html'\n\n    def export(self, fmt):\n        \"\"\"Exports the dataset to a given format.\"\"\"\n        if fmt not in _formats:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported.\")\nE           NotImplementedError: Format 'html' is not supported.\n\ngeneration\\Tablib\\tablib\\core.py:100: NotImplementedError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.47s\n", "stdout_sha1": "43c44a4f463ff7f506548609d64dddfe2396af77", "stdout_len": 2946, "stdout": ".F..F...F..                                                              [100%]\n================================== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset headers=['first_name', 'last_name', 'age'] rows=3>, fmt = 'tsv'\n\n    def export(self, fmt):\n        \"\"\"Exports the dataset to a given format.\"\"\"\n        if fmt not in _formats:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported.\")\nE           NotImplementedError: Format 'tsv' is not supported.\n\ngeneration\\Tablib\\tablib\\core.py:100: NotImplementedError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset headers=['first_name', 'last_name', 'age'] rows=3>, fmt = 'html'\n\n    def export(self, fmt):\n        \"\"\"Exports the dataset to a given format.\"\"\"\n        if fmt not in _formats:\n>           raise NotImplementedError(f\"Format '{fmt}' is not supported.\")\nE           NotImplementedError: Format 'html' is not supported.\n\ngeneration\\Tablib\\tablib\\core.py:100: NotImplementedError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.47s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute 'insert'", "returncode": 1, "elapsed_time_s": 1.867228, "avg_memory_mb": 33.1, "avg_cpu_percent": 99.1, "passed": 7, "failed": 5, "skipped": 0, "total": 12, "functional_score": 0.5833, "timestamp": "2026-01-01 21:03:16", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:210: in tabulate\n    headers, data = _normalize_tabular_data(tabular_data, headers, showindex)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]]\nheaders = 'firstrow', showindex = 'default'\n\n    def _normalize_tabular_data(tabular_data, headers, showindex=\"default\"):\n        \"\"\"Convert various data formats to a list of lists and headers.\"\"\"\n        if isinstance(tabular_data, Mapping):\n            # It's a dict of iterables\n            keys = list(tabular_data.keys())\n            if not headers:\n                headers = keys\n    \n            vals = [list(v) if isinstance(v, Iterable) and not isinstance(v, str) else [v] for v in tabular_data.values()]\n            max_len = max(len(v) for v in vals) if vals else 0\n            data = [[(v[i] if i < len(v) else None) for v in vals] for i in range(max_len)]\n    \n        elif isinstance(tabular_data, Iterable) and not isinstance(tabular_data, str):\n            rows = list(tabular_data)\n            if rows and all(isinstance(row, Mapping) for row in rows):\n                # It's a list of dicts\n                if not headers:\n                    # Use keys from the first dict as headers, preserving order\n                    unique_headers = set()\n                    ordered_headers = []\n                    for row in rows:\n                        for key in row.keys():\n                            if key not in unique_headers:\n                                unique_headers.add(key)\n                                ordered_headers.append(key)\n                    headers = ordered_headers\n    \n                data = [[row.get(h) for h in headers] for row in rows]\n            else:\n                # Assume it's a list of lists or other iterable of iterables\n                data = [list(row) for row in rows]\n        else:\n            data = [[tabular_data]]\n    \n        # Handle showindex\n        if showindex == \"always\" or (showindex == \"default\" and headers):\n            if not headers:\n                num_cols = len(data[0]) if data else 0\n                headers = [\"\"] * num_cols\n>           headers.insert(0, \"\")\nE           AttributeError: 'str' object has no attribute 'insert'\n\ngeneration\\Tabulate\\tabulate\\core.py:89: AttributeError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n>       output = tabulate(table, headers=\"keys\")\n\ntests\\Tabulate\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:210: in tabulate\n    headers, data = _normalize_tabular_data(tabular_data, headers, showindex)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = {'Age': [24, 19], 'Name': ['Alice', 'Bob']}, headers = 'keys'\nshowindex = 'default'\n\n    def _normalize_tabular_data(tabular_data, headers, showindex=\"default\"):\n        \"\"\"Convert various data formats to a list of lists and headers.\"\"\"\n        if isinstance(tabular_data, Mapping):\n            # It's a dict of iterables\n            keys = list(tabular_data.keys())\n            if not headers:\n                headers = keys\n    \n            vals = [list(v) if isinstance(v, Iterable) and not isinstance(v, str) else [v] ", "stdout_sha1": "fe4866449b6b26314764274b31969bab957d48c5", "stdout_len": 10144, "stdout": "..FFF.F...F.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:210: in tabulate\n    headers, data = _normalize_tabular_data(tabular_data, headers, showindex)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]]\nheaders = 'firstrow', showindex = 'default'\n\n    def _normalize_tabular_data(tabular_data, headers, showindex=\"default\"):\n        \"\"\"Convert various data formats to a list of lists and headers.\"\"\"\n        if isinstance(tabular_data, Mapping):\n            # It's a dict of iterables\n            keys = list(tabular_data.keys())\n            if not headers:\n                headers = keys\n    \n            vals = [list(v) if isinstance(v, Iterable) and not isinstance(v, str) else [v] for v in tabular_data.values()]\n            max_len = max(len(v) for v in vals) if vals else 0\n            data = [[(v[i] if i < len(v) else None) for v in vals] for i in range(max_len)]\n    \n        elif isinstance(tabular_data, Iterable) and not isinstance(tabular_data, str):\n            rows = list(tabular_data)\n            if rows and all(isinstance(row, Mapping) for row in rows):\n                # It's a list of dicts\n                if not headers:\n                    # Use keys from the first dict as headers, preserving order\n                    unique_headers = set()\n                    ordered_headers = []\n                    for row in rows:\n                        for key in row.keys():\n                            if key not in unique_headers:\n                                unique_headers.add(key)\n                                ordered_headers.append(key)\n                    headers = ordered_headers\n    \n                data = [[row.get(h) for h in headers] for row in rows]\n            else:\n                # Assume it's a list of lists or other iterable of iterables\n                data = [list(row) for row in rows]\n        else:\n            data = [[tabular_data]]\n    \n        # Handle showindex\n        if showindex == \"always\" or (showindex == \"default\" and headers):\n            if not headers:\n                num_cols = len(data[0]) if data else 0\n                headers = [\"\"] * num_cols\n>           headers.insert(0, \"\")\nE           AttributeError: 'str' object has no attribute 'insert'\n\ngeneration\\Tabulate\\tabulate\\core.py:89: AttributeError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n>       output = tabulate(table, headers=\"keys\")\n\ntests\\Tabulate\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:210: in tabulate\n    headers, data = _normalize_tabular_data(tabular_data, headers, showindex)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = {'Age': [24, 19], 'Name': ['Alice', 'Bob']}, headers = 'keys'\nshowindex = 'default'\n\n    def _normalize_tabular_data(tabular_data, headers, showindex=\"default\"):\n        \"\"\"Convert various data formats to a list of lists and headers.\"\"\"\n        if isinstance(tabular_data, Mapping):\n            # It's a dict of iterables\n            keys = list(tabular_data.keys())\n            if not headers:\n                headers = keys\n    \n            vals = [list(v) if isinstance(v, Iterable) and not isinstance(v, str) else [v] for v in tabular_data.values()]\n            max_len = max(len(v) for v in vals) if vals else 0\n            data = [[(v[i] if i < len(v) else None) for v in vals] for i in range(max_len)]\n    \n        elif isinstance(tabular_data, Iterable) and not isinstance(tabular_data, str):\n            rows = list(tabular_data)\n            if rows and all(isinstance(row, Mapping) for row in rows):\n                # It's a list of dicts\n                if not headers:\n                    # Use keys from the first dict as headers, preserving order\n                    unique_headers = set()\n                    ordered_headers = []\n                    for row in rows:\n                        for key in row.keys():\n                            if key not in unique_headers:\n                                unique_headers.add(key)\n                                ordered_headers.append(key)\n                    headers = ordered_headers\n    \n                data = [[row.get(h) for h in headers] for row in rows]\n            else:\n                # Assume it's a list of lists or other iterable of iterables\n                data = [list(row) for row in rows]\n        else:\n            data = [[tabular_data]]\n    \n        # Handle showindex\n        if showindex == \"always\" or (showindex == \"default\" and headers):\n            if not headers:\n                num_cols = len(data[0]) if data else 0\n                headers = [\"\"] * num_cols\n>           headers.insert(0, \"\")\nE           AttributeError: 'str' object has no attribute 'insert'\n\ngeneration\\Tabulate\\tabulate\\core.py:89: AttributeError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n        out_true = tabulate(table, showindex=True)\n        lines_true = _lines(out_true)\n>       assert any(line.lstrip().startswith(\"0\") for line in lines_true)\nE       assert False\nE        +  where False = any(<generator object test_showindex_variants.<locals>.<genexpr> at 0x0000014784DD8AC0>)\n\ntests\\Tabulate\\functional_test.py:153: AssertionError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            {\"name\": \"Alice\", \"score\": 10},\n            {\"name\": \"Bob\", \"score\": 12},\n        ]\n>       output = tabulate(rows, headers=\"keys\", tablefmt=\"plain\")\n\ntests\\Tabulate\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:210: in tabulate\n    headers, data = _normalize_tabular_data(tabular_data, headers, showindex)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [{'name': 'Alice', 'score': 10}, {'name': 'Bob', 'score': 12}]\nheaders = 'keys', showindex = 'default'\n\n    def _normalize_tabular_data(tabular_data, headers, showindex=\"default\"):\n        \"\"\"Convert various data formats to a list of lists and headers.\"\"\"\n        if isinstance(tabular_data, Mapping):\n            # It's a dict of iterables\n            keys = list(tabular_data.keys())\n            if not headers:\n                headers = keys\n    \n            vals = [list(v) if isinstance(v, Iterable) and not isinstance(v, str) else [v] for v in tabular_data.values()]\n            max_len = max(len(v) for v in vals) if vals else 0\n            data = [[(v[i] if i < len(v) else None) for v in vals] for i in range(max_len)]\n    \n        elif isinstance(tabular_data, Iterable) and not isinstance(tabular_data, str):\n            rows = list(tabular_data)\n            if rows and all(isinstance(row, Mapping) for row in rows):\n                # It's a list of dicts\n                if not headers:\n                    # Use keys from the first dict as headers, preserving order\n                    unique_headers = set()\n                    ordered_headers = []\n                    for row in rows:\n                        for key in row.keys():\n                            if key not in unique_headers:\n                                unique_headers.add(key)\n                                ordered_headers.append(key)\n                    headers = ordered_headers\n    \n                data = [[row.get(h) for h in headers] for row in rows]\n            else:\n                # Assume it's a list of lists or other iterable of iterables\n                data = [list(row) for row in rows]\n        else:\n            data = [[tabular_data]]\n    \n        # Handle showindex\n        if showindex == \"always\" or (showindex == \"default\" and headers):\n            if not headers:\n                num_cols = len(data[0]) if data else 0\n                headers = [\"\"] * num_cols\n>           headers.insert(0, \"\")\nE           AttributeError: 'str' object has no attribute 'insert'\n\ngeneration\\Tabulate\\tabulate\\core.py:89: AttributeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - assert False\nFAILED tests/Tabulate/functional_test.py::test_list_of_dicts_headers_keys_plain\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n5 failed, 7 passed in 0.56s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "TinyDB", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'Table' object is not callable", "returncode": 1, "elapsed_time_s": 2.007502, "avg_memory_mb": 32.96, "avg_cpu_percent": 98.4, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 21:08:56", "stdout_excerpt": "==== FAILURES ===================================\n___________________________ test_insert_and_search ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_insert_and_search0')\n\n    def test_insert_and_search(tmp_path: Path) -> None:\n        \"\"\"Basic insert + search on the default table.\"\"\"\n        db_path = tmp_path / \"db.json\"\n        db = TinyDB(str(db_path))\n    \n>       User = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:62: TypeError\n___________________________ test_update_and_remove ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_update_and_remove0')\n\n    def test_update_and_remove(tmp_path: Path) -> None:\n        \"\"\"Update and remove operations should work on matching documents.\"\"\"\n        db = _open_db(tmp_path)\n    \n>       Task = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:101: TypeError\n_________________________ test_where_helper_querying __________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_where_helper_querying0')\n\n    def test_where_helper_querying(tmp_path: Path) -> None:\n        \"\"\"where('field') helper should build a working query for search().\"\"\"\n        db = _open_db(tmp_path)\n>       db.insert({\"name\": \"Alice\", \"city\": \"Tokyo\"})\nE       TypeError: 'Table' object is not callable\n\ntests\\TinyDB\\functional_test.py:125: TypeError\n______________________ test_get_returns_single_document _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_get_returns_single_docume0')\n\n    def test_get_returns_single_document(tmp_path: Path) -> None:\n        \"\"\"get(query) should retrieve one matching document.\"\"\"\n        db = _open_db(tmp_path)\n>       User = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:138: TypeError\n________________________ test_insert_multiple_and_all _________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_insert_multiple_and_all0')\n\n    def test_insert_multiple_and_all(tmp_path: Path) -> None:\n        \"\"\"insert_multiple should add several documents and return their ids.\"\"\"\n        db = _open_db(tmp_path)\n    \n        docs = [\n            {\"k\": \"a\", \"v\": 1},\n            {\"k\": \"b\", \"v\": 2},\n            {\"k\": \"c\", \"v\": 3},\n        ]\n>       ids = db.insert_multiple(docs)\nE       TypeError: 'Table' object is not callable\n\ntests\\TinyDB\\functional_test.py:160: TypeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_contains_and_count0')\n\n    def test_contains_and_count(tmp_path: Path) -> None:\n        \"\"\"contains and count should reflect stored data and queries.\"\"\"\n        db = _open_db(tmp_path)\n>       User = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:174: TypeError\n_____________________ test_persistence_reopen_and_search ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_persistence_reopen_and_se0')\n\n    def test_persistence_reopen_and_search(tmp_path: Path) -> None:\n        \"\"\"Data should persist on disk and be readable after reopening.\"\"\"\n        db_path = tmp_path / \"persist.json\"\n    \n        db1 = TinyDB(str(db_path))\n>       db1.insert({\"name\": \"Ada\", \"lang\": \"Python\"})\nE       TypeError: 'Table' object is not callable\n\ntests\\TinyDB\\functional_test.py:194: TypeError\n=========================== short test summary info ===========================\nFAILED tests/TinyDB/functional_test.py::test_insert_and_search - TypeError: '...\nFAILED tests/TinyDB/functional_test.py::test_update_and_remove - TypeEr", "stdout_sha1": "f3d81cc8d0627ca29556f68a311c6cbe58813ccb", "stdout_len": 4553, "stdout": "F.FFFFFF....                                                             [100%]\n================================== FAILURES ===================================\n___________________________ test_insert_and_search ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_insert_and_search0')\n\n    def test_insert_and_search(tmp_path: Path) -> None:\n        \"\"\"Basic insert + search on the default table.\"\"\"\n        db_path = tmp_path / \"db.json\"\n        db = TinyDB(str(db_path))\n    \n>       User = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:62: TypeError\n___________________________ test_update_and_remove ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_update_and_remove0')\n\n    def test_update_and_remove(tmp_path: Path) -> None:\n        \"\"\"Update and remove operations should work on matching documents.\"\"\"\n        db = _open_db(tmp_path)\n    \n>       Task = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:101: TypeError\n_________________________ test_where_helper_querying __________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_where_helper_querying0')\n\n    def test_where_helper_querying(tmp_path: Path) -> None:\n        \"\"\"where('field') helper should build a working query for search().\"\"\"\n        db = _open_db(tmp_path)\n>       db.insert({\"name\": \"Alice\", \"city\": \"Tokyo\"})\nE       TypeError: 'Table' object is not callable\n\ntests\\TinyDB\\functional_test.py:125: TypeError\n______________________ test_get_returns_single_document _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_get_returns_single_docume0')\n\n    def test_get_returns_single_document(tmp_path: Path) -> None:\n        \"\"\"get(query) should retrieve one matching document.\"\"\"\n        db = _open_db(tmp_path)\n>       User = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:138: TypeError\n________________________ test_insert_multiple_and_all _________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_insert_multiple_and_all0')\n\n    def test_insert_multiple_and_all(tmp_path: Path) -> None:\n        \"\"\"insert_multiple should add several documents and return their ids.\"\"\"\n        db = _open_db(tmp_path)\n    \n        docs = [\n            {\"k\": \"a\", \"v\": 1},\n            {\"k\": \"b\", \"v\": 2},\n            {\"k\": \"c\", \"v\": 3},\n        ]\n>       ids = db.insert_multiple(docs)\nE       TypeError: 'Table' object is not callable\n\ntests\\TinyDB\\functional_test.py:160: TypeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_contains_and_count0')\n\n    def test_contains_and_count(tmp_path: Path) -> None:\n        \"\"\"contains and count should reflect stored data and queries.\"\"\"\n        db = _open_db(tmp_path)\n>       User = Query()\nE       TypeError: 'QueryBuilder' object is not callable\n\ntests\\TinyDB\\functional_test.py:174: TypeError\n_____________________ test_persistence_reopen_and_search ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-459/test_persistence_reopen_and_se0')\n\n    def test_persistence_reopen_and_search(tmp_path: Path) -> None:\n        \"\"\"Data should persist on disk and be readable after reopening.\"\"\"\n        db_path = tmp_path / \"persist.json\"\n    \n        db1 = TinyDB(str(db_path))\n>       db1.insert({\"name\": \"Ada\", \"lang\": \"Python\"})\nE       TypeError: 'Table' object is not callable\n\ntests\\TinyDB\\functional_test.py:194: TypeError\n=========================== short test summary info ===========================\nFAILED tests/TinyDB/functional_test.py::test_insert_and_search - TypeError: '...\nFAILED tests/TinyDB/functional_test.py::test_update_and_remove - TypeError: '...\nFAILED tests/TinyDB/functional_test.py::test_where_helper_querying - TypeErro...\nFAILED tests/TinyDB/functional_test.py::test_get_returns_single_document - Ty...\nFAILED tests/TinyDB/functional_test.py::test_insert_multiple_and_all - TypeEr...\nFAILED tests/TinyDB/functional_test.py::test_contains_and_count - TypeError: ...\nFAILED tests/TinyDB/functional_test.py::test_persistence_reopen_and_search - ...\n7 failed, 5 passed in 0.71s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "Option() got an unexpected keyword argument 'prompt'", "returncode": 1, "elapsed_time_s": 1.875388, "avg_memory_mb": 32.57, "avg_cpu_percent": 100.0, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 21:11:03", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Typer\\functional_test.py:233: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: Option() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x000002328BFC4520>\n\n    def test_envv", "stdout_sha1": "d55e0916a0f13bbe82d4de6bb76ec7ac86d25868", "stdout_len": 6715, "stdout": "FFF.FF..FFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Typer\\functional_test.py:233: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: Option() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x000002328BFC4520>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: Option() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:159: AttributeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n        app = _create_types_app()\n        # Now stable: \"calc\" always exists as a subcommand (multi-command app).\n        r = runner.invoke(app, [\"calc\", \"2\", \"3\", \"--scale\", \"2.0\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1>.exit_code\n\ntests\\Typer\\functional_test.py:313: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AttributeE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - At...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - assert 1 == 0\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n9 failed, 3 passed in 0.59s\n"}
{"model": "gemini-2.5-pro-thinking", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.973038, "avg_memory_mb": 36.26, "avg_cpu_percent": 101.6, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:13:17", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.62s\n", "stdout_sha1": "28f9a06bd8bcca5d56dc7b7e8db7268586e17b5a", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.62s\n"}
{"model": "gemini-3-pro-preview", "project": "Cachetools", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'answer' not in TTLCache([], maxsize=10, currsize=0)", "returncode": 1, "elapsed_time_s": 3.432527, "avg_memory_mb": 32.68, "avg_cpu_percent": 53.5, "passed": 12, "failed": 1, "skipped": 0, "total": 13, "functional_score": 0.9231, "timestamp": "2025-12-31 16:03:17", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_ttl_cache_expiration __________________________\n\n    def test_ttl_cache_expiration():\n        ttl_seconds = 0.2\n        cache = TTLCache(maxsize=10, ttl=ttl_seconds)\n    \n        cache[\"answer\"] = 42\n        assert cache[\"answer\"] == 42\n        assert \"answer\" in cache\n    \n        # Wait long enough for the entry to expire\n        time.sleep(ttl_seconds + 0.3)\n    \n        # After TTL has passed, the key should no longer be considered valid\n        # Implementations may clean up lazily, but membership and access\n        # must not behave as if the value is still present.\n>       assert \"answer\" not in cache\nE       AssertionError: assert 'answer' not in TTLCache([], maxsize=10, currsize=0)\n\ntests\\Cachetools\\functional_test.py:62: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_ttl_cache_expiration - Asser...\n1 failed, 12 passed in 2.06s\n", "stdout_sha1": "9e3cba054732b5d16c96dc72dc32be95afe75600", "stdout_len": 1138, "stdout": ".F...........                                                            [100%]\n================================== FAILURES ===================================\n__________________________ test_ttl_cache_expiration __________________________\n\n    def test_ttl_cache_expiration():\n        ttl_seconds = 0.2\n        cache = TTLCache(maxsize=10, ttl=ttl_seconds)\n    \n        cache[\"answer\"] = 42\n        assert cache[\"answer\"] == 42\n        assert \"answer\" in cache\n    \n        # Wait long enough for the entry to expire\n        time.sleep(ttl_seconds + 0.3)\n    \n        # After TTL has passed, the key should no longer be considered valid\n        # Implementations may clean up lazily, but membership and access\n        # must not behave as if the value is still present.\n>       assert \"answer\" not in cache\nE       AssertionError: assert 'answer' not in TTLCache([], maxsize=10, currsize=0)\n\ntests\\Cachetools\\functional_test.py:62: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_ttl_cache_expiration - Asser...\n1 failed, 12 passed in 2.06s\n"}
{"model": "gemini-3-pro-preview", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where 'TOKEN=None\\n' = <Result ok>.output", "returncode": 1, "elapsed_time_s": 5.164219, "avg_memory_mb": 32.85, "avg_cpu_percent": 99.4, "passed": 2, "failed": 9, "skipped": 0, "total": 11, "functional_score": 0.1818, "timestamp": "2025-12-31 16:06:52", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exception>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:226: AttributeError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert result.exit_code != 0\n>       assert isinstance(result.exception, CustomError)\nE       assert False\nE        +  where False = isinstance(NameError(\"name 'ClickException' is not defined\"), <class 'functional_test.test_command_exception_is_exposed_in_result.<locals>.CustomError'>)\nE        +    where NameError(\"name 'ClickException' is not defined\") = <Result exception>.exception\n\ntests\\Click\\functional_test.py:251: AssertionError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n        def cli(name: str) -> None:\n            click.echo(f\"NAME={name}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [])\n        assert r1.exit_code == 0\n        assert \"NAME=fallback\" in r1.output\n    \n        r2 = runner.invoke(cli, [], env={\"CLICK_TEST_NAME\": \"fromenv\"})\n        assert r2.exit_code == 0\n>       assert \"NAME=fromenv\" in r2.output\nE       AssertionError: assert 'NAME=fromenv' in 'NAME=fallback\\nNAME=fallback\\n'\nE        +  where 'NAME=fallback\\nNAME=fallback\\n' = <Result ok>.output\n\ntests\\Click\\functional_test.py:274: AssertionError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n        assert r.exit_code == 0\n>       assert \"TOKEN=secret-token\" in r.output\nE       AssertionError: assert 'TOKEN=secret-token' in 'TOKEN=None\\n'\nE        +  where 'TOKEN=None\\n' = <Result ok>.output\n\ntests", "stdout_sha1": "28e750ba9034e8e55cb6855af6602f81e869c98f", "stdout_len": 5721, "stdout": ".FFFFFFFF.F                                                              [100%]\n================================== FAILURES ===================================\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exception>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:226: AttributeError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert result.exit_code != 0\n>       assert isinstance(result.exception, CustomError)\nE       assert False\nE        +  where False = isinstance(NameError(\"name 'ClickException' is not defined\"), <class 'functional_test.test_command_exception_is_exposed_in_result.<locals>.CustomError'>)\nE        +    where NameError(\"name 'ClickException' is not defined\") = <Result exception>.exception\n\ntests\\Click\\functional_test.py:251: AssertionError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n        def cli(name: str) -> None:\n            click.echo(f\"NAME={name}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [])\n        assert r1.exit_code == 0\n        assert \"NAME=fallback\" in r1.output\n    \n        r2 = runner.invoke(cli, [], env={\"CLICK_TEST_NAME\": \"fromenv\"})\n        assert r2.exit_code == 0\n>       assert \"NAME=fromenv\" in r2.output\nE       AssertionError: assert 'NAME=fromenv' in 'NAME=fallback\\nNAME=fallback\\n'\nE        +  where 'NAME=fallback\\nNAME=fallback\\n' = <Result ok>.output\n\ntests\\Click\\functional_test.py:274: AssertionError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n        assert r.exit_code == 0\n>       assert \"TOKEN=secret-token\" in r.output\nE       AssertionError: assert 'TOKEN=secret-token' in 'TOKEN=None\\n'\nE        +  where 'TOKEN=None\\n' = <Result ok>.output\n\ntests\\Click\\functional_test.py:286: AssertionError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:294: AttributeError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - Attribut...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_command_exception_is_exposed_in_result\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - A...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n9 failed, 2 passed in 3.86s\n"}
{"model": "gemini-3-pro-preview", "project": "Cmd2", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert None is not None", "returncode": 1, "elapsed_time_s": 4.837541, "avg_memory_mb": 32.14, "avg_cpu_percent": 98.4, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 16:07:52", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_echo_arguments_and_parsing _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588A99400>\n\n    def test_echo_arguments_and_parsing(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, \"echo_args one two three\")\n>       assert \"one two three\" in output\nE       AssertionError: assert 'one two three' in '\\n'\n\ntests\\Cmd2\\functional_test.py:276: AssertionError\n_______________________ test_echo_arguments_with_quotes _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588AA4EE0>\n\n    def test_echo_arguments_with_quotes(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, 'echo_args \"hello world\" two')\n>       assert \"hello world two\" in output\nE       AssertionError: assert 'hello world two' in '\\n'\n\ntests\\Cmd2\\functional_test.py:283: AssertionError\n_____________________ test_unknown_command_reports_error ______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588B09CA0>\n\n    def test_unknown_command_reports_error(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, \"this_command_does_not_exist\")\n        low = output.lower()\n>       assert (\"unknown\" in low) or (\"syntax\" in low) or (\"not found\" in low) or (output.strip() != \"\")\nE       AssertionError: assert ('unknown' in '' or 'syntax' in '' or 'not found' in '' or '' != '')\nE        +  where '' = <built-in method strip of str object at 0x0000023585C44670>()\nE        +    where <built-in method strip of str object at 0x0000023585C44670> = ''.strip\n\ntests\\Cmd2\\functional_test.py:306: AssertionError\n---------------------------- Captured stderr call -----------------------------\n*** Unknown syntax: this_command_does_not_exist\n_____________________ test_multiple_commands_and_history ______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588AFCB20>\n\n    def test_multiple_commands_and_history(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        commands = [\"greet Alice\", \"greet Bob\", \"history\"]\n        output = run_commands(app, commands)\n>       assert \"Hello Alice\" in output\nE       AssertionError: assert 'Hello Alice' in ''\n\ntests\\Cmd2\\functional_test.py:321: AssertionError\n---------------------------- Captured stderr call -----------------------------\n*** Unknown syntax: history\n____________________ test_history_object_records_commands _____________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023587479EE0>\n\n    def test_history_object_records_commands(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        _ = run_command(app, \"greet Zoe\")\n        hist = getattr(app, \"history\", None)\n>       assert hist is not None\nE       assert None is not None\n\ntests\\Cmd2\\functional_test.py:331: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_and_parsing - Asser...\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_with_quotes - Asser...\nFAILED tests/Cmd2/functional_test.py::test_unknown_command_reports_error - As...\nFAILED tests/Cmd2/functional_test.py::test_multiple_commands_and_history - As...\nFAILED tests/Cmd2/functional_test.py::test_history_object_records_commands - ...\n5 failed, 6 passed in 3.53s\n", "stdout_sha1": "85b8661bfbda792bf7884ac3bbfa84854111ddd0", "stdout_len": 3777, "stdout": "..FF..F.FF.                                                              [100%]\n================================== FAILURES ===================================\n_______________________ test_echo_arguments_and_parsing _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588A99400>\n\n    def test_echo_arguments_and_parsing(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, \"echo_args one two three\")\n>       assert \"one two three\" in output\nE       AssertionError: assert 'one two three' in '\\n'\n\ntests\\Cmd2\\functional_test.py:276: AssertionError\n_______________________ test_echo_arguments_with_quotes _______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588AA4EE0>\n\n    def test_echo_arguments_with_quotes(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, 'echo_args \"hello world\" two')\n>       assert \"hello world two\" in output\nE       AssertionError: assert 'hello world two' in '\\n'\n\ntests\\Cmd2\\functional_test.py:283: AssertionError\n_____________________ test_unknown_command_reports_error ______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588B09CA0>\n\n    def test_unknown_command_reports_error(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        output = run_command(app, \"this_command_does_not_exist\")\n        low = output.lower()\n>       assert (\"unknown\" in low) or (\"syntax\" in low) or (\"not found\" in low) or (output.strip() != \"\")\nE       AssertionError: assert ('unknown' in '' or 'syntax' in '' or 'not found' in '' or '' != '')\nE        +  where '' = <built-in method strip of str object at 0x0000023585C44670>()\nE        +    where <built-in method strip of str object at 0x0000023585C44670> = ''.strip\n\ntests\\Cmd2\\functional_test.py:306: AssertionError\n---------------------------- Captured stderr call -----------------------------\n*** Unknown syntax: this_command_does_not_exist\n_____________________ test_multiple_commands_and_history ______________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023588AFCB20>\n\n    def test_multiple_commands_and_history(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        commands = [\"greet Alice\", \"greet Bob\", \"history\"]\n        output = run_commands(app, commands)\n>       assert \"Hello Alice\" in output\nE       AssertionError: assert 'Hello Alice' in ''\n\ntests\\Cmd2\\functional_test.py:321: AssertionError\n---------------------------- Captured stderr call -----------------------------\n*** Unknown syntax: history\n____________________ test_history_object_records_commands _____________________\n\napp = <functional_test._make_app_class.<locals>.SimpleApp object at 0x0000023587479EE0>\n\n    def test_history_object_records_commands(app: Optional[Any]) -> None:\n        if not _require_app(app):\n            return\n        _ = run_command(app, \"greet Zoe\")\n        hist = getattr(app, \"history\", None)\n>       assert hist is not None\nE       assert None is not None\n\ntests\\Cmd2\\functional_test.py:331: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_and_parsing - Asser...\nFAILED tests/Cmd2/functional_test.py::test_echo_arguments_with_quotes - Asser...\nFAILED tests/Cmd2/functional_test.py::test_unknown_command_reports_error - As...\nFAILED tests/Cmd2/functional_test.py::test_multiple_commands_and_history - As...\nFAILED tests/Cmd2/functional_test.py::test_history_object_records_commands - ...\n5 failed, 6 passed in 3.53s\n"}
{"model": "gemini-3-pro-preview", "project": "Dataset", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "sqlite3.OperationalError: no such table: users", "returncode": 1, "elapsed_time_s": 55.754882, "avg_memory_mb": 34.57, "avg_cpu_percent": 0.27, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 16:10:02", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n>       table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n\ntests\\Dataset\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:100: in insert\n    return self.insert_many([row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA56113790>\nrows = [{'age': 30, 'country': 'DE', 'name': 'Alice'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: users\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n>       table.insert_many(rows)\n\ntests\\Dataset\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA5617DB50>\nrows = [{'account_id': 1, 'balance': 100.0, 'currency': 'EUR', 'owner': 'Alice'}, {'account_id': 2, 'balance': 250.0, 'currency': 'USD', 'owner': 'Bob'}]\nchunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n ", "stdout_sha1": "602ebe8cffeb37baebb767335f6bd6217ac3666e", "stdout_len": 25470, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n>       table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n\ntests\\Dataset\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:100: in insert\n    return self.insert_many([row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA56113790>\nrows = [{'age': 30, 'country': 'DE', 'name': 'Alice'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: users\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n>       table.insert_many(rows)\n\ntests\\Dataset\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA5617DB50>\nrows = [{'account_id': 1, 'balance': 100.0, 'currency': 'EUR', 'owner': 'Alice'}, {'account_id': 2, 'balance': 250.0, 'currency': 'USD', 'owner': 'Bob'}]\nchunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: accounts\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-308/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n>       table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n\ntests\\Dataset\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:100: in insert\n    return self.insert_many([row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA56113E20>\nrows = [{'category': 'ok', 'name': 'committed'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: events\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n        db = create_in_memory_db()\n        table = db[\"items\"]\n    \n        rows = [{\"name\": \"A\"}, {\"name\": \"B\"}, {\"name\": \"C\"}]\n>       ret = table.insert_many(rows)\n\ntests\\Dataset\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA5616BDF0>\nrows = [{'name': 'A'}, {'name': 'B'}, {'name': 'C'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: items\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n        db = create_in_memory_db()\n        table = db[\"t\"]\n>       table.insert({\"name\": \"only\"})\n\ntests\\Dataset\\functional_test.py:237: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:100: in insert\n    return self.insert_many([row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA560D5E80>\nrows = [{'name': 'only'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: t\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n>           table.insert({\"n\": i})\n\ntests\\Dataset\\functional_test.py:246: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:100: in insert\n    return self.insert_many([row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA5617D700>, rows = [{'n': 0}]\nchunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: nums\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n        db = create_in_memory_db()\n        table = db[\"people\"]\n>       table.insert({\"name\": \"Alice\", \"age\": 30})\n\ntests\\Dataset\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:100: in insert\n    return self.insert_many([row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA5617EA90>\nrows = [{'age': 30, 'name': 'Alice'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: people\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n_______________________ test_delete_and_clear_all_rows ________________________\n\n    def test_delete_and_clear_all_rows() -> None:\n        \"\"\"\n        Older dataset.Table may not expose truncate().\n        Clear a table and end at 0 rows without relying on result iteration for DML.\n        \"\"\"\n        db = create_in_memory_db()\n        table = db[\"logs\"]\n>       table.insert_many([{\"kind\": \"a\"}, {\"kind\": \"b\"}, {\"kind\": \"b\"}])\n\ntests\\Dataset\\functional_test.py:270: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA560D15B0>\nrows = [{'kind': 'a'}, {'kind': 'b'}, {'kind': 'b'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: logs\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n>       table.insert({\"x\": 1})\n\ntests\\Dataset\\functional_test.py:299: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:100: in insert\n    return self.insert_many([row])\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA561879A0>, rows = [{'x': 1}]\nchunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: to_drop\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n_____________________ test_raw_sql_query_with_parameters ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-308/test_raw_sql_query_with_parame0')\n\n    def test_raw_sql_query_with_parameters(tmp_path: Path) -> None:\n        db_path = tmp_path / \"param.db\"\n        db = dataset.connect(\"sqlite:///%s\" % str(db_path))\n        table = db[\"kv\"]\n>       table.insert_many([{\"k\": \"a\", \"v\": 1}, {\"k\": \"b\", \"v\": 2}])\n\ntests\\Dataset\\functional_test.py:319: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA561B2610>\nrows = [{'k': 'a', 'v': 1}, {'k': 'b', 'v': 2}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: kv\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n>       table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n\ntests\\Dataset\\functional_test.py:330: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000002BA560CEC40>\nrows = [{'c': 'red'}, {'c': 'red'}, {'c': 'blue'}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        \"\"\"\n        Insert multiple rows.\n        \"\"\"\n        if not rows:\n            return\n    \n        # Normalize rows to dicts\n        rows = [dict(r) for r in rows]\n    \n        # 1. Ensure table exists based on the first row (or union of keys if we were fancy,\n        #    but standard dataset often just looks at what's coming in).\n        #    To be safe, we check schema against all keys in the batch.\n        all_keys = set()\n        for r in rows:\n            all_keys.update(r.keys())\n    \n        # Create a dummy row with all keys to ensure schema\n        dummy_schema_row = {k: rows[0].get(k) for k in all_keys}\n    \n        with self.db.lock:\n            self._ensure_table(dummy_schema_row)\n            self._ensure_columns(dummy_schema_row)\n    \n            # 2. Construct Insert SQL\n            # We use the first row to determine the parameterized query structure,\n            # but since we ensured columns for ALL keys, we can just use all_keys.\n            keys = list(all_keys)\n            placeholders = [f':{k}' for k in keys]\n            columns_sql = \", \".join(f'\"{k}\"' for k in keys)\n            values_sql = \", \".join(placeholders)\n    \n            sql = f'INSERT INTO \"{self.name}\" ({columns_sql}) VALUES ({values_sql})'\n    \n            cursor = self.db._conn.cursor()\n            try:\n>               cursor.executemany(sql, rows)\nE               sqlite3.OperationalError: no such table: colors\n\ngeneration\\Dataset\\dataset\\table.py:138: OperationalError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - sql...\nFAILED tests/Dataset/functional_test.py::test_transactions_commit_and_rollback\nFAILED tests/Dataset/functional_test.py::test_insert_many_returns_ids_and_count\nFAILED tests/Dataset/functional_test.py::test_find_one_missing_returns_none\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_table_all_iteration_and_row_shape\nFAILED tests/Dataset/functional_test.py::test_delete_and_clear_all_rows - sql...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_raw_sql_query_with_parameters\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n11 failed in 54.44s\n"}
{"model": "gemini-3-pro-preview", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Map' object has no attribute 'save'", "returncode": 1, "elapsed_time_s": 1.950627, "avg_memory_mb": 32.32, "avg_cpu_percent": 98.3, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 16:20:50", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-309/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\n2 failed, 10 passed in 0.57s\n", "stdout_sha1": "ccd14716a14b19843e6ef39b55f015c9931bc83a", "stdout_len": 1836, "stdout": "........FF..                                                             [100%]\n================================== FAILURES ===================================\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-309/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\n2 failed, 10 passed in 0.57s\n"}
{"model": "gemini-3-pro-preview", "project": "Loguru", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Logger' object has no attribute 'patch'", "returncode": 1, "elapsed_time_s": 1.570679, "avg_memory_mb": 32.98, "avg_cpu_percent": 98.9, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 16:42:35", "stdout_excerpt": "==== FAILURES ===================================\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x000001FABAC3BCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\ntests\\Loguru\\functional_test.py:211: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\n3 failed, 8 passed in 0.39s\n", "stdout_sha1": "b71d3abf406ee77756c136729a07b9c7f629ac8b", "stdout_len": 3118, "stdout": "....F..FF..                                                              [100%]\n================================== FAILURES ===================================\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x000001FABAC3BCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\ntests\\Loguru\\functional_test.py:211: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\n3 failed, 8 passed in 0.39s\n"}
{"model": "gemini-3-pro-preview", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 2.316764, "avg_memory_mb": 35.45, "avg_cpu_percent": 71.6, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 16:43:32", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.13s\n", "stdout_sha1": "b79df9046e732b82c68e1b798302a15f7acf5f44", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.13s\n"}
{"model": "gemini-3-pro-preview", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Failed: DID NOT RAISE <class 'ModuleNotFoundError'>", "returncode": 1, "elapsed_time_s": 1.854805, "avg_memory_mb": 32.05, "avg_cpu_percent": 94.6, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 16:51:06", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.56s\n", "stdout_sha1": "21d65ececb8fc353e9e43f089cfa9bcb7c9c4223", "stdout_len": 3013, "stdout": "........FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n3 failed, 8 passed in 0.56s\n"}
{"model": "gemini-3-pro-preview", "project": "Mutagen", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "KeyError", "exception_msg": "0", "returncode": 1, "elapsed_time_s": 1.897034, "avg_memory_mb": 33.09, "avg_cpu_percent": 98.3, "passed": 8, "failed": 4, "skipped": 0, "total": 12, "functional_score": 0.6667, "timestamp": "2025-12-31 16:52:47", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_easyid3_genre_and_albumartist_roundtrip _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_easyid3_genre_and_albumar0')\n\n    def test_easyid3_genre_and_albumartist_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common optional fields via EasyID3 (genre/albumartist).\"\"\"\n        audio_path = tmp_path / \"genre_albumartist.mp3\"\n    \n        tags = EasyID3()\n        tags[\"title\"] = [\"Tagged Song\"]\n        tags[\"artist\"] = [\"Main Artist\"]\n>       tags[\"albumartist\"] = [\"Album Artist\"]\n\ntests\\Mutagen\\functional_test.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.easyid3.EasyID3 object at 0x0000028C6EBFFEB0>\nkey = 'albumartist', value = ['Album Artist']\n\n    def __setitem__(self, key, value):\n        frame_class = self._KEY_MAP.get(key)\n        if not frame_class:\n>           raise KeyError(f\"Unknown EasyID3 key: {key}\")\nE           KeyError: 'Unknown EasyID3 key: albumartist'\n\ngeneration\\Mutagen\\mutagen\\easyid3.py:48: KeyError\n______________ test_low_level_id3_written_can_be_read_by_easyid3 ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_low_level_id3_written_can0')\n\n    def test_low_level_id3_written_can_be_read_by_easyid3(tmp_path: Path) -> None:\n        \"\"\"Write low-level ID3 frames and read them back via EasyID3 fields.\"\"\"\n        audio_path = tmp_path / \"interop.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Interop Title\"))\n        tags.add(TPE1(encoding=3, text=\"Interop Artist\"))\n        tags.add(TALB(encoding=3, text=\"Interop Album\"))\n        tags.save(str(audio_path))\n    \n        easy = EasyID3(str(audio_path))\n>       assert easy[\"title\"] == [\"Interop Title\"]\nE       AssertionError: assert ['I', 'n', 't...'r', 'o', ...] == ['Interop Title']\nE         \nE         At index 0 diff: 'I' != 'Interop Title'\nE         Left contains 12 more items, first extra item: 'n'\nE         Use -v to get more diff\n\ntests\\Mutagen\\functional_test.py:216: AssertionError\n_______________ test_low_level_id3_frames_with_comment_and_apic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_low_level_id3_frames_with0')\n\n    def test_low_level_id3_frames_with_comment_and_apic(tmp_path: Path) -> None:\n        \"\"\"Use low-level ID3 frames to store text and embedded artwork.\"\"\"\n        audio_path = tmp_path / \"id3_frames.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Frame Title\"))\n        tags.add(TPE1(encoding=3, text=\"Frame Artist\"))\n        tags.add(\n            COMM(\n                encoding=3,\n                lang=\"eng\",\n                desc=\"Comment\",\n                text=\"This is a test comment.\",\n            )\n        )\n    \n        image_data = b\"\\xff\\xd8\\xff\\x00FAKEJPEGDATA\"\n        tags.add(\n            APIC(\n                encoding=3,\n                mime=\"image/jpeg\",\n                type=3,\n                desc=\"Cover\",\n                data=image_data,\n            )\n        )\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n    \n>       assert \"TIT2\" in loaded\n\ntests\\Mutagen\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3.ID3 object at 0x0000028C6EC05E20>, frame_id = 0\n\n    def __getitem__(self, frame_id):\n        frames = self._frames.get(frame_id)\n        if frames:\n            return frames[0]\n>       raise KeyError(frame_id)\nE       KeyError: 0\n\ngeneration\\Mutagen\\mutagen\\id3.py:90: KeyError\n_______________ test_id3_text_frames_album_and_genre_roundtrip ________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_id3_text_frames_album_and0')\n\n    def test_id3_text_frames_album_and_genre_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Rou", "stdout_sha1": "a08e86418e98369209636be49bee94f482dc9e06", "stdout_len": 5178, "stdout": ".....FFF...F                                                             [100%]\n================================== FAILURES ===================================\n________________ test_easyid3_genre_and_albumartist_roundtrip _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_easyid3_genre_and_albumar0')\n\n    def test_easyid3_genre_and_albumartist_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common optional fields via EasyID3 (genre/albumartist).\"\"\"\n        audio_path = tmp_path / \"genre_albumartist.mp3\"\n    \n        tags = EasyID3()\n        tags[\"title\"] = [\"Tagged Song\"]\n        tags[\"artist\"] = [\"Main Artist\"]\n>       tags[\"albumartist\"] = [\"Album Artist\"]\n\ntests\\Mutagen\\functional_test.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.easyid3.EasyID3 object at 0x0000028C6EBFFEB0>\nkey = 'albumartist', value = ['Album Artist']\n\n    def __setitem__(self, key, value):\n        frame_class = self._KEY_MAP.get(key)\n        if not frame_class:\n>           raise KeyError(f\"Unknown EasyID3 key: {key}\")\nE           KeyError: 'Unknown EasyID3 key: albumartist'\n\ngeneration\\Mutagen\\mutagen\\easyid3.py:48: KeyError\n______________ test_low_level_id3_written_can_be_read_by_easyid3 ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_low_level_id3_written_can0')\n\n    def test_low_level_id3_written_can_be_read_by_easyid3(tmp_path: Path) -> None:\n        \"\"\"Write low-level ID3 frames and read them back via EasyID3 fields.\"\"\"\n        audio_path = tmp_path / \"interop.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Interop Title\"))\n        tags.add(TPE1(encoding=3, text=\"Interop Artist\"))\n        tags.add(TALB(encoding=3, text=\"Interop Album\"))\n        tags.save(str(audio_path))\n    \n        easy = EasyID3(str(audio_path))\n>       assert easy[\"title\"] == [\"Interop Title\"]\nE       AssertionError: assert ['I', 'n', 't...'r', 'o', ...] == ['Interop Title']\nE         \nE         At index 0 diff: 'I' != 'Interop Title'\nE         Left contains 12 more items, first extra item: 'n'\nE         Use -v to get more diff\n\ntests\\Mutagen\\functional_test.py:216: AssertionError\n_______________ test_low_level_id3_frames_with_comment_and_apic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_low_level_id3_frames_with0')\n\n    def test_low_level_id3_frames_with_comment_and_apic(tmp_path: Path) -> None:\n        \"\"\"Use low-level ID3 frames to store text and embedded artwork.\"\"\"\n        audio_path = tmp_path / \"id3_frames.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Frame Title\"))\n        tags.add(TPE1(encoding=3, text=\"Frame Artist\"))\n        tags.add(\n            COMM(\n                encoding=3,\n                lang=\"eng\",\n                desc=\"Comment\",\n                text=\"This is a test comment.\",\n            )\n        )\n    \n        image_data = b\"\\xff\\xd8\\xff\\x00FAKEJPEGDATA\"\n        tags.add(\n            APIC(\n                encoding=3,\n                mime=\"image/jpeg\",\n                type=3,\n                desc=\"Cover\",\n                data=image_data,\n            )\n        )\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n    \n>       assert \"TIT2\" in loaded\n\ntests\\Mutagen\\functional_test.py:255: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <mutagen.id3.ID3 object at 0x0000028C6EC05E20>, frame_id = 0\n\n    def __getitem__(self, frame_id):\n        frames = self._frames.get(frame_id)\n        if frames:\n            return frames[0]\n>       raise KeyError(frame_id)\nE       KeyError: 0\n\ngeneration\\Mutagen\\mutagen\\id3.py:90: KeyError\n_______________ test_id3_text_frames_album_and_genre_roundtrip ________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-313/test_id3_text_frames_album_and0')\n\n    def test_id3_text_frames_album_and_genre_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Roundtrip common text frames (album/genre) using low-level ID3.\"\"\"\n        audio_path = tmp_path / \"album_genre.mp3\"\n    \n        tags = ID3()\n        tags.add(TIT2(encoding=3, text=\"Song X\"))\n        tags.add(TALB(encoding=3, text=\"Album Y\"))\n        tags.add(TCON(encoding=3, text=\"Jazz\"))\n        tags.save(str(audio_path))\n    \n        loaded = ID3(str(audio_path))\n>       assert loaded[\"TIT2\"].text == [\"Song X\"]\nE       AssertionError: assert 'Song X' == ['Song X']\nE        +  where 'Song X' = <mutagen.id3.TIT2 object at 0x0000028C6EC99BB0>.text\n\ntests\\Mutagen\\functional_test.py:346: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Mutagen/functional_test.py::test_easyid3_genre_and_albumartist_roundtrip\nFAILED tests/Mutagen/functional_test.py::test_low_level_id3_written_can_be_read_by_easyid3\nFAILED tests/Mutagen/functional_test.py::test_low_level_id3_frames_with_comment_and_apic\nFAILED tests/Mutagen/functional_test.py::test_id3_text_frames_album_and_genre_roundtrip\n4 failed, 8 passed in 0.62s\n"}
{"model": "gemini-3-pro-preview", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'pendulum' has no attribute 'date'", "returncode": 1, "elapsed_time_s": 1.906429, "avg_memory_mb": 32.46, "avg_cpu_percent": 100.0, "passed": 7, "failed": 5, "skipped": 1, "total": 13, "functional_score": 0.5385, "timestamp": "2025-12-31 16:53:50", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n5 failed, 7 passed, 1 skipped in 0.60s\n", "stdout_sha1": "d1677d2c70c970419415f30ad3d007f32137464a", "stdout_len": 2627, "stdout": ".....FFF.s.FF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n5 failed, 7 passed, 1 skipped in 0.60s\n"}
{"model": "gemini-3-pro-preview", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.421242, "avg_memory_mb": 14.44, "avg_cpu_percent": 104.8, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 16:56:18", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n", "stdout_sha1": "3d43d73e26be0f48c50fe96012d3c4dcf351a1b9", "stdout_len": 1401, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n"}
{"model": "gemini-3-pro-preview", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "NotImplementedError", "exception_msg": "Algorithm HS512 not supported", "returncode": 1, "elapsed_time_s": 1.991217, "avg_memory_mb": 34.21, "avg_cpu_percent": 98.3, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 16:58:28", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:10: in encode\n    return _jwt_global.encode(payload, key, algorithm, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x000002A15CF00FD0>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None\n\n    def encode(self, payload, key, algorithm='HS256', headers=None, json_encoder=None):\n        # Prepare Header\n        header = {'typ': 'JWT', 'alg': algorithm}\n        if headers:\n            header.update(headers)\n    \n        # Serialize Header and Payload\n        # Use separators to match compact JSON representation (no spaces)\n        header_json = json.dumps(header, separators=(',', ':')).encode('utf-8')\n        payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\n    \n        header_b64 = self._base64url_encode(header_json)\n        payload_b64 = self._base64url_encode(payload_json)\n    \n        signing_input = f\"{header_b64}.{payload_b64}\".encode('ascii')\n    \n        # Sign\n        if algorithm == 'HS256':\n            if not key:\n                raise ValueError(\"Key is required for HS256\")\n    \n            key_bytes = key.encode('utf-8') if isinstance(key, str) else key\n            signature = hmac.new(key_bytes, signing_input, hashlib.sha256).digest()\n            signature_b64 = self._base64url_encode(signature)\n        elif algorithm == 'none':\n            signature_b64 = \"\"\n        else:\n>           raise NotImplementedError(f\"Algorithm {algorithm} not supported\")\nE           NotImplementedError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:50: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:10: in encode\n    return _jwt_global.encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:32: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000002A15CF007C0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n           ", "stdout_sha1": "8f99a11827dc21ede30889cd593de45c794fa6e3", "stdout_len": 8042, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:10: in encode\n    return _jwt_global.encode(payload, key, algorithm, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x000002A15CF00FD0>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None\n\n    def encode(self, payload, key, algorithm='HS256', headers=None, json_encoder=None):\n        # Prepare Header\n        header = {'typ': 'JWT', 'alg': algorithm}\n        if headers:\n            header.update(headers)\n    \n        # Serialize Header and Payload\n        # Use separators to match compact JSON representation (no spaces)\n        header_json = json.dumps(header, separators=(',', ':')).encode('utf-8')\n        payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\n    \n        header_b64 = self._base64url_encode(header_json)\n        payload_b64 = self._base64url_encode(payload_json)\n    \n        signing_input = f\"{header_b64}.{payload_b64}\".encode('ascii')\n    \n        # Sign\n        if algorithm == 'HS256':\n            if not key:\n                raise ValueError(\"Key is required for HS256\")\n    \n            key_bytes = key.encode('utf-8') if isinstance(key, str) else key\n            signature = hmac.new(key_bytes, signing_input, hashlib.sha256).digest()\n            signature_b64 = self._base64url_encode(signature)\n        elif algorithm == 'none':\n            signature_b64 = \"\"\n        else:\n>           raise NotImplementedError(f\"Algorithm {algorithm} not supported\")\nE           NotImplementedError: Algorithm HS512 not supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:50: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:10: in encode\n    return _jwt_global.encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:32: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000002A15CF007C0>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\__init__.py:10: in encode\n    return _jwt_global.encode(payload, key, algorithm, **kwargs)\ngeneration\\PyJWT\\jwt\\api_jwt.py:32: in encode\n    payload_json = json.dumps(payload, separators=(',', ':')).encode('utf-8')\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x000002A15D01F8E0>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.63s\n"}
{"model": "gemini-3-pro-preview", "project": "PyPDF", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'PdfWriter' object has no attribute 'get_object'", "returncode": 1, "elapsed_time_s": 24.15433, "avg_memory_mb": 33.11, "avg_cpu_percent": 0.74, "passed": 0, "failed": 11, "skipped": 1, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 17:01:00", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=3)\n\ntests\\PyPDF\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_create_and_read_blank_pdf0/simple.pdf')\nnum_pages = 3\n\n    def _create_simple_pdf(path: Path, num_pages: int = 1) -> None:\n        \"\"\"Create a simple PDF with the given number of blank pages.\"\"\"\n        writer = PdfWriter()\n        # The first add_blank_page call requires explicit dimensions.\n        for i in range(num_pages):\n            if i == 0:\n                writer.add_blank_page(width=200, height=200)\n            else:\n>               writer.add_blank_page()\nE               TypeError: add_blank_page() missing 2 required positional arguments: 'width' and 'height'\n\ntests\\PyPDF\\functional_test.py:76: TypeError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n>       _create_simple_pdf(pdf1, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:159: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n>       _create_simple_pdf(src, num_pages=4)\n\ntests\\PyPDF\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "c5394456d44c2c566d343848f7f0282687e3f93d", "stdout_len": 13943, "stdout": "FFFFFFFFFFsF                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=3)\n\ntests\\PyPDF\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_create_and_read_blank_pdf0/simple.pdf')\nnum_pages = 3\n\n    def _create_simple_pdf(path: Path, num_pages: int = 1) -> None:\n        \"\"\"Create a simple PDF with the given number of blank pages.\"\"\"\n        writer = PdfWriter()\n        # The first add_blank_page call requires explicit dimensions.\n        for i in range(num_pages):\n            if i == 0:\n                writer.add_blank_page(width=200, height=200)\n            else:\n>               writer.add_blank_page()\nE               TypeError: add_blank_page() missing 2 required positional arguments: 'width' and 'height'\n\ntests\\PyPDF\\functional_test.py:76: TypeError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n>       _create_simple_pdf(pdf1, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:159: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n>       _create_simple_pdf(src, num_pages=4)\n\ntests\\PyPDF\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_writer_add_page_preserves0/src.pdf')\nnum_pages = 4\n\n    def _create_simple_pdf(path: Path, num_pages: int = 1) -> None:\n        \"\"\"Create a simple PDF with the given number of blank pages.\"\"\"\n        writer = PdfWriter()\n        # The first add_blank_page call requires explicit dimensions.\n        for i in range(num_pages):\n            if i == 0:\n                writer.add_blank_page(width=200, height=200)\n            else:\n>               writer.add_blank_page()\nE               TypeError: add_blank_page() missing 2 required positional arguments: 'width' and 'height'\n\ntests\\PyPDF\\functional_test.py:76: TypeError\n______________________________ test_rotate_page _______________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_rotate_page0')\n\n    def test_rotate_page(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        rotated = tmp_path / \"rotated.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n_______________________ test_rotate_preserves_page_size _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_rotate_preserves_page_siz0')\n\n    def test_rotate_preserves_page_size(tmp_path: Path) -> None:\n        \"\"\"Rotating a blank page should keep a valid mediabox size.\"\"\"\n        src = tmp_path / \"src_size.pdf\"\n        rotated = tmp_path / \"rot_size.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:210: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n__________________________ test_encrypt_and_decrypt ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_encrypt_and_decrypt0')\n\n    def test_encrypt_and_decrypt(tmp_path: Path) -> None:\n        src = tmp_path / \"plain.pdf\"\n        enc = tmp_path / \"encrypted.pdf\"\n>       _create_simple_pdf(src, num_pages=2)\n\ntests\\PyPDF\\functional_test.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_encrypt_and_decrypt0/plain.pdf')\nnum_pages = 2\n\n    def _create_simple_pdf(path: Path, num_pages: int = 1) -> None:\n        \"\"\"Create a simple PDF with the given number of blank pages.\"\"\"\n        writer = PdfWriter()\n        # The first add_blank_page call requires explicit dimensions.\n        for i in range(num_pages):\n            if i == 0:\n                writer.add_blank_page(width=200, height=200)\n            else:\n>               writer.add_blank_page()\nE               TypeError: add_blank_page() missing 2 required positional arguments: 'width' and 'height'\n\ntests\\PyPDF\\functional_test.py:76: TypeError\n_____________ test_encrypted_pdf_allows_page_access_after_decrypt _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_encrypted_pdf_allows_page0')\n\n    def test_encrypted_pdf_allows_page_access_after_decrypt(tmp_path: Path) -> None:\n        \"\"\"After decrypting, basic page access should succeed and page size is valid.\"\"\"\n        src = tmp_path / \"plain2.pdf\"\n        enc = tmp_path / \"encrypted2.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:256: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n___________________________ test_metadata_roundtrip ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_metadata_roundtrip0')\n\n    def test_metadata_roundtrip(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"meta.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:278: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n___________________ test_metadata_multiple_fields_roundtrip ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_metadata_multiple_fields_0')\n\n    def test_metadata_multiple_fields_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Add several info dict fields and ensure they can be read back.\"\"\"\n        src = tmp_path / \"src_info.pdf\"\n        dst = tmp_path / \"info.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:306: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\ngeneration\\PyPDF\\pypdf\\_writer.py:124: in write\n    page[NameObject(\"/Parent\")] = self._root[\"/Pages\"]\ngeneration\\PyPDF\\pypdf\\generic.py:56: in __getitem__\n    return val.get_object()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = IndirectObject(1, 0)\n\n    def get_object(self):\n>       return self.pdf.get_object(self)\nE       AttributeError: 'PdfWriter' object has no attribute 'get_object'\n\ngeneration\\PyPDF\\pypdf\\generic.py:36: AttributeError\n_________________ test_clone_document_by_writing_reader_pages _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_clone_document_by_writing0')\n\n    def test_clone_document_by_writing_reader_pages(tmp_path: Path) -> None:\n        \"\"\"Clone a document by copying pages and verify page count matches.\"\"\"\n        src = tmp_path / \"orig.pdf\"\n        dst = tmp_path / \"clone.pdf\"\n>       _create_simple_pdf(src, num_pages=3)\n\ntests\\PyPDF\\functional_test.py:361: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-315/test_clone_document_by_writing0/orig.pdf')\nnum_pages = 3\n\n    def _create_simple_pdf(path: Path, num_pages: int = 1) -> None:\n        \"\"\"Create a simple PDF with the given number of blank pages.\"\"\"\n        writer = PdfWriter()\n        # The first add_blank_page call requires explicit dimensions.\n        for i in range(num_pages):\n            if i == 0:\n                writer.add_blank_page(width=200, height=200)\n            else:\n>               writer.add_blank_page()\nE               TypeError: add_blank_page() missing 2 required positional arguments: 'width' and 'height'\n\ntests\\PyPDF\\functional_test.py:76: TypeError\n=========================== short test summary info ===========================\nFAILED tests/PyPDF/functional_test.py::test_create_and_read_blank_pdf - TypeE...\nFAILED tests/PyPDF/functional_test.py::test_blank_page_has_expected_size - At...\nFAILED tests/PyPDF/functional_test.py::test_merge_two_pdfs - AttributeError: ...\nFAILED tests/PyPDF/functional_test.py::test_writer_add_page_preserves_page_count\nFAILED tests/PyPDF/functional_test.py::test_rotate_page - AttributeError: 'Pd...\nFAILED tests/PyPDF/functional_test.py::test_rotate_preserves_page_size - Attr...\nFAILED tests/PyPDF/functional_test.py::test_encrypt_and_decrypt - TypeError: ...\nFAILED tests/PyPDF/functional_test.py::test_encrypted_pdf_allows_page_access_after_decrypt\nFAILED tests/PyPDF/functional_test.py::test_metadata_roundtrip - AttributeErr...\nFAILED tests/PyPDF/functional_test.py::test_metadata_multiple_fields_roundtrip\nFAILED tests/PyPDF/functional_test.py::test_clone_document_by_writing_reader_pages\n11 failed, 1 skipped in 1.02s\n"}
{"model": "gemini-3-pro-preview", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.257938, "avg_memory_mb": 31.66, "avg_cpu_percent": 95.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 17:03:21", "stdout_excerpt": "\n1 skipped in 0.13s\n", "stdout_sha1": "4c4ceb412a81fcf19d92b45ee51d2d9a1553d8c3", "stdout_len": 20, "stdout": "\n1 skipped in 0.13s\n"}
{"model": "gemini-3-pro-preview", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'this-is-a-test' in '___thisisatest___'", "returncode": 1, "elapsed_time_s": 2.021433, "avg_memory_mb": 31.8, "avg_cpu_percent": 99.2, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 17:13:38", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.49s\n", "stdout_sha1": "91c373792260968cdbd942d2a28c5ffb110d8549", "stdout_len": 956, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.49s\n"}
{"model": "gemini-3-pro-preview", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "+  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode", "returncode": 1, "elapsed_time_s": 2.747716, "avg_memory_mb": 32.47, "avg_cpu_percent": 53.3, "passed": 6, "failed": 3, "skipped": 0, "total": 9, "functional_score": 0.6667, "timestamp": "2025-12-31 17:15:08", "stdout_excerpt": "==== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000001EB89AA99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-h] [--version] [-u url] [-v verbose]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x000001EB89AA99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n_____________ test_008_running_without_args_exits_or_prints_help ______________\n\n    def test_008_running_without_args_exits_or_prints_help():\n        p = _run_cli([], timeout_s=30)\n        out = (p.stdout + \"\\n\" + p.stderr).strip()\n>       assert len(out) > 0\nE       AssertionError: assert 0 > 0\nE        +  where 0 = len('')\n\ntests\\Sqlmap\\functional_test.py:133: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_008_running_without_args_exits_or_prints_help\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n3 failed, 6 passed in 1.62s\n", "stdout_sha1": "91b713de64876d50768c5e7da3ed11bb3b2c5e0f", "stdout_len": 2804, "stdout": "....F..FF                                                                [100%]\n================================== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000001EB89AA99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-h] [--version] [-u url] [-v verbose]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x000001EB89AA99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n_____________ test_008_running_without_args_exits_or_prints_help ______________\n\n    def test_008_running_without_args_exits_or_prints_help():\n        p = _run_cli([], timeout_s=30)\n        out = (p.stdout + \"\\n\" + p.stderr).strip()\n>       assert len(out) > 0\nE       AssertionError: assert 0 > 0\nE        +  where 0 = len('')\n\ntests\\Sqlmap\\functional_test.py:133: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod...p.py: error: unrecognized arguments: --output-dir D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Sqlmap\\\\tmp_输出\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_008_running_without_args_exits_or_prints_help\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n3 failed, 6 passed in 1.62s\n"}
{"model": "gemini-3-pro-preview", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "", "exception_msg": "For further information visit https://errors.pydantic.dev/2.11/u/config-both", "returncode": 2, "elapsed_time_s": 2.309181, "avg_memory_mb": 54.44, "avg_cpu_percent": 98.6, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 17:16:17", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:197: in <module>\n    class SQLModel(BaseModel, metaclass=SQLModelMetaclass):\ngeneration\\SQLModel\\sqlmodel\\__init__.py:115: in __new__\n    new_cls = super().__new__(cls, name, bases, class_dict, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\_internal\\_model_construction.py:110: in __new__\n    config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\_internal\\_config.py:134: in for_model\n    raise PydanticUserError('\"Config\" and \"model_config\" cannot be used together', code='config-both')\nE   pydantic.errors.PydanticUserError: \"Config\" and \"model_config\" cannot be used together\nE   \nE   For further information visit https://errors.pydantic.dev/2.11/u/config-both\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - pydantic.errors.PydanticUserError: ...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.14s\n", "stdout_sha1": "421ac6befbf318f85ed476cdcd4065913857aefc", "stdout_len": 1372, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:197: in <module>\n    class SQLModel(BaseModel, metaclass=SQLModelMetaclass):\ngeneration\\SQLModel\\sqlmodel\\__init__.py:115: in __new__\n    new_cls = super().__new__(cls, name, bases, class_dict, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\_internal\\_model_construction.py:110: in __new__\n    config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\_internal\\_config.py:134: in for_model\n    raise PydanticUserError('\"Config\" and \"model_config\" cannot be used together', code='config-both')\nE   pydantic.errors.PydanticUserError: \"Config\" and \"model_config\" cannot be used together\nE   \nE   For further information visit https://errors.pydantic.dev/2.11/u/config-both\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - pydantic.errors.PydanticUserError: ...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.14s\n"}
{"model": "gemini-3-pro-preview", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'generator' object is not callable", "returncode": 1, "elapsed_time_s": 2.911011, "avg_memory_mb": 36.07, "avg_cpu_percent": 98.9, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 17:17:51", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-318/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:56: in hide\n    for x, y in coords:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def mapped_generator():\n>       gen = generator()\nE       TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:41: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\n1 failed, 11 passed in 1.78s\n", "stdout_sha1": "a511612b15d53c505ec68e047b86ac7d5ae8b653", "stdout_len": 1364, "stdout": ".F..........                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-318/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:56: in hide\n    for x, y in coords:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def mapped_generator():\n>       gen = generator()\nE       TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:41: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\n1 failed, 11 passed in 1.78s\n"}
{"model": "gemini-3-pro-preview", "project": "Tablib", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "Unsupported format html", "returncode": 1, "elapsed_time_s": 1.912819, "avg_memory_mb": 32.73, "avg_cpu_percent": 100.9, "passed": 8, "failed": 3, "skipped": 0, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 17:20:01", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E03EBEE7C0>, fmt = 'tsv'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n            return _csv.export_set(self)\n        if fmt == 'json':\n            return _json.export_set(self)\n>       raise ValueError(f\"Unsupported format {fmt}\")\nE       ValueError: Unsupported format tsv\n\ngeneration\\Tablib\\tablib\\core.py:73: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E03EC67B20>, fmt = 'html'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n            return _csv.export_set(self)\n        if fmt == 'json':\n            return _json.export_set(self)\n>       raise ValueError(f\"Unsupported format {fmt}\")\nE       ValueError: Unsupported format html\n\ngeneration\\Tablib\\tablib\\core.py:73: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.56s\n", "stdout_sha1": "39676ddd821b79c02abe121d54c74029a123dc5a", "stdout_len": 2922, "stdout": ".F..F...F..                                                              [100%]\n================================== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E03EBEE7C0>, fmt = 'tsv'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n            return _csv.export_set(self)\n        if fmt == 'json':\n            return _json.export_set(self)\n>       raise ValueError(f\"Unsupported format {fmt}\")\nE       ValueError: Unsupported format tsv\n\ngeneration\\Tablib\\tablib\\core.py:73: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001E03EC67B20>, fmt = 'html'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n            return _csv.export_set(self)\n        if fmt == 'json':\n            return _json.export_set(self)\n>       raise ValueError(f\"Unsupported format {fmt}\")\nE       ValueError: Unsupported format html\n\ngeneration\\Tablib\\tablib\\core.py:73: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n3 failed, 8 passed in 0.56s\n"}
{"model": "gemini-3-pro-preview", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "tabulate() got an unexpected keyword argument 'maxcolwidths'", "returncode": 1, "elapsed_time_s": 1.828611, "avg_memory_mb": 32.81, "avg_cpu_percent": 99.1, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 17:21:14", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['spam', 42], ['eggs', 451], ['bacon', 0]]\nheaders = ['', 'item', 'qty'], tablefmt = 'github', floatfmt = 'g'\nnumalign = 'default', stralign = 'default', missingval = ''\nshowindex = 'default', disable_numparse = False, colalign = None\n\n    def tabulate(tabular_data, headers=(), tablefmt=\"simple\", floatfmt=_DEFAULT_FLOATFMT,\n                 numalign=\"default\", stralign=\"default\", missingval=_DEFAULT_MISSINGVAL,\n                 showindex=\"default\", disable_numparse=False, colalign=None):\n    \n        # 1. Normalize Data\n        rows, header_row = _normalize_tabular_data(tabular_data, headers, showindex)\n    \n        if not rows and not header_row:\n            return \"\"\n    \n        # 2. Resolve Table Format\n        if isinstance(tablefmt, TableFormat):\n            fmt = tablefmt\n        elif tablefmt in _formats:\n            fmt = _formats[tablefmt]\n        else:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: github\n\ngeneration\\Tabulate\\tabulate\\core.py:144: ValueError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n2 failed, 10 passed in 0.47s\n", "stdout_sha1": "36bfbb61691ebe98d6b18fd1696d6a79a2105ce5", "stdout_len": 2548, "stdout": ".....F....F.                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['spam', 42], ['eggs', 451], ['bacon', 0]]\nheaders = ['', 'item', 'qty'], tablefmt = 'github', floatfmt = 'g'\nnumalign = 'default', stralign = 'default', missingval = ''\nshowindex = 'default', disable_numparse = False, colalign = None\n\n    def tabulate(tabular_data, headers=(), tablefmt=\"simple\", floatfmt=_DEFAULT_FLOATFMT,\n                 numalign=\"default\", stralign=\"default\", missingval=_DEFAULT_MISSINGVAL,\n                 showindex=\"default\", disable_numparse=False, colalign=None):\n    \n        # 1. Normalize Data\n        rows, header_row = _normalize_tabular_data(tabular_data, headers, showindex)\n    \n        if not rows and not header_row:\n            return \"\"\n    \n        # 2. Resolve Table Format\n        if isinstance(tablefmt, TableFormat):\n            fmt = tablefmt\n        elif tablefmt in _formats:\n            fmt = _formats[tablefmt]\n        else:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: github\n\ngeneration\\Tabulate\\tabulate\\core.py:144: ValueError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n2 failed, 10 passed in 0.47s\n"}
{"model": "gemini-3-pro-preview", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 2.04051, "avg_memory_mb": 32.64, "avg_cpu_percent": 99.2, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 17:24:57", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "70b213b9f7075c49ba76794ea5a37b209e6d5e10", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-319/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-319/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-319/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000015472D81310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.78s\n"}
{"model": "gemini-3-pro-preview", "project": "TinyDB", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'TinyDB' object has no attribute 'contains'", "returncode": 1, "elapsed_time_s": 2.053466, "avg_memory_mb": 32.84, "avg_cpu_percent": 98.4, "passed": 2, "failed": 10, "skipped": 0, "total": 12, "functional_score": 0.1667, "timestamp": "2025-12-31 17:25:58", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_multiple_tables_isolation ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_multiple_tables_isolation0')\n\n    def test_multiple_tables_isolation(tmp_path: Path) -> None:\n        \"\"\"Data in different tables should be isolated.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"write code\", \"done\": False})\n        tasks.insert({\"title\": \"write tests\", \"done\": False})\n        logs.insert({\"event\": \"created_tasks\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:88: TypeError\n_________________________ test_where_helper_querying __________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_where_helper_querying0')\n\n    def test_where_helper_querying(tmp_path: Path) -> None:\n        \"\"\"where('field') helper should build a working query for search().\"\"\"\n        db = _open_db(tmp_path)\n        db.insert({\"name\": \"Alice\", \"city\": \"Tokyo\"})\n        db.insert({\"name\": \"Bob\", \"city\": \"Osaka\"})\n    \n>       results = db.search(where(\"city\") == \"Tokyo\")\nE       TypeError: 'Query' object is not callable\n\ntests\\TinyDB\\functional_test.py:128: TypeError\n______________________ test_get_returns_single_document _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_get_returns_single_docume0')\n\n    def test_get_returns_single_document(tmp_path: Path) -> None:\n        \"\"\"get(query) should retrieve one matching document.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n        db.insert({\"name\": \"Alice\", \"age\": 30})\n        db.insert({\"name\": \"Bob\", \"age\": 25})\n    \n>       doc = db.get(User.name == \"Bob\")\nE       AttributeError: 'TinyDB' object has no attribute 'get'\n\ntests\\TinyDB\\functional_test.py:143: AttributeError\n________________________ test_insert_multiple_and_all _________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_insert_multiple_and_all0')\n\n    def test_insert_multiple_and_all(tmp_path: Path) -> None:\n        \"\"\"insert_multiple should add several documents and return their ids.\"\"\"\n        db = _open_db(tmp_path)\n    \n        docs = [\n            {\"k\": \"a\", \"v\": 1},\n            {\"k\": \"b\", \"v\": 2},\n            {\"k\": \"c\", \"v\": 3},\n        ]\n>       ids = db.insert_multiple(docs)\nE       AttributeError: 'TinyDB' object has no attribute 'insert_multiple'\n\ntests\\TinyDB\\functional_test.py:160: AttributeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_contains_and_count0')\n\n    def test_contains_and_count(tmp_path: Path) -> None:\n        \"\"\"contains and count should reflect stored data and queries.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n        db.insert({\"name\": \"Alice\", \"age\": 30})\n        db.insert({\"name\": \"Bob\", \"age\": 25})\n        db.insert({\"name\": \"Charlie\", \"age\": 35})\n    \n>       assert db.contains(User.name == \"Alice\") is True\nE       AttributeError: 'TinyDB' object has no attribute 'contains'\n\ntests\\TinyDB\\functional_test.py:180: AttributeError\n_____________________ test_persistence_reopen_and_search ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_persistence_reopen_and_se0')\n\n    def test_persistence_reopen_and_search(tmp_path: Path) -> None:\n        \"\"\"Data should persist on disk and be readable after reopening.\"\"\"\n        db_path = tmp_path / \"persist.json\"\n    \n        db1 = TinyDB(str(db_path))\n        db1.insert({\"name\": \"Ada\", \"lang\": \"Python\"})\n        db1.close()\n    \n        db2 = TinyDB(str(db_path))\n>       r", "stdout_sha1": "f69a99e1e4faea34e4f61166d5463076f769c7f1", "stdout_len": 7752, "stdout": ".F.FFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_multiple_tables_isolation ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_multiple_tables_isolation0')\n\n    def test_multiple_tables_isolation(tmp_path: Path) -> None:\n        \"\"\"Data in different tables should be isolated.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"write code\", \"done\": False})\n        tasks.insert({\"title\": \"write tests\", \"done\": False})\n        logs.insert({\"event\": \"created_tasks\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:88: TypeError\n_________________________ test_where_helper_querying __________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_where_helper_querying0')\n\n    def test_where_helper_querying(tmp_path: Path) -> None:\n        \"\"\"where('field') helper should build a working query for search().\"\"\"\n        db = _open_db(tmp_path)\n        db.insert({\"name\": \"Alice\", \"city\": \"Tokyo\"})\n        db.insert({\"name\": \"Bob\", \"city\": \"Osaka\"})\n    \n>       results = db.search(where(\"city\") == \"Tokyo\")\nE       TypeError: 'Query' object is not callable\n\ntests\\TinyDB\\functional_test.py:128: TypeError\n______________________ test_get_returns_single_document _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_get_returns_single_docume0')\n\n    def test_get_returns_single_document(tmp_path: Path) -> None:\n        \"\"\"get(query) should retrieve one matching document.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n        db.insert({\"name\": \"Alice\", \"age\": 30})\n        db.insert({\"name\": \"Bob\", \"age\": 25})\n    \n>       doc = db.get(User.name == \"Bob\")\nE       AttributeError: 'TinyDB' object has no attribute 'get'\n\ntests\\TinyDB\\functional_test.py:143: AttributeError\n________________________ test_insert_multiple_and_all _________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_insert_multiple_and_all0')\n\n    def test_insert_multiple_and_all(tmp_path: Path) -> None:\n        \"\"\"insert_multiple should add several documents and return their ids.\"\"\"\n        db = _open_db(tmp_path)\n    \n        docs = [\n            {\"k\": \"a\", \"v\": 1},\n            {\"k\": \"b\", \"v\": 2},\n            {\"k\": \"c\", \"v\": 3},\n        ]\n>       ids = db.insert_multiple(docs)\nE       AttributeError: 'TinyDB' object has no attribute 'insert_multiple'\n\ntests\\TinyDB\\functional_test.py:160: AttributeError\n___________________________ test_contains_and_count ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_contains_and_count0')\n\n    def test_contains_and_count(tmp_path: Path) -> None:\n        \"\"\"contains and count should reflect stored data and queries.\"\"\"\n        db = _open_db(tmp_path)\n        User = Query()\n    \n        db.insert({\"name\": \"Alice\", \"age\": 30})\n        db.insert({\"name\": \"Bob\", \"age\": 25})\n        db.insert({\"name\": \"Charlie\", \"age\": 35})\n    \n>       assert db.contains(User.name == \"Alice\") is True\nE       AttributeError: 'TinyDB' object has no attribute 'contains'\n\ntests\\TinyDB\\functional_test.py:180: AttributeError\n_____________________ test_persistence_reopen_and_search ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_persistence_reopen_and_se0')\n\n    def test_persistence_reopen_and_search(tmp_path: Path) -> None:\n        \"\"\"Data should persist on disk and be readable after reopening.\"\"\"\n        db_path = tmp_path / \"persist.json\"\n    \n        db1 = TinyDB(str(db_path))\n        db1.insert({\"name\": \"Ada\", \"lang\": \"Python\"})\n        db1.close()\n    \n        db2 = TinyDB(str(db_path))\n>       results = db2.search(where(\"name\") == \"Ada\")\nE       TypeError: 'Query' object is not callable\n\ntests\\TinyDB\\functional_test.py:198: TypeError\n_________________ test_table_truncate_clears_only_that_table __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_table_truncate_clears_onl0')\n\n    def test_table_truncate_clears_only_that_table(tmp_path: Path) -> None:\n        \"\"\"truncate on a table should clear its rows without affecting other tables.\"\"\"\n        db = _open_db(tmp_path)\n    \n        tasks = db.table(\"tasks\")\n        logs = db.table(\"logs\")\n    \n        tasks.insert({\"title\": \"t1\"})\n        tasks.insert({\"title\": \"t2\"})\n        logs.insert({\"event\": \"created\"})\n    \n>       assert len(tasks) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:215: TypeError\n____________________________ test_update_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_update_by_doc_id0')\n\n    def test_update_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"update with doc_ids should modify the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        doc_id = table.insert({\"name\": \"ItemA\", \"qty\": 1})\n>       assert len(table) == 1\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:231: TypeError\n____________________________ test_remove_by_doc_id ____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_remove_by_doc_id0')\n\n    def test_remove_by_doc_id(tmp_path: Path) -> None:\n        \"\"\"remove with doc_ids should delete the targeted document.\"\"\"\n        db = _open_db(tmp_path)\n        table = db.table(\"items\")\n    \n        id1 = table.insert({\"name\": \"A\"})\n        id2 = table.insert({\"name\": \"B\"})\n>       assert len(table) == 2\nE       TypeError: object of type 'Table' has no len()\n\ntests\\TinyDB\\functional_test.py:249: TypeError\n_________________ test_tables_listing_includes_created_tables _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-320/test_tables_listing_includes_c0')\n\n    def test_tables_listing_includes_created_tables(tmp_path: Path) -> None:\n        \"\"\"tables() should include table names once they have stored data.\"\"\"\n        db = _open_db(tmp_path)\n    \n        t1 = db.table(\"t1\")\n        t2 = db.table(\"t2\")\n        t1.insert({\"x\": 1})\n        t2.insert({\"y\": 2})\n    \n>       names = db.tables()\nE       AttributeError: 'TinyDB' object has no attribute 'tables'\n\ntests\\TinyDB\\functional_test.py:269: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/TinyDB/functional_test.py::test_multiple_tables_isolation - Type...\nFAILED tests/TinyDB/functional_test.py::test_where_helper_querying - TypeErro...\nFAILED tests/TinyDB/functional_test.py::test_get_returns_single_document - At...\nFAILED tests/TinyDB/functional_test.py::test_insert_multiple_and_all - Attrib...\nFAILED tests/TinyDB/functional_test.py::test_contains_and_count - AttributeEr...\nFAILED tests/TinyDB/functional_test.py::test_persistence_reopen_and_search - ...\nFAILED tests/TinyDB/functional_test.py::test_table_truncate_clears_only_that_table\nFAILED tests/TinyDB/functional_test.py::test_update_by_doc_id - TypeError: ob...\nFAILED tests/TinyDB/functional_test.py::test_remove_by_doc_id - TypeError: ob...\nFAILED tests/TinyDB/functional_test.py::test_tables_listing_includes_created_tables\n10 failed, 2 passed in 0.74s\n"}
{"model": "gemini-3-pro-preview", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "+  where 1 = <typer.testing.Result object at 0x000002597D2A1760>.exit_code", "returncode": 1, "elapsed_time_s": 2.107632, "avg_memory_mb": 32.73, "avg_cpu_percent": 96.9, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 17:27:39", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: callback() got an unexpected keyword argument 'invoke_without_command'\n\ntests\\Typer\\functional_test.py:70: TypeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: callback() got an unexpected keyword argument 'invoke_without_command'\n\ntests\\Typer\\functional_test.py:70: TypeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: callback() got an unexpected keyword argument 'invoke_without_command'\n\ntests\\Typer\\functional_test.py:70: TypeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D23ED60>.exit_code\n\ntests\\Typer\\functional_test.py:223: AssertionError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D293E20>.exit_code\n\ntests\\Typer\\functional_test.py:233: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D2A19A0>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"--help\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D2A1760>.exit_code\n\ntests\\Typer\\functional_test.py:264: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _cr", "stdout_sha1": "d8a7a88f0a1fe29df1c388f89231543d01bb20f9", "stdout_len": 7562, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: callback() got an unexpected keyword argument 'invoke_without_command'\n\ntests\\Typer\\functional_test.py:70: TypeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: callback() got an unexpected keyword argument 'invoke_without_command'\n\ntests\\Typer\\functional_test.py:70: TypeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: callback() got an unexpected keyword argument 'invoke_without_command'\n\ntests\\Typer\\functional_test.py:70: TypeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D23ED60>.exit_code\n\ntests\\Typer\\functional_test.py:223: AssertionError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D293E20>.exit_code\n\ntests\\Typer\\functional_test.py:233: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D2A19A0>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"--help\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D2A1760>.exit_code\n\ntests\\Typer\\functional_test.py:264: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D2A1370>.exit_code\n\ntests\\Typer\\functional_test.py:274: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n        app = _create_prompt_app()\n        # Now stable: \"greet\" always exists as a subcommand (multi-command app).\n>       result = runner.invoke(app, [\"greet\"], input=\"Alice\\n\")\nE       TypeError: invoke() got an unexpected keyword argument 'input'\n\ntests\\Typer\\functional_test.py:282: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x000002597D228B80>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n        app = _create_env_app()\n        monkeypatch.setenv(\"APP_TOKEN\", \"abc123\")\n    \n        result = runner.invoke(app, [\"show\"])\n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D228AC0>.exit_code\n\ntests\\Typer\\functional_test.py:292: AssertionError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n        app = _create_callback_app()\n    \n        r1 = runner.invoke(app, [\"run\"])\n        assert r1.exit_code == 0\n        assert \"running\" in r1.stdout\n        assert \"verbose\" not in r1.stdout\n    \n        r2 = runner.invoke(app, [\"--verbose\", \"run\"])\n>       assert r2.exit_code == 0\nE       assert 2 == 0\nE        +  where 2 = <typer.testing.Result object at 0x000002597D22FCA0>.exit_code\n\ntests\\Typer\\functional_test.py:305: AssertionError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n        app = _create_types_app()\n        # Now stable: \"calc\" always exists as a subcommand (multi-command app).\n        r = runner.invoke(app, [\"calc\", \"2\", \"3\", \"--scale\", \"2.0\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000002597D21A730>.exit_code\n\ntests\\Typer\\functional_test.py:313: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - TypeError:...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - Ty...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_list_empty_shows_no_tasks - ...\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - assert 1 == 0\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_help_output_includes_commands - a...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - assert...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n12 failed in 0.81s\n"}
{"model": "gemini-3-pro-preview", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.929915, "avg_memory_mb": 36.22, "avg_cpu_percent": 98.3, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 17:29:48", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n", "stdout_sha1": "ab9a030ccb03922d0202a790bd63e9a6545205ea", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n"}
{"model": "gpt-3.5-turbo", "project": "Astral", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where False = isinstance('Europe/London', (<class 'int'>, <class 'float'>))", "returncode": 1, "elapsed_time_s": 1.654534, "avg_memory_mb": 32.99, "avg_cpu_percent": 99.0, "passed": 5, "failed": 6, "skipped": 0, "total": 11, "functional_score": 0.4545, "timestamp": "2025-12-31 20:55:41", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_sun_times_basic_sanity _________________________\n\n    def test_sun_times_basic_sanity() -> None:\n        \"\"\"sun() returns expected keys and times are in a plausible order.\"\"\"\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 0.38468842668571496, zenith = 90.8333\n\n    def _hour_angle(latitude: float, declination: float, zenith: float) -> Optional[float]:\n        \"\"\"\n        Calculate the hour angle for the sun at the given zenith.\n        Returns hour angle in degrees or None if sun never rises/sets.\n        \"\"\"\n>       lat_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:100: TypeError\n______________________ test_sun_time_changes_across_days ______________________\n\n    def test_sun_time_changes_across_days() -> None:\n        \"\"\"Sunrise and sunset should change slightly between consecutive days.\"\"\"\n        loc = _london_location()\n        d1 = dt.date(2020, 1, 1)\n        d2 = d1 + dt.timedelta(days=1)\n    \n>       s1 = sun(_observer_from_location(loc), date=d1, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = -0.4029454635354721, zenith = 90.8333\n\n    def _hour_angle(latitude: float, declination: float, zenith: float) -> Optional[float]:\n        \"\"\"\n        Calculate the hour angle for the sun at the given zenith.\n        Returns hour angle in degrees or None if sun never rises/sets.\n        \"\"\"\n>       lat_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:100: TypeError\n______________ test_locationinfo_has_lat_lon_fields_or_observer _______________\n\n    def test_locationinfo_has_lat_lon_fields_or_observer() -> None:\n        loc = _london_location()\n    \n        if hasattr(loc, \"observer\"):\n            obs = _observer_from_location(loc)\n            lat = getattr(obs, \"latitude\", None)\n            lon = getattr(obs, \"longitude\", None)\n        else:\n            lat = getattr(loc, \"latitude\", None)\n            lon = getattr(loc, \"longitude\", None)\n    \n>       assert isinstance(lat, (int, float))\nE       AssertionError: assert False\nE        +  where False = isinstance('Europe/London', (<class 'int'>, <class 'float'>))\n\ntests\\Astral\\functional_test.py:169: AssertionError\n_________________________ test_sun_returns_datetimes __________________________\n\n    def test_sun_returns_datetimes() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:185: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 0.38468842668571496, zenith = 90", "stdout_sha1": "65e92f3f3497b6eb956573f2e46396b1551f14e1", "stdout_len": 7968, "stdout": "FF.F.FFF...                                                              [100%]\n================================== FAILURES ===================================\n_________________________ test_sun_times_basic_sanity _________________________\n\n    def test_sun_times_basic_sanity() -> None:\n        \"\"\"sun() returns expected keys and times are in a plausible order.\"\"\"\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 0.38468842668571496, zenith = 90.8333\n\n    def _hour_angle(latitude: float, declination: float, zenith: float) -> Optional[float]:\n        \"\"\"\n        Calculate the hour angle for the sun at the given zenith.\n        Returns hour angle in degrees or None if sun never rises/sets.\n        \"\"\"\n>       lat_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:100: TypeError\n______________________ test_sun_time_changes_across_days ______________________\n\n    def test_sun_time_changes_across_days() -> None:\n        \"\"\"Sunrise and sunset should change slightly between consecutive days.\"\"\"\n        loc = _london_location()\n        d1 = dt.date(2020, 1, 1)\n        d2 = d1 + dt.timedelta(days=1)\n    \n>       s1 = sun(_observer_from_location(loc), date=d1, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = -0.4029454635354721, zenith = 90.8333\n\n    def _hour_angle(latitude: float, declination: float, zenith: float) -> Optional[float]:\n        \"\"\"\n        Calculate the hour angle for the sun at the given zenith.\n        Returns hour angle in degrees or None if sun never rises/sets.\n        \"\"\"\n>       lat_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:100: TypeError\n______________ test_locationinfo_has_lat_lon_fields_or_observer _______________\n\n    def test_locationinfo_has_lat_lon_fields_or_observer() -> None:\n        loc = _london_location()\n    \n        if hasattr(loc, \"observer\"):\n            obs = _observer_from_location(loc)\n            lat = getattr(obs, \"latitude\", None)\n            lon = getattr(obs, \"longitude\", None)\n        else:\n            lat = getattr(loc, \"latitude\", None)\n            lon = getattr(loc, \"longitude\", None)\n    \n>       assert isinstance(lat, (int, float))\nE       AssertionError: assert False\nE        +  where False = isinstance('Europe/London', (<class 'int'>, <class 'float'>))\n\ntests\\Astral\\functional_test.py:169: AssertionError\n_________________________ test_sun_returns_datetimes __________________________\n\n    def test_sun_returns_datetimes() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:185: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 0.38468842668571496, zenith = 90.8333\n\n    def _hour_angle(latitude: float, declination: float, zenith: float) -> Optional[float]:\n        \"\"\"\n        Calculate the hour angle for the sun at the given zenith.\n        Returns hour angle in degrees or None if sun never rises/sets.\n        \"\"\"\n>       lat_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:100: TypeError\n_________________ test_sun_noon_is_between_sunrise_and_sunset _________________\n\n    def test_sun_noon_is_between_sunrise_and_sunset() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 3, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:196: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = -0.13301090125781806, zenith = 90.8333\n\n    def _hour_angle(latitude: float, declination: float, zenith: float) -> Optional[float]:\n        \"\"\"\n        Calculate the hour angle for the sun at the given zenith.\n        Returns hour angle in degrees or None if sun never rises/sets.\n        \"\"\"\n>       lat_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:100: TypeError\n_______ test_sun_times_differ_between_locations_same_date_or_one_raises _______\n\n    def test_sun_times_differ_between_locations_same_date_or_one_raises() -> None:\n        \"\"\"\n        Some generated implementations have edge-case bugs for certain longitudes that can\n        yield out-of-range hours (e.g., hour < 0 or > 23) and raise ValueError.\n        This test remains targeted (different locations) while being compatible across\n        implementations by accepting either:\n          - both computations succeed and differ, OR\n          - one implementation raises a clear exception for the second location.\n        \"\"\"\n        london = _london_location()\n        nyc = _new_york_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s_l = sun(_observer_from_location(london), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:208: in sun\n    return _sun_times(observer, dt, tzinfo)\ngeneration\\Astral\\astral\\sun.py:155: in _sun_times\n    ha = _hour_angle(observer.latitude, decl, ZENITH_OFFICIAL)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 0.38468842668571496, zenith = 90.8333\n\n    def _hour_angle(latitude: float, declination: float, zenith: float) -> Optional[float]:\n        \"\"\"\n        Calculate the hour angle for the sun at the given zenith.\n        Returns hour angle in degrees or None if sun never rises/sets.\n        \"\"\"\n>       lat_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:100: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Astral/functional_test.py::test_sun_times_basic_sanity - TypeErr...\nFAILED tests/Astral/functional_test.py::test_sun_time_changes_across_days - T...\nFAILED tests/Astral/functional_test.py::test_locationinfo_has_lat_lon_fields_or_observer\nFAILED tests/Astral/functional_test.py::test_sun_returns_datetimes - TypeErro...\nFAILED tests/Astral/functional_test.py::test_sun_noon_is_between_sunrise_and_sunset\nFAILED tests/Astral/functional_test.py::test_sun_times_differ_between_locations_same_date_or_one_raises\n6 failed, 5 passed in 0.51s\n"}
{"model": "gpt-3.5-turbo", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword argument 'include'", "returncode": 1, "elapsed_time_s": 1.574887, "avg_memory_mb": 32.93, "avg_cpu_percent": 102.1, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2025-12-31 20:56:42", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=", "stdout_sha1": "a988668895d56720b3f1177dc59d184547d5d0b1", "stdout_len": 8919, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n>       app = _make_app(\"celery_test_app_2\")\n\ntests\\Celery\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app_2'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n>       app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\nE       TypeError: __init__() got an unexpected keyword argument 'include'\n\ntests\\Celery\\functional_test.py:34: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.48s\n"}
{"model": "gpt-3.5-turbo", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "cli() takes 0 positional arguments but 1 was given", "returncode": 1, "elapsed_time_s": 4.32341, "avg_memory_mb": 32.49, "avg_cpu_percent": 97.8, "passed": 3, "failed": 8, "skipped": 0, "total": 11, "functional_score": 0.2727, "timestamp": "2025-12-31 20:57:40", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n        def greet(count: int, name: str) -> None:\n            for _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n        runner = CliRunner()\n        result = runner.invoke(greet, [\"--count\", \"3\", \"World\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x000001ECCEC94E80>.exit_code\n\ntests\\Click\\functional_test.py:143: AssertionError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 2 == 0\nE        +  where 2 = <click.testing.Result object at 0x000001ECCEC72310>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_group_with_subcommands.<locals>.cli at 0x000001ECCECB2B80>\nname = None, cls = None, attrs = {}, grp_name = 'cli'\ngrp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group object at 0x000001ECCECAC1C0>\n\n    def _make_group(f, name=None, cls=None, **attrs):\n        grp_name = name or f.__name__\n        grp_cls = cls or Group\n        grp = grp_cls(name=grp_name, **attrs)\n        # Add commands from decorated functions attached to group\n>       f(grp)\nE       TypeError: cli() takes 0 positional arguments but 1 was given\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_help_output_for_command_and_group.<locals>.cli at 0x000001ECCECB2D30>\nname = None, cls = None, attrs = {'help': 'Top level group'}, grp_name = 'cli'\ngrp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group object at 0x000001ECCEC727F0>\n\n    def _make_group(f, name=None, cls=None, **attrs):\n        grp_name = name or f.__name__\n        grp_cls = cls or Group\n        grp = grp_cls(name=grp_name, **attrs)\n        # Add commands from decorated functions attached to group\n>       f(grp)\nE       TypeError: cli() takes 0 positional arguments but 1 was given\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls, **attrs)\ngeneration\\Clic", "stdout_sha1": "ea66354465d6ea505c06307a484a3634cb9ceb98", "stdout_len": 7416, "stdout": "FFFFF...FFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n        def greet(count: int, name: str) -> None:\n            for _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n        runner = CliRunner()\n        result = runner.invoke(greet, [\"--count\", \"3\", \"World\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x000001ECCEC94E80>.exit_code\n\ntests\\Click\\functional_test.py:143: AssertionError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 2 == 0\nE        +  where 2 = <click.testing.Result object at 0x000001ECCEC72310>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_group_with_subcommands.<locals>.cli at 0x000001ECCECB2B80>\nname = None, cls = None, attrs = {}, grp_name = 'cli'\ngrp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group object at 0x000001ECCECAC1C0>\n\n    def _make_group(f, name=None, cls=None, **attrs):\n        grp_name = name or f.__name__\n        grp_cls = cls or Group\n        grp = grp_cls(name=grp_name, **attrs)\n        # Add commands from decorated functions attached to group\n>       f(grp)\nE       TypeError: cli() takes 0 positional arguments but 1 was given\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_help_output_for_command_and_group.<locals>.cli at 0x000001ECCECB2D30>\nname = None, cls = None, attrs = {'help': 'Top level group'}, grp_name = 'cli'\ngrp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group object at 0x000001ECCEC727F0>\n\n    def _make_group(f, name=None, cls=None, **attrs):\n        grp_name = name or f.__name__\n        grp_cls = cls or Group\n        grp = grp_cls(name=grp_name, **attrs)\n        # Add commands from decorated functions attached to group\n>       f(grp)\nE       TypeError: cli() takes 0 positional arguments but 1 was given\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls, **attrs)\ngeneration\\Click\\click\\decorators.py:54: in _make_group\n    f(grp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nconfig = <click.core.Group object at 0x000001ECCED08880>\n\n    @click.group()\n    @click.option(\"--config\", type=str, default=\"default.cfg\")\n    def cli(config: str) -> None:\n>       ctx = click.get_current_context()\nE       AttributeError: module 'click' has no attribute 'get_current_context'\n\ntests\\Click\\functional_test.py:223: AttributeError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:291: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:67: in decorator\n    grp = _make_group(f, name=name, cls=cls, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <function test_default_map_provides_default_option_value.<locals>.cli at 0x000001ECCEC29310>\nname = None, cls = None, attrs = {}, grp_name = 'cli'\ngrp_cls = <class 'click.core.Group'>\ngrp = <click.core.Group object at 0x000001ECCED0D1F0>\n\n    def _make_group(f, name=None, cls=None, **attrs):\n        grp_name = name or f.__name__\n        grp_cls = cls or Group\n        grp = grp_cls(name=grp_name, **attrs)\n        # Add commands from decorated functions attached to group\n>       f(grp)\nE       TypeError: cli() takes 0 positional arguments but 1 was given\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n_______________ test_parameter_type_validation_error_exit_code ________________\n\n    def test_parameter_type_validation_error_exit_code():\n        @click.command()\n        @click.option(\"--count\", type=int, required=True)\n        def cli(count: int) -> None:\n            click.echo(f\"COUNT={count}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [\"--count\", \"not-an-int\"])\n>       assert r.exit_code != 0\nE       assert 0 != 0\nE        +  where 0 = <click.testing.Result object at 0x000001ECCED05910>.exit_code\n\ntests\\Click\\functional_test.py:313: AssertionError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - TypeErro...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n8 failed, 3 passed in 3.18s\n"}
{"model": "gpt-3.5-turbo", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where False = all(<generator object test_table_all_iteration_and_row_shape.<locals>.<genexpr> at 0x0000025575BC8350>)", "returncode": 1, "elapsed_time_s": 4.251592, "avg_memory_mb": 33.75, "avg_cpu_percent": 99.2, "passed": 4, "failed": 7, "skipped": 0, "total": 11, "functional_score": 0.3636, "timestamp": "2025-12-31 20:59:03", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n>       assert \"id\" in _table_columns(table)\nE       AssertionError: assert 'id' in ['name', 'age', 'country', 'active']\nE        +  where ['name', 'age', 'country', 'active'] = _table_columns(<dataset.table.Table object at 0x0000025575C01E20>)\n\ntests\\Dataset\\functional_test.py:146: AssertionError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-333/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n        table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n>       db.commit()\n\ntests\\Dataset\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000025575C7FB50>\n\n    def commit(self):\n        if not self._transaction_active:\n            return\n>       self._conn.execute(\"COMMIT\")\nE       sqlite3.OperationalError: cannot commit - no transaction is active\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n        db = create_in_memory_db()\n        table = db[\"people\"]\n        table.insert({\"name\": \"Alice\", \"age\": 30})\n        table.insert({\"name\": \"Bob\", \"age\": 31})\n    \n        rows = list(table.all())\n        assert len(rows) == 2\n>       assert all((\"id\" in r and \"name\" in r) for r in rows)\nE       assert False\nE        +  where False = all(<generator object test_table_all_iteration_and_row_shape.<locals>.<genexpr> at 0x0000025575BC8350>)\n\ntests\\Dataset\\functional_test.py:260: AssertionError\n________", "stdout_sha1": "b3c401929a1f4e18d91b276e451605ee62910b28", "stdout_len": 5918, "stdout": "FFF..FF.F.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n>       assert \"id\" in _table_columns(table)\nE       AssertionError: assert 'id' in ['name', 'age', 'country', 'active']\nE        +  where ['name', 'age', 'country', 'active'] = _table_columns(<dataset.table.Table object at 0x0000025575C01E20>)\n\ntests\\Dataset\\functional_test.py:146: AssertionError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-333/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n        table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n>       db.commit()\n\ntests\\Dataset\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x0000025575C7FB50>\n\n    def commit(self):\n        if not self._transaction_active:\n            return\n>       self._conn.execute(\"COMMIT\")\nE       sqlite3.OperationalError: cannot commit - no transaction is active\n\ngeneration\\Dataset\\dataset\\database.py:36: OperationalError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n        db = create_in_memory_db()\n        table = db[\"people\"]\n        table.insert({\"name\": \"Alice\", \"age\": 30})\n        table.insert({\"name\": \"Bob\", \"age\": 31})\n    \n        rows = list(table.all())\n        assert len(rows) == 2\n>       assert all((\"id\" in r and \"name\" in r) for r in rows)\nE       assert False\nE        +  where False = all(<generator object test_table_all_iteration_and_row_shape.<locals>.<genexpr> at 0x0000025575BC8350>)\n\ntests\\Dataset\\functional_test.py:260: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x0000025575BF9A90>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x0000025575C7F970>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - A...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - ass...\nFAILED tests/Dataset/functional_test.py::test_transactions_commit_and_rollback\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - as...\nFAILED tests/Dataset/functional_test.py::test_table_all_iteration_and_row_shape\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n7 failed, 4 passed in 3.10s\n"}
{"model": "gpt-3.5-turbo", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:00:13", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "gpt-3.5-turbo", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert ('failregex' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...   candidate = match.group(0)\\n            if isvalidip(candidate):\\n                return candidate\\n    return none' or '<host>' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...   candidate = match.group(0)\\n            if isvalidip(candidate):\\n                return candidate\\n    return none')", "returncode": 1, "elapsed_time_s": 2.699434, "avg_memory_mb": 31.86, "avg_cpu_percent": 74.5, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 21:00:46", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...   candidate = match.group(0)\\n            if isvalidip(candidate):\\n                return candidate\\n    return none' or '<host>' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...   candidate = match.group(0)\\n            if isvalidip(candidate):\\n                return candidate\\n    return none')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\n2 failed, 10 passed in 1.29s\n", "stdout_sha1": "cabeee81b0ab39fe098b6d9b9c82de86095e0cb2", "stdout_len": 2897, "stdout": "...F....F...                                                             [100%]\n================================== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...   candidate = match.group(0)\\n            if isvalidip(candidate):\\n                return candidate\\n    return none' or '<host>' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...   candidate = match.group(0)\\n            if isvalidip(candidate):\\n                return candidate\\n    return none')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\n2 failed, 10 passed in 1.29s\n"}
{"model": "gpt-3.5-turbo", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "Attribute", "returncode": 1, "elapsed_time_s": 2.111261, "avg_memory_mb": 32.73, "avg_cpu_percent": 99.2, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 21:01:34", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       html = m.get_root().render()\n\ntests\\Folium\\functional_test.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECF2B4CC0>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        root = m.get_root()\n        assert hasattr(root, \"render\")\n>       html = root.render().lower()\n\ntests\\Folium\\functional_test.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECCFE80E0>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECF351090>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECF30C400>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n>       folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\nE       Attribute", "stdout_sha1": "b71facd0a4cf068018f546ef6e8126ebb1a0f18d", "stdout_len": 7709, "stdout": "..FFFFFFFF.F                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       html = m.get_root().render()\n\ntests\\Folium\\functional_test.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECF2B4CC0>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        root = m.get_root()\n        assert hasattr(root, \"render\")\n>       html = root.render().lower()\n\ntests\\Folium\\functional_test.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECCFE80E0>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECF351090>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\map.py:63: in render\n    if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <odict_iterator object at 0x000001AECF30C400>\n\n>   if any(child.get_name().startswith('marker_cluster') for child in self._children.values()):\nE   AttributeError: 'NoneType' object has no attribute 'get_name'\n\ngeneration\\Folium\\folium\\map.py:63: AttributeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n>       folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\nE       AttributeError: 'TileLayer' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:92: AttributeError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, name=\"g\").add_to(m)\nE       AttributeError: 'GeoJson' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:115: AttributeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-334/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       mc = MarkerCluster(name=\"mc\").add_to(m)\nE       AttributeError: 'MarkerCluster' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:174: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root - Attribut...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n9 failed, 3 passed in 0.72s\n"}
{"model": "gpt-3.5-turbo", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "naturaltime() got an unexpected keyword argument 'when'", "returncode": 1, "elapsed_time_s": 2.000968, "avg_memory_mb": 32.36, "avg_cpu_percent": 97.5, "passed": 5, "failed": 5, "skipped": 5, "total": 15, "functional_score": 0.3333, "timestamp": "2025-12-31 21:02:58", "stdout_excerpt": "==== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n        d = humanize.precisedelta(3661)  # seconds\n>       assert \"1 hour\" in d\nE       AssertionError: assert '1 hour' in '3661'\n\ntests\\Humanize\\functional_test.py:113: AssertionError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n_____________________ test_intcomma_float_keeps_decimals ______________________\n\n    def test_intcomma_float_keeps_decimals() -> None:\n        s = humanize.intcomma(1234.56)\n        assert isinstance(s, str)\n>       assert s == \"1,234.56\"\nE       AssertionError: assert '1,234' == '1,234.56'\nE         \nE         - 1,234.56\nE         ?      ---\nE         + 1,234\n\ntests\\Humanize\\functional_test.py:140: AssertionError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - Asserti...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_intcomma_float_keeps_decimals\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n5 failed, 5 passed, 5 skipped in 0.57s\n", "stdout_sha1": "2be43fed2314a1257d535d8385083b4fd3474c93", "stdout_len": 2578, "stdout": "..FF.FF..Fsssss                                                          [100%]\n================================== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n__________________________ test_precisedelta_numeric __________________________\n\n    def test_precisedelta_numeric() -> None:\n        d = humanize.precisedelta(3661)  # seconds\n>       assert \"1 hour\" in d\nE       AssertionError: assert '1 hour' in '3661'\n\ntests\\Humanize\\functional_test.py:113: AssertionError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n_____________________ test_intcomma_float_keeps_decimals ______________________\n\n    def test_intcomma_float_keeps_decimals() -> None:\n        s = humanize.intcomma(1234.56)\n        assert isinstance(s, str)\n>       assert s == \"1,234.56\"\nE       AssertionError: assert '1,234' == '1,234.56'\nE         \nE         - 1,234.56\nE         ?      ---\nE         + 1,234\n\ntests\\Humanize\\functional_test.py:140: AssertionError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_precisedelta_numeric - Asserti...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_intcomma_float_keeps_decimals\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n5 failed, 5 passed, 5 skipped in 0.57s\n"}
{"model": "gpt-3.5-turbo", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "Invalid LZW code", "returncode": 1, "elapsed_time_s": 2.79936, "avg_memory_mb": 44.78, "avg_cpu_percent": 100.0, "passed": 5, "failed": 5, "skipped": 0, "total": 10, "functional_score": 0.5, "timestamp": "2025-12-31 21:04:31", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-337/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       loaded_frames = list(iio.imiter(path))\n\ntests\\Imageio\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:618: in imiter\n    arr = _read_gif(path)\ngeneration\\Imageio\\imageio\\v3.py:379: in _read_gif\n    frame_indices = _decode_lzw(bytes(compressed_data), min_code_size, w*h)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata = b'\\x00\\xaf\\x01(\\'\\xee\\xdc9\\x00\\xe0\\xb4q3\\xe7\\xad \\x00m\\xe2\\xcai;\\xa7\\x8d\\xd5\\xb5\\x8b\\xd7\\xcc\\x91\\x03\\xb0\\xa2\\\\ t\\xda\\x...7\\xa2\\xda\\x12j\\xeb\\xb8B\\xa6\\xb8\\x91\\x12C\\x9e\\xb3\\xb2b*:tg\\xf1Z9\\x87.\\x10\\x80@\\xe2\\xcc\\xad\\xf8\\x08\\xd3\\x9b\\xd0s\\x01\\x01'\nmin_code_size = 8, expected_size = 576\n\n    def _decode_lzw(data, min_code_size, expected_size):\n        # Minimal LZW decoder for GIF\n        # data: bytes of compressed data\n        # min_code_size: int\n        # expected_size: number of pixels expected in output\n        # Returns list of indices\n    \n        clear_code = 1 << min_code_size\n        end_code = clear_code + 1\n        code_size = min_code_size + 1\n        max_code = (1 << code_size) - 1\n    \n        # Initialize dictionary\n        dict_size = end_code + 1\n        dictionary = {i: bytes([i]) for i in range(clear_code)}\n        dictionary[clear_code] = None\n        dictionary[end_code] = None\n    \n        bit_pos = 0\n        bit_len = len(data) * 8\n    \n        def get_code():\n            nonlocal bit_pos\n            code = 0\n            bits_read = 0\n            while bits_read < code_size and bit_pos < bit_len:\n                byte_pos = bit_pos // 8\n                bit_offset = bit_pos % 8\n                bits_left = 8 - bit_offset\n                bits_to_read = min(bits_left, code_size - bits_read)\n                mask = (1 << bits_to_read) - 1\n                bits = (data[byte_pos] >> bit_offset) & mask\n                code |= bits << bits_read\n                bits_read += bits_to_read\n                bit_pos += bits_to_read\n            if bits_read < code_size:\n                return None\n            return code\n    \n        result = bytearray()\n        prev_code = None\n        while True:\n            code = get_code()\n            if code is None:\n                break\n            if code == clear_code:\n                dictionary = {i: bytes([i]) for i in range(clear_code)}\n                dictionary[clear_code] = None\n                dictionary[end_code] = None\n                dict_size = end_code + 1\n                code_size = min_code_size + 1\n                max_code = (1 << code_size) - 1\n                prev_code = None\n                continue\n            if code == end_code:\n                break\n            if code in dictionary:\n                entry = dictionary[code]\n                if prev_code is not None:\n                    dictionary[dict_size] = dictionary[prev_code] + entry[:1]\n                    dict_size += 1\n            elif code == dict_size:\n                entry = dictionary[prev_code] + dictionary[prev_code][:1]\n                dictionary[dict_size] = entry\n                dict_size += 1\n            else:\n>               raise ValueError(\"Invalid LZW code\")\nE               ValueError: Invalid LZW code\n\ngeneration\\Imageio\\imageio\\v3.py:486: ValueError\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer", "stdout_sha1": "08fa4e4c86ddfaa96714f6d4044cf8c87df16a90", "stdout_len": 10192, "stdout": ".F.F..FFF.                                                               [100%]\n================================== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-337/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       loaded_frames = list(iio.imiter(path))\n\ntests\\Imageio\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:618: in imiter\n    arr = _read_gif(path)\ngeneration\\Imageio\\imageio\\v3.py:379: in _read_gif\n    frame_indices = _decode_lzw(bytes(compressed_data), min_code_size, w*h)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata = b'\\x00\\xaf\\x01(\\'\\xee\\xdc9\\x00\\xe0\\xb4q3\\xe7\\xad \\x00m\\xe2\\xcai;\\xa7\\x8d\\xd5\\xb5\\x8b\\xd7\\xcc\\x91\\x03\\xb0\\xa2\\\\ t\\xda\\x...7\\xa2\\xda\\x12j\\xeb\\xb8B\\xa6\\xb8\\x91\\x12C\\x9e\\xb3\\xb2b*:tg\\xf1Z9\\x87.\\x10\\x80@\\xe2\\xcc\\xad\\xf8\\x08\\xd3\\x9b\\xd0s\\x01\\x01'\nmin_code_size = 8, expected_size = 576\n\n    def _decode_lzw(data, min_code_size, expected_size):\n        # Minimal LZW decoder for GIF\n        # data: bytes of compressed data\n        # min_code_size: int\n        # expected_size: number of pixels expected in output\n        # Returns list of indices\n    \n        clear_code = 1 << min_code_size\n        end_code = clear_code + 1\n        code_size = min_code_size + 1\n        max_code = (1 << code_size) - 1\n    \n        # Initialize dictionary\n        dict_size = end_code + 1\n        dictionary = {i: bytes([i]) for i in range(clear_code)}\n        dictionary[clear_code] = None\n        dictionary[end_code] = None\n    \n        bit_pos = 0\n        bit_len = len(data) * 8\n    \n        def get_code():\n            nonlocal bit_pos\n            code = 0\n            bits_read = 0\n            while bits_read < code_size and bit_pos < bit_len:\n                byte_pos = bit_pos // 8\n                bit_offset = bit_pos % 8\n                bits_left = 8 - bit_offset\n                bits_to_read = min(bits_left, code_size - bits_read)\n                mask = (1 << bits_to_read) - 1\n                bits = (data[byte_pos] >> bit_offset) & mask\n                code |= bits << bits_read\n                bits_read += bits_to_read\n                bit_pos += bits_to_read\n            if bits_read < code_size:\n                return None\n            return code\n    \n        result = bytearray()\n        prev_code = None\n        while True:\n            code = get_code()\n            if code is None:\n                break\n            if code == clear_code:\n                dictionary = {i: bytes([i]) for i in range(clear_code)}\n                dictionary[clear_code] = None\n                dictionary[end_code] = None\n                dict_size = end_code + 1\n                code_size = min_code_size + 1\n                max_code = (1 << code_size) - 1\n                prev_code = None\n                continue\n            if code == end_code:\n                break\n            if code in dictionary:\n                entry = dictionary[code]\n                if prev_code is not None:\n                    dictionary[dict_size] = dictionary[prev_code] + entry[:1]\n                    dict_size += 1\n            elif code == dict_size:\n                entry = dictionary[prev_code] + dictionary[prev_code][:1]\n                dictionary[dict_size] = entry\n                dict_size += 1\n            else:\n>               raise ValueError(\"Invalid LZW code\")\nE               ValueError: Invalid LZW code\n\ngeneration\\Imageio\\imageio\\v3.py:486: ValueError\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-337/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       loaded = iio.imread(path)\n\ntests\\Imageio\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:602: in imread\n    arr = _read_gif(path)\ngeneration\\Imageio\\imageio\\v3.py:379: in _read_gif\n    frame_indices = _decode_lzw(bytes(compressed_data), min_code_size, w*h)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata = b\"\\x00\\xaf\\x01('\\xee\\xdc9\\x00\\xe0\\xb4q3\\xe7\\xad \\x00m\\xe2\\xcai;\\xa7\\x8d\\xd5\\xb5\\x8b\\xd7\\xcc\\x91\\x03\\xb0\\xa2\\\\ t\\xda\\x0...x1c\\x00\\x00V\\xac\\\\[\\xa1P\\xdb5\\x00\\xe6\\xac\\x00\\xf0V\\xce\\x9c\\xb8\\x15\\xdc\\xc0q\\xbbVN\\x1b+\\x95\\xe8\\xca%\\\\9\\xd0\\n9t\\x01\\x01\"\nmin_code_size = 8, expected_size = 420\n\n    def _decode_lzw(data, min_code_size, expected_size):\n        # Minimal LZW decoder for GIF\n        # data: bytes of compressed data\n        # min_code_size: int\n        # expected_size: number of pixels expected in output\n        # Returns list of indices\n    \n        clear_code = 1 << min_code_size\n        end_code = clear_code + 1\n        code_size = min_code_size + 1\n        max_code = (1 << code_size) - 1\n    \n        # Initialize dictionary\n        dict_size = end_code + 1\n        dictionary = {i: bytes([i]) for i in range(clear_code)}\n        dictionary[clear_code] = None\n        dictionary[end_code] = None\n    \n        bit_pos = 0\n        bit_len = len(data) * 8\n    \n        def get_code():\n            nonlocal bit_pos\n            code = 0\n            bits_read = 0\n            while bits_read < code_size and bit_pos < bit_len:\n                byte_pos = bit_pos // 8\n                bit_offset = bit_pos % 8\n                bits_left = 8 - bit_offset\n                bits_to_read = min(bits_left, code_size - bits_read)\n                mask = (1 << bits_to_read) - 1\n                bits = (data[byte_pos] >> bit_offset) & mask\n                code |= bits << bits_read\n                bits_read += bits_to_read\n                bit_pos += bits_to_read\n            if bits_read < code_size:\n                return None\n            return code\n    \n        result = bytearray()\n        prev_code = None\n        while True:\n            code = get_code()\n            if code is None:\n                break\n            if code == clear_code:\n                dictionary = {i: bytes([i]) for i in range(clear_code)}\n                dictionary[clear_code] = None\n                dictionary[end_code] = None\n                dict_size = end_code + 1\n                code_size = min_code_size + 1\n                max_code = (1 << code_size) - 1\n                prev_code = None\n                continue\n            if code == end_code:\n                break\n            if code in dictionary:\n                entry = dictionary[code]\n                if prev_code is not None:\n                    dictionary[dict_size] = dictionary[prev_code] + entry[:1]\n                    dict_size += 1\n            elif code == dict_size:\n                entry = dictionary[prev_code] + dictionary[prev_code][:1]\n                dictionary[dict_size] = entry\n                dict_size += 1\n            else:\n>               raise ValueError(\"Invalid LZW code\")\nE               ValueError: Invalid LZW code\n\ngeneration\\Imageio\\imageio\\v3.py:486: ValueError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-337/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-337/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_gif_multiframe_roundtrip_with_imiter\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n5 failed, 5 passed in 1.22s\n"}
{"model": "gpt-3.5-turbo", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "fit() got an unexpected keyword", "returncode": 1, "elapsed_time_s": 12.918572, "avg_memory_mb": 71.5, "avg_cpu_percent": 95.27, "passed": 2, "failed": 13, "skipped": 0, "total": 15, "functional_score": 0.1333, "timestamp": "2025-12-31 21:05:21", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724       NaN\\ntreatment  0.593058       NaN.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000001DF7FEFA730>()\nE        +    where <built-in method lower of str object at 0x000001DF7FEFA730> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x000001DF5D254670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x000001DF5D254670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724       NaN\\ntreatment  0.593058       NaN.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword ", "stdout_sha1": "76e48150204d4e1f54a533c04474fe0d5f299455", "stdout_len": 10771, "stdout": "FFFFFFFFF.FFFF.                                                          [100%]\n================================== FAILURES ===================================\n______________________ test_kmf_on_small_manual_dataset _______________________\n\n    def test_kmf_on_small_manual_dataset() -> None:\n        \"\"\"Basic sanity check for KaplanMeierFitter on a tiny dataset.\"\"\"\n        durations, events = _toy_kmf_data()\n    \n        kmf = KaplanMeierFitter()\n>       kmf.fit(durations=durations, event_observed=events, label=\"test\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:84: TypeError\n_________________________ test_kmf_on_waltons_groups __________________________\n\n    def test_kmf_on_waltons_groups() -> None:\n        \"\"\"Fit KMF on the Waltons dataset for two groups.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        control = df[df[\"group\"] == \"control\"]\n        treated = df[df[\"group\"] != \"control\"]\n    \n        kmf_control = KaplanMeierFitter()\n        kmf_treated = KaplanMeierFitter()\n    \n>       kmf_control.fit(control[\"T\"], control[\"E\"], label=\"control\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:105: TypeError\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724       NaN\\ntreatment  0.593058       NaN.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000001DF7FEFA730>()\nE        +    where <built-in method lower of str object at 0x000001DF7FEFA730> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x000001DF5D254670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x000001DF5D254670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724       NaN\\ntreatment  0.593058       NaN.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n____________________ test_kmf_predict_at_time_zero_is_one _____________________\n\n    def test_kmf_predict_at_time_zero_is_one() -> None:\n        \"\"\"KMF predict at t=0 should be 1.0 for standard KM survival.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:140: TypeError\n________________ test_kmf_predict_is_non_increasing_over_time _________________\n\n    def test_kmf_predict_is_non_increasing_over_time() -> None:\n        \"\"\"KMF predicted survival should not increase as time increases.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:148: TypeError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:169: TypeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:182: TypeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:191: TypeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n>       kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\nE       TypeError: fit() got an unexpected keyword argument 'label'\n\ntests\\Lifelines\\functional_test.py:204: TypeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x_low = pd.DataFrame({\"age\": [25], \"treatment\": [0]})\n        x_high = pd.DataFrame({\"age\": [55], \"treatment\": [1]})\n    \n>       h_low = float(cph.predict_partial_hazard(x_low).iloc[0])\nE       AttributeError: 'CoxPHFitter' object has no attribute 'predict_partial_hazard'\n\ntests\\Lifelines\\functional_test.py:240: AttributeError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x = pd.DataFrame({\"age\": [30, 60], \"treatment\": [0, 1]})\n>       sf = cph.predict_survival_function(x)\n\ntests\\Lifelines\\functional_test.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x000001DF603E0A90>\nrow =    age  treatment\n0   30          0\n1   60          1\n\n    def predict_survival_function(self, row):\n        if not self._fitted:\n            raise ValueError(\"Model must be fitted before prediction\")\n    \n        if not isinstance(row, pd.DataFrame):\n            raise ValueError(\"Input must be a single-row DataFrame\")\n    \n        if row.shape[0] != 1:\n>           raise ValueError(\"Input DataFrame must have exactly one row\")\nE           ValueError: Input DataFrame must have exactly one row\n\ngeneration\\Lifelines\\lifelines\\fitters.py:208: ValueError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n============================== warnings summary ===============================\ntests/Lifelines/functional_test.py::test_coxph_basic_fit\ntests/Lifelines/functional_test.py::test_coxph_params_index_matches_covariates\ntests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\ntests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\ntests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\ntests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\ntests/Lifelines/functional_test.py::test_coxph_fit_on_waltons_with_binary_group_feature\n  D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Lifelines\\lifelines\\fitters.py:169: RuntimeWarning: invalid value encountered in sqrt\n    se = np.sqrt(np.diag(cov_matrix))\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_small_manual_dataset\nFAILED tests/Lifelines/functional_test.py::test_kmf_on_waltons_groups - TypeE...\nFAILED tests/Lifelines/functional_test.py::test_coxph_basic_fit - AssertionEr...\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_at_time_zero_is_one\nFAILED tests/Lifelines/functional_test.py::test_kmf_predict_is_non_increasing_over_time\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\n13 failed, 2 passed, 7 warnings in 11.35s\n"}
{"model": "gpt-3.5-turbo", "project": "Loguru", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "remove() missing 1 required positional argument: 'handler_id'", "returncode": 1, "elapsed_time_s": 2.149362, "avg_memory_mb": 16.35, "avg_cpu_percent": 48.35, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 21:06:05", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "eda5e14088debff6b05ddfb0020f583f9aa645e0", "stdout_len": 9995, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} user={extra[user]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n__________________ test_multiple_sinks_receive_same_message ___________________\n\n    def test_multiple_sinks_receive_same_message() -> None:\n        buf1 = io.StringIO()\n        buf2 = io.StringIO()\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:161: TypeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-338/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:178: TypeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n>       log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n\ntests\\Loguru\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n>       log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n\ntests\\Loguru\\functional_test.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} patched={extra[patched]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n\ntests\\Loguru\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format() -> None:\n        # Default format should include some timestamp-like content, level, and message.\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handler_id'\n\ntests\\Loguru\\functional_test.py:237: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - Ty...\nFAILED tests/Loguru/functional_test.py::test_level_filtering - TypeError: rem...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Typ...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Type...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_multiple_sinks_receive_same_message\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Typ...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n11 failed in 0.75s\n"}
{"model": "gpt-3.5-turbo", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 3.028055, "avg_memory_mb": 35.36, "avg_cpu_percent": 69.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:06:48", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.61s\n", "stdout_sha1": "578c896f9b844997fee0cfa8a3f78d4ce0aa0eef", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.61s\n"}
{"model": "gpt-3.5-turbo", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 2.100564, "avg_memory_mb": 33.97, "avg_cpu_percent": 101.6, "passed": 7, "failed": 3, "skipped": 9, "total": 19, "functional_score": 0.3684, "timestamp": "2025-12-31 21:07:38", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-339/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n        markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n>       html = out_path.read_text(encoding=\"utf-8\")\n\ntests\\Markdown\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-339/test_markdown_from_file0/output.html')\nname = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-339\\\\test_markdown_from_file0\\\\output.html'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-339\\\\test_markdown_from_file0\\\\output.html'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_from_file - FileNotFo...\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.67s\n", "stdout_sha1": "07ea1ee7e5c0e83cb6b78ebb092cf584354a9573", "stdout_len": 3585, "stdout": "......F.FFsssssssss                                                      [100%]\n================================== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-339/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n        markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n>       html = out_path.read_text(encoding=\"utf-8\")\n\ntests\\Markdown\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-339/test_markdown_from_file0/output.html')\nname = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-339\\\\test_markdown_from_file0\\\\output.html'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-339\\\\test_markdown_from_file0\\\\output.html'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_from_file - FileNotFo...\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.67s\n"}
{"model": "gpt-3.5-turbo", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "FileNotFoundError", "exception_msg": "[Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'", "returncode": 1, "elapsed_time_s": 2.011988, "avg_memory_mb": 32.72, "avg_cpu_percent": 100.0, "passed": 4, "failed": 7, "skipped": 0, "total": 11, "functional_score": 0.3636, "timestamp": "2025-12-31 21:08:11", "stdout_excerpt": "==== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs", "stdout_sha1": "2a4020656e98c98734bba21948af54e6e6ad4709", "stdout_len": 7137, "stdout": "..FF.FF.FFF                                                              [100%]\n================================== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_003_version_source_file_exists_and_has_version_like_token\nFAILED tests/Mitmproxy/functional_test.py::test_004_tools_main_file_exists - ...\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_007_tools_main_defines_mitmdump_function_or_wrapper\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n7 failed, 4 passed in 0.72s\n"}
{"model": "gpt-3.5-turbo", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.47709, "avg_memory_mb": 30.91, "avg_cpu_percent": 98.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:09:24", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "gpt-3.5-turbo", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'DateTime' object has no attribute 'year'", "returncode": 1, "elapsed_time_s": 2.265535, "avg_memory_mb": 16.37, "avg_cpu_percent": 49.6, "passed": 0, "failed": 12, "skipped": 1, "total": 13, "functional_score": 0.0, "timestamp": "2025-12-31 21:10:20", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n>       assert dt_utc.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:68: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n>       base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4ab81490>\nyear = 2021, month = 3, day = 15, hour = 10, minute = 30, second = 0\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n>       start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4abd5b20>\nyear = 2011, month = 8, day = 1, hour = 0, minute = 0, second = 0\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n>       assert d.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:118: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n>       dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime", "stdout_sha1": "3d557a2dd79877d564c5f12cc8ff81c723f6bcbb", "stdout_len": 11900, "stdout": "FFFFFFFFFsFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n>       assert dt_utc.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:68: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n>       base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4ab81490>\nyear = 2021, month = 3, day = 15, hour = 10, minute = 30, second = 0\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n>       start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4abd5b20>\nyear = 2011, month = 8, day = 1, hour = 0, minute = 0, second = 0\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n>       assert d.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:118: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n>       dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4abf5ac0>\nyear = 2020, month = 1, day = 1, hour = 12, minute = 0, second = 0\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n>       dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:135: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4ab727f0>\nyear = 2021, month = 12, day = 31, hour = 23, minute = 59, second = 58\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n>       dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4ab742e0>\nyear = 2020, month = 5, day = 20, hour = 13, minute = 14, second = 15\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_________________ test_duration_total_seconds_and_components __________________\n\n    def test_duration_total_seconds_and_components() -> None:\n        \"\"\"Verify duration reports correct total seconds and has component attributes.\"\"\"\n        dur = pendulum.duration(days=1, hours=2, minutes=3, seconds=4)\n    \n        # Total seconds is the most stable cross-version contract.\n        assert dur.total_seconds() == 1 * 86400 + 2 * 3600 + 3 * 60 + 4\n    \n        # Component attributes commonly exist; assert them when present.\n>       assert dur.days == 1\nE       AttributeError: 'Duration' object has no attribute 'days'\n\ntests\\Pendulum\\functional_test.py:168: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n>       dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n\ntests\\Pendulum\\functional_test.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:168: in datetime\n    return DateTime.datetime(year, month, day, hour, minute, second, microsecond, tz)\ngeneration\\Pendulum\\pendulum\\datetime.py:61: in datetime\n    return cls(year, month, day, hour, minute, second, microsecond, tz)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError('_dt') raised in repr()] DateTime object at 0x19d4abe7550>\nyear = 2020, month = 6, day = 1, hour = 0, minute = 0, second = 0\nmicrosecond = 0, tz = 'UTC'\n\n    def __init__(self, year, month=1, day=1, hour=0, minute=0, second=0, microsecond=0, tz=None):\n        if tz is None:\n            tz = timezone(\"UTC\")\n        elif not isinstance(tz, Timezone):\n>           raise TypeError(\"tz must be a pendulum.timezone.Timezone instance or None\")\nE           TypeError: tz must be a pendulum.timezone.Timezone instance or None\n\ngeneration\\Pendulum\\pendulum\\datetime.py:15: TypeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_datetime_arithmetic_and_duration\nFAILED tests/Pendulum/functional_test.py::test_diff_for_humans_months - TypeE...\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - TypeErro...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_duration_total_seconds_and_components\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n12 failed, 1 skipped in 0.87s\n"}
{"model": "gpt-3.5-turbo", "project": "Petl", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "sort() got an unexpected keyword argument 'reverse'", "returncode": 1, "elapsed_time_s": 2.031247, "avg_memory_mb": 32.91, "avg_cpu_percent": 98.4, "passed": 3, "failed": 3, "skipped": 6, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 21:10:56", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:11: in __iter__\n    if self.predicate(row):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = (1, 10, None)\n\n>   table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\nE   TypeError: tuple indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:166: TypeError\n_______________________ test_join_two_tables_fromdicts ________________________\n\n    def test_join_two_tables_fromdicts() -> None:\n        \"\"\"Check that an inner join between two small tables behaves as expected.\"\"\"\n        customers = [\n            {\"id\": 1, \"name\": \"Alice\"},\n            {\"id\": 2, \"name\": \"Bob\"},\n            {\"id\": 3, \"name\": \"Carol\"},\n        ]\n        orders = [\n            {\"id\": 1, \"amount\": 100},\n            {\"id\": 1, \"amount\": 50},\n            {\"id\": 2, \"amount\": 200},\n        ]\n    \n        customers_tbl = petl.fromdicts(customers, header=[\"id\", \"name\"])\n        orders_tbl = petl.fromdicts(orders, header=[\"id\", \"amount\"])\n    \n        joined = petl.join(customers_tbl, orders_tbl, key=\"id\")\n        result = _table_to_list_of_dicts(joined)\n    \n>       assert len(result) == 3\nE       AssertionError: assert 4 == 3\nE        +  where 4 = len([{'amount': 100, 'id': 1, 'name': 'Alice'}, {'amount': 50, 'id': 1, 'name': 'Alice'}, {'amount': 200, 'id': 2, 'name': 'Bob'}, {'amount': None, 'id': 3, 'name': 'Carol'}])\n\ntests\\Petl\\functional_test.py:195: AssertionError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_join_two_tables_fromdicts - Assert...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n3 failed, 3 passed, 6 skipped in 0.68s\n", "stdout_sha1": "d9663982d728e390a5f6b178a8f34ae116c8bd51", "stdout_len": 3550, "stdout": ".FFss.Fs.sss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:11: in __iter__\n    if self.predicate(row):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = (1, 10, None)\n\n>   table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\nE   TypeError: tuple indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:166: TypeError\n_______________________ test_join_two_tables_fromdicts ________________________\n\n    def test_join_two_tables_fromdicts() -> None:\n        \"\"\"Check that an inner join between two small tables behaves as expected.\"\"\"\n        customers = [\n            {\"id\": 1, \"name\": \"Alice\"},\n            {\"id\": 2, \"name\": \"Bob\"},\n            {\"id\": 3, \"name\": \"Carol\"},\n        ]\n        orders = [\n            {\"id\": 1, \"amount\": 100},\n            {\"id\": 1, \"amount\": 50},\n            {\"id\": 2, \"amount\": 200},\n        ]\n    \n        customers_tbl = petl.fromdicts(customers, header=[\"id\", \"name\"])\n        orders_tbl = petl.fromdicts(orders, header=[\"id\", \"amount\"])\n    \n        joined = petl.join(customers_tbl, orders_tbl, key=\"id\")\n        result = _table_to_list_of_dicts(joined)\n    \n>       assert len(result) == 3\nE       AssertionError: assert 4 == 3\nE        +  where 4 = len([{'amount': 100, 'id': 1, 'name': 'Alice'}, {'amount': 50, 'id': 1, 'name': 'Alice'}, {'amount': 200, 'id': 2, 'name': 'Bob'}, {'amount': None, 'id': 3, 'name': 'Carol'}])\n\ntests\\Petl\\functional_test.py:195: AssertionError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_join_two_tables_fromdicts - Assert...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n3 failed, 3 passed, 6 skipped in 0.68s\n"}
{"model": "gpt-3.5-turbo", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.421177, "avg_memory_mb": 14.47, "avg_cpu_percent": 99.8, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:11:57", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n", "stdout_sha1": "3d43d73e26be0f48c50fe96012d3c4dcf351a1b9", "stdout_len": 1401, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n"}
{"model": "gpt-3.5-turbo", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 2.077523, "avg_memory_mb": 33.72, "avg_cpu_percent": 98.4, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 21:12:23", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported\")\nE           NotImplementedError: Only HS256 algorithm is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:34: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:43: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True).encode(\"utf-8\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000019309FD7940>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:43: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True).encode(\"utf", "stdout_sha1": "d99291f192fdd3364b8bdd55c3436225bef8dfde", "stdout_len": 6611, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported\")\nE           NotImplementedError: Only HS256 algorithm is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:34: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:43: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True).encode(\"utf-8\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000019309FD7940>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:43: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True).encode(\"utf-8\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000019309FED640>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.62s\n"}
{"model": "gpt-3.5-turbo", "project": "PyPDF", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'NoneType' object has no attribute 'get'", "returncode": 1, "elapsed_time_s": 25.576024, "avg_memory_mb": 33.55, "avg_cpu_percent": 0.56, "passed": 0, "failed": 11, "skipped": 1, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 21:13:32", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=3)\n    \n>       reader = PdfReader(str(pdf_path))\n\ntests\\PyPDF\\functional_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED2483C10>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n>       reader = PdfReader(str(pdf_path))\n\ntests\\PyPDF\\functional_test.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED2438F40>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n        _create_simple_pdf(pdf1, num_pages=1)\n        _create_simple_pdf(pdf2, num_pages=2)\n    \n>       _write_pdf_with_pages([pdf1, pdf2], merged)\n\ntests\\PyPDF\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:121: in _write_pdf_with_pages\n    reader = PdfReader(str(src))\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _", "stdout_sha1": "ec00b3b7564ea169b48c03ea30ab5361a7efab66", "stdout_len": 18209, "stdout": "FFFFFFFFFFsF                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=3)\n    \n>       reader = PdfReader(str(pdf_path))\n\ntests\\PyPDF\\functional_test.py:136: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED2483C10>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n        _create_simple_pdf(pdf_path, num_pages=1)\n    \n>       reader = PdfReader(str(pdf_path))\n\ntests\\PyPDF\\functional_test.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED2438F40>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n        _create_simple_pdf(pdf1, num_pages=1)\n        _create_simple_pdf(pdf2, num_pages=2)\n    \n>       _write_pdf_with_pages([pdf1, pdf2], merged)\n\ntests\\PyPDF\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:121: in _write_pdf_with_pages\n    reader = PdfReader(str(src))\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED24918E0>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n        _create_simple_pdf(src, num_pages=4)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED247F280>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n______________________________ test_rotate_page _______________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_rotate_page0')\n\n    def test_rotate_page(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        rotated = tmp_path / \"rotated.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED248E2B0>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n_______________________ test_rotate_preserves_page_size _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_rotate_preserves_page_siz0')\n\n    def test_rotate_preserves_page_size(tmp_path: Path) -> None:\n        \"\"\"Rotating a blank page should keep a valid mediabox size.\"\"\"\n        src = tmp_path / \"src_size.pdf\"\n        rotated = tmp_path / \"rot_size.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED248F1F0>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n__________________________ test_encrypt_and_decrypt ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_encrypt_and_decrypt0')\n\n    def test_encrypt_and_decrypt(tmp_path: Path) -> None:\n        src = tmp_path / \"plain.pdf\"\n        enc = tmp_path / \"encrypted.pdf\"\n        _create_simple_pdf(src, num_pages=2)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED25675E0>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n_____________ test_encrypted_pdf_allows_page_access_after_decrypt _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_encrypted_pdf_allows_page0')\n\n    def test_encrypted_pdf_allows_page_access_after_decrypt(tmp_path: Path) -> None:\n        \"\"\"After decrypting, basic page access should succeed and page size is valid.\"\"\"\n        src = tmp_path / \"plain2.pdf\"\n        enc = tmp_path / \"encrypted2.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:258: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED256A0D0>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n___________________________ test_metadata_roundtrip ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_metadata_roundtrip0')\n\n    def test_metadata_roundtrip(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"meta.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED248EE80>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n___________________ test_metadata_multiple_fields_roundtrip ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_metadata_multiple_fields_0')\n\n    def test_metadata_multiple_fields_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Add several info dict fields and ensure they can be read back.\"\"\"\n        src = tmp_path / \"src_info.pdf\"\n        dst = tmp_path / \"info.pdf\"\n        _create_simple_pdf(src, num_pages=1)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:308: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED2481B20>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n_________________ test_clone_document_by_writing_reader_pages _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-341/test_clone_document_by_writing0')\n\n    def test_clone_document_by_writing_reader_pages(tmp_path: Path) -> None:\n        \"\"\"Clone a document by copying pages and verify page count matches.\"\"\"\n        src = tmp_path / \"orig.pdf\"\n        dst = tmp_path / \"clone.pdf\"\n        _create_simple_pdf(src, num_pages=3)\n    \n>       reader = PdfReader(str(src))\n\ntests\\PyPDF\\functional_test.py:363: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\PyPDF\\pypdf\\_reader.py:22: in __init__\n    self._read_pdf()\ngeneration\\PyPDF\\pypdf\\_reader.py:44: in _read_pdf\n    self._build_pages()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._reader.PdfReader object at 0x0000018ED2592EB0>\n\n    def _build_pages(self):\n        # Recursively build pages list from /Pages tree\n        def _recurse_pages(node):\n            node = self._get_object(node)\n            if node is None:\n                return\n            t = node.get(b\"/Type\")\n            if t == b\"/Pages\":\n                kids = node.get(b\"/Kids\", [])\n                for kid in kids:\n                    _recurse_pages(kid)\n            elif t == b\"/Page\":\n                self._pages.append(PageObject(self, node))\n>       _recurse_pages(self._root.get(b\"/Pages\"))\nE       AttributeError: 'NoneType' object has no attribute 'get'\n\ngeneration\\PyPDF\\pypdf\\_reader.py:195: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyPDF/functional_test.py::test_create_and_read_blank_pdf - Attri...\nFAILED tests/PyPDF/functional_test.py::test_blank_page_has_expected_size - At...\nFAILED tests/PyPDF/functional_test.py::test_merge_two_pdfs - AttributeError: ...\nFAILED tests/PyPDF/functional_test.py::test_writer_add_page_preserves_page_count\nFAILED tests/PyPDF/functional_test.py::test_rotate_page - AttributeError: 'No...\nFAILED tests/PyPDF/functional_test.py::test_rotate_preserves_page_size - Attr...\nFAILED tests/PyPDF/functional_test.py::test_encrypt_and_decrypt - AttributeEr...\nFAILED tests/PyPDF/functional_test.py::test_encrypted_pdf_allows_page_access_after_decrypt\nFAILED tests/PyPDF/functional_test.py::test_metadata_roundtrip - AttributeErr...\nFAILED tests/PyPDF/functional_test.py::test_metadata_multiple_fields_roundtrip\nFAILED tests/PyPDF/functional_test.py::test_clone_document_by_writing_reader_pages\n11 failed, 1 skipped in 24.23s\n"}
{"model": "gpt-3.5-turbo", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.502683, "avg_memory_mb": 30.82, "avg_cpu_percent": 102.2, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:14:52", "stdout_excerpt": "\n1 skipped in 0.14s\n", "stdout_sha1": "95c5fda1107f8078c182653b3ba949fc343f3984", "stdout_len": 20, "stdout": "\n1 skipped in 0.14s\n"}
{"model": "gpt-3.5-turbo", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'schedule' has no attribute 'clear'", "returncode": 1, "elapsed_time_s": 1.995402, "avg_memory_mb": 32.43, "avg_cpu_percent": 99.2, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 21:15:27", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n>       _clear()\n\nt", "stdout_sha1": "6ab48d9f63e599c22240f451de876922c16047f4", "stdout_len": 7625, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:261: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_run_pending_executes_due_job_without_sleep\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_day_at_sets_time_component_in_next_run\nFAILED tests/Schedule/functional_test.py::test_weekday_scheduling_creates_job_and_next_run\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n12 failed in 0.66s\n"}
{"model": "gpt-3.5-turbo", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 1.957698, "avg_memory_mb": 34.77, "avg_cpu_percent": 97.4, "passed": 9, "failed": 3, "skipped": 0, "total": 12, "functional_score": 0.75, "timestamp": "2025-12-31 21:15:55", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_allow_unicode_true_preserves_non_ascii _________________\n\n    def test_allow_unicode_true_preserves_non_ascii() -> None:\n        \"\"\"When allow_unicode is True, unicode characters can be preserved.\"\"\"\n        text = \"影師嗎\"\n>       result = slugify(text, allow_unicode=True)\n\ntests\\Slugify\\functional_test.py:135: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Slugify\\slugify\\slugify.py:69: in slugify\n    pattern = re.compile(r'[^\\w\\s\\p{L}\\p{N}\\p{M}\\p{Pc}\\p{Pd}]', re.UNICODE)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:252: in compile\n    return _compile(pattern, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:304: in _compile\n    p = sre_compile.compile(pattern, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_compile.py:764: in compile\n    p = sre_parse.parse(p, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:948: in parse\n    p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:443: in _parse_sub\n    itemsappend(_parse(source, state, verbose, nested + 1,\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:554: in _parse\n    code1 = _class_escape(source, this)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsource = <sre_parse.Tokenizer object at 0x00000238DC5371C0>, escape = '\\\\p'\n\n    def _class_escape(source, escape):\n        # handle escape code inside character class\n        code = ESCAPES.get(escape)\n        if code:\n            return code\n        code = CATEGORIES.get(escape)\n        if code and code[0] is IN:\n            return code\n        try:\n            c = escape[1:2]\n            if c == \"x\":\n                # hexadecimal escape (exactly two digits)\n                escape += source.getwhile(2, HEXDIGITS)\n                if len(escape) != 4:\n                    raise source.error(\"incomplete escape %s\" % escape, len(escape))\n                return LITERAL, int(escape[2:], 16)\n            elif c == \"u\" and source.istext:\n                # unicode escape (exactly four digits)\n                escape += source.getwhile(4, HEXDIGITS)\n                if len(escape) != 6:\n                    raise source.error(\"incomplete escape %s\" % escape, len(escape))\n                return LITERAL, int(escape[2:], 16)\n            elif c == \"U\" and source.istext:\n                # unicode escape (exactly eight digits)\n                escape += source.getwhile(8, HEXDIGITS)\n                if len(escape) != 10:\n                    raise source.error(\"incomplete escape %s\" % escape, len(escape))\n                c = int(escape[2:], 16)\n                chr(c) # raise ValueError for invalid code\n                return LITERAL, c\n            elif c == \"N\" and source.istext:\n                import unicodedata\n                # named unicode escape e.g. \\N{EM DASH}\n                if not source.match('{'):\n                    raise source.error(\"missing {\")\n                charname = source.getuntil('}', 'character name')\n                try:\n                    c = ord(unicodedata.lookup(charname))\n                except KeyError:\n                    raise source.error(\"undefined character name %r\" % charname,\n                                       len(charname) + len(r'\\N{}'))\n                return LITERAL, c\n            elif c in OCTDIGITS:\n                # octal escape (up to three digits)\n                escape += source.getwhile(2, OCTDIGITS)\n                c = int(escape[1:], 8)\n                if c > 0o377:\n                    raise source.error('octal escape value %s outside of '\n                                       'range 0-0o377' % escape, len(escape))\n                return LITERAL, c\n            elif c in DIGITS:\n                raise ValueError\n            if len(escape) == 2:\n               ", "stdout_sha1": "742773b7a225ea4bc2a8c0db0e08b7982592a28f", "stdout_len": 7955, "stdout": "...F...F..F.                                                             [100%]\n================================== FAILURES ===================================\n_________________ test_allow_unicode_true_preserves_non_ascii _________________\n\n    def test_allow_unicode_true_preserves_non_ascii() -> None:\n        \"\"\"When allow_unicode is True, unicode characters can be preserved.\"\"\"\n        text = \"影師嗎\"\n>       result = slugify(text, allow_unicode=True)\n\ntests\\Slugify\\functional_test.py:135: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Slugify\\slugify\\slugify.py:69: in slugify\n    pattern = re.compile(r'[^\\w\\s\\p{L}\\p{N}\\p{M}\\p{Pc}\\p{Pd}]', re.UNICODE)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:252: in compile\n    return _compile(pattern, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\re.py:304: in _compile\n    p = sre_compile.compile(pattern, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_compile.py:764: in compile\n    p = sre_parse.parse(p, flags)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:948: in parse\n    p = _parse_sub(source, state, flags & SRE_FLAG_VERBOSE, 0)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:443: in _parse_sub\n    itemsappend(_parse(source, state, verbose, nested + 1,\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:554: in _parse\n    code1 = _class_escape(source, this)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsource = <sre_parse.Tokenizer object at 0x00000238DC5371C0>, escape = '\\\\p'\n\n    def _class_escape(source, escape):\n        # handle escape code inside character class\n        code = ESCAPES.get(escape)\n        if code:\n            return code\n        code = CATEGORIES.get(escape)\n        if code and code[0] is IN:\n            return code\n        try:\n            c = escape[1:2]\n            if c == \"x\":\n                # hexadecimal escape (exactly two digits)\n                escape += source.getwhile(2, HEXDIGITS)\n                if len(escape) != 4:\n                    raise source.error(\"incomplete escape %s\" % escape, len(escape))\n                return LITERAL, int(escape[2:], 16)\n            elif c == \"u\" and source.istext:\n                # unicode escape (exactly four digits)\n                escape += source.getwhile(4, HEXDIGITS)\n                if len(escape) != 6:\n                    raise source.error(\"incomplete escape %s\" % escape, len(escape))\n                return LITERAL, int(escape[2:], 16)\n            elif c == \"U\" and source.istext:\n                # unicode escape (exactly eight digits)\n                escape += source.getwhile(8, HEXDIGITS)\n                if len(escape) != 10:\n                    raise source.error(\"incomplete escape %s\" % escape, len(escape))\n                c = int(escape[2:], 16)\n                chr(c) # raise ValueError for invalid code\n                return LITERAL, c\n            elif c == \"N\" and source.istext:\n                import unicodedata\n                # named unicode escape e.g. \\N{EM DASH}\n                if not source.match('{'):\n                    raise source.error(\"missing {\")\n                charname = source.getuntil('}', 'character name')\n                try:\n                    c = ord(unicodedata.lookup(charname))\n                except KeyError:\n                    raise source.error(\"undefined character name %r\" % charname,\n                                       len(charname) + len(r'\\N{}'))\n                return LITERAL, c\n            elif c in OCTDIGITS:\n                # octal escape (up to three digits)\n                escape += source.getwhile(2, OCTDIGITS)\n                c = int(escape[1:], 8)\n                if c > 0o377:\n                    raise source.error('octal escape value %s outside of '\n                                       'range 0-0o377' % escape, len(escape))\n                return LITERAL, c\n            elif c in DIGITS:\n                raise ValueError\n            if len(escape) == 2:\n                if c in ASCIILETTERS:\n>                   raise source.error('bad escape %s' % escape, len(escape))\nE                   re.error: bad escape \\p at position 6\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\sre_parse.py:349: error\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x00000238D9704670>('___')\nE        +    where <built-in method startswith of str object at 0x00000238D9704670> = ''.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n___________________ test_replacements_apply_before_slugging ___________________\n\n    def test_replacements_apply_before_slugging() -> None:\n        \"\"\"replacements should transform substrings before final slug is produced.\"\"\"\n        text = \"C# is not C++\"\n>       result = slugify(text, replacements=[[\"C#\", \"Csharp\"], [\"C++\", \"Cpp\"]])\n\ntests\\Slugify\\functional_test.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'C# is not C++', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = [['C#', 'Csharp'], ['C++', 'Cpp']], kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate an ASCII-only slug or a unicode slug from the given text.\n    \n        Parameters\n        ----------\n        text : str\n            Text to slugify.\n        allow_unicode : bool, optional\n            Whether to allow unicode characters in the slug. Defaults to False.\n        max_length : int or None, optional\n            Maximum length of the slug. If set, slug will be truncated.\n        word_boundary : bool, optional\n            If True and max_length is set, truncate at the last separator before max_length.\n        separator : str, optional\n            Separator character to use in the slug. Defaults to '-'.\n        regex_pattern : str or None, optional\n            Custom regex pattern to filter characters. Defaults to None.\n        stopwords : iterable or None, optional\n            Words to exclude from the slug. Defaults to None.\n        lowercase : bool, optional\n            Whether to lowercase the slug. Defaults to True.\n        replacements : dict or None, optional\n            Custom replacements to apply before slugification. Defaults to None.\n        **kwargs\n            Additional keyword arguments (ignored).\n    \n        Returns\n        -------\n        str\n            The slugified string.\n        \"\"\"\n        if not isinstance(text, str):\n            text = str(text)\n    \n        # Apply custom replacements first\n        if replacements:\n>           for search, replace in replacements.items():\nE           AttributeError: 'list' object has no attribute 'items'\n\ngeneration\\Slugify\\slugify\\slugify.py:52: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_allow_unicode_true_preserves_non_ascii\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_replacements_apply_before_slugging\n3 failed, 9 passed in 0.59s\n"}
{"model": "gpt-3.5-turbo", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "+    where <function search at 0x000001C3E9FD99D0> = re.search", "returncode": 1, "elapsed_time_s": 3.146505, "avg_memory_mb": 31.95, "avg_cpu_percent": 52.3, "passed": 8, "failed": 1, "skipped": 0, "total": 9, "functional_score": 0.8889, "timestamp": "2025-12-31 21:16:31", "stdout_excerpt": "==== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000001C3E9FD99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-h] [-hh] [--version] [-u url] [-p param]\\n                 [--level {1,2,3,4,5}] [--risk {1,2,3}]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x000001C3E9FD99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\n1 failed, 8 passed in 1.89s\n", "stdout_sha1": "5bfde7feade406413e06fbfb70c3d9bc85aaf6d6", "stdout_len": 1529, "stdout": "....F....                                                                [100%]\n================================== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x000001C3E9FD99D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-h] [-hh] [--version] [-u url] [-p param]\\n                 [--level {1,2,3,4,5}] [--risk {1,2,3}]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x000001C3E9FD99D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\n1 failed, 8 passed in 1.89s\n"}
{"model": "gpt-3.5-turbo", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "'function' object has no attribute 'clear'", "returncode": 2, "elapsed_time_s": 1.876263, "avg_memory_mb": 36.03, "avg_cpu_percent": 100.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:17:17", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: 'function' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: 'function' object h...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.57s\n", "stdout_sha1": "d5aaffdb93c84a78cb13031cd3ff6de0a7dde96f", "stdout_len": 562, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: 'function' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: 'function' object h...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.57s\n"}
{"model": "gpt-3.5-turbo", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute 'mode'", "returncode": 1, "elapsed_time_s": 23.515338, "avg_memory_mb": 36.02, "avg_cpu_percent": 0.81, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 21:18:30", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image: Image.Image, message: str, generator: Optional[Iterator[int]] = None, shift: int = 0,\n             encoding: str = \"UTF-8\", auto_convert_rgb: bool = False) -> Image.Image:\n        \"\"\"\n        Hide a message in the least significant bits of an image.\n    \n        :param image: PIL Image to hide message in\n        :param message: message string to hide\n        :param generator: optional generator of pixel indices to use for hiding bits\n        :param shift: bit shift for LSB (0 means least significant bit)\n        :param encoding: encoding for message string\n        :param auto_convert_rgb: if True, convert image to RGB if not already\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\", \"L\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:20: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x00000178C4ED4430>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image: Image.Image, message: str, generator: Optional[Iterator[int]] = None, shift: int = 0,\n             encoding: str = \"UTF-8\", auto_convert_rgb: bool = False) -> Image.Image:\n        \"\"\"\n        Hide a message in the least significant bits of an image.\n    \n        :param image: PIL Image to hide message in\n        :param message: message string to hide\n        :param generator: optional generator of pixel indices to use for hiding bits\n        :param shift: bit shift for LSB (0 means least significant bit)\n        :param encoding: encoding for message string\n        :param auto_convert_rgb: if True, convert image to RGB if not already\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\", \"L\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:20: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n", "stdout_sha1": "f032a5bf3ddba014fba8e9c8c06a016aeee150ab", "stdout_len": 15213, "stdout": "FFFFFFFF...F                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image: Image.Image, message: str, generator: Optional[Iterator[int]] = None, shift: int = 0,\n             encoding: str = \"UTF-8\", auto_convert_rgb: bool = False) -> Image.Image:\n        \"\"\"\n        Hide a message in the least significant bits of an image.\n    \n        :param image: PIL Image to hide message in\n        :param message: message string to hide\n        :param generator: optional generator of pixel indices to use for hiding bits\n        :param shift: bit shift for LSB (0 means least significant bit)\n        :param encoding: encoding for message string\n        :param auto_convert_rgb: if True, convert image to RGB if not already\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\", \"L\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:20: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x00000178C4ED4430>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image: Image.Image, message: str, generator: Optional[Iterator[int]] = None, shift: int = 0,\n             encoding: str = \"UTF-8\", auto_convert_rgb: bool = False) -> Image.Image:\n        \"\"\"\n        Hide a message in the least significant bits of an image.\n    \n        :param image: PIL Image to hide message in\n        :param message: message string to hide\n        :param generator: optional generator of pixel indices to use for hiding bits\n        :param shift: bit shift for LSB (0 means least significant bit)\n        :param encoding: encoding for message string\n        :param auto_convert_rgb: if True, convert image to RGB if not already\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\", \"L\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:20: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'This is a longer secret message with punctuation: 12345, hello-world!'\ngenerator = None, shift = 0, encoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image: Image.Image, message: str, generator: Optional[Iterator[int]] = None, shift: int = 0,\n             encoding: str = \"UTF-8\", auto_convert_rgb: bool = False) -> Image.Image:\n        \"\"\"\n        Hide a message in the least significant bits of an image.\n    \n        :param image: PIL Image to hide message in\n        :param message: message string to hide\n        :param generator: optional generator of pixel indices to use for hiding bits\n        :param shift: bit shift for LSB (0 means least significant bit)\n        :param encoding: encoding for message string\n        :param auto_convert_rgb: if True, convert image to RGB if not already\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\", \"L\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:20: AttributeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n>       img_obj = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'object input', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image: Image.Image, message: str, generator: Optional[Iterator[int]] = None, shift: int = 0,\n             encoding: str = \"UTF-8\", auto_convert_rgb: bool = False) -> Image.Image:\n        \"\"\"\n        Hide a message in the least significant bits of an image.\n    \n        :param image: PIL Image to hide message in\n        :param message: message string to hide\n        :param generator: optional generator of pixel indices to use for hiding bits\n        :param shift: bit shift for LSB (0 means least significant bit)\n        :param encoding: encoding for message string\n        :param auto_convert_rgb: if True, convert image to RGB if not already\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\", \"L\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:20: AttributeError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'red secret'\n\n    def hide(image: Image.Image, message: str) -> Image.Image:\n        \"\"\"\n        Hide a message in the red channel of an RGB image using LSB steganography.\n    \n        :param image: PIL Image (must be RGB)\n        :param message: message string to hide\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\red\\red.py:12: AttributeError\n________________ test_red_hide_and_reveal_extended_latin_text _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_red_hide_and_reveal_exten0')\n\n    def test_red_hide_and_reveal_extended_latin_text(tmp_path: Path) -> None:\n        \"\"\"Red backend stores per-char ord() into a byte channel; Latin-1 chars like 'é' are valid.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"Café au lait\"\n        output = tmp_path / \"red_latin.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'Café au lait'\n\n    def hide(image: Image.Image, message: str) -> Image.Image:\n        \"\"\"\n        Hide a message in the red channel of an RGB image using LSB steganography.\n    \n        :param image: PIL Image (must be RGB)\n        :param message: message string to hide\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\red\\red.py:12: AttributeError\n_______________________ test_exif_hide_and_reveal_bytes _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_exif_hide_and_reveal_byte0')\n\n    def test_exif_hide_and_reveal_bytes(tmp_path: Path) -> None:\n        \"\"\"exifHeader.hide writes output file, exifHeader.reveal returns original bytes.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = b\"exif secret bytes\"\n        output = tmp_path / \"exif_out.jpg\"\n    \n        exifHeader.hide(str(EXIF_JPEG), str(output), secret_message=secret)\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n>       revealed = exifHeader.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-345\\\\test_exif_hide_and_reveal_byte0\\\\exif_out.jpg'\n\n    def reveal(image: Image.Image) -> bytes:\n        \"\"\"\n        Reveal a hidden byte message from the EXIF UserComment tag of a PIL Image.\n    \n        :param image: PIL Image object\n        :return: extracted byte message\n        \"\"\"\n>       if \"exif\" not in image.info:\nE       AttributeError: 'str' object has no attribute 'info'\n\ngeneration\\Stegano\\stegano\\exifHeader\\exifHeader.py:48: AttributeError\n_____________ test_exif_hide_two_outputs_with_different_payloads ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_exif_hide_two_outputs_wit0')\n\n    def test_exif_hide_two_outputs_with_different_payloads(tmp_path: Path) -> None:\n        \"\"\"Write two different EXIF-hidden files (two independent happy-path scenarios).\"\"\"\n        _ensure_image_samples_exist()\n    \n        out1 = tmp_path / \"exif_one.jpg\"\n        out2 = tmp_path / \"exif_two.jpg\"\n    \n        secret1 = b\"payload-one\"\n        secret2 = b\"payload-two\"\n    \n        exifHeader.hide(str(EXIF_JPEG), str(out1), secret_message=secret1)\n        exifHeader.hide(str(EXIF_JPEG), str(out2), secret_message=secret2)\n    \n        assert out1.exists() and out1.stat().st_size > 0\n        assert out2.exists() and out2.stat().st_size > 0\n    \n>       assert exifHeader.reveal(str(out1)) == secret1\n\ntests\\Stegano\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-345\\\\test_exif_hide_two_outputs_wit0\\\\exif_one.jpg'\n\n    def reveal(image: Image.Image) -> bytes:\n        \"\"\"\n        Reveal a hidden byte message from the EXIF UserComment tag of a PIL Image.\n    \n        :param image: PIL Image object\n        :return: extracted byte message\n        \"\"\"\n>       if \"exif\" not in image.info:\nE       AttributeError: 'str' object has no attribute 'info'\n\ngeneration\\Stegano\\stegano\\exifHeader\\exifHeader.py:48: AttributeError\n_____________________ test_lsb_and_red_outputs_are_files ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-345/test_lsb_and_red_outputs_are_f0')\n\n    def test_lsb_and_red_outputs_are_files(tmp_path: Path) -> None:\n        \"\"\"Ensure image-encoding backends produce files that can be written to disk.\"\"\"\n        _ensure_image_samples_exist()\n    \n        out_lsb = tmp_path / \"lsb_file.png\"\n        out_red = tmp_path / \"red_file.png\"\n    \n>       lsb.hide(str(LENNA_PNG), \"x\").save(str(out_lsb))\n\ntests\\Stegano\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'x', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image: Image.Image, message: str, generator: Optional[Iterator[int]] = None, shift: int = 0,\n             encoding: str = \"UTF-8\", auto_convert_rgb: bool = False) -> Image.Image:\n        \"\"\"\n        Hide a message in the least significant bits of an image.\n    \n        :param image: PIL Image to hide message in\n        :param message: message string to hide\n        :param generator: optional generator of pixel indices to use for hiding bits\n        :param shift: bit shift for LSB (0 means least significant bit)\n        :param encoding: encoding for message string\n        :param auto_convert_rgb: if True, convert image to RGB if not already\n        :return: new PIL Image with message hidden\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\", \"L\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:20: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_extended_latin_text\nFAILED tests/Stegano/functional_test.py::test_exif_hide_and_reveal_bytes - At...\nFAILED tests/Stegano/functional_test.py::test_exif_hide_two_outputs_with_different_payloads\nFAILED tests/Stegano/functional_test.py::test_lsb_and_red_outputs_are_files\n9 failed, 3 passed in 2.48s\n"}
{"model": "gpt-3.5-turbo", "project": "Tablib", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)", "returncode": 2, "elapsed_time_s": 1.987721, "avg_memory_mb": 35.07, "avg_cpu_percent": 98.4, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:18:56", "stdout_excerpt": "====\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:1: in <module>\n    from .core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:4: in <module>\n    from .formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_csv.py:4: in <module>\n    from ..core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.68s\n", "stdout_sha1": "5aede6d64900f05194f6a6d3cccb49c2d03b2ad8", "stdout_len": 1296, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:1: in <module>\n    from .core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:4: in <module>\n    from .formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_csv.py:4: in <module>\n    from ..core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.68s\n"}
{"model": "gpt-3.5-turbo", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "ValueError", "exception_msg": "Unknown table format: github", "returncode": 1, "elapsed_time_s": 1.973214, "avg_memory_mb": 33.1, "avg_cpu_percent": 99.1, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 21:19:52", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:414: in tabulate\n    return formatter(tabular_data, headers=headers, colalign=colalign)\ngeneration\\Tabulate\\tabulate\\core.py:252: in _format_plain\n    widths, colalign = _column_widths(table, headers, colalign)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]], headers = 'firstrow'\ncolalign = None\n\n    def _column_widths(table, headers, colalign):\n        \"\"\"\n        Calculate max width of each column considering multiline cells.\n        \"\"\"\n        ncols = len(table[0]) if table else (len(headers) if headers else 0)\n        widths = [0] * ncols\n    \n        # Consider headers\n        if headers:\n            for i, h in enumerate(headers):\n                lines = _split_multiline(_stringify(h))\n                maxw = max(len(line) for line in lines)\n>               if maxw > widths[i]:\nE               IndexError: list index out of range\n\ngeneration\\Tabulate\\tabulate\\core.py:99: IndexError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n>       out_true = tabulate(table, showindex=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'showindex'\n\ntests\\Tabulate\\functional_test.py:151: TypeError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['spam', 42], ['eggs', 451], ['bacon', 0]]\nheaders = ['item', 'qty'], tablefmt = 'github', colalign = None\n\n    def tabulate(tabular_data, headers=None, tablefmt=\"simple\", colalign=None):\n        \"\"\"\n        Format tabular data (list of lists, list of dicts, dict) into a string table.\n    \n        Parameters:\n        - tabular_data: data to format\n        - headers: list of headers or None\n        - tablefmt: format name or callable\n        - colalign: list of alignments per column (\"left\", \"right\", \"center\")\n    \n        Returns:\n        - formatted string\n        \"\"\"\n        if callable(tablefmt):\n            return tablefmt(tabular_data, headers=headers, colalign=colalign)\n        fmt = tablefmt.lower()\n        if fmt == \"simple\":\n            fmt = \"plain\"\n        if fmt not in _table_formats:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: github\n\ngeneration\\Tabulate\\tabulate\\core.py:412: ValueError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            ", "stdout_sha1": "d87c2174c1763fe7da8eef92847ef12cda05a519", "stdout_len": 7260, "stdout": "..FFFFFFFFF.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tabulate\\tabulate\\core.py:414: in tabulate\n    return formatter(tabular_data, headers=headers, colalign=colalign)\ngeneration\\Tabulate\\tabulate\\core.py:252: in _format_plain\n    widths, colalign = _column_widths(table, headers, colalign)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]], headers = 'firstrow'\ncolalign = None\n\n    def _column_widths(table, headers, colalign):\n        \"\"\"\n        Calculate max width of each column considering multiline cells.\n        \"\"\"\n        ncols = len(table[0]) if table else (len(headers) if headers else 0)\n        widths = [0] * ncols\n    \n        # Consider headers\n        if headers:\n            for i, h in enumerate(headers):\n                lines = _split_multiline(_stringify(h))\n                maxw = max(len(line) for line in lines)\n>               if maxw > widths[i]:\nE               IndexError: list index out of range\n\ngeneration\\Tabulate\\tabulate\\core.py:99: IndexError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n>       out_true = tabulate(table, showindex=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'showindex'\n\ntests\\Tabulate\\functional_test.py:151: TypeError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['spam', 42], ['eggs', 451], ['bacon', 0]]\nheaders = ['item', 'qty'], tablefmt = 'github', colalign = None\n\n    def tabulate(tabular_data, headers=None, tablefmt=\"simple\", colalign=None):\n        \"\"\"\n        Format tabular data (list of lists, list of dicts, dict) into a string table.\n    \n        Parameters:\n        - tabular_data: data to format\n        - headers: list of headers or None\n        - tablefmt: format name or callable\n        - colalign: list of alignments per column (\"left\", \"right\", \"center\")\n    \n        Returns:\n        - formatted string\n        \"\"\"\n        if callable(tablefmt):\n            return tablefmt(tabular_data, headers=headers, colalign=colalign)\n        fmt = tablefmt.lower()\n        if fmt == \"simple\":\n            fmt = \"plain\"\n        if fmt not in _table_formats:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: github\n\ngeneration\\Tabulate\\tabulate\\core.py:412: ValueError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            {\"name\": \"Alice\", \"score\": 10},\n            {\"name\": \"Bob\", \"score\": 12},\n        ]\n        output = tabulate(rows, headers=\"keys\", tablefmt=\"plain\")\n        lines = _lines(output)\n    \n        header = lines[0]\n>       assert \"name\" in header\nE       AssertionError: assert 'name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:194: AssertionError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\nE       TypeError: tabulate() got an unexpected keyword argument 'missingval'\n\ntests\\Tabulate\\functional_test.py:207: TypeError\n__________________ test_floatfmt_controls_numeric_rendering ___________________\n\n    def test_floatfmt_controls_numeric_rendering() -> None:\n        rows = [\n            [\"pi\", 3.14159],\n            [\"e\", 2.71828],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"value\"], tablefmt=\"plain\", floatfmt=\".2f\")\nE       TypeError: tabulate() got an unexpected keyword argument 'floatfmt'\n\ntests\\Tabulate\\functional_test.py:222: TypeError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - TypeError...\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\nFAILED tests/Tabulate/functional_test.py::test_list_of_dicts_headers_keys_plain\nFAILED tests/Tabulate/functional_test.py::test_missingval_renders_placeholder\nFAILED tests/Tabulate/functional_test.py::test_floatfmt_controls_numeric_rendering\nFAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n9 failed, 3 passed in 0.61s\n"}
{"model": "gpt-3.5-turbo", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for +=: 'int' and 'str'", "returncode": 1, "elapsed_time_s": 51.960732, "avg_memory_mb": 33.26, "avg_cpu_percent": 0.33, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 21:21:17", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000202858A4E80>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x00000202858A8FA0>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020285900B80>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x0000020285900B20>\n\n    def draw(self):\n        # Only horizontal stacked bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # sum values per item (stacked)\n        sums = []\n        n_items = self.data.num_items()\n        n_series = self.data.num_series()\n        for i in range(n_items):\n            s = 0\n            for series in self.data.data:\n                if i < len(series):\n>                   s += series[i]\nE                   TypeError: unsupported operand type(s) for +=: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:102: TypeError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020285898040>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>", "stdout_sha1": "2b1253885e71012006586988906826843c422f4d", "stdout_len": 20249, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000202858A4E80>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x00000202858A8FA0>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020285900B80>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x0000020285900B20>\n\n    def draw(self):\n        # Only horizontal stacked bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # sum values per item (stacked)\n        sums = []\n        n_items = self.data.num_items()\n        n_series = self.data.num_series()\n        for i in range(n_items):\n            s = 0\n            for series in self.data.data:\n                if i < len(series):\n>                   s += series[i]\nE                   TypeError: unsupported operand type(s) for +=: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:102: TypeError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020285898040>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000020285898AC0>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020283E00C10>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000020285871AF0>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020285923CA0>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Labels\", width=10, no_labels=True, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000020285923D60>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000202858A4550>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Suffix\", width=18, suffix=\"%\", format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x00000202858A4190>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000202859115E0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Fmt\", width=20, format=\"{:>6.2f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x00000202859114C0>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020285859EB0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack Labels\", width=25, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x00000202858597C0>\n\n    def draw(self):\n        # Only horizontal stacked bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # sum values per item (stacked)\n        sums = []\n        n_items = self.data.num_items()\n        n_series = self.data.num_series()\n        for i in range(n_items):\n            s = 0\n            for series in self.data.data:\n                if i < len(series):\n>                   s += series[i]\nE                   TypeError: unsupported operand type(s) for +=: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:102: TypeError\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000202858921F0>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack No Values\", width=30, no_values=True, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.StackedChart object at 0x00000202858922E0>\n\n    def draw(self):\n        # Only horizontal stacked bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # sum values per item (stacked)\n        sums = []\n        n_items = self.data.num_items()\n        n_series = self.data.num_series()\n        for i in range(n_items):\n            s = 0\n            for series in self.data.data:\n                if i < len(series):\n>                   s += series[i]\nE                   TypeError: unsupported operand type(s) for +=: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:102: TypeError\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000202858FF2E0>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=None, width=15, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x00000202858FF970>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x0000020285912130>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x0000020285912F70>\n\n    def draw(self):\n        # Only horizontal bar charts supported\n        if self.args.vertical:\n            print(\"Vertical charts not supported in this implementation.\", file=sys.stderr)\n            return\n    \n        labels = self.args.labels if self.args.labels is not None else self.data.labels\n        if labels is None:\n            labels = [''] * self.data.num_items()\n    \n        max_label_len = max((len(str(label)) for label in labels), default=0)\n        max_label_len = min(max_label_len, 20)  # limit label width\n    \n        max_width = self.args.width\n        format_str = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n    \n        # For bar length scaling\n        max_val = 0\n        for series in self.data.data:\n            for val in series:\n>               if val > max_val:\nE               TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:31: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 25.89s\n"}
{"model": "gpt-3.5-turbo", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 2.103612, "avg_memory_mb": 32.79, "avg_cpu_percent": 95.3, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 21:22:00", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "ef6b568f77745357b0b5c5ab7f37d3f7334058eb", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-346/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-346/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-346/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x000001D3C73E1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.81s\n"}
{"model": "gpt-3.5-turbo", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 2.022345, "avg_memory_mb": 35.99, "avg_cpu_percent": 99.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:22:39", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n", "stdout_sha1": "a8559e885e2b486a88b02e9cadfbdc30b4b61c98", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n"}
{"model": "gpt-3.5-turbo", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'Result' object has no attribute 'stdout'", "returncode": 1, "elapsed_time_s": 1.915471, "avg_memory_mb": 32.4, "avg_cpu_percent": 99.2, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 21:23:22", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n        assert r.exit_code == 0\n>       assert \"No tasks.\" in r.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:224: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n        assert r1.exit_code == 0\n>       assert \"Added: Write tests\" in r1.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:234: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x0000014EA7172E20>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n>       out = result.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:265: AttributeError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\"", "stdout_sha1": "e1aa2ce3e4878cbf99f50e538a75394e692aa4ea", "stdout_len": 8529, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n        assert r.exit_code == 0\n>       assert \"No tasks.\" in r.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:224: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n        assert r1.exit_code == 0\n>       assert \"Added: Write tests\" in r1.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:234: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x0000014EA7172E20>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n>       out = result.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:265: AttributeError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n>       out = result.stdout\nE       AttributeError: 'Result' object has no attribute 'stdout'\n\ntests\\Typer\\functional_test.py:275: AttributeError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000014EA71D16D0>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:159: AttributeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n>       app = _create_types_app()\n\ntests\\Typer\\functional_test.py:310: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_types_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"calc\" exists as a subcommand.\n        Covers typed arguments and a float option.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def calc(x: int, y: int, scale: float = typer.Option(1.0, \"--scale\")) -> None:\nE       TypeError: __init__() takes from 1 to 2 positional arguments but 3 were given\n\ntests\\Typer\\functional_test.py:181: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AttributeE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - At...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_list_empty_shows_no_tasks - ...\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - AttributeErro...\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_help_output_includes_commands - A...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n12 failed in 0.62s\n"}
{"model": "gpt-3.5-turbo", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Observer' from 'watchdog.observers' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\observers\\__init__.py)", "returncode": 2, "elapsed_time_s": 2.077284, "avg_memory_mb": 36.51, "avg_cpu_percent": 97.6, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 21:23:48", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:54: in <module>\n    from watchdog.observers import Observer  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Observer' from 'watchdog.observers' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\observers\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n", "stdout_sha1": "14687d1041874c711a5a0baccf1a8f2e00b7a462", "stdout_len": 1022, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:54: in <module>\n    from watchdog.observers import Observer  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Observer' from 'watchdog.observers' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\observers\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n"}
{"model": "gpt-3.5-turbo", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert {'#text': '1'} == '1'", "returncode": 1, "elapsed_time_s": 1.964426, "avg_memory_mb": 33.75, "avg_cpu_percent": 100.0, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 21:24:21", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n>       assert any(k.startswith(\"x:\") for k in keys)\nE       assert False\nE        +  where False = any(<generator object test_namespace_prefix_is_preserved.<locals>.<genexpr> at 0x0000024685E12BA0>)\n\ntests\\Xmltodict\\functional_test.py:131: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n            assert isinstance(item, list)\n            assert item == [\"1\"]\n        else:\n            # Fallback: without force_list support, single element is typically a scalar string.\n>           assert item == \"1\"\nE           AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:169: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n            assert \"@id\" not in user\n            assert user[\"name\"] == \"Alice\"\n        else:\n            # Fallback: attri", "stdout_sha1": "abc6e9d8fc04790c2ab88fc51369c2a440ceab91", "stdout_len": 7566, "stdout": "FF..FFF.FFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n>       assert any(k.startswith(\"x:\") for k in keys)\nE       assert False\nE        +  where False = any(<generator object test_namespace_prefix_is_preserved.<locals>.<genexpr> at 0x0000024685E12BA0>)\n\ntests\\Xmltodict\\functional_test.py:131: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n            assert isinstance(item, list)\n            assert item == [\"1\"]\n        else:\n            # Fallback: without force_list support, single element is typically a scalar string.\n>           assert item == \"1\"\nE           AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:169: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n            assert \"@id\" not in user\n            assert user[\"name\"] == \"Alice\"\n        else:\n            # Fallback: attribute is included in typical default behavior.\n            assert user.get(\"@id\") == \"9\"\n>           assert user[\"name\"] == \"Alice\"\nE           AssertionError: assert {'#text': 'Alice'} == 'Alice'\n\ntests\\Xmltodict\\functional_test.py:201: AssertionError\n______________________ test_dict_constructor_ordereddict ______________________\n\n    def test_dict_constructor_ordereddict() -> None:\n        \"\"\"dict_constructor should allow choosing mapping type (e.g., OrderedDict) when supported.\"\"\"\n        xml = \"<root><a>1</a><b>2</b></root>\"\n        data = _parse(xml, dict_constructor=OrderedDict)\n    \n        if \"dict_constructor\" in _PARSE_PARAMS:\n            assert isinstance(data, OrderedDict)\n            assert isinstance(data[\"root\"], OrderedDict)\n        else:\n            assert isinstance(data, dict)\n    \n>       assert data[\"root\"][\"a\"] == \"1\"\nE       AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:215: AssertionError\n_____________________ test_unparse_pretty_and_parse_back ______________________\n\n    def test_unparse_pretty_and_parse_back() -> None:\n        \"\"\"Pretty/full_document knobs should not break roundtrip of basic structure.\"\"\"\n        original: Dict[str, Any] = {\"root\": {\"x\": \"1\", \"y\": \"2\"}}\n    \n        xml = _unparse(original, pretty=True, full_document=True)\n        assert \"<root>\" in xml or \"<root\" in xml\n    \n        round_tripped = _parse(xml)\n>       assert round_tripped == original\nE       AssertionError: assert {'root': {'x'...#text': '2'}}} == {'root': {'x': '1', 'y': '2'}}\nE         \nE         Differing items:\nE         {'root': {'x': {'#text': '1'}, 'y': {'#text': '2'}}} != {'root': {'x': '1', 'y': '2'}}\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:227: AssertionError\n______________ test_postprocessor_transforms_value_if_supported _______________\n\n    def test_postprocessor_transforms_value_if_supported() -> None:\n        \"\"\"postprocessor can transform values in a happy-path parse when supported.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n    \n        def _pp(path: Any, key: str, value: Any) -> Any:\n            if key == \"message\" and isinstance(value, str):\n                return key, value.upper()\n            return key, value\n    \n        data = _parse(xml, postprocessor=_pp)\n    \n        if \"postprocessor\" in _PARSE_PARAMS:\n            assert data[\"root\"][\"message\"] == \"HELLO\"\n        else:\n>           assert data[\"root\"][\"message\"] == \"Hello\"\nE           AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:244: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_parse_simple_element - Assert...\nFAILED tests/Xmltodict/functional_test.py::test_parse_repeated_elements_as_list\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\nFAILED tests/Xmltodict/functional_test.py::test_parse_nested_structure - Asse...\nFAILED tests/Xmltodict/functional_test.py::test_force_list_option_for_single_element\nFAILED tests/Xmltodict/functional_test.py::test_xml_attribs_false_drops_attributes_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_dict_constructor_ordereddict\nFAILED tests/Xmltodict/functional_test.py::test_unparse_pretty_and_parse_back\nFAILED tests/Xmltodict/functional_test.py::test_postprocessor_transforms_value_if_supported\n9 failed, 3 passed in 0.65s\n"}
{"model": "gpt-4-turbo", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "update() got an unexpected keyword argument 'task_always_eager'", "returncode": 1, "elapsed_time_s": 28.727656, "avg_memory_mb": 32.29, "avg_cpu_percent": 0.61, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2026-01-01 13:17:39", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            r", "stdout_sha1": "fabc5606b03fb6356a01cb0d2223cf8718f4c7cf", "stdout_len": 13248, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n>       app = _make_app(\"celery_test_app_2\")\n\ntests\\Celery\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app_2'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() got an unexpected keyword argument 'task_always_eager'\n\ntests\\Celery\\functional_test.py:41: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.46s\n"}
{"model": "gpt-4-turbo", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "__init__() got multiple values for argument 'callback'", "returncode": 1, "elapsed_time_s": 4.195898, "avg_memory_mb": 32.94, "avg_cpu_percent": 99.2, "passed": 1, "failed": 10, "skipped": 0, "total": 11, "functional_score": 0.0909, "timestamp": "2026-01-01 13:17:52", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n        def greet(count: int, name: str) -> None:\n            for _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n        runner = CliRunner()\n        result = runner.invoke(greet, [\"--count\", \"3\", \"World\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x00000219D1C48F40>.exit_code\n\ntests\\Click\\functional_test.py:143: AssertionError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 2 == 0\nE        +  where 2 = <click.testing.Result object at 0x00000219D1CA7A60>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:12: in decorator\n    grp = Group(name=name or f.__name__, callback=f, **attrs)\ngeneration\\Click\\click\\decorators.py:54: in __init__\n    orig_init(self, *args, callback=callback, params=params, **kwargs)\ngeneration\\Click\\click\\core.py:283: in __init__\n    super().__init__(name, callback, params, help, short_help, context_settings)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Group object at 0x00000219D1C202B0>, callback = None\nparams = None\nargs = ('cli', <function test_group_with_subcommands.<locals>.cli at 0x00000219D1C90AF0>, None, None, None, None)\nkwargs = {}\n\n    def __init__(self, *args, callback=None, params=None, **kwargs):\n        if callback and hasattr(callback, \"__click_params__\"):\n            params = list(callback.__click_params__) + (params or [])\n>       orig_init(self, *args, callback=callback, params=params, **kwargs)\nE       TypeError: __init__() got multiple values for argument 'callback'\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:12: in decorator\n    grp = Group(name=name or f.__name__, callback=f, **attrs)\ngeneration\\Click\\click\\decorators.py:54: in __init__\n    orig_init(self, *args, callback=callback, params=params, **kwargs)\ngeneration\\Click\\click\\core.py:283: in __init__\n    super().__init__(name, callback, params, help, short_help, context_settings)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Group object at 0x00000219D1C197F0>, callback = None\nparams = None\nargs = ('cli', <function test_help_output_for_command_and_group.<locals>.cli at 0x00000219D1C90CA0>, None, 'Top level group', None, None)\nkwargs = {}\n\n    def __init__(self, *args, callback=None, params=None, **kwargs):\n        if callback and hasattr(callback, \"__click_params__\"):\n            params = list(callback.__click_params__) + (params or [])\n>       orig_init(self, *args, callback=callback, params=params, **kwargs)\nE       TypeError: __init__() got multiple values for argument 'callback'\n", "stdout_sha1": "247a012bef4f2d7ae784b8a499c2a2feea625b1b", "stdout_len": 10768, "stdout": "FFFFFFFFF.F                                                              [100%]\n================================== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n        @click.option(\"--count\", \"-c\", type=int, default=1)\n        @click.argument(\"name\")\n        def greet(count: int, name: str) -> None:\n            for _ in range(count):\n                click.echo(f\"Hello {name}!\")\n    \n        runner = CliRunner()\n        result = runner.invoke(greet, [\"--count\", \"3\", \"World\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x00000219D1C48F40>.exit_code\n\ntests\\Click\\functional_test.py:143: AssertionError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 2 == 0\nE        +  where 2 = <click.testing.Result object at 0x00000219D1CA7A60>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:12: in decorator\n    grp = Group(name=name or f.__name__, callback=f, **attrs)\ngeneration\\Click\\click\\decorators.py:54: in __init__\n    orig_init(self, *args, callback=callback, params=params, **kwargs)\ngeneration\\Click\\click\\core.py:283: in __init__\n    super().__init__(name, callback, params, help, short_help, context_settings)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Group object at 0x00000219D1C202B0>, callback = None\nparams = None\nargs = ('cli', <function test_group_with_subcommands.<locals>.cli at 0x00000219D1C90AF0>, None, None, None, None)\nkwargs = {}\n\n    def __init__(self, *args, callback=None, params=None, **kwargs):\n        if callback and hasattr(callback, \"__click_params__\"):\n            params = list(callback.__click_params__) + (params or [])\n>       orig_init(self, *args, callback=callback, params=params, **kwargs)\nE       TypeError: __init__() got multiple values for argument 'callback'\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:12: in decorator\n    grp = Group(name=name or f.__name__, callback=f, **attrs)\ngeneration\\Click\\click\\decorators.py:54: in __init__\n    orig_init(self, *args, callback=callback, params=params, **kwargs)\ngeneration\\Click\\click\\core.py:283: in __init__\n    super().__init__(name, callback, params, help, short_help, context_settings)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Group object at 0x00000219D1C197F0>, callback = None\nparams = None\nargs = ('cli', <function test_help_output_for_command_and_group.<locals>.cli at 0x00000219D1C90CA0>, None, 'Top level group', None, None)\nkwargs = {}\n\n    def __init__(self, *args, callback=None, params=None, **kwargs):\n        if callback and hasattr(callback, \"__click_params__\"):\n            params = list(callback.__click_params__) + (params or [])\n>       orig_init(self, *args, callback=callback, params=params, **kwargs)\nE       TypeError: __init__() got multiple values for argument 'callback'\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:12: in decorator\n    grp = Group(name=name or f.__name__, callback=f, **attrs)\ngeneration\\Click\\click\\decorators.py:54: in __init__\n    orig_init(self, *args, callback=callback, params=params, **kwargs)\ngeneration\\Click\\click\\core.py:283: in __init__\n    super().__init__(name, callback, params, help, short_help, context_settings)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Group object at 0x00000219D1D1F820>, callback = None\nparams = None\nargs = ('cli', <function test_get_current_context_propagation.<locals>.cli at 0x00000219D1C90DC0>, [<click.core.Option object at 0x00000219D1D1FAC0>], None, None, None)\nkwargs = {}\n\n    def __init__(self, *args, callback=None, params=None, **kwargs):\n        if callback and hasattr(callback, \"__click_params__\"):\n            params = list(callback.__click_params__) + (params or [])\n>       orig_init(self, *args, callback=callback, params=params, **kwargs)\nE       TypeError: __init__() got multiple values for argument 'callback'\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert result.exit_code != 0\n>       assert isinstance(result.exception, CustomError)\nE       AssertionError: assert False\nE        +  where False = isinstance(None, <class 'functional_test.test_command_exception_is_exposed_in_result.<locals>.CustomError'>)\nE        +    where None = <click.testing.Result object at 0x00000219D1CDBAF0>.exception\n\ntests\\Click\\functional_test.py:251: AssertionError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n>       def cli(name: str) -> None:\n\ntests\\Click\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:33: in decorator\n    param = Option(name=name, opts=opts, **attrs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x00000219D1CD17F0>, name = 'name'\nopts = ['--name'], kwargs = {'default': 'fallback', 'envvar': 'CLICK_TEST_NAME'}\n\n    def __init__(self, name, opts, **kwargs):\n>       super().__init__(name, param_type_name=\"option\", opts=opts, **kwargs)\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ngeneration\\Click\\click\\core.py:142: TypeError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n        assert r.exit_code == 0\n>       assert \"TOKEN=secret-token\" in r.output\nE       AssertionError: assert 'TOKEN=secret-token' in 'TOKEN=None\\n'\nE        +  where 'TOKEN=None\\n' = <click.testing.Result object at 0x00000219D1CDB550>.output\n\ntests\\Click\\functional_test.py:286: AssertionError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n>       def cli() -> None:\n\ntests\\Click\\functional_test.py:291: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:12: in decorator\n    grp = Group(name=name or f.__name__, callback=f, **attrs)\ngeneration\\Click\\click\\decorators.py:54: in __init__\n    orig_init(self, *args, callback=callback, params=params, **kwargs)\ngeneration\\Click\\click\\core.py:283: in __init__\n    super().__init__(name, callback, params, help, short_help, context_settings)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Group object at 0x00000219D1C9D310>, callback = None\nparams = None\nargs = ('cli', <function test_default_map_provides_default_option_value.<locals>.cli at 0x00000219D1CE6550>, None, None, None, None)\nkwargs = {}\n\n    def __init__(self, *args, callback=None, params=None, **kwargs):\n        if callback and hasattr(callback, \"__click_params__\"):\n            params = list(callback.__click_params__) + (params or [])\n>       orig_init(self, *args, callback=callback, params=params, **kwargs)\nE       TypeError: __init__() got multiple values for argument 'callback'\n\ngeneration\\Click\\click\\decorators.py:54: TypeError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - TypeErro...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_command_exception_is_exposed_in_result\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - T...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n10 failed, 1 passed in 3.10s\n"}
{"model": "gpt-4-turbo", "project": "Dataset", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "sqlite3.OperationalError: unable to open database file", "returncode": 1, "elapsed_time_s": 4.198321, "avg_memory_mb": 33.38, "avg_cpu_percent": 99.2, "passed": 2, "failed": 9, "skipped": 0, "total": 11, "functional_score": 0.1818, "timestamp": "2026-01-01 13:18:18", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n           ", "stdout_sha1": "98f0a912870bdb0d50e0d561a473ee3c6158ba20", "stdout_len": 10860, "stdout": "FF.FFFFFF.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:243: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n_______________________ test_delete_and_clear_all_rows ________________________\n\n    def test_delete_and_clear_all_rows() -> None:\n        \"\"\"\n        Older dataset.Table may not expose truncate().\n        Clear a table and end at 0 rows without relying on result iteration for DML.\n        \"\"\"\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nurl = 'sqlite:///:memory:'\n\n    def connect(url):\n        \"\"\"\n        Connect to a database. Only supports sqlite:// URLs.\n        \"\"\"\n        if url.startswith(_SQLITE_PREFIX):\n            path = url[len(_SQLITE_PREFIX):]\n            if path == \":memory:\":\n                conn = sqlite3.connect(\":memory:\", check_same_thread=False, isolation_level=None)\n            else:\n>               conn = sqlite3.connect(path, check_same_thread=False, isolation_level=None)\nE               sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:17: OperationalError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - sql...\nFAILED tests/Dataset/functional_test.py::test_insert_many_returns_ids_and_count\nFAILED tests/Dataset/functional_test.py::test_find_one_missing_returns_none\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_table_all_iteration_and_row_shape\nFAILED tests/Dataset/functional_test.py::test_delete_and_clear_all_rows - sql...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n9 failed, 2 passed in 3.10s\n"}
{"model": "gpt-4-turbo", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:18:34", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "gpt-4-turbo", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('failregex' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...match in re.findall(regex, line):\\n            if isvalidip(match):\\n                ips.append(match)\\n    return ips' or '<host>' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...match in re.findall(regex, line):\\n            if isvalidip(match):\\n                ips.append(match)\\n    return ips')", "returncode": 1, "elapsed_time_s": 1.999526, "avg_memory_mb": 32.14, "avg_cpu_percent": 75.2, "passed": 9, "failed": 3, "skipped": 0, "total": 12, "functional_score": 0.75, "timestamp": "2026-01-01 13:18:46", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...match in re.findall(regex, line):\\n            if isvalidip(match):\\n                ips.append(match)\\n    return ips' or '<host>' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...match in re.findall(regex, line):\\n            if isvalidip(match):\\n                ips.append(match)\\n    return ips')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.", "stdout_sha1": "eddc8215dc5e8a8f402aaad17cc4a524d4c0d70f", "stdout_len": 5441, "stdout": "...F....F..F                                                             [100%]\n================================== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...match in re.findall(regex, line):\\n            if isvalidip(match):\\n                ips.append(match)\\n    return ips' or '<host>' in 'import re\\nimport ipaddress\\n\\ndef isvalidip(ip):\\n    \"\"\"check if the given string is a valid ipv4 or ipv6 address.\"...match in re.findall(regex, line):\\n            if isvalidip(match):\\n                ips.append(match)\\n    return ips')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n>           assert (\"line\" in out) or (\"lines\" in out)\nE           AssertionError: assert ('line' in 'failed password for invalid user root from 203.0.113.5 port 2222 ssh2\\nfailed password for invalid user admin from 203.0.113.5 port 2223 ssh2\\nfailed password for invalid user test from 203.0.113.9 port 4444 ssh2\\ntotal matches: 3\\n\\n' or 'lines' in 'failed password for invalid user root from 203.0.113.5 port 2222 ssh2\\nfailed password for invalid user admin from 203.0.113.5 port 2223 ssh2\\nfailed password for invalid user test from 203.0.113.9 port 4444 ssh2\\ntotal matches: 3\\n\\n')\n\ntests\\Fail2ban\\functional_test.py:246: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n3 failed, 9 passed in 0.87s\n"}
{"model": "gpt-4-turbo", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ImportError", "exception_msg": "canno", "returncode": 1, "elapsed_time_s": 1.667757, "avg_memory_mb": 32.6, "avg_cpu_percent": 98.0, "passed": 1, "failed": 11, "skipped": 0, "total": 12, "functional_score": 0.0833, "timestamp": "2026-01-01 13:18:56", "stdout_excerpt": "==== FAILURES ===================================\n___________________________ test_001_import_folium ____________________________\n\n    def test_001_import_folium():\n        _prepend_import_path()\n>       import folium  # noqa: F401\n\ntests\\Folium\\functional_test.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:44: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:53: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: canno", "stdout_sha1": "2beccb4e2e65b86db4de396d7b2d2ee9033fc5a6", "stdout_len": 11494, "stdout": ".FFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n___________________________ test_001_import_folium ____________________________\n\n    def test_001_import_folium():\n        _prepend_import_path()\n>       import folium  # noqa: F401\n\ntests\\Folium\\functional_test.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:44: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:53: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-419/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:149: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n______________ test_010_plugins_markercluster_module_importable _______________\n\n    def test_010_plugins_markercluster_module_importable():\n        _prepend_import_path()\n>       plugins = _plugins_module()\n\ntests\\Folium\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Folium\\functional_test.py:29: in _plugins_module\n    return importlib.import_module(\"folium.plugins\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n>       import folium\n\ntests\\Folium\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\__init__.py:1: in <module>\n    from .map import Map\ngeneration\\Folium\\folium\\map.py:4: in <module>\n    from .tilelayer import TileLayer\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   from .map import MacroElement\nE   ImportError: cannot import name 'MacroElement' from partially initialized module 'folium.map' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\map.py)\n\ngeneration\\Folium\\folium\\tilelayer.py:1: ImportError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_001_import_folium - ImportError:...\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root - ImportEr...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Impor...\nFAILED tests/Folium/functional_test.py::test_010_plugins_markercluster_module_importable\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n11 failed, 1 passed in 0.58s\n"}
{"model": "gpt-4-turbo", "project": "Imageio", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "module 'imageio.v3' has no attribute 'imopen'", "returncode": 1, "elapsed_time_s": 1.948488, "avg_memory_mb": 46.06, "avg_cpu_percent": 99.2, "passed": 6, "failed": 4, "skipped": 0, "total": 10, "functional_score": 0.6, "timestamp": "2026-01-01 13:19:31", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-422/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape[0] == frames.shape[0]\nE       assert 20 == 5\n\ntests\\Imageio\\functional_test.py:194: AssertionError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-422/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-422/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n4 failed, 6 passed in 0.80s\n", "stdout_sha1": "9e7c09614d880cd92d28b6e1a9426a894a364d53", "stdout_len": 3212, "stdout": "...F..FFF.                                                               [100%]\n================================== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-422/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n        loaded = iio.imread(path)\n        assert isinstance(loaded, np.ndarray)\n>       assert loaded.shape[0] == frames.shape[0]\nE       assert 20 == 5\n\ntests\\Imageio\\functional_test.py:194: AssertionError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-422/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-422/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n4 failed, 6 passed in 0.80s\n"}
{"model": "gpt-4-turbo", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'KaplanMeierFitter' object has no attribute 'event_table'", "returncode": 1, "elapsed_time_s": 45.326034, "avg_memory_mb": 72.48, "avg_cpu_percent": 0.54, "passed": 4, "failed": 11, "skipped": 0, "total": 15, "functional_score": 0.2667, "timestamp": "2026-01-01 13:20:28", "stdout_excerpt": "==== FAILURES ===================================\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n>       cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20D98AF0>\ndf =    duration  event  age  treatment\n0         5      1   30          0\n1         6      0   40          0\n2         6  ... 60          1\n5         3      0   35          0\n6         8      1   45          1\n7         7      1   55          0\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (8,) and (8,2,2) not aligned: 8 (dim 0) != 2 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_d", "stdout_sha1": "1c4d33c5c7f6074e4914f94e33cef734a8239670", "stdout_len": 22175, "stdout": "..F..FFFFFFFFFF                                                          [100%]\n================================== FAILURES ===================================\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n>       cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20D98AF0>\ndf =    duration  event  age  treatment\n0         5      1   30          0\n1         6      0   40          0\n2         6  ... 60          1\n5         3      0   35          0\n6         8      1   45          1\n7         7      1   55          0\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (8,) and (8,2,2) not aligned: 8 (dim 0) != 2 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n_________________ test_coxph_params_index_matches_covariates __________________\n\n    def test_coxph_params_index_matches_covariates() -> None:\n        \"\"\"Cox model params_ should be indexed by covariate names.\"\"\"\n        df = _toy_cox_df()\n>       cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20DCC8B0>\ndf =    duration  event  age  treatment\n0         5      1   30          0\n1         6      0   40          0\n2         6  ... 60          1\n5         3      0   35          0\n6         8      1   45          1\n7         7      1   55          0\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (8,) and (8,2,2) not aligned: 8 (dim 0) != 2 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n>       cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20E53820>\ndf =    duration  event  age  treatment\n0         5      1   30          0\n1         6      0   40          0\n2         6  ... 60          1\n5         3      0   35          0\n6         8      1   45          1\n7         7      1   55          0\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (8,) and (8,2,2) not aligned: 8 (dim 0) != 2 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n>       cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20E58880>\ndf =    duration  event  age  treatment\n0         5      1   30          0\n1         6      0   40          0\n2         6  ... 60          1\n5         3      0   35          0\n6         8      1   45          1\n7         7      1   55          0\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (8,) and (8,2,2) not aligned: 8 (dim 0) != 2 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n>       cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:251: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20E511C0>\ndf =    duration  event  age  treatment\n0         5      1   30          0\n1         6      0   40          0\n2         6  ... 60          1\n5         3      0   35          0\n6         8      1   45          1\n7         7      1   55          0\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (8,) and (8,2,2) not aligned: 8 (dim 0) != 2 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n>       cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20E72BE0>\ndf =    duration  event  age  treatment\n0         5      1   30          0\n1         6      0   40          0\n2         6  ... 60          1\n5         3      0   35          0\n6         8      1   45          1\n7         7      1   55          0\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (8,) and (8,2,2) not aligned: 8 (dim 0) != 2 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n_____________ test_coxph_fit_on_waltons_with_binary_group_feature _____________\n\n    def test_coxph_fit_on_waltons_with_binary_group_feature() -> None:\n        \"\"\"Fit CoxPH on Waltons dataset using a binary treated indicator derived from group.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        df2 = df.copy()\n        df2[\"treated\"] = (df2[\"group\"] != \"control\").astype(int)\n    \n        model_df = df2[[\"T\", \"E\", \"treated\"]].rename(columns={\"T\": \"duration\", \"E\": \"event\"})\n    \n        cph = CoxPHFitter()\n>       cph.fit(model_df, duration_col=\"duration\", event_col=\"event\")\n\ntests\\Lifelines\\functional_test.py:284: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.fitters.CoxPHFitter object at 0x0000018B20E886A0>\ndf =     duration  event  treated\n0          6      1        0\n1          6      1        0\n2          6      1        0\n3 ...  1\n15        17      1        1\n16        19      1        1\n17        25      1        1\n18        32      0        1\nduration_col = 'duration', event_col = 'event', show_progress = False\n\n    def fit(self, df, duration_col, event_col, show_progress=False):\n        # Only numeric covariates supported\n        X = df.drop([duration_col, event_col], axis=1)\n        X = X.astype(float)\n        T = df[duration_col].values\n        E = df[event_col].values.astype(int)\n        n, p = X.shape\n        self._X_cols = list(X.columns)\n        # Sort by time ascending\n        order = np.argsort(T)\n        T = T[order]\n        E = E[order]\n        X = X.values[order, :]\n    \n        # Newton-Raphson for partial likelihood\n        beta = np.zeros(p)\n        max_iter = 50\n        tol = 1e-7\n        for it in range(max_iter):\n            risk_scores = np.exp(np.dot(X, beta))\n            # For each subject, compute risk set sum\n            # Breslow: for each event time, sum over those at risk\n            # Compute log-likelihood, gradient, Hessian\n            loglik = 0.0\n            grad = np.zeros(p)\n            hess = np.zeros((p, p))\n            for i in range(n):\n                if E[i] == 1:\n                    xi = X[i]\n                    ti = T[i]\n                    at_risk = (T >= ti)\n                    rs_sum = np.sum(risk_scores[at_risk])\n                    loglik += np.dot(beta, xi) - np.log(rs_sum)\n                    grad += xi - np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    xbar = np.dot(risk_scores[at_risk], X[at_risk]) / rs_sum\n                    x2bar = np.dot(risk_scores[at_risk], X[at_risk]**2) / rs_sum\n                    hess -= np.outer(xbar, xbar)\n>                   hess += np.dot(risk_scores[at_risk], X[at_risk][:, :, None] * X[at_risk][:, None, :]) / rs_sum\nE                   ValueError: shapes (19,) and (19,1,1) not aligned: 19 (dim 0) != 1 (dim 1)\n\ngeneration\\Lifelines\\lifelines\\fitters.py:142: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_coxph_basic_fit - ValueError:...\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_params_index_matches_covariates\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\nFAILED tests/Lifelines/functional_test.py::test_coxph_fit_on_waltons_with_binary_group_feature\n11 failed, 4 passed in 22.47s\n"}
{"model": "gpt-4-turbo", "project": "Loguru", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "remove() missing 1 required positional argument: 'handle'", "returncode": 1, "elapsed_time_s": 1.584654, "avg_memory_mb": 32.41, "avg_cpu_percent": 98.9, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 13:20:38", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "ff5d24849c7c41afb578c90e5bf44f09448e471d", "stdout_len": 9951, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} user={extra[user]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n__________________ test_multiple_sinks_receive_same_message ___________________\n\n    def test_multiple_sinks_receive_same_message() -> None:\n        buf1 = io.StringIO()\n        buf2 = io.StringIO()\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:161: TypeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-423/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:178: TypeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n>       log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n\ntests\\Loguru\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n>       log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n\ntests\\Loguru\\functional_test.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} patched={extra[patched]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n\ntests\\Loguru\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format() -> None:\n        # Default format should include some timestamp-like content, level, and message.\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'handle'\n\ntests\\Loguru\\functional_test.py:237: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - Ty...\nFAILED tests/Loguru/functional_test.py::test_level_filtering - TypeError: rem...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Typ...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Type...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_multiple_sinks_receive_same_message\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Typ...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n11 failed in 0.49s\n"}
{"model": "gpt-4-turbo", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 1.573819, "avg_memory_mb": 35.59, "avg_cpu_percent": 98.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:20:50", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.44s\n", "stdout_sha1": "c2315ab5683b055e9f8ff2d3f325157b4bef67e4", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.44s\n"}
{"model": "gpt-4-turbo", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p><p>---</p><p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 1.77874, "avg_memory_mb": 34.16, "avg_cpu_percent": 98.1, "passed": 7, "failed": 3, "skipped": 9, "total": 19, "functional_score": 0.3684, "timestamp": "2026-01-01 13:21:01", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<b>\" in norm\n>       assert \"literal &lt;b&gt; tag in code block\" in norm\nE       AssertionError: assert 'literal &lt;b&gt; tag in code block' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p><pre><code>literal <b> tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:210: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-424/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n        markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n>       html = out_path.read_text(encoding=\"utf-8\")\n\ntests\\Markdown\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-424/test_markdown_from_file0/output.html')\nname = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-424\\\\test_markdown_from_file0\\\\output.html'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-424\\\\test_markdown_from_file0\\\\output.html'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p><p>---</p><p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_from_file - FileNotFo...\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.51s\n", "stdout_sha1": "790bd7960052102cee0ce786820d9a1bcab94fb0", "stdout_len": 3666, "stdout": "......F.FFsssssssss                                                      [100%]\n================================== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<b>\" in norm\n>       assert \"literal &lt;b&gt; tag in code block\" in norm\nE       AssertionError: assert 'literal &lt;b&gt; tag in code block' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p><pre><code>literal <b> tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:210: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-424/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n        markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n>       html = out_path.read_text(encoding=\"utf-8\")\n\ntests\\Markdown\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-424/test_markdown_from_file0/output.html')\nname = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-424\\\\test_markdown_from_file0\\\\output.html'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-424\\\\test_markdown_from_file0\\\\output.html'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p><p>---</p><p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_from_file - FileNotFo...\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n3 failed, 7 passed, 9 skipped in 0.51s\n"}
{"model": "gpt-4-turbo", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "FileNotFoundError", "exception_msg": "[Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'", "returncode": 1, "elapsed_time_s": 1.848219, "avg_memory_mb": 33.44, "avg_cpu_percent": 97.3, "passed": 4, "failed": 7, "skipped": 0, "total": 11, "functional_score": 0.3636, "timestamp": "2026-01-01 13:21:12", "stdout_excerpt": "==== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs", "stdout_sha1": "21d5179116fa69ce00a6feef3dd1e9a13fe1793d", "stdout_len": 7137, "stdout": "..FF.FF.FFF                                                              [100%]\n================================== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_003_version_source_file_exists_and_has_version_like_token\nFAILED tests/Mitmproxy/functional_test.py::test_004_tools_main_file_exists - ...\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_007_tools_main_defines_mitmdump_function_or_wrapper\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n7 failed, 4 passed in 0.52s\n"}
{"model": "gpt-4-turbo", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.361181, "avg_memory_mb": 31.46, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:21:23", "stdout_excerpt": "\n1 skipped in 0.11s\n", "stdout_sha1": "75923eec7092d4a8427af710fe49bcf2a0b64e5b", "stdout_len": 20, "stdout": "\n1 skipped in 0.11s\n"}
{"model": "gpt-4-turbo", "project": "Pendulum", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.554255, "avg_memory_mb": 30.84, "avg_cpu_percent": 102.2, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:21:36", "stdout_excerpt": "\n1 skipped in 0.13s\n", "stdout_sha1": "4c4ceb412a81fcf19d92b45ee51d2d9a1553d8c3", "stdout_len": 20, "stdout": "\n1 skipped in 0.13s\n"}
{"model": "gpt-4-turbo", "project": "Petl", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "sort() got an unexpected keyword argument 'reverse'", "returncode": 1, "elapsed_time_s": 1.760136, "avg_memory_mb": 32.61, "avg_cpu_percent": 99.0, "passed": 3, "failed": 3, "skipped": 6, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 13:21:48", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:10: in __iter__\n    for row in it:\ngeneration\\Petl\\petl\\transform\\conversions.py:64: in __iter__\n    new_value = self.func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = (1, 10)\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: tuple indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_______________________ test_join_two_tables_fromdicts ________________________\n\n    def test_join_two_tables_fromdicts() -> None:\n        \"\"\"Check that an inner join between two small tables behaves as expected.\"\"\"\n        customers = [\n            {\"id\": 1, \"name\": \"Alice\"},\n            {\"id\": 2, \"name\": \"Bob\"},\n            {\"id\": 3, \"name\": \"Carol\"},\n        ]\n        orders = [\n            {\"id\": 1, \"amount\": 100},\n            {\"id\": 1, \"amount\": 50},\n            {\"id\": 2, \"amount\": 200},\n        ]\n    \n        customers_tbl = petl.fromdicts(customers, header=[\"id\", \"name\"])\n        orders_tbl = petl.fromdicts(orders, header=[\"id\", \"amount\"])\n    \n        joined = petl.join(customers_tbl, orders_tbl, key=\"id\")\n        result = _table_to_list_of_dicts(joined)\n    \n>       assert len(result) == 3\nE       AssertionError: assert 2 == 3\nE        +  where 2 = len([{'amount': 50, 'id': 1, 'name': 'Alice'}, {'amount': 200, 'id': 2, 'name': 'Bob'}])\n\ntests\\Petl\\functional_test.py:195: AssertionError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_join_two_tables_fromdicts - Assert...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n3 failed, 3 passed, 6 skipped in 0.50s\n", "stdout_sha1": "4497723cd23c3ff4949649f04541b31a3b426d5d", "stdout_len": 3550, "stdout": ".FFss.Fs.sss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:10: in __iter__\n    for row in it:\ngeneration\\Petl\\petl\\transform\\conversions.py:64: in __iter__\n    new_value = self.func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = (1, 10)\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: tuple indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_______________________ test_join_two_tables_fromdicts ________________________\n\n    def test_join_two_tables_fromdicts() -> None:\n        \"\"\"Check that an inner join between two small tables behaves as expected.\"\"\"\n        customers = [\n            {\"id\": 1, \"name\": \"Alice\"},\n            {\"id\": 2, \"name\": \"Bob\"},\n            {\"id\": 3, \"name\": \"Carol\"},\n        ]\n        orders = [\n            {\"id\": 1, \"amount\": 100},\n            {\"id\": 1, \"amount\": 50},\n            {\"id\": 2, \"amount\": 200},\n        ]\n    \n        customers_tbl = petl.fromdicts(customers, header=[\"id\", \"name\"])\n        orders_tbl = petl.fromdicts(orders, header=[\"id\", \"amount\"])\n    \n        joined = petl.join(customers_tbl, orders_tbl, key=\"id\")\n        result = _table_to_list_of_dicts(joined)\n    \n>       assert len(result) == 3\nE       AssertionError: assert 2 == 3\nE        +  where 2 = len([{'amount': 50, 'id': 1, 'name': 'Alice'}, {'amount': 200, 'id': 2, 'name': 'Bob'}])\n\ntests\\Petl\\functional_test.py:195: AssertionError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_join_two_tables_fromdicts - Assert...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n3 failed, 3 passed, 6 skipped in 0.50s\n"}
{"model": "gpt-4-turbo", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.382364, "avg_memory_mb": 13.96, "avg_cpu_percent": 94.2, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:21:53", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n", "stdout_sha1": "3d43d73e26be0f48c50fe96012d3c4dcf351a1b9", "stdout_len": 1401, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n"}
{"model": "gpt-4-turbo", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.788075, "avg_memory_mb": 33.32, "avg_cpu_percent": 101.0, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 13:22:04", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:60: in encode\n    signature = _sign(signing_input, key, algorithm)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nmsg = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY3RpdmUiOnRydWUsInNjb3BlIjpbInJlYWQiLCJ3cml0ZSJdfQ'\nkey = 'secret', algorithm = 'HS512'\n\n    def _sign(msg, key, algorithm):\n        if algorithm == \"HS256\":\n            return hmac.new(\n                key.encode(\"utf-8\") if isinstance(key, str) else key,\n                msg.encode(\"utf-8\"),\n                hashlib.sha256\n            ).digest()\n        else:\n>           raise NotImplementedError(\"Algorithm not supported: %s\" % algorithm)\nE           NotImplementedError: Algorithm not supported: HS512\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:41: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: in encode\n    payload_segment = _base64url_encode(_json_encode(payload))\ngeneration\\PyJWT\\jwt\\api_jwt.py:28: in _json_encode\n    return json.dumps(obj, separators=(',', ':'), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000207FBE17A90>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", ", "stdout_sha1": "d493397cf13e3f567d230bcfd36d5184aee736b4", "stdout_len": 7100, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:60: in encode\n    signature = _sign(signing_input, key, algorithm)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nmsg = 'eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY3RpdmUiOnRydWUsInNjb3BlIjpbInJlYWQiLCJ3cml0ZSJdfQ'\nkey = 'secret', algorithm = 'HS512'\n\n    def _sign(msg, key, algorithm):\n        if algorithm == \"HS256\":\n            return hmac.new(\n                key.encode(\"utf-8\") if isinstance(key, str) else key,\n                msg.encode(\"utf-8\"),\n                hashlib.sha256\n            ).digest()\n        else:\n>           raise NotImplementedError(\"Algorithm not supported: %s\" % algorithm)\nE           NotImplementedError: Algorithm not supported: HS512\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:41: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: in encode\n    payload_segment = _base64url_encode(_json_encode(payload))\ngeneration\\PyJWT\\jwt\\api_jwt.py:28: in _json_encode\n    return json.dumps(obj, separators=(',', ':'), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000207FBE17A90>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: in encode\n    payload_segment = _base64url_encode(_json_encode(payload))\ngeneration\\PyJWT\\jwt\\api_jwt.py:28: in _json_encode\n    return json.dumps(obj, separators=(',', ':'), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x00000207FBE89D00>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.55s\n"}
{"model": "gpt-4-turbo", "project": "PyPDF", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.387798, "avg_memory_mb": 30.93, "avg_cpu_percent": 97.6, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:22:17", "stdout_excerpt": "\n1 skipped in 0.13s\n", "stdout_sha1": "4c4ceb412a81fcf19d92b45ee51d2d9a1553d8c3", "stdout_len": 20, "stdout": "\n1 skipped in 0.13s\n"}
{"model": "gpt-4-turbo", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.432129, "avg_memory_mb": 31.17, "avg_cpu_percent": 98.8, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:22:44", "stdout_excerpt": "\n1 skipped in 0.14s\n", "stdout_sha1": "95c5fda1107f8078c182653b3ba949fc343f3984", "stdout_len": 20, "stdout": "\n1 skipped in 0.14s\n"}
{"model": "gpt-4-turbo", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Job' object has no attribute 'hour'", "returncode": 1, "elapsed_time_s": 1.739686, "avg_memory_mb": 31.84, "avg_cpu_percent": 101.0, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 13:22:55", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       TypeError: tag() takes 2 positional arguments but 3 were given\n\ntests\\Schedule\\functional_test.py:97: TypeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n        schedule.cancel_job(j2)\n    \n        schedule.run_all()\n        assert calls == [\"job1\"]\n>       assert j1 in schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:155: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       schedule.every().hour.do(job)\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:253: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n   ", "stdout_sha1": "6b30f99c650c048247ee82936716ff0ce51a090f", "stdout_len": 5719, "stdout": "FFFF.F..FFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n>       schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\nE       TypeError: tag() takes 2 positional arguments but 3 were given\n\ntests\\Schedule\\functional_test.py:97: TypeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n>       schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:121: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n        schedule.cancel_job(j2)\n    \n        schedule.run_all()\n        assert calls == [\"job1\"]\n>       assert j1 in schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:155: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:198: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       schedule.every().hour.do(job)\nE       AttributeError: 'Job' object has no attribute 'hour'\n\ntests\\Schedule\\functional_test.py:253: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n>       schedule.every().minute.do(a).tag(\"alpha\")\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:269: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n>       j = schedule.every().minute.do(job)\nE       AttributeError: 'Job' object has no attribute 'minute'\n\ntests\\Schedule\\functional_test.py:290: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Type...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n9 failed, 3 passed in 0.44s\n"}
{"model": "gpt-4-turbo", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where <built-in method startswith of str object at 0x0000027546AC3D30> = 'hisisatest'.startswith", "returncode": 1, "elapsed_time_s": 1.637817, "avg_memory_mb": 31.3, "avg_cpu_percent": 102.0, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 13:23:06", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000027546AC3D30>('___')\nE        +    where <built-in method startswith of str object at 0x0000027546AC3D30> = 'hisisatest'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.34s\n", "stdout_sha1": "b35fa76cc95f892cd5f70d980f639acde7a6d4e4", "stdout_len": 1077, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000027546AC3D30>('___')\nE        +    where <built-in method startswith of str object at 0x0000027546AC3D30> = 'hisisatest'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.34s\n"}
{"model": "gpt-4-turbo", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "type object 'SQLModel' has no attribute 'metadata'", "returncode": 2, "elapsed_time_s": 1.866525, "avg_memory_mb": 36.09, "avg_cpu_percent": 99.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:23:32", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: type object 'SQLModel' has no attribute 'metadata'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: type object 'SQLMod...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.48s\n", "stdout_sha1": "385dd59b15cf2edb5a61508732dc6f57e0a25659", "stdout_len": 570, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: type object 'SQLModel' has no attribute 'metadata'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: type object 'SQLMod...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.48s\n"}
{"model": "gpt-4-turbo", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'generator' object is not callable", "returncode": 1, "elapsed_time_s": 3.52688, "avg_memory_mb": 36.32, "avg_cpu_percent": 97.7, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 13:23:46", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-428/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x2344FFFEAC0>\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x000002344FE06890>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if isinstance(image, str):\n            image = Image.open(image)\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n        elif image.mode not in (\"RGB\", \"RGBA\"):\n            image = image.convert(\"RGB\")\n        pixels = image.load()\n        width, height = image.size\n        bits = list(_message_to_bits(message, encoding))\n        if generator is None:\n            positions = ((x, y) for y in range(height) for x in range(width))\n        else:\n>           gen = generator()\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:44: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\n1 failed, 11 passed in 2.23s\n", "stdout_sha1": "d9edf3da15a5bb7c9d36f69909c59bc2eb0430b3", "stdout_len": 2026, "stdout": ".F..........                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-428/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x2344FFFEAC0>\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x000002344FE06890>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if isinstance(image, str):\n            image = Image.open(image)\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n        elif image.mode not in (\"RGB\", \"RGBA\"):\n            image = image.convert(\"RGB\")\n        pixels = image.load()\n        width, height = image.size\n        bits = list(_message_to_bits(message, encoding))\n        if generator is None:\n            positions = ((x, y) for y in range(height) for x in range(width))\n        else:\n>           gen = generator()\nE           TypeError: 'generator' object is not callable\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:44: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\n1 failed, 11 passed in 2.23s\n"}
{"model": "gpt-4-turbo", "project": "Tablib", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)", "returncode": 2, "elapsed_time_s": 1.737139, "avg_memory_mb": 36.15, "avg_cpu_percent": 98.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:23:57", "stdout_excerpt": "====\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:1: in <module>\n    from .core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:3: in <module>\n    from .formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_csv.py:3: in <module>\n    from ..core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.49s\n", "stdout_sha1": "b3245db0ea4677e4ee0baa1a8f23210fad1ae2ba", "stdout_len": 1296, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:1: in <module>\n    from .core import Dataset, Databook\ngeneration\\Tablib\\tablib\\core.py:3: in <module>\n    from .formats import _csv, _json\ngeneration\\Tablib\\tablib\\formats\\_csv.py:3: in <module>\n    from ..core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.49s\n"}
{"model": "gpt-4-turbo", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "tabulate() got an unexpected keyword argument 'maxcolwidths'", "returncode": 1, "elapsed_time_s": 1.657973, "avg_memory_mb": 32.51, "avg_cpu_percent": 96.0, "passed": 9, "failed": 3, "skipped": 0, "total": 12, "functional_score": 0.75, "timestamp": "2026-01-01 13:24:09", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n        assert lines[0].strip().startswith(\"Name\")\n        assert \"Age\" in lines[0]\n        # separator line usually contains dashes\n>       assert \"-\" in lines[1].replace(\" \", \"\")\nE       AssertionError: assert '-' in 'Alice24'\nE        +  where 'Alice24' = <built-in method replace of str object at 0x000001F7AB90F330>(' ', '')\nE        +    where <built-in method replace of str object at 0x000001F7AB90F330> = 'Alice  24'.replace\n\ntests\\Tabulate\\functional_test.py:123: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001F7AB8F89B0>('|')\nE        +    where <built-in method startswith of str object at 0x000001F7AB8F89B0> = 'item  qty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Asse...\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n3 failed, 9 passed in 0.38s\n", "stdout_sha1": "6a812c5eae81b11240869de2de98ebbb2cda2f27", "stdout_len": 2672, "stdout": "..F..F....F.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n        assert lines[0].strip().startswith(\"Name\")\n        assert \"Age\" in lines[0]\n        # separator line usually contains dashes\n>       assert \"-\" in lines[1].replace(\" \", \"\")\nE       AssertionError: assert '-' in 'Alice24'\nE        +  where 'Alice24' = <built-in method replace of str object at 0x000001F7AB90F330>(' ', '')\nE        +    where <built-in method replace of str object at 0x000001F7AB90F330> = 'Alice  24'.replace\n\ntests\\Tabulate\\functional_test.py:123: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001F7AB8F89B0>('|')\nE        +    where <built-in method startswith of str object at 0x000001F7AB8F89B0> = 'item  qty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Asse...\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n3 failed, 9 passed in 0.38s\n"}
{"model": "gpt-4-turbo", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for +: 'int' and 'str'", "returncode": 1, "elapsed_time_s": 47.119134, "avg_memory_mb": 33.4, "avg_cpu_percent": 0.39, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 13:25:05", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C6D74F0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C6D7490>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C7308B0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:81: in draw\n    max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000002008C7306D0>\n\n>   max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:81: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C68ABE0>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C68A850>\nfile = <_io.TextIOWrapper name='<tempfile._Tempo", "stdout_sha1": "41e77acf8d527b6669b686fa3223bc1913c144c5", "stdout_len": 21083, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C6D74F0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C6D7490>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nTest Chart\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C7308B0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:81: in draw\n    max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000002008C7306D0>\n\n>   max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:81: TypeError\n---------------------------- Captured stdout call -----------------------------\nStacked Chart\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C68ABE0>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C68A850>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nBars\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C721CA0>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C7216A0>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Values\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C727850>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Labels\", width=10, no_labels=True, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C727AF0>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nNo Labels\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C7204F0>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Suffix\", width=18, suffix=\"%\", format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C7206A0>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nSuffix\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C740430>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Fmt\", width=20, format=\"{:>6.2f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C740100>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nFmt\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C7303D0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack Labels\", width=25, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:81: in draw\n    max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000002008C730160>\n\n>   max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:81: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack Labels\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C7226D0>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack No Values\", width=30, no_values=True, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:81: in draw\n    max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000002008C722DF0>\n\n>   max_val = max(sum(series) for series in self.data.data) if self.data.data else 1\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:81: TypeError\n---------------------------- Captured stdout call -----------------------------\nStack No Values\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C721520>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=None, width=15, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C721EE0>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002008C742070>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002008C7422E0>\nfile = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000002008AC0D6A0>' mode='r+' encoding='utf-8'>\n\n    def draw(self, file=sys.stdout):\n        if self.args.title:\n            print(self.args.title, file=file)\n        max_label_len = max((len(str(label)) for label in self.data.labels), default=0)\n        width = self.args.width\n        fmt = self.args.format\n        suffix = self.args.suffix\n        no_labels = self.args.no_labels\n        no_values = self.args.no_values\n        color = self.args.color\n    \n        # Find max value for scaling\n        if self.args.different_scale:\n            max_vals = [max(series) if series else 0 for series in self.data.data]\n        else:\n            max_val = self.data.max_value()\n    \n        for idx, (label, series) in enumerate(zip(self.data.labels, self.data.data)):\n            if self.args.different_scale:\n                scale = max_vals[idx] if max_vals[idx] else 1\n            else:\n                scale = max_val if max_val else 1\n    \n            bars = []\n            for sidx, value in enumerate(series):\n>               bar_len = int(round((value / scale) * width)) if scale else 0\nE               TypeError: unsupported operand type(s) for /: 'str' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:49: TypeError\n---------------------------- Captured stdout call -----------------------------\nNarrow\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 23.61s\n"}
{"model": "gpt-4-turbo", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 1.859612, "avg_memory_mb": 32.11, "avg_cpu_percent": 98.2, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 13:25:17", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "3f3dff09baef26a040dc0b15745bef52b6e558f0", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-429/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-429/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-429/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000237A98B1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.56s\n"}
{"model": "gpt-4-turbo", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.774439, "avg_memory_mb": 35.25, "avg_cpu_percent": 100.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:25:29", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n", "stdout_sha1": "2c168ba6d4f8a29c5fc645a8c9c8783a94494322", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n"}
{"model": "gpt-4-turbo", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword argument 'prompt'", "returncode": 1, "elapsed_time_s": 1.792139, "avg_memory_mb": 32.84, "avg_cpu_percent": 99.0, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 13:25:40", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000001B7A95A2460>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'Added: --help\\n' or 'title' in 'Added: --help\\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonke", "stdout_sha1": "871b39ae7509ceee0c5cb2d3d6686bd08034a7c2", "stdout_len": 7096, "stdout": "FFF..F.FFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.Result object at 0x000001B7A95A2460>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'Added: --help\\n' or 'title' in 'Added: --help\\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x000001B7A9593250>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:159: AttributeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n>       app = _create_types_app()\n\ntests\\Typer\\functional_test.py:310: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_types_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"calc\" exists as a subcommand.\n        Covers typed arguments and a float option.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def calc(x: int, y: int, scale: float = typer.Option(1.0, \"--scale\")) -> None:\nE       TypeError: __init__() takes from 1 to 2 positional arguments but 3 were given\n\ntests\\Typer\\functional_test.py:181: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AttributeE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - At...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n9 failed, 3 passed in 0.50s\n"}
{"model": "gpt-4-turbo", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.743663, "avg_memory_mb": 35.44, "avg_cpu_percent": 101.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 13:25:58", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n", "stdout_sha1": "7254f0fbbea23091c6c494f74d5bfa2d6a40b865", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n"}
{"model": "gpt-4-turbo", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '@id' not in {'@id': '9', 'name': {'#text': 'Alice'}}", "returncode": 1, "elapsed_time_s": 1.718243, "avg_memory_mb": 31.56, "avg_cpu_percent": 98.1, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 13:26:09", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n        assert any(k.startswith(\"x:\") for k in keys)\n    \n        key = next(k for k in keys if k.startswith(\"x:\"))\n>       assert root[key] == \"value\"\nE       AssertionError: assert {'#text': 'value'} == 'value'\n\ntests\\Xmltodict\\functional_test.py:134: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n>           assert isinstance(item, list)\nE           AssertionError: assert False\nE            +  where False = isinstance({'#text': '1'}, list)\n\ntests\\Xmltodict\\functional_test.py:165: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n>           assert \"@id\" not in user\nE           AssertionError: assert '@id' not in {'@id': '9', 'name': {'#text': 'Alice'}}\n\ntests\\Xmltodict\\functional_test.py:196: AssertionError\n______________________ test_dict_constructor_ordereddict", "stdout_sha1": "76d0b00eefe1419abdcfea2b93a6c4b5b6ce0661", "stdout_len": 6885, "stdout": "FF..FFF.FFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n        assert any(k.startswith(\"x:\") for k in keys)\n    \n        key = next(k for k in keys if k.startswith(\"x:\"))\n>       assert root[key] == \"value\"\nE       AssertionError: assert {'#text': 'value'} == 'value'\n\ntests\\Xmltodict\\functional_test.py:134: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n>           assert isinstance(item, list)\nE           AssertionError: assert False\nE            +  where False = isinstance({'#text': '1'}, list)\n\ntests\\Xmltodict\\functional_test.py:165: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n>           assert \"@id\" not in user\nE           AssertionError: assert '@id' not in {'@id': '9', 'name': {'#text': 'Alice'}}\n\ntests\\Xmltodict\\functional_test.py:196: AssertionError\n______________________ test_dict_constructor_ordereddict ______________________\n\n    def test_dict_constructor_ordereddict() -> None:\n        \"\"\"dict_constructor should allow choosing mapping type (e.g., OrderedDict) when supported.\"\"\"\n        xml = \"<root><a>1</a><b>2</b></root>\"\n        data = _parse(xml, dict_constructor=OrderedDict)\n    \n        if \"dict_constructor\" in _PARSE_PARAMS:\n>           assert isinstance(data, OrderedDict)\nE           AssertionError: assert False\nE            +  where False = isinstance({'root': OrderedDict([('a', OrderedDict([('#text', '1')])), ('b', OrderedDict([('#text', '2')]))])}, OrderedDict)\n\ntests\\Xmltodict\\functional_test.py:210: AssertionError\n_____________________ test_unparse_pretty_and_parse_back ______________________\n\n    def test_unparse_pretty_and_parse_back() -> None:\n        \"\"\"Pretty/full_document knobs should not break roundtrip of basic structure.\"\"\"\n        original: Dict[str, Any] = {\"root\": {\"x\": \"1\", \"y\": \"2\"}}\n    \n        xml = _unparse(original, pretty=True, full_document=True)\n>       assert \"<root>\" in xml or \"<root\" in xml\nE       TypeError: a bytes-like object is required, not 'str'\n\ntests\\Xmltodict\\functional_test.py:224: TypeError\n______________ test_postprocessor_transforms_value_if_supported _______________\n\n    def test_postprocessor_transforms_value_if_supported() -> None:\n        \"\"\"postprocessor can transform values in a happy-path parse when supported.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n    \n        def _pp(path: Any, key: str, value: Any) -> Any:\n            if key == \"message\" and isinstance(value, str):\n                return key, value.upper()\n            return key, value\n    \n        data = _parse(xml, postprocessor=_pp)\n    \n        if \"postprocessor\" in _PARSE_PARAMS:\n>           assert data[\"root\"][\"message\"] == \"HELLO\"\nE           AssertionError: assert {'#text': 'Hello'} == 'HELLO'\n\ntests\\Xmltodict\\functional_test.py:242: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_parse_simple_element - Assert...\nFAILED tests/Xmltodict/functional_test.py::test_parse_repeated_elements_as_list\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\nFAILED tests/Xmltodict/functional_test.py::test_parse_nested_structure - Asse...\nFAILED tests/Xmltodict/functional_test.py::test_force_list_option_for_single_element\nFAILED tests/Xmltodict/functional_test.py::test_xml_attribs_false_drops_attributes_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_dict_constructor_ordereddict\nFAILED tests/Xmltodict/functional_test.py::test_unparse_pretty_and_parse_back\nFAILED tests/Xmltodict/functional_test.py::test_postprocessor_transforms_value_if_supported\n9 failed, 3 passed in 0.46s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Astral", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where False = isinstance('Europe/London', (<class 'int'>, <class 'float'>))", "returncode": 1, "elapsed_time_s": 1.577103, "avg_memory_mb": 32.18, "avg_cpu_percent": 100.0, "passed": 5, "failed": 6, "skipped": 0, "total": 11, "functional_score": 0.4545, "timestamp": "2025-12-31 12:58:53", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_sun_times_basic_sanity _________________________\n\n    def test_sun_times_basic_sanity() -> None:\n        \"\"\"sun() returns expected keys and times are in a plausible order.\"\"\"\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 22.164779321292222, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination: float, zenith: float) -> float:\n        \"\"\"Calculate the hour angle for sunrise/sunset.\"\"\"\n>       latitude_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:11: TypeError\n______________________ test_sun_time_changes_across_days ______________________\n\n    def test_sun_time_changes_across_days() -> None:\n        \"\"\"Sunrise and sunset should change slightly between consecutive days.\"\"\"\n        loc = _london_location()\n        d1 = dt.date(2020, 1, 1)\n        d2 = d1 + dt.timedelta(days=1)\n    \n>       s1 = sun(_observer_from_location(loc), date=d1, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = -23.001823663166522, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination: float, zenith: float) -> float:\n        \"\"\"Calculate the hour angle for sunrise/sunset.\"\"\"\n>       latitude_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:11: TypeError\n______________ test_locationinfo_has_lat_lon_fields_or_observer _______________\n\n    def test_locationinfo_has_lat_lon_fields_or_observer() -> None:\n        loc = _london_location()\n    \n        if hasattr(loc, \"observer\"):\n            obs = _observer_from_location(loc)\n            lat = getattr(obs, \"latitude\", None)\n            lon = getattr(obs, \"longitude\", None)\n        else:\n            lat = getattr(loc, \"latitude\", None)\n            lon = getattr(loc, \"longitude\", None)\n    \n>       assert isinstance(lat, (int, float))\nE       AssertionError: assert False\nE        +  where False = isinstance('Europe/London', (<class 'int'>, <class 'float'>))\n\ntests\\Astral\\functional_test.py:169: AssertionError\n_________________________ test_sun_returns_datetimes __________________________\n\n    def test_sun_returns_datetimes() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:185: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 22.164779321292222, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination:", "stdout_sha1": "134a67204ab073a77436112730467b747fee2eea", "stdout_len": 7693, "stdout": "FF.F.FFF...                                                              [100%]\n================================== FAILURES ===================================\n_________________________ test_sun_times_basic_sanity _________________________\n\n    def test_sun_times_basic_sanity() -> None:\n        \"\"\"sun() returns expected keys and times are in a plausible order.\"\"\"\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 22.164779321292222, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination: float, zenith: float) -> float:\n        \"\"\"Calculate the hour angle for sunrise/sunset.\"\"\"\n>       latitude_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:11: TypeError\n______________________ test_sun_time_changes_across_days ______________________\n\n    def test_sun_time_changes_across_days() -> None:\n        \"\"\"Sunrise and sunset should change slightly between consecutive days.\"\"\"\n        loc = _london_location()\n        d1 = dt.date(2020, 1, 1)\n        d2 = d1 + dt.timedelta(days=1)\n    \n>       s1 = sun(_observer_from_location(loc), date=d1, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = -23.001823663166522, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination: float, zenith: float) -> float:\n        \"\"\"Calculate the hour angle for sunrise/sunset.\"\"\"\n>       latitude_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:11: TypeError\n______________ test_locationinfo_has_lat_lon_fields_or_observer _______________\n\n    def test_locationinfo_has_lat_lon_fields_or_observer() -> None:\n        loc = _london_location()\n    \n        if hasattr(loc, \"observer\"):\n            obs = _observer_from_location(loc)\n            lat = getattr(obs, \"latitude\", None)\n            lon = getattr(obs, \"longitude\", None)\n        else:\n            lat = getattr(loc, \"latitude\", None)\n            lon = getattr(loc, \"longitude\", None)\n    \n>       assert isinstance(lat, (int, float))\nE       AssertionError: assert False\nE        +  where False = isinstance('Europe/London', (<class 'int'>, <class 'float'>))\n\ntests\\Astral\\functional_test.py:169: AssertionError\n_________________________ test_sun_returns_datetimes __________________________\n\n    def test_sun_returns_datetimes() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 6, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:185: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 22.164779321292222, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination: float, zenith: float) -> float:\n        \"\"\"Calculate the hour angle for sunrise/sunset.\"\"\"\n>       latitude_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:11: TypeError\n_________________ test_sun_noon_is_between_sunrise_and_sunset _________________\n\n    def test_sun_noon_is_between_sunrise_and_sunset() -> None:\n        loc = _london_location()\n        d = dt.date(2020, 3, 1)\n>       s = sun(_observer_from_location(loc), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:196: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = -7.911536766486016, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination: float, zenith: float) -> float:\n        \"\"\"Calculate the hour angle for sunrise/sunset.\"\"\"\n>       latitude_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:11: TypeError\n_______ test_sun_times_differ_between_locations_same_date_or_one_raises _______\n\n    def test_sun_times_differ_between_locations_same_date_or_one_raises() -> None:\n        \"\"\"\n        Some generated implementations have edge-case bugs for certain longitudes that can\n        yield out-of-range hours (e.g., hour < 0 or > 23) and raise ValueError.\n        This test remains targeted (different locations) while being compatible across\n        implementations by accepting either:\n          - both computations succeed and differ, OR\n          - one implementation raises a clear exception for the second location.\n        \"\"\"\n        london = _london_location()\n        nyc = _new_york_location()\n        d = dt.date(2020, 6, 1)\n    \n>       s_l = sun(_observer_from_location(london), date=d, tzinfo=_safe_tzinfo())\n\ntests\\Astral\\functional_test.py:213: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Astral\\astral\\sun.py:53: in sun\n    times[event] = calculate_event(observer, date, zenith, is_rise, tzinfo)\ngeneration\\Astral\\astral\\sun.py:23: in calculate_event\n    hour_angle = calculate_hour_angle(observer.latitude, declination, zenith)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nlatitude = 'Europe/London', declination = 22.164779321292222, zenith = 96\n\n    def calculate_hour_angle(latitude: float, declination: float, zenith: float) -> float:\n        \"\"\"Calculate the hour angle for sunrise/sunset.\"\"\"\n>       latitude_rad = radians(latitude)\nE       TypeError: must be real number, not str\n\ngeneration\\Astral\\astral\\sun.py:11: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Astral/functional_test.py::test_sun_times_basic_sanity - TypeErr...\nFAILED tests/Astral/functional_test.py::test_sun_time_changes_across_days - T...\nFAILED tests/Astral/functional_test.py::test_locationinfo_has_lat_lon_fields_or_observer\nFAILED tests/Astral/functional_test.py::test_sun_returns_datetimes - TypeErro...\nFAILED tests/Astral/functional_test.py::test_sun_noon_is_between_sunrise_and_sunset\nFAILED tests/Astral/functional_test.py::test_sun_times_differ_between_locations_same_date_or_one_raises\n6 failed, 5 passed in 0.46s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Cachetools", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "assert 1 == 2", "returncode": 1, "elapsed_time_s": 2.656403, "avg_memory_mb": 32.5, "avg_cpu_percent": 55.2, "passed": 7, "failed": 6, "skipped": 0, "total": 13, "functional_score": 0.5385, "timestamp": "2025-12-31 12:59:05", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_lru_cache_eviction ________________________\n\n    def test_basic_lru_cache_eviction():\n        cache = LRUCache(maxsize=2)\n    \n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n    \n        # Touch \"a\" so it becomes most recently used\n        _ = cache[\"a\"]\n    \n        # Adding \"c\" should evict the least recently used entry (\"b\")\n        cache[\"c\"] = 3\n    \n        assert \"a\" in cache\n        assert \"c\" in cache\n        assert \"b\" not in cache\n>       assert len(cache) == 2\nE       assert 0 == 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:45: AssertionError\n________________ test_lru_cache_update_does_not_increase_size _________________\n\n    def test_lru_cache_update_does_not_increase_size():\n        cache = LRUCache(maxsize=3)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n>       assert len(cache) == 2\nE       assert 0 == 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:165: AssertionError\n______________________ test_lru_cache_clear_resets_state ______________________\n\n    def test_lru_cache_clear_resets_state():\n        cache = LRUCache(maxsize=2)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n>       assert len(cache) == 2\nE       assert 0 == 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:176: AssertionError\n__________________ test_lru_cache_popitem_removes_one_entry ___________________\n\n    def test_lru_cache_popitem_removes_one_entry():\n        cache = LRUCache(maxsize=3)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n        cache[\"c\"] = 3\n>       assert len(cache) == 3\nE       assert 0 == 3\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:189: AssertionError\n__________________ test_ttl_cache_len_drops_after_expiration __________________\n\n    def test_ttl_cache_len_drops_after_expiration():\n        ttl_seconds = 0.15\n        cache = TTLCache(maxsize=10, ttl=ttl_seconds)\n    \n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n>       assert len(cache) >= 2\nE       assert 0 >= 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:217: AssertionError\n_____________ test_cached_decorator_cache_clear_forces_recompute ______________\n\n    def test_cached_decorator_cache_clear_forces_recompute():\n        cache = LRUCache(maxsize=32)\n        calls = {\"count\": 0}\n    \n        @cached(cache=cache)\n        def f(x: int) -> int:\n            calls[\"count\"] += 1\n            return x + 1\n    \n        assert f(1) == 2\n        assert calls[\"count\"] == 1\n        assert f(1) == 2\n        assert calls[\"count\"] == 1  # cached\n    \n        cache.clear()\n        assert f(1) == 2\n>       assert calls[\"count\"] == 2  # recomputed after clear\nE       assert 1 == 2\n\ntests\\Cachetools\\functional_test.py:247: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_basic_lru_cache_eviction - a...\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_update_does_not_increase_size\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_clear_resets_state\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_popitem_removes_one_entry\nFAILED tests/Cachetools/functional_test.py::test_ttl_cache_len_drops_after_expiration\nFAILED tests/Cachetools/functional_test.py::test_cached_decorator_cache_clear_forces_recompute\n6 failed, 7 passed in 1.53s\n", "stdout_sha1": "3fa154ca3f17bc5f7be78cc3511a55da6655c835", "stdout_len": 3550, "stdout": "F....FFF.FF..                                                            [100%]\n================================== FAILURES ===================================\n________________________ test_basic_lru_cache_eviction ________________________\n\n    def test_basic_lru_cache_eviction():\n        cache = LRUCache(maxsize=2)\n    \n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n    \n        # Touch \"a\" so it becomes most recently used\n        _ = cache[\"a\"]\n    \n        # Adding \"c\" should evict the least recently used entry (\"b\")\n        cache[\"c\"] = 3\n    \n        assert \"a\" in cache\n        assert \"c\" in cache\n        assert \"b\" not in cache\n>       assert len(cache) == 2\nE       assert 0 == 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:45: AssertionError\n________________ test_lru_cache_update_does_not_increase_size _________________\n\n    def test_lru_cache_update_does_not_increase_size():\n        cache = LRUCache(maxsize=3)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n>       assert len(cache) == 2\nE       assert 0 == 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:165: AssertionError\n______________________ test_lru_cache_clear_resets_state ______________________\n\n    def test_lru_cache_clear_resets_state():\n        cache = LRUCache(maxsize=2)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n>       assert len(cache) == 2\nE       assert 0 == 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:176: AssertionError\n__________________ test_lru_cache_popitem_removes_one_entry ___________________\n\n    def test_lru_cache_popitem_removes_one_entry():\n        cache = LRUCache(maxsize=3)\n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n        cache[\"c\"] = 3\n>       assert len(cache) == 3\nE       assert 0 == 3\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:189: AssertionError\n__________________ test_ttl_cache_len_drops_after_expiration __________________\n\n    def test_ttl_cache_len_drops_after_expiration():\n        ttl_seconds = 0.15\n        cache = TTLCache(maxsize=10, ttl=ttl_seconds)\n    \n        cache[\"a\"] = 1\n        cache[\"b\"] = 2\n>       assert len(cache) >= 2\nE       assert 0 >= 2\nE        +  where 0 = len({})\n\ntests\\Cachetools\\functional_test.py:217: AssertionError\n_____________ test_cached_decorator_cache_clear_forces_recompute ______________\n\n    def test_cached_decorator_cache_clear_forces_recompute():\n        cache = LRUCache(maxsize=32)\n        calls = {\"count\": 0}\n    \n        @cached(cache=cache)\n        def f(x: int) -> int:\n            calls[\"count\"] += 1\n            return x + 1\n    \n        assert f(1) == 2\n        assert calls[\"count\"] == 1\n        assert f(1) == 2\n        assert calls[\"count\"] == 1  # cached\n    \n        cache.clear()\n        assert f(1) == 2\n>       assert calls[\"count\"] == 2  # recomputed after clear\nE       assert 1 == 2\n\ntests\\Cachetools\\functional_test.py:247: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_basic_lru_cache_eviction - a...\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_update_does_not_increase_size\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_clear_resets_state\nFAILED tests/Cachetools/functional_test.py::test_lru_cache_popitem_removes_one_entry\nFAILED tests/Cachetools/functional_test.py::test_ttl_cache_len_drops_after_expiration\nFAILED tests/Cachetools/functional_test.py::test_cached_decorator_cache_clear_forces_recompute\n6 failed, 7 passed in 1.53s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "+  where 1 = <click.testing.Result object at 0x0000017A6DA56730>.exit_code", "returncode": 1, "elapsed_time_s": 4.216122, "avg_memory_mb": 32.68, "avg_cpu_percent": 100.4, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 12:59:43", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n>       @click.option(\"--count\", \"-c\", type=int, default=1)\nE       TypeError: option() takes 1 positional argument but 2 were given\n\ntests\\Click\\functional_test.py:134: TypeError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000017A6DAD0CA0>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:226: AttributeError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert result.exit_code != 0\n>       assert isinstance(result.exception, CustomError)\nE       AttributeError: 'Result' object has no attribute 'exception'\n\ntests\\Click\\functional_test.py:251: AttributeError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n        def cli(name: str) -> None:\n            click.echo(f\"NAME={name}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000017A6DA89940>.exit_code\n\ntests\\Click\\functional_test.py:269: AssertionError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000017A6DA56730>.exit_code\n\ntests\\Click\\functional_test.py:285: AssertionError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_", "stdout_sha1": "511673dad7eec70da79a4b0ecf94ecdb34a0b7c4", "stdout_len": 6671, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n>       @click.option(\"--count\", \"-c\", type=int, default=1)\nE       TypeError: option() takes 1 positional argument but 2 were given\n\ntests\\Click\\functional_test.py:134: TypeError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000017A6DAD0CA0>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:226: AttributeError\n_________________ test_command_exception_is_exposed_in_result _________________\n\n    def test_command_exception_is_exposed_in_result():\n        class CustomError(Exception):\n            pass\n    \n        @click.command()\n        def boom() -> None:\n            raise CustomError(\"explode\")\n    \n        runner = CliRunner()\n        result = runner.invoke(boom, [])\n    \n        assert result.exit_code != 0\n>       assert isinstance(result.exception, CustomError)\nE       AttributeError: 'Result' object has no attribute 'exception'\n\ntests\\Click\\functional_test.py:251: AttributeError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n        def cli(name: str) -> None:\n            click.echo(f\"NAME={name}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000017A6DA89940>.exit_code\n\ntests\\Click\\functional_test.py:269: AssertionError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000017A6DA56730>.exit_code\n\ntests\\Click\\functional_test.py:285: AssertionError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:294: AttributeError\n_______________ test_parameter_type_validation_error_exit_code ________________\n\n    def test_parameter_type_validation_error_exit_code():\n        @click.command()\n        @click.option(\"--count\", type=int, required=True)\n        def cli(count: int) -> None:\n            click.echo(f\"COUNT={count}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [\"--count\", \"not-an-int\"])\n        assert r.exit_code != 0\n>       assert (\"Invalid value\" in r.output) or (\"Error\" in r.output)\nE       assert ('Invalid value' in \"'Command' object has no attribute 'make_context'\" or 'Error' in \"'Command' object has no attribute 'make_context'\")\nE        +  where \"'Command' object has no attribute 'make_context'\" = <click.testing.Result object at 0x0000017A6DA56970>.output\nE        +  and   \"'Command' object has no attribute 'make_context'\" = <click.testing.Result object at 0x0000017A6DA56970>.output\n\ntests\\Click\\functional_test.py:314: AssertionError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - Attribut...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_command_exception_is_exposed_in_result\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - a...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n11 failed in 3.08s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Dataset", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "sqlite3.OperationalError: table events has no column named name", "returncode": 1, "elapsed_time_s": 25.872048, "avg_memory_mb": 33.71, "avg_cpu_percent": 0.74, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 13:00:31", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076BA0FD0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076BEFEE0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-265/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n>       table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n\ntests\\Dataset\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000001E075578EE0>\nrow = {'category': 'ok', 'name': 'committed'}\n\n    def insert(self, row):\n        keys = row.keys()\n        columns = \", \".join(keys)\n        placeholders = \", \".join(f\":{key}\" for key in keys)\n>       self.connection.execute(f\"INSERT INTO {self.name} ({columns}) VALUES ({placeholders})\", row)\nE       sqlite3.OperationalError: table events has no column named name\n\ngeneration\\Dataset\\dataset\\table.py:18: OperationalError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076B867C0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3", "stdout_sha1": "f64a0927a30673f26ca10a086fac751d14b9262d", "stdout_len": 12787, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076BA0FD0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076BEFEE0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n____________________ test_transactions_commit_and_rollback ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-265/test_transactions_commit_and_r0')\n\n    def test_transactions_commit_and_rollback(tmp_path: Path) -> None:\n        db_path = tmp_path / \"tx_sample.db\"\n        db_url = \"sqlite:///%s\" % str(db_path)\n        db = dataset.connect(db_url)\n        table = db[\"events\"]\n    \n        db.begin()\n>       table.insert({\"name\": \"committed\", \"category\": \"ok\"})\n\ntests\\Dataset\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000001E075578EE0>\nrow = {'category': 'ok', 'name': 'committed'}\n\n    def insert(self, row):\n        keys = row.keys()\n        columns = \", \".join(keys)\n        placeholders = \", \".join(f\":{key}\" for key in keys)\n>       self.connection.execute(f\"INSERT INTO {self.name} ({columns}) VALUES ({placeholders})\", row)\nE       sqlite3.OperationalError: table events has no column named name\n\ngeneration\\Dataset\\dataset\\table.py:18: OperationalError\n___________________ test_insert_many_returns_ids_and_count ____________________\n\n    def test_insert_many_returns_ids_and_count() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076B867C0>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n_____________________ test_find_one_missing_returns_none ______________________\n\n    def test_find_one_missing_returns_none() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076C2A340>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:243: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076C06970>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n___________________ test_table_all_iteration_and_row_shape ____________________\n\n    def test_table_all_iteration_and_row_shape() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076C09700>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n_______________________ test_delete_and_clear_all_rows ________________________\n\n    def test_delete_and_clear_all_rows() -> None:\n        \"\"\"\n        Older dataset.Table may not expose truncate().\n        Clear a table and end at 0 rows without relying on result iteration for DML.\n        \"\"\"\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076BE6A60>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076C23490>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n_____________________ test_raw_sql_query_with_parameters ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-265/test_raw_sql_query_with_parame0')\n\n    def test_raw_sql_query_with_parameters(tmp_path: Path) -> None:\n        db_path = tmp_path / \"param.db\"\n        db = dataset.connect(\"sqlite:///%s\" % str(db_path))\n        table = db[\"kv\"]\n>       table.insert_many([{\"k\": \"a\", \"v\": 1}, {\"k\": \"b\", \"v\": 2}])\n\ntests\\Dataset\\functional_test.py:319: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000001E076BEF070>\nrows = [{'k': 'a', 'v': 1}, {'k': 'b', 'v': 2}], chunk_size = None\n\n    def insert_many(self, rows, chunk_size=None):\n        if not rows:\n            return\n        keys = rows[0].keys()\n        columns = \", \".join(keys)\n        placeholders = \", \".join(f\":{key}\" for key in keys)\n        query = f\"INSERT INTO {self.name} ({columns}) VALUES ({placeholders})\"\n        if chunk_size:\n            for i in range(0, len(rows), chunk_size):\n                self.connection.executemany(query, rows[i:i+chunk_size])\n        else:\n>           self.connection.executemany(query, rows)\nE           sqlite3.OperationalError: table kv has no column named k\n\ngeneration\\Dataset\\dataset\\table.py:31: OperationalError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n>       db = create_in_memory_db()\n\ntests\\Dataset\\functional_test.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Dataset\\functional_test.py:106: in create_in_memory_db\n    return dataset.connect(\"sqlite:///:memory:\")\ngeneration\\Dataset\\dataset\\database.py:41: in connect\n    return Database(url)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001E076C27640>\nurl = 'sqlite:///:memory:'\n\n    def __init__(self, url):\n        if not url.startswith(\"sqlite://\"):\n            raise ValueError(\"Only SQLite databases are supported.\")\n>       self.connection = sqlite3.connect(url.split(\"://\")[1], isolation_level=None)\nE       sqlite3.OperationalError: unable to open database file\n\ngeneration\\Dataset\\dataset\\database.py:10: OperationalError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - sql...\nFAILED tests/Dataset/functional_test.py::test_transactions_commit_and_rollback\nFAILED tests/Dataset/functional_test.py::test_insert_many_returns_ids_and_count\nFAILED tests/Dataset/functional_test.py::test_find_one_missing_returns_none\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - sq...\nFAILED tests/Dataset/functional_test.py::test_table_all_iteration_and_row_shape\nFAILED tests/Dataset/functional_test.py::test_delete_and_clear_all_rows - sql...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_raw_sql_query_with_parameters\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n11 failed in 3.16s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:00:39", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "gpt-4o-2024-11-20", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('failregex' in 'import re\\n\\ndef isvalidip(ip):\\n    \"\"\"\\n    validate if the given string is a valid ipv4 address.\\n    \"\"\"\\n    pat...ile(r\"(?:[0-9]{1,3}\\\\.){3}[0-9]{1,3}\")\\n    match = pattern.search(line)\\n    return match.group(0) if match else none' or '<host>' in 'import re\\n\\ndef isvalidip(ip):\\n    \"\"\"\\n    validate if the given string is a valid ipv4 address.\\n    \"\"\"\\n    pat...ile(r\"(?:[0-9]{1,3}\\\\.){3}[0-9]{1,3}\")\\n    match = pattern.search(line)\\n    return match.group(0) if match else none')", "returncode": 1, "elapsed_time_s": 2.099026, "avg_memory_mb": 32.12, "avg_cpu_percent": 69.8, "passed": 9, "failed": 3, "skipped": 0, "total": 12, "functional_score": 0.75, "timestamp": "2025-12-31 13:00:50", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\n\\ndef isvalidip(ip):\\n    \"\"\"\\n    validate if the given string is a valid ipv4 address.\\n    \"\"\"\\n    pat...ile(r\"(?:[0-9]{1,3}\\\\.){3}[0-9]{1,3}\")\\n    match = pattern.search(line)\\n    return match.group(0) if match else none' or '<host>' in 'import re\\n\\ndef isvalidip(ip):\\n    \"\"\"\\n    validate if the given string is a valid ipv4 address.\\n    \"\"\"\\n    pat...ile(r\"(?:[0-9]{1,3}\\\\.){3}[0-9]{1,3}\")\\n    match = pattern.search(line)\\n    return match.group(0) if match else none')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.", "stdout_sha1": "9eb3f729fa613ca5532f14bea6a0e108d8e2c647", "stdout_len": 5847, "stdout": "...F....F..F                                                             [100%]\n================================== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\n\\ndef isvalidip(ip):\\n    \"\"\"\\n    validate if the given string is a valid ipv4 address.\\n    \"\"\"\\n    pat...ile(r\"(?:[0-9]{1,3}\\\\.){3}[0-9]{1,3}\")\\n    match = pattern.search(line)\\n    return match.group(0) if match else none' or '<host>' in 'import re\\n\\ndef isvalidip(ip):\\n    \"\"\"\\n    validate if the given string is a valid ipv4 address.\\n    \"\"\"\\n    pat...ile(r\"(?:[0-9]{1,3}\\\\.){3}[0-9]{1,3}\")\\n    match = pattern.search(line)\\n    return match.group(0) if match else none')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n___________ test_012_fail2ban_regex_matches_simple_pattern_offline ____________\n\n    def test_012_fail2ban_regex_matches_simple_pattern_offline():\n        \"\"\"\n        Offline-only functional check:\n        - Create a temp log with repeated failure lines.\n        - Run fail2ban-regex <LOG> <REGEX>\n        - Assert output indicates it processed lines and found matches.\n        \"\"\"\n        base = _resolve_repo_root()\n        script = base / \"bin\" / \"fail2ban-regex\"\n    \n        env = os.environ.copy()\n        env[\"PYTHONUNBUFFERED\"] = \"1\"\n        env[\"PYTHONPATH\"] = str(_resolve_repo_root()) + (os.pathsep + env[\"PYTHONPATH\"] if env.get(\"PYTHONPATH\") else \"\")\n    \n        with tempfile.TemporaryDirectory(prefix=\"racb_fail2ban_\") as td:\n            logp = Path(td) / \"auth.log\"\n            logp.write_text(\n                \"\\n\".join(\n                    [\n                        \"Failed password for invalid user root from 203.0.113.5 port 2222 ssh2\",\n                        \"Failed password for invalid user admin from 203.0.113.5 port 2223 ssh2\",\n                        \"Accepted password for user ok from 198.51.100.2 port 3333 ssh2\",\n                        \"Failed password for invalid user test from 203.0.113.9 port 4444 ssh2\",\n                    ]\n                ),\n                encoding=\"utf-8\",\n            )\n    \n            # Use a very simple regex (do not rely on <HOST> substitutions).\n            regex = r\"Failed password\"\n            p = subprocess.run(\n                [sys.executable, str(script), str(logp), regex],\n                text=True,\n                input=\"\",\n                capture_output=True,\n                timeout=30,\n                env=env,\n            )\n            out = _out(p)\n    \n            # Must not hang; and should show it processed lines.\n            assert (\"line\" in out) or (\"lines\" in out)\n            # Try to detect match reporting; be tolerant across versions.\n>           assert (\"match\" in out) or (\"found\" in out) or (\"failregex\" in out)\nE           assert ('match' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'found' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n' or 'failregex' in '\\ntraceback (most recent call last):\\n  file \"d:\\\\桌面\\\\realappcodebench_generic_eval\\\\generation\\\\fail2ban\\\\bin\\\\fail2...error(action, message % conflict_string)\\nargparse.argumenterror: argument --help: conflicting option string: --help\\n')\n\ntests\\Fail2ban\\functional_test.py:248: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\nFAILED tests/Fail2ban/functional_test.py::test_012_fail2ban_regex_matches_simple_pattern_offline\n3 failed, 9 passed in 0.97s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword", "returncode": 1, "elapsed_time_s": 1.537129, "avg_memory_mb": 32.12, "avg_cpu_percent": 97.8, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2025-12-31 13:01:01", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.Marker([0, 0], tooltip=\"t\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'tooltip'\n\ntests\\Folium\\functional_test.py:69: TypeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.CircleMarker([0, 0], radius=5).add_to(m)\nE       AttributeError: 'CircleMarker' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:82: AttributeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n>       folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:92: TypeError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, name=\"g\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:115: TypeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-266/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       mc = MarkerCluster(name=\"mc\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword", "stdout_sha1": "14e726a3303e1abc8dcdecc3c5801104e9610e7a", "stdout_len": 4857, "stdout": "....FFFFFF.F                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.Marker([0, 0], tooltip=\"t\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'tooltip'\n\ntests\\Folium\\functional_test.py:69: TypeError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.CircleMarker([0, 0], radius=5).add_to(m)\nE       AttributeError: 'CircleMarker' object has no attribute 'add_to'\n\ntests\\Folium\\functional_test.py:82: AttributeError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n>       folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:92: TypeError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, name=\"g\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:115: TypeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-266/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       mc = MarkerCluster(name=\"mc\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'name'\n\ntests\\Folium\\functional_test.py:174: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n7 failed, 5 passed in 0.41s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "naturaltime() got an unexpected keyword argument 'when'", "returncode": 1, "elapsed_time_s": 1.511552, "avg_memory_mb": 31.68, "avg_cpu_percent": 102.2, "passed": 6, "failed": 4, "skipped": 5, "total": 15, "functional_score": 0.4, "timestamp": "2025-12-31 13:01:24", "stdout_excerpt": "==== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n_________________________ test_naturalsize_binary_kib _________________________\n\n    def test_naturalsize_binary_kib() -> None:\n        s = humanize.naturalsize(1536, binary=True)\n        assert isinstance(s, str)\n        assert s\n        # Compatible across versions: \"KiB\" (common) or any case variant.\n>       assert (\"KiB\" in s) or (\"kib\" in s.lower())\nE       AssertionError: assert ('KiB' in '1.5 KB' or 'kib' in '1.5 kb')\nE        +  where '1.5 kb' = <built-in method lower of str object at 0x000002D06075B670>()\nE        +    where <built-in method lower of str object at 0x000002D06075B670> = '1.5 KB'.lower\n\ntests\\Humanize\\functional_test.py:148: AssertionError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturalsize_binary_kib - Asser...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n4 failed, 6 passed, 5 skipped in 0.37s\n", "stdout_sha1": "2cae9da244579e47ec3d5d8493dd5bdde9377a6a", "stdout_len": 2444, "stdout": "..F..F.F.Fsssss                                                          [100%]\n================================== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1.0 KB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?     ^\nE         + 1.0 KB\nE         ?     ^\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n_________________________ test_naturalsize_binary_kib _________________________\n\n    def test_naturalsize_binary_kib() -> None:\n        s = humanize.naturalsize(1536, binary=True)\n        assert isinstance(s, str)\n        assert s\n        # Compatible across versions: \"KiB\" (common) or any case variant.\n>       assert (\"KiB\" in s) or (\"kib\" in s.lower())\nE       AssertionError: assert ('KiB' in '1.5 KB' or 'kib' in '1.5 kb')\nE        +  where '1.5 kb' = <built-in method lower of str object at 0x000002D06075B670>()\nE        +    where <built-in method lower of str object at 0x000002D06075B670> = '1.5 KB'.lower\n\ntests\\Humanize\\functional_test.py:148: AssertionError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturalsize_binary_kib - Asser...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n4 failed, 6 passed, 5 skipped in 0.37s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "imwrite() got an unexpected keyword argument 'extension'", "returncode": 1, "elapsed_time_s": 1.917308, "avg_memory_mb": 46.2, "avg_cpu_percent": 101.7, "passed": 4, "failed": 6, "skipped": 0, "total": 10, "functional_score": 0.4, "timestamp": "2025-12-31 13:01:35", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_multiframe_roundtrip_0/anim.gif')\nimage = array([[[175,  48,   5, ..., 108, 239,  95],\n        [239,  95,  27, ..., 228,  72, 250],\n        [155, 220,  51, ...,...99, 236, 251],\n        [120, 166, 247, ..., 100, 131,  54],\n        [ 79, 139,  45, ..., 112, 215,  45]]], dtype=uint8)\n\n    def imwrite(uri, image):\n        \"\"\"\n        Write an image or an animated image to the specified URI.\n    \n        Parameters:\n            uri (str or pathlib.Path): The file path to write the image to.\n            image (numpy.ndarray): The image data to write. Can be 2D, 3D, or 4D.\n        \"\"\"\n        uri = Path(uri)\n        if image.ndim == 2:  # Grayscale image\n            img = Image.fromarray(image)\n            img.save(uri, format=\"PNG\")\n        elif image.ndim == 3:\n            if image.shape[2] == 1:  # Grayscale image with single channel\n                img = Image.fromarray(image.squeeze(-1))\n                img.save(uri, format=\"PNG\")\n            elif image.shape[2] == 3:  # RGB image\n                img = Image.fromarray(image)\n                img.save(uri, format=\"PNG\")\n            else:\n>               raise ValueError(\"Unsupported 3D array shape for imwrite.\")\nE               ValueError: Unsupported 3D array shape for imwrite.\n\ngeneration\\Imageio\\imageio\\v3.py:27: ValueError\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_imread_returns_stack_0/stack.gif')\nimage = array([[[175,  48,   5, ..., 173,  66,  93],\n        [108, 239,  95, ...,  84,  50,  73],\n        [  3,  59, 140, ...,...18,  26, 217],\n        [255, 220, 204, ...,  46,  65,  79],\n        [235, 162, 251, ..., 155,  10, 108]]], dtype=uint8)\n\n    def imwrite(uri, image):\n        \"\"\"\n        Write an image or an animated image to the specified URI.\n    \n        Parameters:\n            uri (str or pathlib.Path): The file path to write the image to.\n            image (numpy.ndarray): The image data to write. Can be 2D, 3D, or 4D.\n        \"\"\"\n        uri = Path(uri)\n        if image.ndim == 2:  # Grayscale image\n            img = Image.fromarray(image)\n            img.save(uri, format=", "stdout_sha1": "4e2bf50773322bcef52100b61b4ca21ab04cb6f8", "stdout_len": 10318, "stdout": ".F.F..FFFF                                                               [100%]\n================================== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_multiframe_roundtrip_0/anim.gif')\nimage = array([[[175,  48,   5, ..., 108, 239,  95],\n        [239,  95,  27, ..., 228,  72, 250],\n        [155, 220,  51, ...,...99, 236, 251],\n        [120, 166, 247, ..., 100, 131,  54],\n        [ 79, 139,  45, ..., 112, 215,  45]]], dtype=uint8)\n\n    def imwrite(uri, image):\n        \"\"\"\n        Write an image or an animated image to the specified URI.\n    \n        Parameters:\n            uri (str or pathlib.Path): The file path to write the image to.\n            image (numpy.ndarray): The image data to write. Can be 2D, 3D, or 4D.\n        \"\"\"\n        uri = Path(uri)\n        if image.ndim == 2:  # Grayscale image\n            img = Image.fromarray(image)\n            img.save(uri, format=\"PNG\")\n        elif image.ndim == 3:\n            if image.shape[2] == 1:  # Grayscale image with single channel\n                img = Image.fromarray(image.squeeze(-1))\n                img.save(uri, format=\"PNG\")\n            elif image.shape[2] == 3:  # RGB image\n                img = Image.fromarray(image)\n                img.save(uri, format=\"PNG\")\n            else:\n>               raise ValueError(\"Unsupported 3D array shape for imwrite.\")\nE               ValueError: Unsupported 3D array shape for imwrite.\n\ngeneration\\Imageio\\imageio\\v3.py:27: ValueError\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_imread_returns_stack_0/stack.gif')\nimage = array([[[175,  48,   5, ..., 173,  66,  93],\n        [108, 239,  95, ...,  84,  50,  73],\n        [  3,  59, 140, ...,...18,  26, 217],\n        [255, 220, 204, ...,  46,  65,  79],\n        [235, 162, 251, ..., 155,  10, 108]]], dtype=uint8)\n\n    def imwrite(uri, image):\n        \"\"\"\n        Write an image or an animated image to the specified URI.\n    \n        Parameters:\n            uri (str or pathlib.Path): The file path to write the image to.\n            image (numpy.ndarray): The image data to write. Can be 2D, 3D, or 4D.\n        \"\"\"\n        uri = Path(uri)\n        if image.ndim == 2:  # Grayscale image\n            img = Image.fromarray(image)\n            img.save(uri, format=\"PNG\")\n        elif image.ndim == 3:\n            if image.shape[2] == 1:  # Grayscale image with single channel\n                img = Image.fromarray(image.squeeze(-1))\n                img.save(uri, format=\"PNG\")\n            elif image.shape[2] == 3:  # RGB image\n                img = Image.fromarray(image)\n                img.save(uri, format=\"PNG\")\n            else:\n>               raise ValueError(\"Unsupported 3D array shape for imwrite.\")\nE               ValueError: Unsupported 3D array shape for imwrite.\n\ngeneration\\Imageio\\imageio\\v3.py:27: ValueError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_gif_imread_index0_matches0/index0.gif')\nimage = array([[[175,  48,   5, ...,  93, 108, 239],\n        [ 95, 239,  95, ...,  59, 140, 228],\n        [ 72, 250, 155, ...,...57, 165, 255],\n        [ 18,  28,  29, ..., 155, 216, 213],\n        [219, 124,  59, ..., 250, 200, 138]]], dtype=uint8)\n\n    def imwrite(uri, image):\n        \"\"\"\n        Write an image or an animated image to the specified URI.\n    \n        Parameters:\n            uri (str or pathlib.Path): The file path to write the image to.\n            image (numpy.ndarray): The image data to write. Can be 2D, 3D, or 4D.\n        \"\"\"\n        uri = Path(uri)\n        if image.ndim == 2:  # Grayscale image\n            img = Image.fromarray(image)\n            img.save(uri, format=\"PNG\")\n        elif image.ndim == 3:\n            if image.shape[2] == 1:  # Grayscale image with single channel\n                img = Image.fromarray(image.squeeze(-1))\n                img.save(uri, format=\"PNG\")\n            elif image.shape[2] == 3:  # RGB image\n                img = Image.fromarray(image)\n                img.save(uri, format=\"PNG\")\n            else:\n>               raise ValueError(\"Unsupported 3D array shape for imwrite.\")\nE               ValueError: Unsupported 3D array shape for imwrite.\n\ngeneration\\Imageio\\imageio\\v3.py:27: ValueError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n____________ test_improps_for_gif_has_expected_spatial_dimensions _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_improps_for_gif_has_expec0')\n\n    def test_improps_for_gif_has_expected_spatial_dimensions(tmp_path: Path) -> None:\n        \"\"\"improps on a GIF should include the written frame height/width in its reported shape.\n    \n        In practice, different plugins/paths can report shapes like:\n          - (T, H, W)\n          - (T, H, W, C)\n          - (H, W, C)\n          - (W, H, C)\n        Therefore we validate that the expected H and W appear somewhere in props.shape,\n        without assuming their exact positions.\n        \"\"\"\n        frames = _make_grayscale_frames(num_frames=3, height=17, width=19)\n        path = tmp_path / \"props.gif\"\n    \n>       iio.imwrite(path, frames)\n\ntests\\Imageio\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nuri = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-269/test_improps_for_gif_has_expec0/props.gif')\nimage = array([[[175,  48,   5,  97, 162,  98,  32, 180, 237, 234,  27, 119,\n         129, 130, 192, 109,  49,  37, 173],\n    ...193, 108,  94, 224, 102,  31,  61, 217, 175, 231, 194, 199,\n          97, 107,  97,  61, 152,  69, 111]]], dtype=uint8)\n\n    def imwrite(uri, image):\n        \"\"\"\n        Write an image or an animated image to the specified URI.\n    \n        Parameters:\n            uri (str or pathlib.Path): The file path to write the image to.\n            image (numpy.ndarray): The image data to write. Can be 2D, 3D, or 4D.\n        \"\"\"\n        uri = Path(uri)\n        if image.ndim == 2:  # Grayscale image\n            img = Image.fromarray(image)\n            img.save(uri, format=\"PNG\")\n        elif image.ndim == 3:\n            if image.shape[2] == 1:  # Grayscale image with single channel\n                img = Image.fromarray(image.squeeze(-1))\n                img.save(uri, format=\"PNG\")\n            elif image.shape[2] == 3:  # RGB image\n                img = Image.fromarray(image)\n                img.save(uri, format=\"PNG\")\n            else:\n>               raise ValueError(\"Unsupported 3D array shape for imwrite.\")\nE               ValueError: Unsupported 3D array shape for imwrite.\n\ngeneration\\Imageio\\imageio\\v3.py:27: ValueError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_gif_multiframe_roundtrip_with_imiter\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\nFAILED tests/Imageio/functional_test.py::test_improps_for_gif_has_expected_spatial_dimensions\n6 failed, 4 passed in 0.82s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Lifelines", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 2.123335, "avg_memory_mb": 68.93, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:01:51", "stdout_excerpt": "\n1 skipped in 0.95s\n", "stdout_sha1": "33314373b9348182522136c3368ea6d0edcc7a03", "stdout_len": 20, "stdout": "\n1 skipped in 0.95s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Loguru", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "remove() missing 1 required positional argument: 'sink_id'", "returncode": 1, "elapsed_time_s": 1.555729, "avg_memory_mb": 32.21, "avg_cpu_percent": 98.9, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 13:02:01", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "b6fe21a593c3ccc6ee17881513391607cc704bcb", "stdout_len": 9962, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} user={extra[user]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n__________________ test_multiple_sinks_receive_same_message ___________________\n\n    def test_multiple_sinks_receive_same_message() -> None:\n        buf1 = io.StringIO()\n        buf2 = io.StringIO()\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:161: TypeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-270/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:178: TypeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n>       log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n\ntests\\Loguru\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n>       log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n\ntests\\Loguru\\functional_test.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} patched={extra[patched]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n\ntests\\Loguru\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:81: TypeError\n____________________ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format() -> None:\n        # Default format should include some timestamp-like content, level, and message.\n        buf = io.StringIO()\n>       logger.remove()\nE       TypeError: remove() missing 1 required positional argument: 'sink_id'\n\ntests\\Loguru\\functional_test.py:237: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - Ty...\nFAILED tests/Loguru/functional_test.py::test_level_filtering - TypeError: rem...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Typ...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Type...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_multiple_sinks_receive_same_message\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Typ...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n11 failed in 0.47s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 1.532494, "avg_memory_mb": 36.29, "avg_cpu_percent": 102.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:02:12", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.43s\n", "stdout_sha1": "8c622b36dfd7a19282d3cc1510fe2316bcd7a43d", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.43s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert ('<em>' in '<p>Second document with *emphasis*.</p>' or '<i>' in '<p>Second document with *emphasis*.</p>')", "returncode": 1, "elapsed_time_s": 1.552397, "avg_memory_mb": 32.64, "avg_cpu_percent": 100.0, "passed": 4, "failed": 6, "skipped": 9, "total": 19, "functional_score": 0.2105, "timestamp": "2025-12-31 13:02:22", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_emphasis_and_strong ___________________________\n\n    def test_emphasis_and_strong() -> None:\n        src = \"This is *italic* and **bold** and __also bold__.\"\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<em>\" in norm and \"</em>\" in norm\nE       AssertionError: assert ('<em>' in '<p>This is *italic* and **bold** and __also bold__.</p>')\n\ntests\\Markdown\\functional_test.py:122: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       AssertionError: assert ('<a ' in '<p>A [link](https://example.com) and an image: ![alt text](https://example.com/image.png)</p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n__________________ test_markdown_class_multiple_conversions ___________________\n\n    def test_markdown_class_multiple_conversions() -> None:\n        src1 = \"# First\\n\\nParagraph.\"\n        src2 = \"Second document with *emphasis*.\"\n    \n        md = markdown.Markdown()\n        html1 = md.convert(src1)\n        if hasattr(md, \"reset\"):\n            md.reset()\n        html2 = md.convert(src2)\n    \n        norm1 = normalize_html(html1)\n        norm2 = normalize_html(html2)\n    \n        assert \"First\" in norm1\n        assert \"Paragraph.\" in norm1\n        assert \"<h1>\" in norm1\n    \n        assert \"Second document\" in norm2\n>       assert \"<em>\" in norm2 or \"<i>\" in norm2\nE       AssertionError: assert ('<em>' in '<p>Second document with *emphasis*.</p>' or '<i>' in '<p>Second document with *emphasis*.</p>')\n\ntests\\Markdown\\functional_test.py:231: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-271/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n>       markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n\ntests\\Markdown\\functional_test.py:246: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ninput_file = None, output_file = None, encoding = 'utf-8'\nkwargs = {'input': 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-271\\\\test_markdown_from_file0\\\\input.md', 'output': 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-271\\\\test_markdown_from_file0\\\\output.html'}\n\n    def markdownFromFile(input_file=None, output_file=None, encoding=\"utf-8\", **kwargs):\n        \"\"\"\n        Convert Markdown text from a file to HTML.\n    \n        :param input_file: Path to the input Markdown file.\n        :param output_file: Path to the output HTML file (optional).\n        :param enco", "stdout_sha1": "134e3c6642e1f54b49e58febc5aaefbedde4e45f", "stdout_len": 5618, "stdout": ".F...FFFFFsssssssss                                                      [100%]\n================================== FAILURES ===================================\n__________________________ test_emphasis_and_strong ___________________________\n\n    def test_emphasis_and_strong() -> None:\n        src = \"This is *italic* and **bold** and __also bold__.\"\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<em>\" in norm and \"</em>\" in norm\nE       AssertionError: assert ('<em>' in '<p>This is *italic* and **bold** and __also bold__.</p>')\n\ntests\\Markdown\\functional_test.py:122: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       AssertionError: assert ('<a ' in '<p>A [link](https://example.com) and an image: ![alt text](https://example.com/image.png)</p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n__________________ test_markdown_class_multiple_conversions ___________________\n\n    def test_markdown_class_multiple_conversions() -> None:\n        src1 = \"# First\\n\\nParagraph.\"\n        src2 = \"Second document with *emphasis*.\"\n    \n        md = markdown.Markdown()\n        html1 = md.convert(src1)\n        if hasattr(md, \"reset\"):\n            md.reset()\n        html2 = md.convert(src2)\n    \n        norm1 = normalize_html(html1)\n        norm2 = normalize_html(html2)\n    \n        assert \"First\" in norm1\n        assert \"Paragraph.\" in norm1\n        assert \"<h1>\" in norm1\n    \n        assert \"Second document\" in norm2\n>       assert \"<em>\" in norm2 or \"<i>\" in norm2\nE       AssertionError: assert ('<em>' in '<p>Second document with *emphasis*.</p>' or '<i>' in '<p>Second document with *emphasis*.</p>')\n\ntests\\Markdown\\functional_test.py:231: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-271/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n>       markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n\ntests\\Markdown\\functional_test.py:246: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ninput_file = None, output_file = None, encoding = 'utf-8'\nkwargs = {'input': 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-271\\\\test_markdown_from_file0\\\\input.md', 'output': 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-271\\\\test_markdown_from_file0\\\\output.html'}\n\n    def markdownFromFile(input_file=None, output_file=None, encoding=\"utf-8\", **kwargs):\n        \"\"\"\n        Convert Markdown text from a file to HTML.\n    \n        :param input_file: Path to the input Markdown file.\n        :param output_file: Path to the output HTML file (optional).\n        :param encoding: File encoding (default: utf-8).\n        :param kwargs: Additional options (not implemented in this basic version).\n        \"\"\"\n        if input_file is None:\n>           raise ValueError(\"input_file must be specified\")\nE           ValueError: input_file must be specified\n\ngeneration\\Markdown\\markdown\\core.py:110: ValueError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<ul>\\n<li>--</li>\\n</ul>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_emphasis_and_strong - Assertio...\nFAILED tests/Markdown/functional_test.py::test_links_and_images - AssertionEr...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_class_multiple_conversions\nFAILED tests/Markdown/functional_test.py::test_markdown_from_file - ValueErro...\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n6 failed, 4 passed, 9 skipped in 0.45s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "FileNotFoundError", "exception_msg": "[Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'", "returncode": 1, "elapsed_time_s": 1.597045, "avg_memory_mb": 33.02, "avg_cpu_percent": 100.0, "passed": 4, "failed": 7, "skipped": 0, "total": 11, "functional_score": 0.3636, "timestamp": "2025-12-31 13:02:32", "stdout_excerpt": "==== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs", "stdout_sha1": "e254dfeba67c8925a7eaae0d56211a68280b687f", "stdout_len": 7137, "stdout": "..FF.FF.FFF                                                              [100%]\n================================== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_003_version_source_file_exists_and_has_version_like_token\nFAILED tests/Mitmproxy/functional_test.py::test_004_tools_main_file_exists - ...\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_007_tools_main_defines_mitmdump_function_or_wrapper\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n7 failed, 4 passed in 0.48s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.211539, "avg_memory_mb": 30.67, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:02:42", "stdout_excerpt": "\n1 skipped in 0.10s\n", "stdout_sha1": "5ee49fd678cee172b4a38cd2b3fed6a83f610490", "stdout_len": 20, "stdout": "\n1 skipped in 0.10s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'pendulum' has no attribute 'date'", "returncode": 1, "elapsed_time_s": 1.90792, "avg_memory_mb": 31.58, "avg_cpu_percent": 100.9, "passed": 1, "failed": 11, "skipped": 1, "total": 13, "functional_score": 0.0769, "timestamp": "2025-12-31 13:02:53", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n>       assert dt_utc.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:68: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n>       shifted = base.add(days=2, hours=5, minutes=15)\nE       TypeError: add() got an unexpected keyword argument 'days'\n\ntests\\Pendulum\\functional_test.py:89: TypeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\nE       TypeError: add() got an unexpected keyword argument 'months'\n\ntests\\Pendulum\\functional_test.py:104: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n>       assert d.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:118: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n>       dt_ny = dt_utc.in_timezone(\"America/New_York\")\n\ntests\\Pendulum\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:38: in in_timezone\n    tz = timezone(tz)\ngeneration\\Pendulum\\pend", "stdout_sha1": "f25fb772e25d42b1853894ac90b01d3f792149c3", "stdout_len": 6424, "stdout": "FFFFFFFF.sFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n>       assert dt_utc.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:68: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n>       shifted = base.add(days=2, hours=5, minutes=15)\nE       TypeError: add() got an unexpected keyword argument 'days'\n\ntests\\Pendulum\\functional_test.py:89: TypeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\nE       TypeError: add() got an unexpected keyword argument 'months'\n\ntests\\Pendulum\\functional_test.py:104: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n>       assert d.year == 2020\nE       AttributeError: 'DateTime' object has no attribute 'year'\n\ntests\\Pendulum\\functional_test.py:118: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n>       dt_ny = dt_utc.in_timezone(\"America/New_York\")\n\ntests\\Pendulum\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\datetime.py:38: in in_timezone\n    tz = timezone(tz)\ngeneration\\Pendulum\\pendulum\\timezone.py:17: in timezone\n    return Timezone(name).to_datetime_timezone()\ngeneration\\Pendulum\\pendulum\\timezone.py:6: in __init__\n    self.offset = self._get_offset(name)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pendulum.timezone.Timezone object at 0x0000020F0A9D9BE0>\nname = 'America/New_York'\n\n    def _get_offset(self, name):\n        if name == \"UTC\":\n            return timedelta(0)\n>       raise ValueError(f\"Unsupported timezone: {name}\")\nE       ValueError: Unsupported timezone: America/New_York\n\ngeneration\\Pendulum\\pendulum\\timezone.py:11: ValueError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_datetime_arithmetic_and_duration\nFAILED tests/Pendulum/functional_test.py::test_diff_for_humans_months - TypeE...\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n11 failed, 1 passed, 1 skipped in 0.57s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Petl", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'function' object is not iterable", "returncode": 1, "elapsed_time_s": 1.678117, "avg_memory_mb": 32.57, "avg_cpu_percent": 102.0, "passed": 1, "failed": 5, "skipped": 6, "total": 12, "functional_score": 0.0833, "timestamp": "2025-12-31 13:03:04", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = <function select.<locals>.filtered at 0x000002A5488DC700>\n\n    def _table_to_list_of_dicts(table: Iterable[Iterable[Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Convert a petl table into a list of dictionaries using the header row.\"\"\"\n>       iterator = iter(table)\nE       TypeError: 'function' object is not iterable\n\ntests\\Petl\\functional_test.py:81: TypeError\n_______________________ test_join_two_tables_fromdicts ________________________\n\n    def test_join_two_tables_fromdicts() -> None:\n        \"\"\"Check that an inner join between two small tables behaves as expected.\"\"\"\n        customers = [\n            {\"id\": 1, \"name\": \"Alice\"},\n            {\"id\": 2, \"name\": \"Bob\"},\n            {\"id\": 3, \"name\": \"Carol\"},\n        ]\n        orders = [\n            {\"id\": 1, \"amount\": 100},\n            {\"id\": 1, \"amount\": 50},\n            {\"id\": 2, \"amount\": 200},\n        ]\n    \n        customers_tbl = petl.fromdicts(customers, header=[\"id\", \"name\"])\n        orders_tbl = petl.fromdicts(orders, header=[\"id\", \"amount\"])\n    \n        joined = petl.join(customers_tbl, orders_tbl, key=\"id\")\n>       result = _table_to_list_of_dicts(joined)\n\ntests\\Petl\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = <function join.<locals>.joined at 0x000002A548918670>\n\n    def _table_to_list_of_dicts(table: Iterable[Iterable[Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Convert a petl table into a list of dictionaries using the header row.\"\"\"\n>       iterator = iter(table)\nE       TypeError: 'function' object is not iterable\n\ntests\\Petl\\functional_test.py:81: TypeError\n________________ test_convert_with_lambda_and_values_preserved ________________\n\n    def test_convert_with_lambda_and_values_preserved() -> None:\n        \"\"\"Convert a column with a lambda and verify new typed values.\"\"\"\n        records = [\n            {\"id\": \"1\", \"amount\": \"100\"},\n            {\"id\": \"2\", \"amount\": \"250\"},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"amount\"])\n    \n        converted = petl.convert(table, \"amount\", lambda v: int(v) + 1)\n>       rows = _table_to_list_of_dicts(converted)\n\ntests\\Petl\\functional_test.py:260: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = <function convert.<locals>.transformed at 0x000002A548918C10>\n\n    def _table_to_list_of_dicts(table: Iterable[Iterable[Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Convert a petl table into a list of dictionaries using the header row.\"\"\"\n>       iterator = iter(table)\nE       TypeError: 'function' object is not iterable\n\ntests\\Petl\\functional_test.py:81: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>    ", "stdout_sha1": "7860edc096b0472c2a2fb13b61fae12eab721529", "stdout_len": 5575, "stdout": ".FFssFFsFsss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = <function select.<locals>.filtered at 0x000002A5488DC700>\n\n    def _table_to_list_of_dicts(table: Iterable[Iterable[Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Convert a petl table into a list of dictionaries using the header row.\"\"\"\n>       iterator = iter(table)\nE       TypeError: 'function' object is not iterable\n\ntests\\Petl\\functional_test.py:81: TypeError\n_______________________ test_join_two_tables_fromdicts ________________________\n\n    def test_join_two_tables_fromdicts() -> None:\n        \"\"\"Check that an inner join between two small tables behaves as expected.\"\"\"\n        customers = [\n            {\"id\": 1, \"name\": \"Alice\"},\n            {\"id\": 2, \"name\": \"Bob\"},\n            {\"id\": 3, \"name\": \"Carol\"},\n        ]\n        orders = [\n            {\"id\": 1, \"amount\": 100},\n            {\"id\": 1, \"amount\": 50},\n            {\"id\": 2, \"amount\": 200},\n        ]\n    \n        customers_tbl = petl.fromdicts(customers, header=[\"id\", \"name\"])\n        orders_tbl = petl.fromdicts(orders, header=[\"id\", \"amount\"])\n    \n        joined = petl.join(customers_tbl, orders_tbl, key=\"id\")\n>       result = _table_to_list_of_dicts(joined)\n\ntests\\Petl\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = <function join.<locals>.joined at 0x000002A548918670>\n\n    def _table_to_list_of_dicts(table: Iterable[Iterable[Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Convert a petl table into a list of dictionaries using the header row.\"\"\"\n>       iterator = iter(table)\nE       TypeError: 'function' object is not iterable\n\ntests\\Petl\\functional_test.py:81: TypeError\n________________ test_convert_with_lambda_and_values_preserved ________________\n\n    def test_convert_with_lambda_and_values_preserved() -> None:\n        \"\"\"Convert a column with a lambda and verify new typed values.\"\"\"\n        records = [\n            {\"id\": \"1\", \"amount\": \"100\"},\n            {\"id\": \"2\", \"amount\": \"250\"},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"amount\"])\n    \n        converted = petl.convert(table, \"amount\", lambda v: int(v) + 1)\n>       rows = _table_to_list_of_dicts(converted)\n\ntests\\Petl\\functional_test.py:260: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntable = <function convert.<locals>.transformed at 0x000002A548918C10>\n\n    def _table_to_list_of_dicts(table: Iterable[Iterable[Any]]) -> List[Dict[str, Any]]:\n        \"\"\"Convert a petl table into a list of dictionaries using the header row.\"\"\"\n>       iterator = iter(table)\nE       TypeError: 'function' object is not iterable\n\ntests\\Petl\\functional_test.py:81: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-272/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n>       rows = list(table2)\nE       TypeError: 'function' object is not iterable\n\ntests\\Petl\\functional_test.py:328: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_join_two_tables_fromdicts - TypeEr...\nFAILED tests/Petl/functional_test.py::test_convert_with_lambda_and_values_preserved\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n5 failed, 1 passed, 6 skipped in 0.50s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.365368, "avg_memory_mb": 14.15, "avg_cpu_percent": 100.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:03:08", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n", "stdout_sha1": "3d43d73e26be0f48c50fe96012d3c4dcf351a1b9", "stdout_len": 1401, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n"}
{"model": "gpt-4o-2024-11-20", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.609031, "avg_memory_mb": 33.78, "avg_cpu_percent": 101.0, "passed": 5, "failed": 5, "skipped": 1, "total": 11, "functional_score": 0.4545, "timestamp": "2025-12-31 13:03:19", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 is supported in this implementation.\")\nE           NotImplementedError: Only HS256 is supported in this implementation.\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:17: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: in encode\n    payload_b64 = base64url_encode(json.dumps(payload).encode(\"utf-8\"))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:231: in dumps\n    return _default_encoder.encode(obj)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000025FC186B250>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: in encode\n    payload_b64 = base64url_encode(json.dumps(payload).enco", "stdout_sha1": "831c9edfc9c6e07c515c749474bfcb0a67fa31d5", "stdout_len": 8350, "stdout": ".F.FF...FFs                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 is supported in this implementation.\")\nE           NotImplementedError: Only HS256 is supported in this implementation.\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:17: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: in encode\n    payload_b64 = base64url_encode(json.dumps(payload).encode(\"utf-8\"))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:231: in dumps\n    return _default_encoder.encode(obj)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000025FC186B250>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: in encode\n    payload_b64 = base64url_encode(json.dumps(payload).encode(\"utf-8\"))\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:231: in dumps\n    return _default_encoder.encode(obj)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000025FC186B250>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n_________________________ test_decode_with_bytes_key __________________________\n\n    def test_decode_with_bytes_key() -> None:\n        payload = {\"user\": \"bob\", \"plan\": \"pro\"}\n        key = b\"secret-bytes\"\n>       decoded = _encode_decode(payload, key=key, algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'plan': 'pro', 'user': 'bob'}, key = b'secret-bytes'\nalgorithm = 'HS256', kwargs = {}, header = {'alg': 'HS256', 'typ': 'JWT'}\nheader_b64 = 'eyJhbGciOiAiSFMyNTYiLCAidHlwIjogIkpXVCJ9'\npayload_b64 = 'eyJ1c2VyIjogImJvYiIsICJwbGFuIjogInBybyJ9'\nsigning_input = b'eyJhbGciOiAiSFMyNTYiLCAidHlwIjogIkpXVCJ9.eyJ1c2VyIjogImJvYiIsICJwbGFuIjogInBybyJ9'\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n            raise NotImplementedError(\"Only HS256 is supported in this implementation.\")\n    \n        header = {\"alg\": algorithm, \"typ\": \"JWT\"}\n        header_b64 = base64url_encode(json.dumps(header).encode(\"utf-8\"))\n        payload_b64 = base64url_encode(json.dumps(payload).encode(\"utf-8\"))\n    \n        signing_input = f\"{header_b64}.{payload_b64}\".encode(\"utf-8\")\n>       signature = hmac.new(key.encode(\"utf-8\"), signing_input, hashlib.sha256).digest()\nE       AttributeError: 'bytes' object has no attribute 'encode'\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:24: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\nFAILED tests/PyJWT/functional_test.py::test_decode_with_bytes_key - Attribute...\n5 failed, 5 passed, 1 skipped in 0.48s\n"}
{"model": "gpt-4o-2024-11-20", "project": "PyPDF", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.278271, "avg_memory_mb": 30.57, "avg_cpu_percent": 101.3, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:03:31", "stdout_excerpt": "\n1 skipped in 0.09s\n", "stdout_sha1": "ad3c0b911c7a11c016805aca6b7abd955253316d", "stdout_len": 20, "stdout": "\n1 skipped in 0.09s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.292252, "avg_memory_mb": 31.03, "avg_cpu_percent": 97.4, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:03:55", "stdout_excerpt": "\n1 skipped in 0.13s\n", "stdout_sha1": "4c4ceb412a81fcf19d92b45ee51d2d9a1553d8c3", "stdout_len": 20, "stdout": "\n1 skipped in 0.13s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'schedule' has no attribute 'clear'", "returncode": 1, "elapsed_time_s": 1.700906, "avg_memory_mb": 32.44, "avg_cpu_percent": 98.0, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 13:04:05", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n>       _clear()\n\nt", "stdout_sha1": "fb0b7b96d3e7e8b0c88d3cfd0843be181564cb62", "stdout_len": 7625, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:261: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_run_pending_executes_due_job_without_sleep\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_day_at_sets_time_component_in_next_run\nFAILED tests/Schedule/functional_test.py::test_weekday_scheduling_creates_job_and_next_run\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n12 failed in 0.51s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Slugify", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "normalize expected 2 arguments, got 1", "returncode": 1, "elapsed_time_s": 48.892004, "avg_memory_mb": 32.16, "avg_cpu_percent": 0.31, "passed": 1, "failed": 11, "skipped": 0, "total": 12, "functional_score": 0.0833, "timestamp": "2025-12-31 13:05:04", "stdout_excerpt": "==== FAILURES ===================================\n____________________________ test_basic_ascii_slug ____________________________\n\n    def test_basic_ascii_slug() -> None:\n        \"\"\"Basic ASCII text should be lowercased and separated by dashes.\"\"\"\n        text = \"This is a test ---\"\n>       result = slugify(text)\n\ntests\\Slugify\\functional_test.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'This is a test ---', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n____________ test_ascii_punctuation_collapses_to_single_separator _____________\n\n    def test_ascii_punctuation_collapses_to_single_separator() -> None:\n        \"\"\"Punctuation should be normalized so separators don't repeat.\"\"\"\n        text = \"Hello!!!  World??? -- Rich__Text\"\n>       result = slugify(text)\n\ntests\\Slugify\\functional_test.py:113: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'Hello!!!  World??? -- Rich__Text', allow_unicode = False\nmax_length = None, word_boundary = False, separator = '-', regex_pattern = None\nstopwords = None, lowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(tex", "stdout_sha1": "02bb2c04cb2d2207709048261b8c94c802dd77ef", "stdout_len": 26484, "stdout": "FFF.FFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n____________________________ test_basic_ascii_slug ____________________________\n\n    def test_basic_ascii_slug() -> None:\n        \"\"\"Basic ASCII text should be lowercased and separated by dashes.\"\"\"\n        text = \"This is a test ---\"\n>       result = slugify(text)\n\ntests\\Slugify\\functional_test.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'This is a test ---', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n____________ test_ascii_punctuation_collapses_to_single_separator _____________\n\n    def test_ascii_punctuation_collapses_to_single_separator() -> None:\n        \"\"\"Punctuation should be normalized so separators don't repeat.\"\"\"\n        text = \"Hello!!!  World??? -- Rich__Text\"\n>       result = slugify(text)\n\ntests\\Slugify\\functional_test.py:113: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'Hello!!!  World??? -- Rich__Text', allow_unicode = False\nmax_length = None, word_boundary = False, separator = '-', regex_pattern = None\nstopwords = None, lowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n_____________________ test_unicode_default_is_ascii_only ______________________\n\n    def test_unicode_default_is_ascii_only() -> None:\n        \"\"\"By default, unicode text should produce an ASCII-only slug.\n    \n        With the unidecode stub, non-ascii chars may be removed and result may be empty.\n        We only assert ASCII-only property.\n        \"\"\"\n        text = \"影師嗎\"\n>       result = slugify(text)\n\ntests\\Slugify\\functional_test.py:128: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = '影師嗎', allow_unicode = False, max_length = None, word_boundary = False\nseparator = '-', regex_pattern = None, stopwords = None, lowercase = True\nreplacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n__________________ test_max_length_truncation_respects_limit __________________\n\n    def test_max_length_truncation_respects_limit() -> None:\n        \"\"\"max_length should cap the resulting slug length.\"\"\"\n        text = \"one two three four five six seven\"\n>       result = slugify(text, max_length=10)\n\ntests\\Slugify\\functional_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'one two three four five six seven', allow_unicode = False\nmax_length = 10, word_boundary = False, separator = '-', regex_pattern = None\nstopwords = None, lowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n______________ test_word_boundary_keeps_whole_words_when_enabled ______________\n\n    def test_word_boundary_keeps_whole_words_when_enabled() -> None:\n        \"\"\"word_boundary=True should avoid cutting in the middle of a word (typical behavior).\"\"\"\n        text = \"alpha beta gamma delta\"\n>       result = slugify(text, max_length=12, word_boundary=True)\n\ntests\\Slugify\\functional_test.py:152: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'alpha beta gamma delta', allow_unicode = False, max_length = 12\nword_boundary = True, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n________________________ test_separator_customization _________________________\n\n    def test_separator_customization() -> None:\n        \"\"\"Custom separator should be used between tokens.\"\"\"\n        text = \"This is a test\"\n>       result = slugify(text, separator=\"_\")\n\ntests\\Slugify\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'This is a test', allow_unicode = False, max_length = None\nword_boundary = False, separator = '_', regex_pattern = None, stopwords = None\nlowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n>       result_default_sep = slugify(text, regex_pattern=regex_pattern)\n\ntests\\Slugify\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = '___This is a test___', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = '[^-a-z0-9_]+'\nstopwords = None, lowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n________________________ test_stopwords_remove_tokens _________________________\n\n    def test_stopwords_remove_tokens() -> None:\n        \"\"\"Stopwords should be removed from the slug.\"\"\"\n        text = \"the quick brown fox jumps over the lazy dog in a hurry\"\n>       result = slugify(text, stopwords=[\"the\", \"in\", \"a\", \"hurry\"])\n\ntests\\Slugify\\functional_test.py:183: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'the quick brown fox jumps over the lazy dog in a hurry'\nallow_unicode = False, max_length = None, word_boundary = False, separator = '-'\nregex_pattern = None, stopwords = ['the', 'in', 'a', 'hurry'], lowercase = True\nreplacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n__________ test_lowercase_false_preserves_case_for_remaining_tokens ___________\n\n    def test_lowercase_false_preserves_case_for_remaining_tokens() -> None:\n        \"\"\"lowercase=False should preserve original case for non-removed words.\"\"\"\n        mixed = \"thIs Has a stopword Stopword\"\n>       result = slugify(mixed, stopwords=[\"Stopword\"], lowercase=False)\n\ntests\\Slugify\\functional_test.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'thIs Has a stopword Stopword', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None\nstopwords = ['Stopword'], lowercase = False, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n___________________ test_replacements_apply_before_slugging ___________________\n\n    def test_replacements_apply_before_slugging() -> None:\n        \"\"\"replacements should transform substrings before final slug is produced.\"\"\"\n        text = \"C# is not C++\"\n>       result = slugify(text, replacements=[[\"C#\", \"Csharp\"], [\"C++\", \"Cpp\"]])\n\ntests\\Slugify\\functional_test.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = 'Csharp is not Cpp', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = [['C#', 'Csharp'], ['C++', 'Cpp']], kwargs = {}\nsearch = 'C++', replace = 'Cpp'\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n________________ test_trailing_and_leading_separators_trimmed _________________\n\n    def test_trailing_and_leading_separators_trimmed() -> None:\n        \"\"\"Slug should not start or end with the separator in normal usage.\"\"\"\n        text = \" --- spaced --- \"\n>       result = slugify(text)\n\ntests\\Slugify\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntext = ' --- spaced --- ', allow_unicode = False, max_length = None\nword_boundary = False, separator = '-', regex_pattern = None, stopwords = None\nlowercase = True, replacements = None, kwargs = {}\n\n    def slugify(\n        text,\n        allow_unicode=False,\n        max_length=None,\n        word_boundary=False,\n        separator='-',\n        regex_pattern=None,\n        stopwords=None,\n        lowercase=True,\n        replacements=None,\n        **kwargs\n    ):\n        \"\"\"\n        Generate a slug for the given text.\n    \n        Parameters:\n            text (str): The input text to slugify.\n            allow_unicode (bool): Whether to allow Unicode characters in the slug.\n            max_length (int): Maximum length of the slug.\n            word_boundary (bool): Ensure truncation happens at word boundaries.\n            separator (str): Separator to use for the slug.\n            regex_pattern (str): Custom regex pattern for filtering characters.\n            stopwords (list): Words to exclude from the slug.\n            lowercase (bool): Whether to convert the slug to lowercase.\n            replacements (list): List of (search, replace) tuples for custom replacements.\n    \n        Returns:\n            str: The generated slug.\n        \"\"\"\n        if not isinstance(text, str):\n            raise TypeError(\"Input text must be a string.\")\n    \n        # Apply custom replacements if provided\n        if replacements:\n            for search, replace in replacements:\n                text = text.replace(search, replace)\n    \n        # Normalize text to NFKD form for consistent processing\n        if not allow_unicode:\n>           text = unicodedata.normalize('NFKD').encode('ascii', 'ignore').decode('ascii')\nE           TypeError: normalize expected 2 arguments, got 1\n\ngeneration\\Slugify\\slugify\\slugify.py:43: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_basic_ascii_slug - TypeError: n...\nFAILED tests/Slugify/functional_test.py::test_ascii_punctuation_collapses_to_single_separator\nFAILED tests/Slugify/functional_test.py::test_unicode_default_is_ascii_only\nFAILED tests/Slugify/functional_test.py::test_max_length_truncation_respects_limit\nFAILED tests/Slugify/functional_test.py::test_word_boundary_keeps_whole_words_when_enabled\nFAILED tests/Slugify/functional_test.py::test_separator_customization - TypeE...\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\nFAILED tests/Slugify/functional_test.py::test_stopwords_remove_tokens - TypeE...\nFAILED tests/Slugify/functional_test.py::test_lowercase_false_preserves_case_for_remaining_tokens\nFAILED tests/Slugify/functional_test.py::test_replacements_apply_before_slugging\nFAILED tests/Slugify/functional_test.py::test_trailing_and_leading_separators_trimmed\n11 failed, 1 passed in 47.77s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('no such option' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n' or 'unrecognized' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n' or 'unknown' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n')", "returncode": 1, "elapsed_time_s": 3.377085, "avg_memory_mb": 32.17, "avg_cpu_percent": 53.3, "passed": 7, "failed": 2, "skipped": 0, "total": 9, "functional_score": 0.7778, "timestamp": "2025-12-31 13:05:19", "stdout_excerpt": "==== FAILURES ===================================\n_________________________ test_004_advanced_help_runs _________________________\n\n    def test_004_advanced_help_runs():\n        p = _run_cli([\"-hh\"], timeout_s=30)\n        assert p.returncode == 0\n        out = _out(p)\n>       assert \"target\" in out or \"request\" in out or \"enumeration\" in out or \"techniques\" in out\nE       AssertionError: assert ('target' in 'advanced help: this is a sql injection testing tool.\\n\\n' or 'request' in 'advanced help: this is a sql injection testing tool.\\n\\n' or 'enumeration' in 'advanced help: this is a sql injection testing tool.\\n\\n' or 'techniques' in 'advanced help: this is a sql injection testing tool.\\n\\n')\n\ntests\\Sqlmap\\functional_test.py:67: AssertionError\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       AssertionError: assert ('no such option' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n' or 'unrecognized' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n' or 'unknown' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_004_advanced_help_runs - Asserti...\nFAILED tests/Sqlmap/functional_test.py::test_006_invalid_option_reports_error_cleanly\n2 failed, 7 passed in 2.00s\n", "stdout_sha1": "2ddea12724b7976e1a6801c13172008b970cb462", "stdout_len": 2104, "stdout": "...F.F...                                                                [100%]\n================================== FAILURES ===================================\n_________________________ test_004_advanced_help_runs _________________________\n\n    def test_004_advanced_help_runs():\n        p = _run_cli([\"-hh\"], timeout_s=30)\n        assert p.returncode == 0\n        out = _out(p)\n>       assert \"target\" in out or \"request\" in out or \"enumeration\" in out or \"techniques\" in out\nE       AssertionError: assert ('target' in 'advanced help: this is a sql injection testing tool.\\n\\n' or 'request' in 'advanced help: this is a sql injection testing tool.\\n\\n' or 'enumeration' in 'advanced help: this is a sql injection testing tool.\\n\\n' or 'techniques' in 'advanced help: this is a sql injection testing tool.\\n\\n')\n\ntests\\Sqlmap\\functional_test.py:67: AssertionError\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       AssertionError: assert ('no such option' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n' or 'unrecognized' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n' or 'unknown' in 'starting sql injection testing tool...\\ntool execution completed.\\n\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_004_advanced_help_runs - Asserti...\nFAILED tests/Sqlmap/functional_test.py::test_006_invalid_option_reports_error_cleanly\n2 failed, 7 passed in 2.00s\n"}
{"model": "gpt-4o-2024-11-20", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'ModelMetaclass' from 'pydantic.main' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\main.py)", "returncode": 2, "elapsed_time_s": 2.035912, "avg_memory_mb": 40.9, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:05:32", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:3: in <module>\n    from pydantic.main import ModelMetaclass\nE   ImportError: cannot import name 'ModelMetaclass' from 'pydantic.main' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\main.py)\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.80s\n", "stdout_sha1": "9cdb516896b8cbc424c7704da6da699a8a4563a9", "stdout_len": 1109, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\SQLModel\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\SQLModel\\functional_test.py:24: in <module>\n    from sqlmodel import (  # type: ignore  # noqa: E402\ngeneration\\SQLModel\\sqlmodel\\__init__.py:3: in <module>\n    from pydantic.main import ModelMetaclass\nE   ImportError: cannot import name 'ModelMetaclass' from 'pydantic.main' (C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydantic\\main.py)\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.80s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Stegano", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute 'getdata'", "returncode": 1, "elapsed_time_s": 28.257983, "avg_memory_mb": 37.92, "avg_cpu_percent": 0.7, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2025-12-31 13:06:10", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x00000230AB3A6CF0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'This is a longer secret message with punctuation: 12345, hello-world!'\ngenerator = None, shift = 0, encoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_obj", "stdout_sha1": "8cf302d032801bcb34145995ed29d235d7af741c", "stdout_len": 15601, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x00000230AB3A6CF0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'This is a longer secret message with punctuation: 12345, hello-world!'\ngenerator = None, shift = 0, encoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n>       img_obj = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'object input', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'red secret'\n\n    def hide(image, message):\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\red\\red.py:4: AttributeError\n________________ test_red_hide_and_reveal_extended_latin_text _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_red_hide_and_reveal_exten0')\n\n    def test_red_hide_and_reveal_extended_latin_text(tmp_path: Path) -> None:\n        \"\"\"Red backend stores per-char ord() into a byte channel; Latin-1 chars like 'é' are valid.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"Café au lait\"\n        output = tmp_path / \"red_latin.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'Café au lait'\n\n    def hide(image, message):\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\red\\red.py:4: AttributeError\n_______________________ test_exif_hide_and_reveal_bytes _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_exif_hide_and_reveal_byte0')\n\n    def test_exif_hide_and_reveal_bytes(tmp_path: Path) -> None:\n        \"\"\"exifHeader.hide writes output file, exifHeader.reveal returns original bytes.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = b\"exif secret bytes\"\n        output = tmp_path / \"exif_out.jpg\"\n    \n        exifHeader.hide(str(EXIF_JPEG), str(output), secret_message=secret)\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n>       revealed = exifHeader.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-275\\\\test_exif_hide_and_reveal_byte0\\\\exif_out.jpg'\n\n    def reveal(image):\n        exif_dict = piexif.load(image)\n>       return exif_dict[\"0th\"].get(piexif.ImageIFD.Make, \"\").encode(\"utf-8\")\nE       AttributeError: 'bytes' object has no attribute 'encode'\n\ngeneration\\Stegano\\stegano\\exifHeader\\exifHeader.py:14: AttributeError\n_____________ test_exif_hide_two_outputs_with_different_payloads ______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_exif_hide_two_outputs_wit0')\n\n    def test_exif_hide_two_outputs_with_different_payloads(tmp_path: Path) -> None:\n        \"\"\"Write two different EXIF-hidden files (two independent happy-path scenarios).\"\"\"\n        _ensure_image_samples_exist()\n    \n        out1 = tmp_path / \"exif_one.jpg\"\n        out2 = tmp_path / \"exif_two.jpg\"\n    \n        secret1 = b\"payload-one\"\n        secret2 = b\"payload-two\"\n    \n        exifHeader.hide(str(EXIF_JPEG), str(out1), secret_message=secret1)\n        exifHeader.hide(str(EXIF_JPEG), str(out2), secret_message=secret2)\n    \n        assert out1.exists() and out1.stat().st_size > 0\n        assert out2.exists() and out2.stat().st_size > 0\n    \n>       assert exifHeader.reveal(str(out1)) == secret1\n\ntests\\Stegano\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-275\\\\test_exif_hide_two_outputs_wit0\\\\exif_one.jpg'\n\n    def reveal(image):\n        exif_dict = piexif.load(image)\n>       return exif_dict[\"0th\"].get(piexif.ImageIFD.Make, \"\").encode(\"utf-8\")\nE       AttributeError: 'bytes' object has no attribute 'encode'\n\ngeneration\\Stegano\\stegano\\exifHeader\\exifHeader.py:14: AttributeError\n________________________ test_wav_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_wav_hide_and_reveal_text0')\n\n    def test_wav_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"wav.hide writes output WAV; wav.reveal returns the same string.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"wav secret\"\n        output = tmp_path / \"out.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       assert 'wav secret\\\\x...\\\\x82\\\\x94\\xc9P\\xbbv,' == 'wav secret'\nE         \nE         - wav secret\nE         + wav secret\\x80\\x80\\x9f\\x15\\x10U\\x82\\x03|\\x81\\xcdT\\x8a\\x13\nE         \nE         + J'y\\xfe\\xc2\\xaa\\x82\\x97\\xffe^h(\\x08\\xa0\\x8d\\xdf\\x0f\\xd3\\xb2\\x82\\x08\\xcdgu\\xdb9(*g\\x9f\\xe0\\x8a\\xa0\\xb5]T\\xae\\xc2W\\xf1\\x8a(\"\nE         + \\x03\\xf1\\xfdu\\xdft\\xaf\\xa8\\xe2 \\x02\\x89_\\x14:\\xe2\\x885\\xff\\xda\\xec\\xa9LV{\\x82\\x9aT\\xa8\\x8aZ\nE         ...\nE         \nE         ...Full output truncated (11781 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:224: AssertionError\n_____________________ test_wav_hide_and_reveal_short_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_wav_hide_and_reveal_short0')\n\n    def test_wav_hide_and_reveal_short_text(tmp_path: Path) -> None:\n        \"\"\"A short message should also roundtrip.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"ok\"\n        output = tmp_path / \"out_short.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       assert 'ok\\\\x18,\\\\xad\\\\...\\\\x82\\\\x94\\xc9P\\xbbv,' == 'ok'\nE         \nE         - ok\nE         + ok\\x18,\\xad\\xadE\\xf4\"(\\x80\\x80\\x9f\\x15\\x10U\\x82\\x03|\\x81\\xcdT\\x8a\\x13\nE         \nE         + J'y\\xfe\\xc2\\xaa\\x82\\x97\\xffe^h(\\x08\\xa0\\x8d\\xdf\\x0f\\xd3\\xb2\\x82\\x08\\xcdgu\\xdb9(*g\\x9f\\xe0\\x8a\\xa0\\xb5]T\\xae\\xc2W\\xf1\\x8a(\"\nE         + \\x03\\xf1\\xfdu\\xdft\\xaf\\xa8\\xe2 \\x02\\x89_\\x14:\\xe2\\x885\\xff\\xda\\xec\\xa9LV{\\x82\\x9aT\\xa8\\x8aZ\nE         ...\nE         \nE         ...Full output truncated (11781 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:239: AssertionError\n____________________ test_wav_hide_and_reveal_longer_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_wav_hide_and_reveal_longe0')\n\n    def test_wav_hide_and_reveal_longer_text(tmp_path: Path) -> None:\n        \"\"\"Roundtrip a longer ASCII message via WAV backend.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\"\n        output = tmp_path / \"out_long.wav\"\n    \n        wav.hide(str(wav_in), secret, str(output))\n        assert output.exists()\n        assert output.stat().st_size > 0\n    \n        revealed = wav.reveal(str(output))\n>       assert revealed == secret\nE       assert 'WAV backend ...\\\\x82\\\\x94\\xc9P\\xbbv,' == 'WAV backend ...nopqrstuvwxyz'\nE         \nE         Skipping 52 identical leading characters in diff, use -v to show\nE         - pqrstuvwxyz\nE         + pqrstuvwxyz\\xc2W\\xf1\\x8a(\"\nE         ?            +++++++\nE         + \\x03\\xf1\\xfdu\\xdft\\xaf\\xa8\\xe2 \\x02\\x89_\\x14:\\xe2\\x885\\xff\\xda\\xec\\xa9LV{\\x82\\x9aT\\xa8\\x8aZ\nE         ...\nE         \nE         ...Full output truncated (11781 lines hidden), use '-vv' to show\n\ntests\\Stegano\\functional_test.py:254: AssertionError\n_____________________ test_lsb_and_red_outputs_are_files ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-275/test_lsb_and_red_outputs_are_f0')\n\n    def test_lsb_and_red_outputs_are_files(tmp_path: Path) -> None:\n        \"\"\"Ensure image-encoding backends produce files that can be written to disk.\"\"\"\n        _ensure_image_samples_exist()\n    \n        out_lsb = tmp_path / \"lsb_file.png\"\n        out_red = tmp_path / \"red_file.png\"\n    \n>       lsb.hide(str(LENNA_PNG), \"x\").save(str(out_lsb))\n\ntests\\Stegano\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'x', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(image, message, generator=None, shift=0, encoding=\"UTF-8\", auto_convert_rgb=False):\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       pixels = list(image.getdata())\nE       AttributeError: 'str' object has no attribute 'getdata'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:7: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_extended_latin_text\nFAILED tests/Stegano/functional_test.py::test_exif_hide_and_reveal_bytes - At...\nFAILED tests/Stegano/functional_test.py::test_exif_hide_two_outputs_with_different_payloads\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_text - asse...\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_short_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_longer_text\nFAILED tests/Stegano/functional_test.py::test_lsb_and_red_outputs_are_files\n12 failed in 5.83s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Tablib", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'Dataset' object has no attribute 'insert'", "returncode": 1, "elapsed_time_s": 1.594868, "avg_memory_mb": 32.69, "avg_cpu_percent": 100.0, "passed": 2, "failed": 9, "skipped": 0, "total": 11, "functional_score": 0.1818, "timestamp": "2025-12-31 13:06:22", "stdout_excerpt": "==== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n        assert loaded_csv.height == data.height\n        assert loaded_csv.width == data.width\n    \n        orig_dict_norm = _normalize_dict_rows(data.dict)\n        loaded_dict_norm = _normalize_dict_rows(loaded_csv.dict)\n        assert loaded_dict_norm == orig_dict_norm\n    \n        # JSON roundtrip via export + .json setter.\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'headers': ['first_name', 'last_name', 'age'], 'rows': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]]}, list)\n\ntests\\Tablib\\functional_test.py:146: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CEF5DF0>, fmt = 'tsv'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n            from .formats._csv import export_set\n            return export_set(self)\n        elif fmt == 'json':\n            from .formats._json import export_set\n            return export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:65: ValueError\n_______________ test_dataset_row_column_operations_and_slicing ________________\n\n    def test_dataset_row_column_operations_and_slicing() -> None:\n        \"\"\"Validate row appending, column appending, and slicing semantics.\"\"\"\n        data = tablib.Dataset()\n>       data.headers = (\"city\", \"country\")\n\ntests\\Tablib\\functional_test.py:201: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CF06940>\nheaders = ('city', 'country')\n\n    @headers.setter\n    def headers(self, headers):\n        if headers and len(headers) != self.width:\n>           raise ValueError(\"Number of headers must match the number of columns\")\nE           ValueError: Number of headers must match the number of columns\n\ngeneration\\Tablib\\tablib\\core.py:22: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence __________________\n\n    def test_dataset_title_and_headers_persistence() -> None:\n        \"\"\"Dataset title and headers should be assignable and remain consistent.\"\"\"\n        data = tablib.Dataset", "stdout_sha1": "85f3a1c10700330039483079ed84af978de10b6b", "stdout_len": 10338, "stdout": "FF.FF.FFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n        assert loaded_csv.height == data.height\n        assert loaded_csv.width == data.width\n    \n        orig_dict_norm = _normalize_dict_rows(data.dict)\n        loaded_dict_norm = _normalize_dict_rows(loaded_csv.dict)\n        assert loaded_dict_norm == orig_dict_norm\n    \n        # JSON roundtrip via export + .json setter.\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'headers': ['first_name', 'last_name', 'age'], 'rows': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]]}, list)\n\ntests\\Tablib\\functional_test.py:146: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CEF5DF0>, fmt = 'tsv'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n            from .formats._csv import export_set\n            return export_set(self)\n        elif fmt == 'json':\n            from .formats._json import export_set\n            return export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:65: ValueError\n_______________ test_dataset_row_column_operations_and_slicing ________________\n\n    def test_dataset_row_column_operations_and_slicing() -> None:\n        \"\"\"Validate row appending, column appending, and slicing semantics.\"\"\"\n        data = tablib.Dataset()\n>       data.headers = (\"city\", \"country\")\n\ntests\\Tablib\\functional_test.py:201: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CF06940>\nheaders = ('city', 'country')\n\n    @headers.setter\n    def headers(self, headers):\n        if headers and len(headers) != self.width:\n>           raise ValueError(\"Number of headers must match the number of columns\")\nE           ValueError: Number of headers must match the number of columns\n\ngeneration\\Tablib\\tablib\\core.py:22: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence __________________\n\n    def test_dataset_title_and_headers_persistence() -> None:\n        \"\"\"Dataset title and headers should be assignable and remain consistent.\"\"\"\n        data = tablib.Dataset(headers=(\"k\", \"v\"))\n        data.title = \"Config\"\n        data.append((\"a\", 1))\n        data.append((\"b\", 2))\n    \n        assert getattr(data, \"title\") == \"Config\"\n        assert tuple(data.headers) == (\"k\", \"v\")\n        assert data.height == 2\n>       assert data[1][0] == \"b\"\n\ntests\\Tablib\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CF06E20>, key = 1\n\n    def __getitem__(self, key):\n        if isinstance(key, slice):\n            return [tuple(row) for row in self._data[key]]\n        elif isinstance(key, str):\n            if key not in self._headers:\n                raise KeyError(f\"Column '{key}' not found in headers\")\n            idx = self._headers.index(key)\n            return [row[idx] for row in self._data]\n        else:\n>           raise TypeError(\"Invalid key type\")\nE           TypeError: Invalid key type\n\ngeneration\\Tablib\\tablib\\core.py:42: TypeError\n________________ test_dataset_export_json_contains_all_records ________________\n\n    def test_dataset_export_json_contains_all_records() -> None:\n        \"\"\"JSON export should serialize all dataset records in a list-like structure.\"\"\"\n        data = _build_sample_dataset()\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'headers': ['first_name', 'last_name', 'age'], 'rows': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]]}, list)\n\ntests\\Tablib\\functional_test.py:278: AssertionError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CE604C0>, fmt = 'html'\n\n    def export(self, fmt):\n        if fmt == 'csv':\n            from .formats._csv import export_set\n            return export_set(self)\n        elif fmt == 'json':\n            from .formats._json import export_set\n            return export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:65: ValueError\n__________________ test_databook_multi_sheet_json_roundtrip ___________________\n\n    def test_databook_multi_sheet_json_roundtrip() -> None:\n        \"\"\"Databook should preserve sheet structure when exported/imported as JSON.\"\"\"\n        sheet1 = tablib.Dataset(\n            (1, \"a\"),\n            (2, \"b\"),\n            headers=(\"id\", \"value\"),\n        )\n        sheet1.title = \"First\"\n    \n        sheet2 = tablib.Dataset(\n            (3, \"c\"),\n            (4, \"d\"),\n            headers=(\"id\", \"value\"),\n        )\n        sheet2.title = \"Second\"\n    \n        book = tablib.Databook([sheet1, sheet2])\n    \n        json_text = book.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n        assert isinstance(parsed, list)\n        assert len(parsed) == 2\n    \n>       loaded_book = tablib.Databook()\nE       TypeError: __init__() missing 1 required positional argument: 'datasets'\n\ntests\\Tablib\\functional_test.py:327: TypeError\n_________________ test_databook_add_sheet_and_iteration_order _________________\n\n    def test_databook_add_sheet_and_iteration_order() -> None:\n        \"\"\"Databook should allow adding sheets and preserve the order in iteration.\"\"\"\n        s1 = tablib.Dataset((1, \"x\"), headers=(\"id\", \"val\"))\n        s1.title = \"S1\"\n        s2 = tablib.Dataset((2, \"y\"), headers=(\"id\", \"val\"))\n        s2.title = \"S2\"\n    \n        book = tablib.Databook([s1])\n    \n        if hasattr(book, \"add_sheet\"):\n            book.add_sheet(s2)  # type: ignore[attr-defined]\n        else:\n            # Fallback: reconstruct via the public constructor (still normal usage).\n            book = tablib.Databook([s1, s2])\n    \n        assert book.size == 2\n    \n        sheets = _iter_databook_sheets(book)\n        assert len(sheets) == 2\n        assert sheets[0].title == \"S1\"\n        assert sheets[1].title == \"S2\"\n>       assert sheets[0][0] == (1, \"x\")\n\ntests\\Tablib\\functional_test.py:365: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001BF0CEE3C40>, key = 0\n\n    def __getitem__(self, key):\n        if isinstance(key, slice):\n            return [tuple(row) for row in self._data[key]]\n        elif isinstance(key, str):\n            if key not in self._headers:\n                raise KeyError(f\"Column '{key}' not found in headers\")\n            idx = self._headers.index(key)\n            return [row[idx] for row in self._data]\n        else:\n>           raise TypeError(\"Invalid key type\")\nE           TypeError: Invalid key type\n\ngeneration\\Tablib\\tablib\\core.py:42: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_csv_and_json_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_row_column_operations_and_slicing\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_title_and_headers_persistence\nFAILED tests/Tablib/functional_test.py::test_dataset_export_json_contains_all_records\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\nFAILED tests/Tablib/functional_test.py::test_databook_multi_sheet_json_roundtrip\nFAILED tests/Tablib/functional_test.py::test_databook_add_sheet_and_iteration_order\n9 failed, 2 passed in 0.48s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "ValueError", "exception_msg": "Unknown table format: github", "returncode": 1, "elapsed_time_s": 1.757224, "avg_memory_mb": 32.51, "avg_cpu_percent": 99.0, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 13:06:34", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]], headers = 'firstrow'\ntablefmt = 'simple', numalign = 'right', stralign = 'left'\n\n    def tabulate(data, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        \"\"\"\n        Generate a formatted table string from the given data.\n    \n        :param data: List of lists, dictionaries, or list of dictionaries.\n        :param headers: Optional list of column headers.\n        :param tablefmt: Table format (e.g., \"plain\", \"grid\", \"pipe\").\n        :param numalign: Alignment for numeric columns (\"left\", \"center\", \"right\").\n        :param stralign: Alignment for string columns (\"left\", \"center\", \"right\").\n        :return: Formatted table string.\n        \"\"\"\n        if tablefmt not in PRESET_FORMATS:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: simple\n\ngeneration\\Tabulate\\tabulate\\core.py:18: ValueError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n>       out_true = tabulate(table, showindex=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'showindex'\n\ntests\\Tabulate\\functional_test.py:151: TypeError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata = [['spam', 42], ['eggs', 451], ['bacon', 0]], headers = ['item', 'qty']\ntablefmt = 'github', numalign = 'right', stralign = 'left'\n\n    def tabulate(data, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        \"\"\"\n        Generate a formatted table string from the given data.\n    \n        :param data: List of lists, dictionaries, or list of dictionaries.\n        :param headers: Optional list of column headers.\n        :param tablefmt: Table format (e.g., \"plain\", \"grid\", \"pipe\").\n        :param numalign: Alignment for numeric columns (\"left\", \"center\", \"right\").\n        :param stralign: Alignment for string columns (\"left\", \"center\", \"right\").\n        :return: Formatted table string.\n        \"\"\"\n        if tablefmt not in PRESET_FORMATS:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: github\n\ngeneration\\Tabulate\\tabulate\\core.py:18: ValueError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            {\"name\": \"Alice\", \"score\": 10},\n            {\"name\": \"Bob\", \"score\": 12},\n        ]\n        output = tabulate(rows, headers=\"keys", "stdout_sha1": "be4b7d8476f8c7bcca6f9f14b98328b48d568340", "stdout_len": 7131, "stdout": "..FFFFFFFFF.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n>       output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n\ntests\\Tabulate\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata = [['Name', 'Age'], ['Alice', 24], ['Bob', 19]], headers = 'firstrow'\ntablefmt = 'simple', numalign = 'right', stralign = 'left'\n\n    def tabulate(data, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        \"\"\"\n        Generate a formatted table string from the given data.\n    \n        :param data: List of lists, dictionaries, or list of dictionaries.\n        :param headers: Optional list of column headers.\n        :param tablefmt: Table format (e.g., \"plain\", \"grid\", \"pipe\").\n        :param numalign: Alignment for numeric columns (\"left\", \"center\", \"right\").\n        :param stralign: Alignment for string columns (\"left\", \"center\", \"right\").\n        :return: Formatted table string.\n        \"\"\"\n        if tablefmt not in PRESET_FORMATS:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: simple\n\ngeneration\\Tabulate\\tabulate\\core.py:18: ValueError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n>       out_true = tabulate(table, showindex=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'showindex'\n\ntests\\Tabulate\\functional_test.py:151: TypeError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ndata = [['spam', 42], ['eggs', 451], ['bacon', 0]], headers = ['item', 'qty']\ntablefmt = 'github', numalign = 'right', stralign = 'left'\n\n    def tabulate(data, headers=None, tablefmt=\"plain\", numalign=\"right\", stralign=\"left\"):\n        \"\"\"\n        Generate a formatted table string from the given data.\n    \n        :param data: List of lists, dictionaries, or list of dictionaries.\n        :param headers: Optional list of column headers.\n        :param tablefmt: Table format (e.g., \"plain\", \"grid\", \"pipe\").\n        :param numalign: Alignment for numeric columns (\"left\", \"center\", \"right\").\n        :param stralign: Alignment for string columns (\"left\", \"center\", \"right\").\n        :return: Formatted table string.\n        \"\"\"\n        if tablefmt not in PRESET_FORMATS:\n>           raise ValueError(f\"Unknown table format: {tablefmt}\")\nE           ValueError: Unknown table format: github\n\ngeneration\\Tabulate\\tabulate\\core.py:18: ValueError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            {\"name\": \"Alice\", \"score\": 10},\n            {\"name\": \"Bob\", \"score\": 12},\n        ]\n        output = tabulate(rows, headers=\"keys\", tablefmt=\"plain\")\n        lines = _lines(output)\n    \n        header = lines[0]\n>       assert \"name\" in header\nE       AssertionError: assert 'name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:194: AssertionError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\nE       TypeError: tabulate() got an unexpected keyword argument 'missingval'\n\ntests\\Tabulate\\functional_test.py:207: TypeError\n__________________ test_floatfmt_controls_numeric_rendering ___________________\n\n    def test_floatfmt_controls_numeric_rendering() -> None:\n        rows = [\n            [\"pi\", 3.14159],\n            [\"e\", 2.71828],\n        ]\n>       output = tabulate(rows, headers=[\"name\", \"value\"], tablefmt=\"plain\", floatfmt=\".2f\")\nE       TypeError: tabulate() got an unexpected keyword argument 'floatfmt'\n\ntests\\Tabulate\\functional_test.py:222: TypeError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - TypeError...\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\nFAILED tests/Tabulate/functional_test.py::test_list_of_dicts_headers_keys_plain\nFAILED tests/Tabulate/functional_test.py::test_missingval_renders_placeholder\nFAILED tests/Tabulate/functional_test.py::test_floatfmt_controls_numeric_rendering\nFAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n9 failed, 3 passed in 0.50s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "'>' not supported between instances of 'str' and 'int'", "returncode": 1, "elapsed_time_s": 26.434046, "avg_memory_mb": 32.75, "avg_cpu_percent": 0.68, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2025-12-31 13:07:11", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167BD370>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167BD310>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F71680D6A0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:55: in draw\n    max_value = max(sum(series) for series in self.data.series)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001F71680D3A0>\n\n>   max_value = max(sum(series) for series in self.data.series)\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:55: TypeError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167FC040>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167FCE50>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167FFA60>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167FFC70>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_v", "stdout_sha1": "9d28c9cb00b5f86022bf3bd38731988dc612042b", "stdout_len": 12747, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167BD370>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Test Chart\", width=20, format=\"{:>5.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167BD310>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F71680D6A0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stacked Chart\", width=30, format=\"{:>4.1f}\")\n    \n        chart = StackedChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:55: in draw\n    max_value = max(sum(series) for series in self.data.series)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001F71680D3A0>\n\n>   max_value = max(sum(series) for series in self.data.series)\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:55: TypeError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167FC040>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Bars\", width=10, format=\"{:>4.1f}\")\n    \n        chart = BarChart(data, args)\n>       chart.draw()\n\ntests\\Termgraph\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167FCE50>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167FFA60>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Values\", width=12, no_values=True, format=\"{:>5.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167FFC70>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7151B88E0>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"No Labels\", width=10, no_labels=True, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F71680CDF0>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167FBBB0>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Suffix\", width=18, suffix=\"%\", format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:175: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167FB130>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F71684F940>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Fmt\", width=20, format=\"{:>6.2f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F71684F8B0>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7151CF280>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack Labels\", width=25, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:55: in draw\n    max_value = max(sum(series) for series in self.data.series)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001F7151CF460>\n\n>   max_value = max(sum(series) for series in self.data.series)\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:55: TypeError\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F71680C9D0>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=\"Stack No Values\", width=30, no_values=True, format=\"{:>4.1f}\")\n    \n>       StackedChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Termgraph\\termgraph\\charts.py:55: in draw\n    max_value = max(sum(series) for series in self.data.series)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001F7167BD220>\n\n>   max_value = max(sum(series) for series in self.data.series)\nE   TypeError: unsupported operand type(s) for +: 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:55: TypeError\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F716855490>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n        data = Data(values, labels)\n        args = _make_args(title=None, width=15, format=\"{:>4.1f}\")\n    \n>       BarChart(data, args).draw()\n\ntests\\Termgraph\\functional_test.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7168557F0>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000001F7167BDC70>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000001F7167BD670>\n\n    def draw(self):\n        \"\"\"\n        Render the horizontal bar chart to stdout.\n        \"\"\"\n        self.data.validate()\n        max_value = max(max(series) for series in self.data.series)\n>       scale = self.args.width / max_value if max_value > 0 else 1\nE       TypeError: '>' not supported between instances of 'str' and 'int'\n\ngeneration\\Termgraph\\termgraph\\charts.py:23: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 0.49s\n"}
{"model": "gpt-4o-2024-11-20", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.830155, "avg_memory_mb": 36.46, "avg_cpu_percent": 101.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:07:41", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n", "stdout_sha1": "2c168ba6d4f8a29c5fc645a8c9c8783a94494322", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'where' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Typer", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.421992, "avg_memory_mb": 30.46, "avg_cpu_percent": 104.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:07:53", "stdout_excerpt": "\n1 skipped in 0.12s\n", "stdout_sha1": "2c297eff6659b1c3f522bd1a20de05b2bdd71aca", "stdout_len": 20, "stdout": "\n1 skipped in 0.12s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.831259, "avg_memory_mb": 34.65, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:08:11", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.46s\n", "stdout_sha1": "a4feedbb1e48f5d2887b448966333765b6b921e9", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.46s\n"}
{"model": "gpt-4o-2024-11-20", "project": "Xmltodict", "failure_stage": "pre-test", "failure_type": "syntax_error", "exception_type": "IndentationError", "exception_msg": "expected an indented block", "returncode": 2, "elapsed_time_s": 1.88185, "avg_memory_mb": 35.98, "avg_cpu_percent": 99.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 13:08:24", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Xmltodict/functional_test.py _____________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\Xmltodict\\functional_test.py:49: in <module>\n    import xmltodict  # type: ignore  # noqa: E402\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Xmltodict\\xmltodict.py\", line 33\nE       for child in child_elements:\nE                                   ^\nE   IndentationError: expected an indented block\n=========================== short test summary info ===========================\nERROR tests/Xmltodict/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.64s\n", "stdout_sha1": "81a1d352c73ec25c17a450d3fc982f15677ca3b0", "stdout_len": 1556, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Xmltodict/functional_test.py _____________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\Xmltodict\\functional_test.py:49: in <module>\n    import xmltodict  # type: ignore  # noqa: E402\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Xmltodict\\xmltodict.py\", line 33\nE       for child in child_elements:\nE                                   ^\nE   IndentationError: expected an indented block\n=========================== short test summary info ===========================\nERROR tests/Xmltodict/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.64s\n"}
{"model": "gpt-5-2025-08-07", "project": "Cachetools", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for |: '_CallableType' and 'NoneType'", "returncode": 2, "elapsed_time_s": 1.676459, "avg_memory_mb": 35.31, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 22:24:42", "stdout_excerpt": "====\n____________ ERROR collecting tests/Cachetools/functional_test.py _____________\ntests\\Cachetools\\functional_test.py:26: in <module>\n    from cachetools import LRUCache, TTLCache, cached  # type: ignore  # noqa: E402\ngeneration\\Cachetools\\cachetools\\__init__.py:17: in <module>\n    from .cache import Cache\ngeneration\\Cachetools\\cachetools\\cache.py:10: in <module>\n    class Cache(MutableMapping):\ngeneration\\Cachetools\\cachetools\\cache.py:20: in Cache\n    def __init__(self, maxsize: int, getsizeof: Callable | None = None):\nE   TypeError: unsupported operand type(s) for |: '_CallableType' and 'NoneType'\n=========================== short test summary info ===========================\nERROR tests/Cachetools/functional_test.py - TypeError: unsupported operand ty...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n", "stdout_sha1": "eee8359efc58e749d39ce9e915da98d20fa63cee", "stdout_len": 945, "stdout": "\n=================================== ERRORS ====================================\n____________ ERROR collecting tests/Cachetools/functional_test.py _____________\ntests\\Cachetools\\functional_test.py:26: in <module>\n    from cachetools import LRUCache, TTLCache, cached  # type: ignore  # noqa: E402\ngeneration\\Cachetools\\cachetools\\__init__.py:17: in <module>\n    from .cache import Cache\ngeneration\\Cachetools\\cachetools\\cache.py:10: in <module>\n    class Cache(MutableMapping):\ngeneration\\Cachetools\\cachetools\\cache.py:20: in Cache\n    def __init__(self, maxsize: int, getsizeof: Callable | None = None):\nE   TypeError: unsupported operand type(s) for |: '_CallableType' and 'NoneType'\n=========================== short test summary info ===========================\nERROR tests/Cachetools/functional_test.py - TypeError: unsupported operand ty...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n"}
{"model": "gpt-5-2025-08-07", "project": "Click", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for |: 'type' and 'NoneType'", "returncode": 2, "elapsed_time_s": 5.396518, "avg_memory_mb": 35.86, "avg_cpu_percent": 98.8, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 22:27:58", "stdout_excerpt": "====\n_______________ ERROR collecting tests/Click/functional_test.py _______________\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:14: in <module>\n    from . import testing\ngeneration\\Click\\click\\testing.py:10: in <module>\n    class Result:\ngeneration\\Click\\click\\testing.py:16: in Result\n    exc_info: tuple | None = None\nE   TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py - TypeError: unsupported operand type(s)...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.00s\n", "stdout_sha1": "7799cb20126e8b5736eaff78b8d721acec14b024", "stdout_len": 813, "stdout": "\n=================================== ERRORS ====================================\n_______________ ERROR collecting tests/Click/functional_test.py _______________\ntests\\Click\\functional_test.py:128: in <module>\n    import click  # type: ignore  # noqa: E402\ngeneration\\Click\\click\\__init__.py:14: in <module>\n    from . import testing\ngeneration\\Click\\click\\testing.py:10: in <module>\n    class Result:\ngeneration\\Click\\click\\testing.py:16: in Result\n    exc_info: tuple | None = None\nE   TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'\n=========================== short test summary info ===========================\nERROR tests/Click/functional_test.py - TypeError: unsupported operand type(s)...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 4.00s\n"}
{"model": "gpt-5-2025-08-07", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "string indices must be integers", "returncode": 1, "elapsed_time_s": 5.299159, "avg_memory_mb": 34.15, "avg_cpu_percent": 98.5, "passed": 7, "failed": 4, "skipped": 0, "total": 11, "functional_score": 0.6364, "timestamp": "2025-12-31 22:32:20", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:229: in find\n    cur = self.database._execute(sql, values)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000142552FAFA0>\nsql = 'SELECT * FROM \"users\" WHERE \"age\"=?', params = [{'>=': 40}]\n\n    def _execute(self, sql: str, params: Optional[Iterable[Any]] = None) -> sqlite3.Cursor:\n        with self._lock:\n            if params is None:\n                return self._conn.execute(sql)\n>           return self._conn.execute(sql, params)\nE           sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\database.py:101: InterfaceError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x00000142552F26D0>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x00000142552DB190>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - as...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n4 failed, 7 passed in 3.90s\n", "stdout_sha1": "f0bbdef93165ea39c3a4bc4b710c456af41663fe", "stdout_len": 3923, "stdout": "F....F..F.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:229: in find\n    cur = self.database._execute(sql, values)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x00000142552FAFA0>\nsql = 'SELECT * FROM \"users\" WHERE \"age\"=?', params = [{'>=': 40}]\n\n    def _execute(self, sql: str, params: Optional[Iterable[Any]] = None) -> sqlite3.Cursor:\n        with self._lock:\n            if params is None:\n                return self._conn.execute(sql)\n>           return self._conn.execute(sql, params)\nE           sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\database.py:101: InterfaceError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x00000142552F26D0>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x00000142552DB190>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - as...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n4 failed, 7 passed in 3.90s\n"}
{"model": "gpt-5-2025-08-07", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 22:36:26", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "gpt-5-2025-08-07", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword argument 'style_function'", "returncode": 1, "elapsed_time_s": 1.528198, "avg_memory_mb": 32.84, "avg_cpu_percent": 98.8, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2025-12-31 22:39:06", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.Marker([0, 0], tooltip=\"t\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'tooltip'\n\ntests\\Folium\\functional_test.py:69: TypeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\n2 failed, 10 passed in 0.39s\n", "stdout_sha1": "bfc461686559f266e440a86ee59669b35a7251b7", "stdout_len": 1758, "stdout": "....F...F...                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        base = m.get_root().render()\n    \n>       folium.Marker([0, 0], tooltip=\"t\").add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'tooltip'\n\ntests\\Folium\\functional_test.py:69: TypeError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       folium.GeoJson(gj, style_function=style_fn).add_to(m)\nE       TypeError: __init__() got an unexpected keyword argument 'style_function'\n\ntests\\Folium\\functional_test.py:141: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\n2 failed, 10 passed in 0.39s\n"}
{"model": "gpt-5-2025-08-07", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 2.391135, "avg_memory_mb": 22.6, "avg_cpu_percent": 48.55, "passed": 5, "failed": 5, "skipped": 0, "total": 10, "functional_score": 0.5, "timestamp": "2025-12-31 22:46:01", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-359/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       loaded_frames = list(iio.imiter(path))\n\ntests\\Imageio\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-359\\\\test_gif_multiframe_roundtrip_0\\\\anim.gif'\n\n    def _gif_iterate_frames(path: str) -> Generator[np.ndarray, None, None]:\n        with open(path, \"rb\") as fp:\n            header = fp.read(6)\n            if header not in (b\"GIF87a\", b\"GIF89a\"):\n                raise ValueError(\"Not a GIF file.\")\n            # Logical Screen Descriptor\n            ls = fp.read(7)\n            W, H, packed, bg, aspect = struct.unpack(\"<HHBBB\", ls)\n            gct_flag = (packed & 0x80) >> 7\n            gct_size_value = packed & 0x07\n            gct_size = 2 ** (gct_size_value + 1)\n            if gct_flag:\n                fp.read(3 * gct_size)\n            # Iterate blocks\n            while True:\n                introducer = fp.read(1)\n                if not introducer:\n                    break\n                b = introducer[0]\n                if b == 0x3B:\n                    # Trailer\n                    break\n                elif b == 0x21:\n                    # Extension\n                    label = fp.read(1)\n                    if not label:\n                        break\n                    if label[0] == 0xF9:\n                        # Graphics Control Extension\n                        block_size_b = fp.read(1)\n                        if not block_size_b:\n                            break\n                        block_size = block_size_b[0]\n                        data = fp.read(block_size)\n                        fp.read(1)  # block terminator\n                    else:\n                        # Application or other extension: read data sub-blocks\n                        # First block may be application ID length (usually 11)\n                        # Read until terminator\n                        # Read a block size; if zero then done\n                        # We already read label; now read subblocks generically\n                        # Possibly there is a fixed-length initial block for APP\n                        # We'll consume in generic fashion\n                        # Read sub-blocks (size, data) until sz==0\n                        # First we may have an initial block size preceding sub-blocks\n                        # We'll handle generically:\n                        # Read blocks until terminator\n                        _ = _read_subblocks(fp)\n                elif b == 0x2C:\n                    # Image Descriptor\n                    idesc = fp.read(9)\n                    left, top, width, height, ipacked = struct.unpack(\"<HHHHB\", idesc)\n                    lct_flag = (ipacked & 0x80) >> 7\n                    interlace_flag = (ipacked & 0x40) >> 6\n                    lct_size_value = ipacked & 0x07\n                    if lct_flag:\n                        lct_size = 2 ** (lct_size_value + 1)\n                        fp.read(3 * lct_size)\n                    # LZW minimum code size\n                    lzw_min_b = fp.read(1)\n                    if not lzw_min_b:\n                        break\n                    lzw_min_code_size = lzw_min_b[0]\n                    # Image data\n                    data_stream = _read_subblocks(fp)\n                    # Decode\n                    pixels = _lzw_decode(data_stream, lzw_min_code_s", "stdout_sha1": "29260c7ffdda54ec3fa7de26e6ba435572925469", "stdout_len": 11439, "stdout": ".F.F..FFF.                                                               [100%]\n================================== FAILURES ===================================\n__________________ test_gif_multiframe_roundtrip_with_imiter __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-359/test_gif_multiframe_roundtrip_0')\n\n    def test_gif_multiframe_roundtrip_with_imiter(tmp_path: Path) -> None:\n        \"\"\"Write a small animated GIF and iterate frames using imiter.\"\"\"\n        frames = _make_grayscale_frames(num_frames=6, height=24, width=24)\n        path = tmp_path / \"anim.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       loaded_frames = list(iio.imiter(path))\n\ntests\\Imageio\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-359\\\\test_gif_multiframe_roundtrip_0\\\\anim.gif'\n\n    def _gif_iterate_frames(path: str) -> Generator[np.ndarray, None, None]:\n        with open(path, \"rb\") as fp:\n            header = fp.read(6)\n            if header not in (b\"GIF87a\", b\"GIF89a\"):\n                raise ValueError(\"Not a GIF file.\")\n            # Logical Screen Descriptor\n            ls = fp.read(7)\n            W, H, packed, bg, aspect = struct.unpack(\"<HHBBB\", ls)\n            gct_flag = (packed & 0x80) >> 7\n            gct_size_value = packed & 0x07\n            gct_size = 2 ** (gct_size_value + 1)\n            if gct_flag:\n                fp.read(3 * gct_size)\n            # Iterate blocks\n            while True:\n                introducer = fp.read(1)\n                if not introducer:\n                    break\n                b = introducer[0]\n                if b == 0x3B:\n                    # Trailer\n                    break\n                elif b == 0x21:\n                    # Extension\n                    label = fp.read(1)\n                    if not label:\n                        break\n                    if label[0] == 0xF9:\n                        # Graphics Control Extension\n                        block_size_b = fp.read(1)\n                        if not block_size_b:\n                            break\n                        block_size = block_size_b[0]\n                        data = fp.read(block_size)\n                        fp.read(1)  # block terminator\n                    else:\n                        # Application or other extension: read data sub-blocks\n                        # First block may be application ID length (usually 11)\n                        # Read until terminator\n                        # Read a block size; if zero then done\n                        # We already read label; now read subblocks generically\n                        # Possibly there is a fixed-length initial block for APP\n                        # We'll consume in generic fashion\n                        # Read sub-blocks (size, data) until sz==0\n                        # First we may have an initial block size preceding sub-blocks\n                        # We'll handle generically:\n                        # Read blocks until terminator\n                        _ = _read_subblocks(fp)\n                elif b == 0x2C:\n                    # Image Descriptor\n                    idesc = fp.read(9)\n                    left, top, width, height, ipacked = struct.unpack(\"<HHHHB\", idesc)\n                    lct_flag = (ipacked & 0x80) >> 7\n                    interlace_flag = (ipacked & 0x40) >> 6\n                    lct_size_value = ipacked & 0x07\n                    if lct_flag:\n                        lct_size = 2 ** (lct_size_value + 1)\n                        fp.read(3 * lct_size)\n                    # LZW minimum code size\n                    lzw_min_b = fp.read(1)\n                    if not lzw_min_b:\n                        break\n                    lzw_min_code_size = lzw_min_b[0]\n                    # Image data\n                    data_stream = _read_subblocks(fp)\n                    # Decode\n                    pixels = _lzw_decode(data_stream, lzw_min_code_size)\n                    # Expect width*height bytes\n                    if len(pixels) < width * height:\n                        # Some encoders might store interlaced data; we don't support.\n>                       raise ValueError(\"Unsupported GIF interlace or truncated data.\")\nE                       ValueError: Unsupported GIF interlace or truncated data.\n\ngeneration\\Imageio\\imageio\\v3.py:537: ValueError\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_returns_stack_with_expected_frame_count ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-359/test_gif_imread_returns_stack_0')\n\n    def test_gif_imread_returns_stack_with_expected_frame_count(tmp_path: Path) -> None:\n        \"\"\"Reading a GIF via imread should produce a stack/sequence with the right number of frames.\"\"\"\n        frames = _make_grayscale_frames(num_frames=5, height=20, width=21)\n        path = tmp_path / \"stack.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       loaded = iio.imread(path)\n\ntests\\Imageio\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Imageio\\imageio\\v3.py:104: in imread\n    for frame in _gif_iterate_frames(path):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npath = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-359\\\\test_gif_imread_returns_stack_0\\\\stack.gif'\n\n    def _gif_iterate_frames(path: str) -> Generator[np.ndarray, None, None]:\n        with open(path, \"rb\") as fp:\n            header = fp.read(6)\n            if header not in (b\"GIF87a\", b\"GIF89a\"):\n                raise ValueError(\"Not a GIF file.\")\n            # Logical Screen Descriptor\n            ls = fp.read(7)\n            W, H, packed, bg, aspect = struct.unpack(\"<HHBBB\", ls)\n            gct_flag = (packed & 0x80) >> 7\n            gct_size_value = packed & 0x07\n            gct_size = 2 ** (gct_size_value + 1)\n            if gct_flag:\n                fp.read(3 * gct_size)\n            # Iterate blocks\n            while True:\n                introducer = fp.read(1)\n                if not introducer:\n                    break\n                b = introducer[0]\n                if b == 0x3B:\n                    # Trailer\n                    break\n                elif b == 0x21:\n                    # Extension\n                    label = fp.read(1)\n                    if not label:\n                        break\n                    if label[0] == 0xF9:\n                        # Graphics Control Extension\n                        block_size_b = fp.read(1)\n                        if not block_size_b:\n                            break\n                        block_size = block_size_b[0]\n                        data = fp.read(block_size)\n                        fp.read(1)  # block terminator\n                    else:\n                        # Application or other extension: read data sub-blocks\n                        # First block may be application ID length (usually 11)\n                        # Read until terminator\n                        # Read a block size; if zero then done\n                        # We already read label; now read subblocks generically\n                        # Possibly there is a fixed-length initial block for APP\n                        # We'll consume in generic fashion\n                        # Read sub-blocks (size, data) until sz==0\n                        # First we may have an initial block size preceding sub-blocks\n                        # We'll handle generically:\n                        # Read blocks until terminator\n                        _ = _read_subblocks(fp)\n                elif b == 0x2C:\n                    # Image Descriptor\n                    idesc = fp.read(9)\n                    left, top, width, height, ipacked = struct.unpack(\"<HHHHB\", idesc)\n                    lct_flag = (ipacked & 0x80) >> 7\n                    interlace_flag = (ipacked & 0x40) >> 6\n                    lct_size_value = ipacked & 0x07\n                    if lct_flag:\n                        lct_size = 2 ** (lct_size_value + 1)\n                        fp.read(3 * lct_size)\n                    # LZW minimum code size\n                    lzw_min_b = fp.read(1)\n                    if not lzw_min_b:\n                        break\n                    lzw_min_code_size = lzw_min_b[0]\n                    # Image data\n                    data_stream = _read_subblocks(fp)\n                    # Decode\n                    pixels = _lzw_decode(data_stream, lzw_min_code_size)\n                    # Expect width*height bytes\n                    if len(pixels) < width * height:\n                        # Some encoders might store interlaced data; we don't support.\n>                       raise ValueError(\"Unsupported GIF interlace or truncated data.\")\nE                       ValueError: Unsupported GIF interlace or truncated data.\n\ngeneration\\Imageio\\imageio\\v3.py:537: ValueError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-359/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-359/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_gif_multiframe_roundtrip_with_imiter\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_returns_stack_with_expected_frame_count\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n5 failed, 5 passed in 0.93s\n"}
{"model": "gpt-5-2025-08-07", "project": "Lifelines", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 2.170205, "avg_memory_mb": 69.2, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 22:48:06", "stdout_excerpt": "\n1 skipped in 0.97s\n", "stdout_sha1": "c735a326c271a18e32a98ac35adce4b3ba9075d6", "stdout_len": 20, "stdout": "\n1 skipped in 0.97s\n"}
{"model": "gpt-5-2025-08-07", "project": "Loguru", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "add() got an unexpected keyword argument 'colorize'", "returncode": 1, "elapsed_time_s": 1.574658, "avg_memory_mb": 32.82, "avg_cpu_percent": 97.9, "passed": 3, "failed": 8, "skipped": 0, "total": 11, "functional_score": 0.2727, "timestamp": "2025-12-31 22:49:15", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable", "stdout_sha1": "70f1c13cea4d62f85c4e7010077c9f6e659b4aab", "stdout_len": 10143, "stdout": "FFFFF..FFF.                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} user={extra[user]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n>       log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n\ntests\\Loguru\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n>       log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n\ntests\\Loguru\\functional_test.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} patched={extra[patched]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n\ntests\\Loguru\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - Ty...\nFAILED tests/Loguru/functional_test.py::test_level_filtering - TypeError: add...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Typ...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Type...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\n8 failed, 3 passed in 0.49s\n"}
{"model": "gpt-5-2025-08-07", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 2.751962, "avg_memory_mb": 35.12, "avg_cpu_percent": 64.5, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 22:51:15", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.44s\n", "stdout_sha1": "d6e123a7a43717f1743d637ce0bc14ef66fd1b6c", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.44s\n"}
{"model": "gpt-5-2025-08-07", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 1.889975, "avg_memory_mb": 32.3, "avg_cpu_percent": 99.1, "passed": 6, "failed": 4, "skipped": 9, "total": 19, "functional_score": 0.3158, "timestamp": "2025-12-31 22:53:30", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_inline_code_and_code_block _______________________\n\n    def test_inline_code_and_code_block() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use `code()` inline.\n    \n            ```\n            def foo():\n                return 42\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<code>\" in norm and \"</code>\" in norm\n>       assert \"code()\" in norm\nE       AssertionError: assert 'code()' in '<p>Use MDPH<em>0</em>X inline.</p>\\n<pre><code>def foo():\\nreturn 42\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:143: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       AssertionError: assert ('<a ' in '<p>A MDPH<em>1</em>X and an image: MDPH<em>0</em>X</p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_inline_code_and_code_block - A...\nFAILED tests/Markdown/functional_test.py::test_links_and_images - AssertionEr...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n4 failed, 6 passed, 9 skipped in 0.53s\n", "stdout_sha1": "39634ac612267b80a8622c20835d06cc0851ccac", "stdout_len": 3064, "stdout": "..F..FF..Fsssssssss                                                      [100%]\n================================== FAILURES ===================================\n_______________________ test_inline_code_and_code_block _______________________\n\n    def test_inline_code_and_code_block() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use `code()` inline.\n    \n            ```\n            def foo():\n                return 42\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n        assert \"<code>\" in norm and \"</code>\" in norm\n>       assert \"code()\" in norm\nE       AssertionError: assert 'code()' in '<p>Use MDPH<em>0</em>X inline.</p>\\n<pre><code>def foo():\\nreturn 42\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:143: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       AssertionError: assert ('<a ' in '<p>A MDPH<em>1</em>X and an image: MDPH<em>0</em>X</p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block\\n</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_inline_code_and_code_block - A...\nFAILED tests/Markdown/functional_test.py::test_links_and_images - AssertionEr...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n4 failed, 6 passed, 9 skipped in 0.53s\n"}
{"model": "gpt-5-2025-08-07", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file", "returncode": 1, "elapsed_time_s": 1.923313, "avg_memory_mb": 33.56, "avg_cpu_percent": 99.1, "passed": 5, "failed": 6, "skipped": 0, "total": 11, "functional_score": 0.4545, "timestamp": "2025-12-31 22:54:55", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.h", "stdout_sha1": "fbd17efe3e2900763fc643715dc1092f3591caba", "stdout_len": 5957, "stdout": "...F.FF.FFF                                                              [100%]\n================================== FAILURES ===================================\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_004_tools_main_file_exists - ...\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_007_tools_main_defines_mitmdump_function_or_wrapper\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n6 failed, 5 passed in 0.65s\n"}
{"model": "gpt-5-2025-08-07", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.45244, "avg_memory_mb": 31.39, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 22:56:09", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "gpt-5-2025-08-07", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'Duration' object has no attribute 'days'", "returncode": 1, "elapsed_time_s": 1.95882, "avg_memory_mb": 32.59, "avg_cpu_percent": 98.3, "passed": 2, "failed": 10, "skipped": 1, "total": 13, "functional_score": 0.1538, "timestamp": "2025-12-31 22:57:18", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n>       offset_utc = dt_utc.utcoffset()\nE       AttributeError: 'DateTime' object has no attribute 'utcoffset'\n\ntests\\Pendulum\\functional_test.py:72: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n        shifted = base.add(days=2, hours=5, minutes=15)\n        delta = shifted - base\n    \n>       assert delta.days == 2\nE       AttributeError: 'Duration' object has no attribute 'days'\n\ntests\\Pendulum\\functional_test.py:92: AttributeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_________________ test_duration_total_seconds_and_components __________________\n\n    def test_duration_total_seconds_and_components() -> None:\n        \"\"\"Verify duration reports correct total seconds and has component attributes.\"\"\"\n        dur = pendulum.duration(days=1, hours=2, minutes=3, seconds=4)\n    \n        # Total seconds is the most stable cross-version contract.\n        assert dur.total_seconds() == 1 * 86400 + 2 * 3600 + 3 * 60 + 4\n    \n        # Component attributes commonly exist; assert them when present.\n>       assert dur.days == 1\nE       AttributeError: 'Duration' object has no attribute 'days'\n\ntests\\Pendulum\\functional_test.py:168: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n        dt_ny = dt_utc.in_timezone(\"America/New_York\")\n    \n        assert int(dt_utc.timestamp()) == int(dt_ny.timestamp())\n>       assert dt_ny.to_date_string() in (", "stdout_sha1": "d2c885a273204aff1766a0eb53ab1bd63ae24e98", "stdout_len": 5886, "stdout": "FF.F.FFFFsFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n>       offset_utc = dt_utc.utcoffset()\nE       AttributeError: 'DateTime' object has no attribute 'utcoffset'\n\ntests\\Pendulum\\functional_test.py:72: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n        shifted = base.add(days=2, hours=5, minutes=15)\n        delta = shifted - base\n    \n>       assert delta.days == 2\nE       AttributeError: 'Duration' object has no attribute 'days'\n\ntests\\Pendulum\\functional_test.py:92: AttributeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_________________ test_duration_total_seconds_and_components __________________\n\n    def test_duration_total_seconds_and_components() -> None:\n        \"\"\"Verify duration reports correct total seconds and has component attributes.\"\"\"\n        dur = pendulum.duration(days=1, hours=2, minutes=3, seconds=4)\n    \n        # Total seconds is the most stable cross-version contract.\n        assert dur.total_seconds() == 1 * 86400 + 2 * 3600 + 3 * 60 + 4\n    \n        # Component attributes commonly exist; assert them when present.\n>       assert dur.days == 1\nE       AttributeError: 'Duration' object has no attribute 'days'\n\ntests\\Pendulum\\functional_test.py:168: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n        dt_ny = dt_utc.in_timezone(\"America/New_York\")\n    \n        assert int(dt_utc.timestamp()) == int(dt_ny.timestamp())\n>       assert dt_ny.to_date_string() in (\"2020-05-31\", \"2020-06-01\")\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:202: AttributeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_datetime_arithmetic_and_duration\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_duration_total_seconds_and_components\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n10 failed, 2 passed, 1 skipped in 0.68s\n"}
{"model": "gpt-5-2025-08-07", "project": "Petl", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.443989, "avg_memory_mb": 30.84, "avg_cpu_percent": 96.5, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 22:58:49", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "gpt-5-2025-08-07", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.384619, "avg_memory_mb": 14.56, "avg_cpu_percent": 89.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:04:15", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 5, in <module>\n    from .token import Token\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\token.py\", line 75, in <module>\n    Keyword.Constant = Keyword.Constant\nAttributeError: 'TokenType' object has no attribute 'Constant'\n", "stdout_sha1": "c452ba466edfa588c0841fe570254663c0861062", "stdout_len": 1674, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 5, in <module>\n    from .token import Token\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\token.py\", line 75, in <module>\n    Keyword.Constant = Keyword.Constant\nAttributeError: 'TokenType' object has no attribute 'Constant'\n"}
{"model": "gpt-5-2025-08-07", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'jwt' has no attribute 'get_unverified_header'", "returncode": 1, "elapsed_time_s": 1.864891, "avg_memory_mb": 32.89, "avg_cpu_percent": 97.4, "passed": 8, "failed": 2, "skipped": 1, "total": 11, "functional_score": 0.7273, "timestamp": "2025-12-31 23:05:07", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}, headers = None, json_encoder = None\n\n    def encode(\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        **kwargs: Any,\n    ) -> str:\n        \"\"\"\n        Create a JWT from a payload and key using HS256 by default.\n    \n        Supported kwargs:\n        - headers: optional dict to merge into header\n        - json_encoder: optional custom JSON encoder class\n        \"\"\"\n        headers = kwargs.get(\"headers\")\n        json_encoder = kwargs.get(\"json_encoder\")\n    \n        if algorithm != \"HS256\":\n            # Keep behavior minimal; only HS256 supported\n>           raise InvalidAlgorithmError(f\"Unsupported algorithm: {algorithm}\")\nE           jwt.exceptions.InvalidAlgorithmError: Unsupported algorithm: HS512\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:142: InvalidAlgorithmError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - j...\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n2 failed, 8 passed, 1 skipped in 0.48s\n", "stdout_sha1": "e457456343f0b2bf2344ee5d42604f156b40e531", "stdout_len": 2493, "stdout": ".F......F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}, headers = None, json_encoder = None\n\n    def encode(\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        **kwargs: Any,\n    ) -> str:\n        \"\"\"\n        Create a JWT from a payload and key using HS256 by default.\n    \n        Supported kwargs:\n        - headers: optional dict to merge into header\n        - json_encoder: optional custom JSON encoder class\n        \"\"\"\n        headers = kwargs.get(\"headers\")\n        json_encoder = kwargs.get(\"json_encoder\")\n    \n        if algorithm != \"HS256\":\n            # Keep behavior minimal; only HS256 supported\n>           raise InvalidAlgorithmError(f\"Unsupported algorithm: {algorithm}\")\nE           jwt.exceptions.InvalidAlgorithmError: Unsupported algorithm: HS512\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:142: InvalidAlgorithmError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - j...\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n2 failed, 8 passed, 1 skipped in 0.48s\n"}
{"model": "gpt-5-2025-08-07", "project": "PyPDF", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.435484, "avg_memory_mb": 31.09, "avg_cpu_percent": 97.7, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:07:27", "stdout_excerpt": "\n1 skipped in 0.11s\n", "stdout_sha1": "75923eec7092d4a8427af710fe49bcf2a0b64e5b", "stdout_len": 20, "stdout": "\n1 skipped in 0.11s\n"}
{"model": "gpt-5-2025-08-07", "project": "Requests", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword argument 'headers'", "returncode": 1, "elapsed_time_s": 3.524825, "avg_memory_mb": 36.43, "avg_cpu_percent": 53.7, "passed": 8, "failed": 2, "skipped": 0, "total": 10, "functional_score": 0.8, "timestamp": "2025-12-31 23:09:02", "stdout_excerpt": "==== FAILURES ===================================\n____________________ test_streaming_response_iter_content _____________________\n\n    def test_streaming_response_iter_content() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/get\", stream=True)\n\ntests\\Requests\\functional_test.py:258: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <requests.sessions.Session object at 0x000001D7960602B0>\nurl = 'http://127.0.0.1:60927/get'\nkwargs = {'allow_redirects': True, 'stream': True}\n\n    def get(self, url, **kwargs):\n        kwargs.setdefault(\"allow_redirects\", True)\n>       return self.request(\"GET\", url, **kwargs)\nE       TypeError: request() got an unexpected keyword argument 'stream'\n\ngeneration\\Requests\\requests\\sessions.py:95: TypeError\n_______________ test_prepared_request_contains_headers_and_url ________________\n\n    def test_prepared_request_contains_headers_and_url() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           req = requests.Request(\"GET\", base_url + \"/get\", headers={\"X-Test\": \"1\"})\nE           TypeError: __init__() got an unexpected keyword argument 'headers'\n\ntests\\Requests\\functional_test.py:285: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Requests/functional_test.py::test_streaming_response_iter_content\nFAILED tests/Requests/functional_test.py::test_prepared_request_contains_headers_and_url\n2 failed, 8 passed in 2.23s\n", "stdout_sha1": "2487cf07451545193616ab32d10d6c5eb3439067", "stdout_len": 1690, "stdout": ".......F.F                                                               [100%]\n================================== FAILURES ===================================\n____________________ test_streaming_response_iter_content _____________________\n\n    def test_streaming_response_iter_content() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/get\", stream=True)\n\ntests\\Requests\\functional_test.py:258: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <requests.sessions.Session object at 0x000001D7960602B0>\nurl = 'http://127.0.0.1:60927/get'\nkwargs = {'allow_redirects': True, 'stream': True}\n\n    def get(self, url, **kwargs):\n        kwargs.setdefault(\"allow_redirects\", True)\n>       return self.request(\"GET\", url, **kwargs)\nE       TypeError: request() got an unexpected keyword argument 'stream'\n\ngeneration\\Requests\\requests\\sessions.py:95: TypeError\n_______________ test_prepared_request_contains_headers_and_url ________________\n\n    def test_prepared_request_contains_headers_and_url() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           req = requests.Request(\"GET\", base_url + \"/get\", headers={\"X-Test\": \"1\"})\nE           TypeError: __init__() got an unexpected keyword argument 'headers'\n\ntests\\Requests\\functional_test.py:285: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Requests/functional_test.py::test_streaming_response_iter_content\nFAILED tests/Requests/functional_test.py::test_prepared_request_contains_headers_and_url\n2 failed, 8 passed in 2.23s\n"}
{"model": "gpt-5-2025-08-07", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.468845, "avg_memory_mb": 32.12, "avg_cpu_percent": 101.2, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:13:24", "stdout_excerpt": "\n1 skipped in 0.16s\n", "stdout_sha1": "a1849a7e09f94d0f14b1c3622e0bedba158ebbdf", "stdout_len": 20, "stdout": "\n1 skipped in 0.16s\n"}
{"model": "gpt-5-2025-08-07", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where <built-in method startswith of str object at 0x000001BD985B9F30> = 'thisisatest'.startswith", "returncode": 1, "elapsed_time_s": 1.87216, "avg_memory_mb": 31.71, "avg_cpu_percent": 101.7, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2025-12-31 23:14:41", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001BD985B9F30>('___')\nE        +    where <built-in method startswith of str object at 0x000001BD985B9F30> = 'thisisatest'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.48s\n", "stdout_sha1": "2eed1a69370da8a49ab9a9cbc16b145ceaa9d688", "stdout_len": 1078, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001BD985B9F30>('___')\nE        +    where <built-in method startswith of str object at 0x000001BD985B9F30> = 'thisisatest'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.48s\n"}
{"model": "gpt-5-2025-08-07", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "", "exception_msg": "assert None is not None", "returncode": 1, "elapsed_time_s": 3.48246, "avg_memory_mb": 32.1, "avg_cpu_percent": 50.9, "passed": 8, "failed": 1, "skipped": 0, "total": 9, "functional_score": 0.8889, "timestamp": "2025-12-31 23:15:42", "stdout_excerpt": "==== FAILURES ===================================\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_importable():\n        \"\"\"\n        Alignment anchors (must exist in BOTH reference and generated repos):\n    \n          - lib.parse.cmdline.cmdLineParser\n          - lib.core.option.init, lib.core.option.initOptions\n          - lib.core.data: cmdLineOptions, conf, kb\n          - lib.core.settings: VERSION, DESCRIPTION\n          - lib.controller.controller.start\n    \n        Only checks importability + symbol presence; does not execute scanning logic.\n        \"\"\"\n        repo = _repo_root()\n        sys.path.insert(0, str(repo))\n        try:\n            from lib.parse.cmdline import cmdLineParser  # noqa: F401\n            from lib.core.option import init, initOptions  # noqa: F401\n            from lib.core.data import cmdLineOptions, conf, kb  # noqa: F401\n            from lib.core.settings import VERSION, DESCRIPTION  # noqa: F401\n            from lib.controller.controller import start  # noqa: F401\n    \n            assert callable(cmdLineParser)\n            assert callable(init)\n            assert callable(initOptions)\n>           assert cmdLineOptions is not None\nE           assert None is not None\n\ntests\\Sqlmap\\functional_test.py:119: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_007_alignment_api_surface_symbols_importable\n1 failed, 8 passed in 2.09s\n", "stdout_sha1": "57170569520990a728b8004b2de78011dd301325", "stdout_len": 1655, "stdout": "......F..                                                                [100%]\n================================== FAILURES ===================================\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_importable():\n        \"\"\"\n        Alignment anchors (must exist in BOTH reference and generated repos):\n    \n          - lib.parse.cmdline.cmdLineParser\n          - lib.core.option.init, lib.core.option.initOptions\n          - lib.core.data: cmdLineOptions, conf, kb\n          - lib.core.settings: VERSION, DESCRIPTION\n          - lib.controller.controller.start\n    \n        Only checks importability + symbol presence; does not execute scanning logic.\n        \"\"\"\n        repo = _repo_root()\n        sys.path.insert(0, str(repo))\n        try:\n            from lib.parse.cmdline import cmdLineParser  # noqa: F401\n            from lib.core.option import init, initOptions  # noqa: F401\n            from lib.core.data import cmdLineOptions, conf, kb  # noqa: F401\n            from lib.core.settings import VERSION, DESCRIPTION  # noqa: F401\n            from lib.controller.controller import start  # noqa: F401\n    \n            assert callable(cmdLineParser)\n            assert callable(init)\n            assert callable(initOptions)\n>           assert cmdLineOptions is not None\nE           assert None is not None\n\ntests\\Sqlmap\\functional_test.py:119: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_007_alignment_api_surface_symbols_importable\n1 failed, 8 passed in 2.09s\n"}
{"model": "gpt-5-2025-08-07", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "'Metadata' object has no attribute 'clear'", "returncode": 2, "elapsed_time_s": 1.908516, "avg_memory_mb": 36.37, "avg_cpu_percent": 99.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:17:04", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: 'Metadata' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: 'Metadata' object h...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.56s\n", "stdout_sha1": "9d83b5a9f8be28bc69748710da23c5b5110bdb8a", "stdout_len": 562, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: 'Metadata' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: 'Metadata' object h...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.56s\n"}
{"model": "gpt-5-2025-08-07", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "image must be a PIL.Image.Image instance", "returncode": 1, "elapsed_time_s": 7.869946, "avg_memory_mb": 36.24, "avg_cpu_percent": 99.5, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2025-12-31 23:19:01", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: Union[str, bytes],\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False,\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text/byte message inside the least significant bits of image channels.\n        - If generator is provided, it selects the slot indices to modify (offset by 'shift').\n        - Otherwise, slots are used sequentially starting from 'shift'.\n        The message is stored with a 32-bit big-endian length prefix to allow extraction.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:80: TypeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x0000025593E28BA0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: Union[str, bytes],\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False,\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text/byte message inside the least significant bits of image channels.\n        - If generator is provided, it selects the slot indices to modify (offset by 'shift').\n        - Otherwise, slots are used sequentially starting from 'shift'.\n        The message is stored with a 32-bit big-endian length prefix to allow extraction.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:80: TypeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret m", "stdout_sha1": "82820420bb52afed6f8e1b0d34f5246466dc6ce3", "stdout_len": 11938, "stdout": "FFFFFF.....F                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: Union[str, bytes],\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False,\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text/byte message inside the least significant bits of image channels.\n        - If generator is provided, it selects the slot indices to modify (offset by 'shift').\n        - Otherwise, slots are used sequentially starting from 'shift'.\n        The message is stored with a 32-bit big-endian length prefix to allow extraction.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:80: TypeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x0000025593E28BA0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: Union[str, bytes],\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False,\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text/byte message inside the least significant bits of image channels.\n        - If generator is provided, it selects the slot indices to modify (offset by 'shift').\n        - Otherwise, slots are used sequentially starting from 'shift'.\n        The message is stored with a 32-bit big-endian length prefix to allow extraction.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:80: TypeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'This is a longer secret message with punctuation: 12345, hello-world!'\ngenerator = None, shift = 0, encoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: Union[str, bytes],\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False,\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text/byte message inside the least significant bits of image channels.\n        - If generator is provided, it selects the slot indices to modify (offset by 'shift').\n        - Otherwise, slots are used sequentially starting from 'shift'.\n        The message is stored with a 32-bit big-endian length prefix to allow extraction.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:80: TypeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n>       img_obj = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'object input', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: Union[str, bytes],\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False,\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text/byte message inside the least significant bits of image channels.\n        - If generator is provided, it selects the slot indices to modify (offset by 'shift').\n        - Otherwise, slots are used sequentially starting from 'shift'.\n        The message is stored with a 32-bit big-endian length prefix to allow extraction.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:80: TypeError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'red secret'\n\n    def hide(image: Image.Image, message: Union[str, bytes]) -> Image.Image:\n        \"\"\"\n        Hide text in the red channel (LSB) of an RGB/RGBA image.\n        Stores a 32-bit big-endian length prefix followed by message bytes.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\red\\red.py:20: TypeError\n________________ test_red_hide_and_reveal_extended_latin_text _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_red_hide_and_reveal_exten0')\n\n    def test_red_hide_and_reveal_extended_latin_text(tmp_path: Path) -> None:\n        \"\"\"Red backend stores per-char ord() into a byte channel; Latin-1 chars like 'é' are valid.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"Café au lait\"\n        output = tmp_path / \"red_latin.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'Café au lait'\n\n    def hide(image: Image.Image, message: Union[str, bytes]) -> Image.Image:\n        \"\"\"\n        Hide text in the red channel (LSB) of an RGB/RGBA image.\n        Stores a 32-bit big-endian length prefix followed by message bytes.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\red\\red.py:20: TypeError\n_____________________ test_lsb_and_red_outputs_are_files ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-365/test_lsb_and_red_outputs_are_f0')\n\n    def test_lsb_and_red_outputs_are_files(tmp_path: Path) -> None:\n        \"\"\"Ensure image-encoding backends produce files that can be written to disk.\"\"\"\n        _ensure_image_samples_exist()\n    \n        out_lsb = tmp_path / \"lsb_file.png\"\n        out_red = tmp_path / \"red_file.png\"\n    \n>       lsb.hide(str(LENNA_PNG), \"x\").save(str(out_lsb))\n\ntests\\Stegano\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'x', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: Union[str, bytes],\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False,\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text/byte message inside the least significant bits of image channels.\n        - If generator is provided, it selects the slot indices to modify (offset by 'shift').\n        - Otherwise, slots are used sequentially starting from 'shift'.\n        The message is stored with a 32-bit big-endian length prefix to allow extraction.\n        \"\"\"\n        if not isinstance(image, Image.Image):\n>           raise TypeError(\"image must be a PIL.Image.Image instance\")\nE           TypeError: image must be a PIL.Image.Image instance\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:80: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Type...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_text - Type...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_extended_latin_text\nFAILED tests/Stegano/functional_test.py::test_lsb_and_red_outputs_are_files\n7 failed, 5 passed in 6.46s\n"}
{"model": "gpt-5-2025-08-07", "project": "Tablib", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "ValueError", "exception_msg": "Unsupported format: html", "returncode": 1, "elapsed_time_s": 2.036042, "avg_memory_mb": 31.95, "avg_cpu_percent": 94.3, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2025-12-31 23:20:09", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tablib\\tablib\\core.py:154: in export\n    exporter, _ = _get_dataset_format_handlers(fmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = 'tsv'\n\n    def _get_dataset_format_handlers(fmt: str):\n        \"\"\"Lazily import dataset format handlers.\"\"\"\n        if fmt == \"csv\":\n            from .formats import _csv as mod\n        elif fmt == \"json\":\n            from .formats import _json as mod\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:12: ValueError\n_______________ test_dataset_row_column_operations_and_slicing ________________\n\n    def test_dataset_row_column_operations_and_slicing() -> None:\n        \"\"\"Validate row appending, column appending, and slicing semantics.\"\"\"\n        data = tablib.Dataset()\n        data.headers = (\"city\", \"country\")\n        data.append((\"Berlin\", \"DE\"))\n        data.append((\"Paris\", \"FR\"))\n        data.append((\"Tokyo\", \"JP\"))\n    \n        populations = (3_500_000, 2_100_000, 13_900_000)\n        data.append_col(populations, header=\"population\")\n    \n        assert data.height == 3\n>       assert data.width == 3\nE       assert 2 == 3\nE        +  where 2 = <tablib.core.Dataset object at 0x00000195E4A47DC0>.width\n\ntests\\Tablib\\functional_test.py:210: AssertionError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tablib\\tablib\\core.py:154: in export\n    exporter, _ = _get_dataset_format_handlers(fmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = 'html'\n\n    def _get_dataset_format_handlers(fmt: str):\n        \"\"\"Lazily import dataset format handlers.\"\"\"\n        if fmt == \"csv\":\n            from .formats import _csv as mod\n        elif fmt == \"json\":\n            from .formats import _json as mod\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:12: ValueError\n__________________ test_databook_multi_sheet_json_roundtrip ___________________\n\n    def test_databook_multi_sheet_json_roundtrip() -> None:\n        \"\"\"Databook should preserve sheet structure when exported/imported as JSON.\"\"\"\n        sheet1 = tablib.Dataset(\n            (1, \"a\"),\n            (2, \"b\"),\n            headers=(\"id\", \"val", "stdout_sha1": "1e60c72f24a9d1b7832d5e77a8a8a48ae7ba022c", "stdout_len": 5376, "stdout": ".F.FF...FF.                                                              [100%]\n================================== FAILURES ===================================\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tablib\\tablib\\core.py:154: in export\n    exporter, _ = _get_dataset_format_handlers(fmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = 'tsv'\n\n    def _get_dataset_format_handlers(fmt: str):\n        \"\"\"Lazily import dataset format handlers.\"\"\"\n        if fmt == \"csv\":\n            from .formats import _csv as mod\n        elif fmt == \"json\":\n            from .formats import _json as mod\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:12: ValueError\n_______________ test_dataset_row_column_operations_and_slicing ________________\n\n    def test_dataset_row_column_operations_and_slicing() -> None:\n        \"\"\"Validate row appending, column appending, and slicing semantics.\"\"\"\n        data = tablib.Dataset()\n        data.headers = (\"city\", \"country\")\n        data.append((\"Berlin\", \"DE\"))\n        data.append((\"Paris\", \"FR\"))\n        data.append((\"Tokyo\", \"JP\"))\n    \n        populations = (3_500_000, 2_100_000, 13_900_000)\n        data.append_col(populations, header=\"population\")\n    \n        assert data.height == 3\n>       assert data.width == 3\nE       assert 2 == 3\nE        +  where 2 = <tablib.core.Dataset object at 0x00000195E4A47DC0>.width\n\ntests\\Tablib\\functional_test.py:210: AssertionError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Tablib\\tablib\\core.py:154: in export\n    exporter, _ = _get_dataset_format_handlers(fmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = 'html'\n\n    def _get_dataset_format_handlers(fmt: str):\n        \"\"\"Lazily import dataset format handlers.\"\"\"\n        if fmt == \"csv\":\n            from .formats import _csv as mod\n        elif fmt == \"json\":\n            from .formats import _json as mod\n        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:12: ValueError\n__________________ test_databook_multi_sheet_json_roundtrip ___________________\n\n    def test_databook_multi_sheet_json_roundtrip() -> None:\n        \"\"\"Databook should preserve sheet structure when exported/imported as JSON.\"\"\"\n        sheet1 = tablib.Dataset(\n            (1, \"a\"),\n            (2, \"b\"),\n            headers=(\"id\", \"value\"),\n        )\n        sheet1.title = \"First\"\n    \n        sheet2 = tablib.Dataset(\n            (3, \"c\"),\n            (4, \"d\"),\n            headers=(\"id\", \"value\"),\n        )\n        sheet2.title = \"Second\"\n    \n        book = tablib.Databook([sheet1, sheet2])\n    \n        json_text = book.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'sheets': [{'data': [[1, 'a'], [2, 'b']], 'headers': ['id', 'value'], 'title': 'First'}, {'data': [[3, 'c'], [4, 'd']], 'headers': ['id', 'value'], 'title': 'Second'}]}, list)\n\ntests\\Tablib\\functional_test.py:324: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_row_column_operations_and_slicing\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\nFAILED tests/Tablib/functional_test.py::test_databook_multi_sheet_json_roundtrip\n5 failed, 6 passed in 0.70s\n"}
{"model": "gpt-5-2025-08-07", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "tabulate() got an unexpected keyword argument 'maxcolwidths'", "returncode": 1, "elapsed_time_s": 1.965115, "avg_memory_mb": 32.71, "avg_cpu_percent": 100.8, "passed": 8, "failed": 4, "skipped": 0, "total": 12, "functional_score": 0.6667, "timestamp": "2025-12-31 23:22:01", "stdout_excerpt": "==== FAILURES ===================================\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n>       out_true = tabulate(table, showindex=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'showindex'\n\ntests\\Tabulate\\functional_test.py:151: TypeError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001915F3D7170>('|')\nE        +    where <built-in method startswith of str object at 0x000001915F3D7170> = 'item  qty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - TypeError...\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Asse...\nFAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n4 failed, 8 passed in 0.56s\n", "stdout_sha1": "506835ed250a75eed09aa0bf58c34ae5b5431400", "stdout_len": 2777, "stdout": "....FF...FF.                                                             [100%]\n================================== FAILURES ===================================\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n>       out_true = tabulate(table, showindex=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'showindex'\n\ntests\\Tabulate\\functional_test.py:151: TypeError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000001915F3D7170>('|')\nE        +    where <built-in method startswith of str object at 0x000001915F3D7170> = 'item  qty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - TypeError...\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Asse...\nFAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n4 failed, 8 passed in 0.56s\n"}
{"model": "gpt-5-2025-08-07", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "could not convert string to float: 'X'", "returncode": 124, "elapsed_time_s": 60.051201, "avg_memory_mb": 32.73, "avg_cpu_percent": 0.26, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:24:11", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\nself = <termgraph.data.Data object at 0x00000163A7F214F0>\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'A'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F216A0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7F214F0>\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: A\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\nself = <termgraph.data.Data object at 0x00000163A7F82A90>\nlabels = [[1, 2], [3, 4]], series = ['X', 'Y']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'X'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F82940>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       ", "stdout_sha1": "7e2583e860a11cfc5a11709dc257747ed1129778", "stdout_len": 19619, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\nself = <termgraph.data.Data object at 0x00000163A7F214F0>\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'A'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F216A0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7F214F0>\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: A\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\nself = <termgraph.data.Data object at 0x00000163A7F82A90>\nlabels = [[1, 2], [3, 4]], series = ['X', 'Y']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'X'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F82940>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7F82A90>\nlabels = [[1, 2], [3, 4]], series = ['X', 'Y']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: X\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\nself = <termgraph.data.Data object at 0x00000163A7F12400>, labels = [[4], [1]]\nseries = ['D', 'E']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'D'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F129D0>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7F12400>, labels = [[4], [1]]\nseries = ['D', 'E']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: D\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\nself = <termgraph.data.Data object at 0x00000163A7F010D0>, labels = [[2], [7]]\nseries = ['A', 'B']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'A'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F016A0>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7F010D0>, labels = [[2], [7]]\nseries = ['A', 'B']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: A\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\nself = <termgraph.data.Data object at 0x00000163A7F00E80>\nlabels = [[1], [2], [3]], series = ['L1', 'L2', 'L3']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'L'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F00F40>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7F00E80>\nlabels = [[1], [2], [3]], series = ['L1', 'L2', 'L3']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: L\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\nself = <termgraph.data.Data object at 0x00000163A7EFB5E0>\nlabels = [[12.5], [7.0]], series = ['CPU', 'RAM']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'C'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F01670>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7EFB5E0>\nlabels = [[12.5], [7.0]], series = ['CPU', 'RAM']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: C\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\nself = <termgraph.data.Data object at 0x00000163A7EDFD90>\nlabels = [[3.14159], [2.71828]], series = ['P', 'Q']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'P'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7EDF9D0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.data.Data object at 0x00000163A7EDFD90>\nlabels = [[3.14159], [2.71828]], series = ['P', 'Q']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n                        new_row.append(float(v))\n                except Exception:\n>                   raise ValueError(f\"Non-numeric value at row {i}: {v}\")\nE                   ValueError: Non-numeric value at row 0: P\n\ngeneration\\Termgraph\\termgraph\\data.py:32: ValueError\n____________________ test_stacked_chart_renders_all_labels ____________________\n\nself = <termgraph.data.Data object at 0x00000163A7F83FD0>\nlabels = [[1, 1], [2, 1], [1, 3]], series = ['S1', 'S2', 'S3']\n\n    def __init__(self, labels: Sequence[str], series: Sequence[Sequence[float]]):\n        self.labels = list(labels)\n        self.series = [list(row) for row in series]\n        if len(self.labels) != len(self.series):\n            raise ValueError(\"labels and series must have the same number of rows\")\n        # Normalize None rows\n        for i, row in enumerate(self.series):\n            if row is None:\n                self.series[i] = []\n        # Ensure numbers\n        for i, row in enumerate(self.series):\n            new_row = []\n            for v in row:\n                try:\n                    if v is None:\n                        new_row.append(0.0)\n                    else:\n>                       new_row.append(float(v))\nE                       ValueError: could not convert string to float: 'S'\n\ngeneration\\Termgraph\\termgraph\\data.py:30: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000163A7F832E0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n"}
{"model": "gpt-5-2025-08-07", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 2.207544, "avg_memory_mb": 32.98, "avg_cpu_percent": 93.35, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 23:27:37", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "11b843c9e1eab345569d5cb06f42f9f26ae21a96", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-366/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-366/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-366/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x00000247DCB51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.80s\n"}
{"model": "gpt-5-2025-08-07", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'TinyDB' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.960023, "avg_memory_mb": 36.1, "avg_cpu_percent": 99.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:33:18", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'TinyDB' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.62s\n", "stdout_sha1": "2d2152812bbb419a5e743aa15f3570e11f007eb3", "stdout_len": 988, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'TinyDB' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.62s\n"}
{"model": "gpt-5-2025-08-07", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword argument 'prompt'", "returncode": 1, "elapsed_time_s": 2.10478, "avg_memory_mb": 32.7, "avg_cpu_percent": 97.7, "passed": 4, "failed": 8, "skipped": 0, "total": 12, "functional_score": 0.3333, "timestamp": "2025-12-31 23:34:25", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1 stdout_len=0 stderr_len=58>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x00000212AD485FD0>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command", "stdout_sha1": "9cb32ab3f6c741a1e442e835c33a67828d495b61", "stdout_len": 6258, "stdout": "FFF..F..FFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1 stdout_len=0 stderr_len=58>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x00000212AD485FD0>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:159: AttributeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n        app = _create_types_app()\n        # Now stable: \"calc\" always exists as a subcommand (multi-command app).\n        r = runner.invoke(app, [\"calc\", \"2\", \"3\", \"--scale\", \"2.0\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result exit_code=1 stdout_len=0 stderr_len=56>.exit_code\n\ntests\\Typer\\functional_test.py:313: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AttributeE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - At...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n8 failed, 4 passed in 0.66s\n"}
{"model": "gpt-5-2025-08-07", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 2.398937, "avg_memory_mb": 36.04, "avg_cpu_percent": 95.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:35:56", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n", "stdout_sha1": "ab9a030ccb03922d0202a790bd63e9a6545205ea", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n"}
{"model": "gpt-5-2025-08-07", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert {'#text': '1'} == '1'", "returncode": 1, "elapsed_time_s": 2.070727, "avg_memory_mb": 34.13, "avg_cpu_percent": 100.8, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2025-12-31 23:37:11", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n        assert any(k.startswith(\"x:\") for k in keys)\n    \n        key = next(k for k in keys if k.startswith(\"x:\"))\n>       assert root[key] == \"value\"\nE       AssertionError: assert {'#text': 'value'} == 'value'\n\ntests\\Xmltodict\\functional_test.py:134: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n            assert isinstance(item, list)\n            assert item == [\"1\"]\n        else:\n            # Fallback: without force_list support, single element is typically a scalar string.\n>           assert item == \"1\"\nE           AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:169: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n            assert \"@id\" not in user\n            assert user[\"name\"] == \"Alice\"\n        else:\n            # Fa", "stdout_sha1": "e3bac09a4a3624f3971293b11ef5e539da5b8aab", "stdout_len": 7564, "stdout": "FF..FFF.FFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n        assert any(k.startswith(\"x:\") for k in keys)\n    \n        key = next(k for k in keys if k.startswith(\"x:\"))\n>       assert root[key] == \"value\"\nE       AssertionError: assert {'#text': 'value'} == 'value'\n\ntests\\Xmltodict\\functional_test.py:134: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n            assert isinstance(item, list)\n            assert item == [\"1\"]\n        else:\n            # Fallback: without force_list support, single element is typically a scalar string.\n>           assert item == \"1\"\nE           AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:169: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n            assert \"@id\" not in user\n            assert user[\"name\"] == \"Alice\"\n        else:\n            # Fallback: attribute is included in typical default behavior.\n            assert user.get(\"@id\") == \"9\"\n>           assert user[\"name\"] == \"Alice\"\nE           AssertionError: assert {'#text': 'Alice'} == 'Alice'\n\ntests\\Xmltodict\\functional_test.py:201: AssertionError\n______________________ test_dict_constructor_ordereddict ______________________\n\n    def test_dict_constructor_ordereddict() -> None:\n        \"\"\"dict_constructor should allow choosing mapping type (e.g., OrderedDict) when supported.\"\"\"\n        xml = \"<root><a>1</a><b>2</b></root>\"\n        data = _parse(xml, dict_constructor=OrderedDict)\n    \n        if \"dict_constructor\" in _PARSE_PARAMS:\n>           assert isinstance(data, OrderedDict)\nE           AssertionError: assert False\nE            +  where False = isinstance({'root': OrderedDict([('a', OrderedDict([('#text', '1')])), ('b', OrderedDict([('#text', '2')]))])}, OrderedDict)\n\ntests\\Xmltodict\\functional_test.py:210: AssertionError\n_____________________ test_unparse_pretty_and_parse_back ______________________\n\n    def test_unparse_pretty_and_parse_back() -> None:\n        \"\"\"Pretty/full_document knobs should not break roundtrip of basic structure.\"\"\"\n        original: Dict[str, Any] = {\"root\": {\"x\": \"1\", \"y\": \"2\"}}\n    \n        xml = _unparse(original, pretty=True, full_document=True)\n        assert \"<root>\" in xml or \"<root\" in xml\n    \n        round_tripped = _parse(xml)\n>       assert round_tripped == original\nE       AssertionError: assert {'root': {'x'...#text': '2'}}} == {'root': {'x': '1', 'y': '2'}}\nE         \nE         Differing items:\nE         {'root': {'x': {'#text': '1'}, 'y': {'#text': '2'}}} != {'root': {'x': '1', 'y': '2'}}\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:227: AssertionError\n______________ test_postprocessor_transforms_value_if_supported _______________\n\n    def test_postprocessor_transforms_value_if_supported() -> None:\n        \"\"\"postprocessor can transform values in a happy-path parse when supported.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n    \n        def _pp(path: Any, key: str, value: Any) -> Any:\n            if key == \"message\" and isinstance(value, str):\n                return key, value.upper()\n            return key, value\n    \n        data = _parse(xml, postprocessor=_pp)\n    \n        if \"postprocessor\" in _PARSE_PARAMS:\n            assert data[\"root\"][\"message\"] == \"HELLO\"\n        else:\n>           assert data[\"root\"][\"message\"] == \"Hello\"\nE           AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:244: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_parse_simple_element - Assert...\nFAILED tests/Xmltodict/functional_test.py::test_parse_repeated_elements_as_list\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\nFAILED tests/Xmltodict/functional_test.py::test_parse_nested_structure - Asse...\nFAILED tests/Xmltodict/functional_test.py::test_force_list_option_for_single_element\nFAILED tests/Xmltodict/functional_test.py::test_xml_attribs_false_drops_attributes_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_dict_constructor_ordereddict\nFAILED tests/Xmltodict/functional_test.py::test_unparse_pretty_and_parse_back\nFAILED tests/Xmltodict/functional_test.py::test_postprocessor_transforms_value_if_supported\n9 failed, 3 passed in 0.72s\n"}
{"model": "gpt-5.2", "project": "Cachetools", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "TypeError", "exception_msg": "nonempty __slots__ not supported for subtype of 'tuple'", "returncode": 2, "elapsed_time_s": 1.631377, "avg_memory_mb": 35.64, "avg_cpu_percent": 98.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2025-12-31 23:46:24", "stdout_excerpt": "====\n____________ ERROR collecting tests/Cachetools/functional_test.py _____________\ntests\\Cachetools\\functional_test.py:26: in <module>\n    from cachetools import LRUCache, TTLCache, cached  # type: ignore  # noqa: E402\ngeneration\\Cachetools\\cachetools\\__init__.py:12: in <module>\n    from .decorators import cached, cachedmethod\ngeneration\\Cachetools\\cachetools\\decorators.py:6: in <module>\n    from .keys import hashkey, methodkey\ngeneration\\Cachetools\\cachetools\\keys.py:6: in <module>\n    class _HashedTuple(tuple):\nE   TypeError: nonempty __slots__ not supported for subtype of 'tuple'\n=========================== short test summary info ===========================\nERROR tests/Cachetools/functional_test.py - TypeError: nonempty __slots__ not...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.48s\n", "stdout_sha1": "73a14fa0eab2109dc2803ca52b6979e815a5cef4", "stdout_len": 926, "stdout": "\n=================================== ERRORS ====================================\n____________ ERROR collecting tests/Cachetools/functional_test.py _____________\ntests\\Cachetools\\functional_test.py:26: in <module>\n    from cachetools import LRUCache, TTLCache, cached  # type: ignore  # noqa: E402\ngeneration\\Cachetools\\cachetools\\__init__.py:12: in <module>\n    from .decorators import cached, cachedmethod\ngeneration\\Cachetools\\cachetools\\decorators.py:6: in <module>\n    from .keys import hashkey, methodkey\ngeneration\\Cachetools\\cachetools\\keys.py:6: in <module>\n    class _HashedTuple(tuple):\nE   TypeError: nonempty __slots__ not supported for subtype of 'tuple'\n=========================== short test summary info ===========================\nERROR tests/Cachetools/functional_test.py - TypeError: nonempty __slots__ not...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.48s\n"}
{"model": "gpt-5.2", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ImportError", "exception_msg": "cannot import name 'signature' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)", "returncode": 1, "elapsed_time_s": 1.980997, "avg_memory_mb": 32.86, "avg_cpu_percent": 100.0, "passed": 5, "failed": 5, "skipped": 0, "total": 10, "functional_score": 0.5, "timestamp": "2025-12-31 23:48:06", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n        app = _make_app()\n>       from celery import group\nE       ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:90: ImportError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n        app = _make_app()\n>       from celery import chain\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:104: ImportError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n        app = _make_app()\n>       from celery import chord, group\nE       ImportError: cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:117: ImportError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n        app = _make_app()\n>       from celery import signature\nE       ImportError: cannot import name 'signature' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:191: ImportError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\n5 failed, 5 passed in 0.62s\n", "stdout_sha1": "19eaa03bd8f98f80b1236d24ec057f6d11cf5b0f", "stdout_len": 2777, "stdout": "F..FFF..F.                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n        app = _make_app()\n>       from celery import group\nE       ImportError: cannot import name 'group' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:90: ImportError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n        app = _make_app()\n>       from celery import chain\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:104: ImportError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n        app = _make_app()\n>       from celery import chord, group\nE       ImportError: cannot import name 'chord' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:117: ImportError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n        app = _make_app()\n>       from celery import signature\nE       ImportError: cannot import name 'signature' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:191: ImportError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\n5 failed, 5 passed in 0.62s\n"}
{"model": "gpt-5.2", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "string indices must be integers", "returncode": 1, "elapsed_time_s": 5.021787, "avg_memory_mb": 34.82, "avg_cpu_percent": 99.3, "passed": 7, "failed": 4, "skipped": 0, "total": 11, "functional_score": 0.6364, "timestamp": "2025-12-31 23:57:56", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:252: in find\n    cur = self.db.execute(f\"SELECT * FROM {self.quoted_name} WHERE {where_sql}\", params)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001F39A7201F0>\nsql = 'SELECT * FROM \"users\" WHERE \"age\" = :age', params = {'age': {'>=': 40}}\n\n    def execute(self, sql: str, params: Optional[Mapping[str, Any]] = None) -> sqlite3.Cursor:\n        with self._lock:\n            if params is None:\n                return self._conn.execute(sql)\n>           return self._conn.execute(sql, dict(params))\nE           sqlite3.InterfaceError: Error binding parameter :age - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\database.py:172: InterfaceError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x000001F39A763340>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001F39A711D60>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - as...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n4 failed, 7 passed in 3.70s\n", "stdout_sha1": "34a30a0f17a5d35600adb81179cc7f92ab9675b0", "stdout_len": 3990, "stdout": "F....F..F.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Dataset\\dataset\\table.py:252: in find\n    cur = self.db.execute(f\"SELECT * FROM {self.quoted_name} WHERE {where_sql}\", params)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.database.Database object at 0x000001F39A7201F0>\nsql = 'SELECT * FROM \"users\" WHERE \"age\" = :age', params = {'age': {'>=': 40}}\n\n    def execute(self, sql: str, params: Optional[Mapping[str, Any]] = None) -> sqlite3.Cursor:\n        with self._lock:\n            if params is None:\n                return self._conn.execute(sql)\n>           return self._conn.execute(sql, dict(params))\nE           sqlite3.InterfaceError: Error binding parameter :age - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\database.py:172: InterfaceError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x000001F39A763340>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001F39A711D60>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - as...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n4 failed, 7 passed in 3.70s\n"}
{"model": "gpt-5.2", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 00:00:12", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "gpt-5.2", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "RecursionError", "exception_msg": "maximum recursion depth exceeded while encoding a JSON object", "returncode": 1, "elapsed_time_s": 16.052347, "avg_memory_mb": 115.04, "avg_cpu_percent": 99.4, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 00:04:06", "stdout_excerpt": "==== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       html = m.get_root().render()\n\ntests\\Folium\\functional_test.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        root = m.get_root()\n        assert hasattr(root, \"render\")\n>       html = root.render().lower()\n\ntests\\Folium\\functional_test.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n        folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\n        folium.LayerControl().add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:95: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while encoding a JSON object\n!!! Recursion ", "stdout_sha1": "4cd50e4073381c7bc926f72aa4397389b58992de", "stdout_len": 8879, "stdout": "..FFFFFFFF.F                                                             [100%]\n================================== FAILURES ===================================\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       html = m.get_root().render()\n\ntests\\Folium\\functional_test.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        root = m.get_root()\n        assert hasattr(root, \"render\")\n>       html = root.render().lower()\n\ntests\\Folium\\functional_test.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       base = m.get_root().render()\n\ntests\\Folium\\functional_test.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n        import folium\n    \n        m = folium.Map(location=[0, 0], zoom_start=2, tiles=None)\n        folium.TileLayer(\"OpenStreetMap\", name=\"osm\").add_to(m)\n        folium.LayerControl().add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:95: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while encoding a JSON object\n!!! Recursion detected (same locals & position)\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"name\": \"p\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        folium.GeoJson(gj, name=\"g\").add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while encoding a JSON object\n!!! Recursion detected (same locals & position)\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n        import folium\n    \n        gj = {\n            \"type\": \"FeatureCollection\",\n            \"features\": [\n                {\n                    \"type\": \"Feature\",\n                    \"properties\": {\"style\": \"x\"},\n                    \"geometry\": {\"type\": \"Point\", \"coordinates\": [0.0, 0.0]},\n                }\n            ],\n        }\n    \n        def style_fn(feature):\n            _ = feature\n            return {\"color\": \"red\", \"weight\": 2}\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        folium.GeoJson(gj, style_function=style_fn).add_to(m)\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while encoding a JSON object\n!!! Recursion detected (same locals & position)\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-370/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n        import folium\n    \n        out = tmp_path / \"m.html\"\n        m = folium.Map(location=[0, 0], zoom_start=2)\n>       m.save(str(out))\nE       AttributeError: 'Map' object has no attribute 'save'\n\ntests\\Folium\\functional_test.py:153: AttributeError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n        import folium\n    \n        plugins = _plugins_module()\n        MarkerCluster = getattr(plugins, \"MarkerCluster\")\n    \n        m = folium.Map(location=[0, 0], zoom_start=2)\n        mc = MarkerCluster(name=\"mc\").add_to(m)\n        assert mc is not None\n    \n>       html = m.get_root().render().lower()\n\ntests\\Folium\\functional_test.py:177: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\ngeneration\\Folium\\folium\\map.py:103: in render\n    return fig.render(**kwargs)\ngeneration\\Folium\\folium\\elements.py:65: in render\n    ch.render(**kwargs)\nE   RecursionError: maximum recursion depth exceeded while calling a Python object\n!!! Recursion detected (same locals & position)\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root - Recursio...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html - Attri...\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n9 failed, 3 passed in 14.67s\n"}
{"model": "gpt-5.2", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+ 1 kB", "returncode": 1, "elapsed_time_s": 1.832702, "avg_memory_mb": 32.28, "avg_cpu_percent": 100.0, "passed": 14, "failed": 1, "skipped": 0, "total": 15, "functional_score": 0.9333, "timestamp": "2026-01-01 00:06:40", "stdout_excerpt": "==== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1 kB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?  --\nE         + 1 kB\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\n1 failed, 14 passed in 0.52s\n", "stdout_sha1": "46b7753f51019717828b9f8fc44cfc1f9c97ddea", "stdout_len": 689, "stdout": "..F............                                                          [100%]\n================================== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1 kB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?  --\nE         + 1 kB\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\n1 failed, 14 passed in 0.52s\n"}
{"model": "gpt-5.2", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'imageio.v3' has no attribute 'imopen'", "returncode": 1, "elapsed_time_s": 2.144305, "avg_memory_mb": 43.92, "avg_cpu_percent": 100.0, "passed": 7, "failed": 3, "skipped": 0, "total": 10, "functional_score": 0.7, "timestamp": "2026-01-01 00:10:32", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-373/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-373/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n3 failed, 7 passed in 0.85s\n", "stdout_sha1": "254724f8613337fd091fc5a14bd198339e193849", "stdout_len": 2328, "stdout": "...F...FF.                                                               [100%]\n================================== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-373/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-373/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n3 failed, 7 passed in 0.85s\n"}
{"model": "gpt-5.2", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'KaplanMeierFitter' object has no attribute 'median_survival_time_'", "returncode": 1, "elapsed_time_s": 3.635445, "avg_memory_mb": 36.47, "avg_cpu_percent": 49.55, "passed": 7, "failed": 8, "skipped": 0, "total": 15, "functional_score": 0.4667, "timestamp": "2026-01-01 00:12:06", "stdout_excerpt": "==== FAILURES ===================================\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051454\\ntreatment  0.593058  0.941823.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002085AD86670>()\nE        +    where <built-in method lower of str object at 0x000002085AD86670> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x0000020838154670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x0000020838154670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051454\\ntreatment  0.593058  0.941823.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df", "stdout_sha1": "c5bf1d36c19df97b07e4941b5eb1de948bb40c64", "stdout_len": 7302, "stdout": "..F..FFFF..FFF.                                                          [100%]\n================================== FAILURES ===================================\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051454\\ntreatment  0.593058  0.941823.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002085AD86670>()\nE        +    where <built-in method lower of str object at 0x000002085AD86670> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x0000020838154670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x0000020838154670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.042724  0.051454\\ntreatment  0.593058  0.941823.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x_low = pd.DataFrame({\"age\": [25], \"treatment\": [0]})\n        x_high = pd.DataFrame({\"age\": [55], \"treatment\": [1]})\n    \n>       h_low = float(cph.predict_partial_hazard(x_low).iloc[0])\nE       AttributeError: 'CoxPHFitter' object has no attribute 'predict_partial_hazard'\n\ntests\\Lifelines\\functional_test.py:240: AttributeError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x = pd.DataFrame({\"age\": [30, 60], \"treatment\": [0, 1]})\n>       sf = cph.predict_survival_function(x)\n\ntests\\Lifelines\\functional_test.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = CoxPHFitter(penalizer=0.0, l1_ratio=0.0, params_=age         -0.042724\ntreatment    0.593058\nName: coef, dtype: float6...5\n6.0                0.062123\n7.0                0.007317\n8.0                0.000399, _X_columns=['age', 'treatment'])\nrow =    age  treatment\n0   30          0\n1   60          1\n\n    def predict_survival_function(self, row: pd.DataFrame) -> pd.DataFrame:\n        if self.params_ is None or self.baseline_survival_ is None:\n            raise ValueError(\"Call fit before predict_survival_function.\")\n        if not isinstance(row, pd.DataFrame):\n            raise TypeError(\"row must be a pandas DataFrame.\")\n        if row.shape[0] != 1:\n>           raise ValueError(\"row must be a single-row DataFrame.\")\nE           ValueError: row must be a single-row DataFrame.\n\ngeneration\\Lifelines\\lifelines\\fitters\\coxph_fitter.py:246: ValueError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_coxph_basic_fit - AssertionEr...\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\n8 failed, 7 passed in 1.97s\n"}
{"model": "gpt-5.2", "project": "Loguru", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "INFO:yep", "returncode": 1, "elapsed_time_s": 1.894744, "avg_memory_mb": 32.76, "avg_cpu_percent": 100.0, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 00:14:10", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n    \n        bound = log.bind(user=\"alice\", request_id=\"req-123\")\n        bound.info(\"hello\")\n    \n        out = buf.getvalue()\n>       assert \"INFO:\" in out\nE       AssertionError: assert 'INFO:' in ''\n\ntests\\Loguru\\functional_test.py:140: AssertionError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x00000209631BBCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\ntests\\Loguru\\functional_test.py:211: AttributeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n    \n        log.debug(\"nope\")\n        log.info(\"yep\")\n    \n        out = buf.getvalue()\n>       assert \"nope\" not in out\nE       AssertionError: assert 'nope' not in 'DEBUG:nope\\nINFO:yep\\n'\nE         \nE         'nope' is contained here:\nE           DEBUG:nope\nE         ?       ++++\nE           INFO:yep\n\ntests\\Loguru\\functional_test.py:229: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Asse.", "stdout_sha1": "28fd07d6b287bc43955ab6f5a04a9fc821b9be00", "stdout_len": 4474, "stdout": "...FF..FFF.                                                              [100%]\n================================== FAILURES ===================================\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n    \n        bound = log.bind(user=\"alice\", request_id=\"req-123\")\n        bound.info(\"hello\")\n    \n        out = buf.getvalue()\n>       assert \"INFO:\" in out\nE       AssertionError: assert 'INFO:' in ''\n\ntests\\Loguru\\functional_test.py:140: AssertionError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError: 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149: AttributeError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n    \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n    return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x00000209631BBCD0>\ns = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\": \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\ntests\\Loguru\\functional_test.py:211: AttributeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n        log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n    \n        log.debug(\"nope\")\n        log.info(\"yep\")\n    \n        out = buf.getvalue()\n>       assert \"nope\" not in out\nE       AssertionError: assert 'nope' not in 'DEBUG:nope\\nINFO:yep\\n'\nE         \nE         'nope' is contained here:\nE           DEBUG:nope\nE         ?       ++++\nE           INFO:yep\n\ntests\\Loguru\\functional_test.py:229: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Asse...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\n5 failed, 6 passed in 0.56s\n"}
{"model": "gpt-5.2", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Safe_Pipe' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 2.776114, "avg_memory_mb": 34.99, "avg_cpu_percent": 63.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 00:15:24", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'Safe_Pipe' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.48s\n", "stdout_sha1": "dfafb15e2771536bd5111c369b2c5f855a05307f", "stdout_len": 1028, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'Safe_Pipe' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.48s\n"}
{"model": "gpt-5.2", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'", "returncode": 1, "elapsed_time_s": 1.834294, "avg_memory_mb": 32.42, "avg_cpu_percent": 97.3, "passed": 9, "failed": 1, "skipped": 9, "total": 19, "functional_score": 0.4737, "timestamp": "2026-01-01 00:16:59", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\n1 failed, 9 passed, 9 skipped in 0.50s\n", "stdout_sha1": "40efaa5a36891a50b5e9da2bec32650395e274a2", "stdout_len": 1008, "stdout": "......F...sssssssss                                                      [100%]\n================================== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\n1 failed, 9 passed, 9 skipped in 0.50s\n"}
{"model": "gpt-5.2", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file", "returncode": 1, "elapsed_time_s": 2.014774, "avg_memory_mb": 33.48, "avg_cpu_percent": 99.2, "passed": 5, "failed": 6, "skipped": 0, "total": 11, "functional_score": 0.4545, "timestamp": "2026-01-01 00:18:01", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.h", "stdout_sha1": "150cbc6a6b61013573f14681096c84c4133010c2", "stdout_len": 5957, "stdout": "...F.FF.FFF                                                              [100%]\n================================== FAILURES ===================================\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_004_tools_main_file_exists - ...\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_007_tools_main_defines_mitmdump_function_or_wrapper\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n6 failed, 5 passed in 0.69s\n"}
{"model": "gpt-5.2", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.460677, "avg_memory_mb": 31.62, "avg_cpu_percent": 98.8, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 00:19:25", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "gpt-5.2", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'DateTime' object has no attribute 'start_of'", "returncode": 1, "elapsed_time_s": 2.009634, "avg_memory_mb": 32.89, "avg_cpu_percent": 101.6, "passed": 1, "failed": 11, "skipped": 1, "total": 13, "functional_score": 0.0769, "timestamp": "2026-01-01 00:20:48", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n        assert offset_tokyo.total_seconds() == 9 * 60 * 60\n    \n>       as_str = dt_tokyo.to_datetime_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_datetime_string'\n\ntests\\Pendulum\\functional_test.py:81: AttributeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n        end = start.add(months=1)\n    \n>       text = start.diff_for_humans(end)\n\ntests\\Pendulum\\functional_test.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DateTime(2011, 8, 1, 0, 0, tzinfo=datetime.timezone.utc)\nother = DateTime(2011, 9, 1, 0, 0, tzinfo=datetime.timezone.utc)\nabsolute = False\n\n    def diff_for_humans(\n        self,\n        other: Optional[Union[_dt, \"DateTime\"]] = None,\n        absolute: bool = False,\n    ) -> str:\n        if other is None:\n            other = _dt.now(tz=self.tzinfo) if self.tzinfo else _dt.now()\n        other_dt = DateTime.instance(other)\n    \n        diff = self - other_dt  # Duration\n>       seconds = diff.total_seconds()\nE       TypeError: 'float' object is not callable\n\ngeneration\\Pendulum\\pendulum\\datetime.py:119: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"", "stdout_sha1": "fa30824a91525110dbcd659808a02d965445d944", "stdout_len": 7196, "stdout": "F.FFFFFFFsFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n        assert offset_tokyo.total_seconds() == 9 * 60 * 60\n    \n>       as_str = dt_tokyo.to_datetime_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_datetime_string'\n\ntests\\Pendulum\\functional_test.py:81: AttributeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n        end = start.add(months=1)\n    \n>       text = start.diff_for_humans(end)\n\ntests\\Pendulum\\functional_test.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = DateTime(2011, 8, 1, 0, 0, tzinfo=datetime.timezone.utc)\nother = DateTime(2011, 9, 1, 0, 0, tzinfo=datetime.timezone.utc)\nabsolute = False\n\n    def diff_for_humans(\n        self,\n        other: Optional[Union[_dt, \"DateTime\"]] = None,\n        absolute: bool = False,\n    ) -> str:\n        if other is None:\n            other = _dt.now(tz=self.tzinfo) if self.tzinfo else _dt.now()\n        other_dt = DateTime.instance(other)\n    \n        diff = self - other_dt  # Duration\n>       seconds = diff.total_seconds()\nE       TypeError: 'float' object is not callable\n\ngeneration\\Pendulum\\pendulum\\datetime.py:119: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_________________ test_duration_total_seconds_and_components __________________\n\n    def test_duration_total_seconds_and_components() -> None:\n        \"\"\"Verify duration reports correct total seconds and has component attributes.\"\"\"\n        dur = pendulum.duration(days=1, hours=2, minutes=3, seconds=4)\n    \n        # Total seconds is the most stable cross-version contract.\n>       assert dur.total_seconds() == 1 * 86400 + 2 * 3600 + 3 * 60 + 4\nE       TypeError: 'float' object is not callable\n\ntests\\Pendulum\\functional_test.py:165: TypeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n        dt_ny = dt_utc.in_timezone(\"America/New_York\")\n    \n        assert int(dt_utc.timestamp()) == int(dt_ny.timestamp())\n>       assert dt_ny.to_date_string() in (\"2020-05-31\", \"2020-06-01\")\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:202: AttributeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_diff_for_humans_months - TypeE...\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_duration_total_seconds_and_components\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n11 failed, 1 passed, 1 skipped in 0.69s\n"}
{"model": "gpt-5.2", "project": "Petl", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "sort() got an unexpected keyword argument 'reverse'", "returncode": 1, "elapsed_time_s": 1.854256, "avg_memory_mb": 32.58, "avg_cpu_percent": 100.9, "passed": 5, "failed": 1, "skipped": 6, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 00:21:43", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n1 failed, 5 passed, 6 skipped in 0.53s\n", "stdout_sha1": "2268eed472e6a411dfb547384d8da201cb41a129", "stdout_len": 1049, "stdout": "...ss.Fs.sss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n1 failed, 5 passed, 6 skipped in 0.53s\n"}
{"model": "gpt-5.2", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.904354, "avg_memory_mb": 33.64, "avg_cpu_percent": 98.3, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 00:27:45", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None, kwargs = {}\n\n    def encode(\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        headers: Optional[Dict[str, Any]] = None,\n        json_encoder=None,\n        **kwargs,\n    ) -> str:\n        if algorithm is None:\n            algorithm = \"HS256\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 is supported in this implementation\")\nE           NotImplementedError: Only HS256 is supported in this implementation\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:68: in encode\n    payload_json = _json_dumps(payload).encode(\"utf-8\")\ngeneration\\PyJWT\\jwt\\api_jwt.py:30: in _json_dumps\n    return json.dumps(obj, separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000024A27638C40>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\f", "stdout_sha1": "60a880df7d17b3d40236a838461db2a48cf1a4c3", "stdout_len": 7059, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None, kwargs = {}\n\n    def encode(\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        headers: Optional[Dict[str, Any]] = None,\n        json_encoder=None,\n        **kwargs,\n    ) -> str:\n        if algorithm is None:\n            algorithm = \"HS256\"\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 is supported in this implementation\")\nE           NotImplementedError: Only HS256 is supported in this implementation\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:58: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:68: in encode\n    payload_json = _json_dumps(payload).encode(\"utf-8\")\ngeneration\\PyJWT\\jwt\\api_jwt.py:30: in _json_dumps\n    return json.dumps(obj, separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000024A27638C40>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:68: in encode\n    payload_json = _json_dumps(payload).encode(\"utf-8\")\ngeneration\\PyJWT\\jwt\\api_jwt.py:30: in _json_dumps\n    return json.dumps(obj, separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000024A276A65B0>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.58s\n"}
{"model": "gpt-5.2", "project": "Requests", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AttributeError", "exception_msg": "'Session' object has no attribute 'get'", "returncode": 1, "elapsed_time_s": 6.860111, "avg_memory_mb": 35.8, "avg_cpu_percent": 24.8, "passed": 1, "failed": 9, "skipped": 0, "total": 10, "functional_score": 0.1, "timestamp": "2026-01-01 00:34:55", "stdout_excerpt": "==== FAILURES ===================================\n___________________________ test_get_text_response ____________________________\n\n    def test_get_text_response() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/get\")\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:154: AttributeError\n_________________________ test_get_with_query_params __________________________\n\n    def test_get_with_query_params() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/echo-params\", params={\"a\": \"1\", \"b\": \"two\"})\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:167: AttributeError\n_____________________________ test_post_form_data _____________________________\n\n    def test_post_form_data() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.post(base_url + \"/submit\", data={\"x\": \"10\", \"y\": \"20\"})\nE           AttributeError: 'Session' object has no attribute 'post'\n\ntests\\Requests\\functional_test.py:182: AttributeError\n_____________________________ test_post_json_data _____________________________\n\n    def test_post_json_data() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.post(base_url + \"/json-submit\", json={\"ok\": True, \"n\": 3})\nE           AttributeError: 'Session' object has no attribute 'post'\n\ntests\\Requests\\functional_test.py:198: AttributeError\n____________________ test_redirect_is_followed_by_default _____________________\n\n    def test_redirect_is_followed_by_default() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/redirect\")\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:214: AttributeError\n________________________ test_session_persists_cookies ________________________\n\n    def test_session_persists_cookies() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r1 = s.get(base_url + \"/set-cookie\")\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:228: AttributeError\n___________________________ test_basic_auth_success ___________________________\n\n    def test_basic_auth_success() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/basic-auth\", auth=(\"user\", \"pass\"))\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:245: AttributeError\n____________________ test_streaming_response_iter_content _____________________\n\n    def test_streaming_response_iter_content() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/get\", stream=True)\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:258: AttributeError\n___________________ test_timeout_parameter_on_fast_endpoint ___________________\n\n    def test_timeout_parameter_on_fast_endpoint() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/slow\", timeout=1.0)\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:272: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Requests/functional_test.py::test_get_text_response - AttributeE...\nFAILED tests/Requests/functional_test.py::test_get_with_query_params - Attrib...\nFAILED tests/Requests/functional_test.py::test_post_form_data - AttributeErro...\nFAILED tests/Requests/functional_test.py::test_post_json_data - AttributeEr", "stdout_sha1": "99146f8b4b81270ac7e1ac8c17c088f2737894e8", "stdout_len": 4546, "stdout": "FFFFFFFFF.                                                               [100%]\n================================== FAILURES ===================================\n___________________________ test_get_text_response ____________________________\n\n    def test_get_text_response() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/get\")\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:154: AttributeError\n_________________________ test_get_with_query_params __________________________\n\n    def test_get_with_query_params() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/echo-params\", params={\"a\": \"1\", \"b\": \"two\"})\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:167: AttributeError\n_____________________________ test_post_form_data _____________________________\n\n    def test_post_form_data() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.post(base_url + \"/submit\", data={\"x\": \"10\", \"y\": \"20\"})\nE           AttributeError: 'Session' object has no attribute 'post'\n\ntests\\Requests\\functional_test.py:182: AttributeError\n_____________________________ test_post_json_data _____________________________\n\n    def test_post_json_data() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.post(base_url + \"/json-submit\", json={\"ok\": True, \"n\": 3})\nE           AttributeError: 'Session' object has no attribute 'post'\n\ntests\\Requests\\functional_test.py:198: AttributeError\n____________________ test_redirect_is_followed_by_default _____________________\n\n    def test_redirect_is_followed_by_default() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/redirect\")\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:214: AttributeError\n________________________ test_session_persists_cookies ________________________\n\n    def test_session_persists_cookies() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r1 = s.get(base_url + \"/set-cookie\")\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:228: AttributeError\n___________________________ test_basic_auth_success ___________________________\n\n    def test_basic_auth_success() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/basic-auth\", auth=(\"user\", \"pass\"))\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:245: AttributeError\n____________________ test_streaming_response_iter_content _____________________\n\n    def test_streaming_response_iter_content() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/get\", stream=True)\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:258: AttributeError\n___________________ test_timeout_parameter_on_fast_endpoint ___________________\n\n    def test_timeout_parameter_on_fast_endpoint() -> None:\n        httpd, base_url = _start_server()\n        s = _new_session()\n        try:\n>           r = s.get(base_url + \"/slow\", timeout=1.0)\nE           AttributeError: 'Session' object has no attribute 'get'\n\ntests\\Requests\\functional_test.py:272: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Requests/functional_test.py::test_get_text_response - AttributeE...\nFAILED tests/Requests/functional_test.py::test_get_with_query_params - Attrib...\nFAILED tests/Requests/functional_test.py::test_post_form_data - AttributeErro...\nFAILED tests/Requests/functional_test.py::test_post_json_data - AttributeErro...\nFAILED tests/Requests/functional_test.py::test_redirect_is_followed_by_default\nFAILED tests/Requests/functional_test.py::test_session_persists_cookies - Att...\nFAILED tests/Requests/functional_test.py::test_basic_auth_success - Attribute...\nFAILED tests/Requests/functional_test.py::test_streaming_response_iter_content\nFAILED tests/Requests/functional_test.py::test_timeout_parameter_on_fast_endpoint\n9 failed, 1 passed in 5.68s\n"}
{"model": "gpt-5.2", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.318994, "avg_memory_mb": 30.96, "avg_cpu_percent": 96.1, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 00:36:41", "stdout_excerpt": "\n1 skipped in 0.11s\n", "stdout_sha1": "75923eec7092d4a8427af710fe49bcf2a0b64e5b", "stdout_len": 20, "stdout": "\n1 skipped in 0.11s\n"}
{"model": "gpt-5.2", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'schedule' has no attribute 'get_jobs'", "returncode": 1, "elapsed_time_s": 1.538171, "avg_memory_mb": 32.91, "avg_cpu_percent": 102.2, "passed": 6, "failed": 6, "skipped": 0, "total": 12, "functional_score": 0.5, "timestamp": "2026-01-01 00:38:09", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\n        schedule.every().minutes.do(job2).tag(\"min\", \"common\")\n    \n>       jobs = schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:100: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n        schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\n        schedule.every().hour.do(job_drop).tag(\"drop\", \"group\")\n    \n>       drop_jobs = schedule.get_jobs(\"drop\")\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:124: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n        schedule.cancel_job(j2)\n    \n        schedule.run_all()\n        assert calls == [\"job1\"]\n>       assert j1 in schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:155: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n        j = schedule.every(2).to(5).seconds.do(job)\n>       assert j in schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:240: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n        schedule.every().minute.do(a).tag(\"alpha\")\n        schedule.every().minute.do(b).tag(\"beta\")\n    \n>       alpha_jobs = schedule.get_jobs(\"alpha\")\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:272: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_ta", "stdout_sha1": "9c4292aad43970eb81e6f9226f972075aa5c3847", "stdout_len": 4496, "stdout": "FFFF....F.F.                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\n        schedule.every().minutes.do(job2).tag(\"min\", \"common\")\n    \n>       jobs = schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:100: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n        schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\n        schedule.every().hour.do(job_drop).tag(\"drop\", \"group\")\n    \n>       drop_jobs = schedule.get_jobs(\"drop\")\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:124: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n        schedule.cancel_job(j2)\n    \n        schedule.run_all()\n        assert calls == [\"job1\"]\n>       assert j1 in schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:155: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\nE       AttributeError: module 'schedule' has no attribute 'repeat'\n\ntests\\Schedule\\functional_test.py:164: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n        j = schedule.every(2).to(5).seconds.do(job)\n>       assert j in schedule.get_jobs()\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:240: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n        schedule.every().minute.do(a).tag(\"alpha\")\n        schedule.every().minute.do(b).tag(\"beta\")\n    \n>       alpha_jobs = schedule.get_jobs(\"alpha\")\nE       AttributeError: module 'schedule' has no attribute 'get_jobs'\n\ntests\\Schedule\\functional_test.py:272: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\n6 failed, 6 passed in 0.41s\n"}
{"model": "gpt-5.2", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where <built-in method startswith of str object at 0x00000201D703E6F0> = 'this-is-a-test'.startswith", "returncode": 1, "elapsed_time_s": 1.667033, "avg_memory_mb": 31.79, "avg_cpu_percent": 98.0, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 00:38:42", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x00000201D703E6F0>('___')\nE        +    where <built-in method startswith of str object at 0x00000201D703E6F0> = 'this-is-a-test'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.41s\n", "stdout_sha1": "d58d6eb44226eff1c7c7a6a950e216a4d6093746", "stdout_len": 1081, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n>       assert result_default_sep.startswith(\"___\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x00000201D703E6F0>('___')\nE        +    where <built-in method startswith of str object at 0x00000201D703E6F0> = 'this-is-a-test'.startswith\n\ntests\\Slugify\\functional_test.py:173: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.41s\n"}
{"model": "gpt-5.2", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "'_SQLModelMetadata' object has no attribute 'clear'", "returncode": 2, "elapsed_time_s": 1.887468, "avg_memory_mb": 35.43, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 00:41:19", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: '_SQLModelMetadata' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: '_SQLModelMetadata'...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.58s\n", "stdout_sha1": "0605a5150437e1e59bfc35ee21e7875ceb61431f", "stdout_len": 571, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: '_SQLModelMetadata' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: '_SQLModelMetadata'...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.58s\n"}
{"model": "gpt-5.2", "project": "Stegano", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "StopIteration", "returncode": 1, "elapsed_time_s": 5.601144, "avg_memory_mb": 38.2, "avg_cpu_percent": 98.9, "passed": 8, "failed": 4, "skipped": 0, "total": 12, "functional_score": 0.6667, "timestamp": "2026-01-01 00:43:31", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-378/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n>       revealed = lsb.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:93: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:158: in reveal\n    msg_bits_list = _reveal_bits_from_channels(channels, msg_bits, pos_it)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nchannels = [226, 136, 124, 226, 136, 124, ...], nbits = 88\npositions = <generator object _positions_sequential at 0x000002A141D7C820>\n\n    def _reveal_bits_from_channels(channels: list[int], nbits: int, positions: Iterator[int]) -> list[int]:\n        out_bits: list[int] = []\n        for _ in range(nbits):\n>           pos = next(positions)\nE           StopIteration\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:55: StopIteration\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-378/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n        encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n        encoded_img.save(str(output))\n    \n        gen2 = generators.eratosthenes()\n>       revealed = lsb.reveal(str(output), generator=gen2)\n\ntests\\Stegano\\functional_test.py:109: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:158: in reveal\n    msg_bits_list = _reveal_bits_from_channels(channels, msg_bits, pos_it)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nchannels = [226, 137, 124, 226, 137, 124, ...], nbits = 128\npositions = <generator object _positions_from_generator at 0x000002A141BDF350>\n\n    def _reveal_bits_from_channels(channels: list[int], nbits: int, positions: Iterator[int]) -> list[int]:\n        out_bits: list[int] = []\n        for _ in range(nbits):\n>           pos = next(positions)\nE           StopIteration\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:55: StopIteration\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-378/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n>       revealed = lsb.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:158: in reveal\n    msg_bits_list = _reveal_bits_from_channels(channels, msg_bits, pos_it)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nchannels = [226, 136, 124, 226, 136, 124, ...], nbits = 552\npositions = <generator object _positi", "stdout_sha1": "a3bb97463712aadbbec56c10a785abf9cd7d6986", "stdout_len": 6011, "stdout": "FFFF........                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-378/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n>       revealed = lsb.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:93: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:158: in reveal\n    msg_bits_list = _reveal_bits_from_channels(channels, msg_bits, pos_it)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nchannels = [226, 136, 124, 226, 136, 124, ...], nbits = 88\npositions = <generator object _positions_sequential at 0x000002A141D7C820>\n\n    def _reveal_bits_from_channels(channels: list[int], nbits: int, positions: Iterator[int]) -> list[int]:\n        out_bits: list[int] = []\n        for _ in range(nbits):\n>           pos = next(positions)\nE           StopIteration\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:55: StopIteration\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-378/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n        encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n        encoded_img.save(str(output))\n    \n        gen2 = generators.eratosthenes()\n>       revealed = lsb.reveal(str(output), generator=gen2)\n\ntests\\Stegano\\functional_test.py:109: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:158: in reveal\n    msg_bits_list = _reveal_bits_from_channels(channels, msg_bits, pos_it)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nchannels = [226, 137, 124, 226, 137, 124, ...], nbits = 128\npositions = <generator object _positions_from_generator at 0x000002A141BDF350>\n\n    def _reveal_bits_from_channels(channels: list[int], nbits: int, positions: Iterator[int]) -> list[int]:\n        out_bits: list[int] = []\n        for _ in range(nbits):\n>           pos = next(positions)\nE           StopIteration\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:55: StopIteration\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-378/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n        encoded_img = lsb.hide(str(LENNA_PNG), secret)\n        encoded_img.save(str(output))\n    \n>       revealed = lsb.reveal(str(output))\n\ntests\\Stegano\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:158: in reveal\n    msg_bits_list = _reveal_bits_from_channels(channels, msg_bits, pos_it)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nchannels = [226, 136, 124, 226, 136, 124, ...], nbits = 552\npositions = <generator object _positions_sequential at 0x000002A141D0F740>\n\n    def _reveal_bits_from_channels(channels: list[int], nbits: int, positions: Iterator[int]) -> list[int]:\n        out_bits: list[int] = []\n        for _ in range(nbits):\n>           pos = next(positions)\nE           StopIteration\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:55: StopIteration\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n        img_obj = lsb.hide(str(LENNA_PNG), secret)\n>       revealed = lsb.reveal(img_obj)\n\ntests\\Stegano\\functional_test.py:133: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:158: in reveal\n    msg_bits_list = _reveal_bits_from_channels(channels, msg_bits, pos_it)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nchannels = [226, 136, 124, 226, 136, 124, ...], nbits = 96\npositions = <generator object _positions_sequential at 0x000002A143AD3270>\n\n    def _reveal_bits_from_channels(channels: list[int], nbits: int, positions: Iterator[int]) -> list[int]:\n        out_bits: list[int] = []\n        for _ in range(nbits):\n>           pos = next(positions)\nE           StopIteration\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:55: StopIteration\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Stop...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\n4 failed, 8 passed in 4.33s\n"}
{"model": "gpt-5.2", "project": "Tablib", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where False = isinstance({'data': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]], 'headers': ['first_name', 'last_name', 'age']}, list)", "returncode": 1, "elapsed_time_s": 1.865449, "avg_memory_mb": 32.08, "avg_cpu_percent": 100.9, "passed": 5, "failed": 6, "skipped": 0, "total": 11, "functional_score": 0.4545, "timestamp": "2026-01-01 00:44:40", "stdout_excerpt": "==== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n        assert loaded_csv.height == data.height\n        assert loaded_csv.width == data.width\n    \n        orig_dict_norm = _normalize_dict_rows(data.dict)\n        loaded_dict_norm = _normalize_dict_rows(loaded_csv.dict)\n        assert loaded_dict_norm == orig_dict_norm\n    \n        # JSON roundtrip via export + .json setter.\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'data': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]], 'headers': ['first_name', 'last_name', 'age']}, list)\n\ntests\\Tablib\\functional_test.py:146: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000128F941DF70>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        fmt = (fmt or \"\").lower()\n        if fmt == \"csv\":\n            return csv_format.export_dataset(self)\n        if fmt == \"json\":\n            return json_format.export_dataset(self)\n>       raise ValueError(f\"Unsupported format: {fmt}\")\nE       ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:135: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n________________ test_dataset_export_json_contains_all_records ________________\n\n    def test_dataset_export_json_contains_all_records() -> None:\n        \"\"\"JSON export should serialize all dataset records in a list-like structure.\"\"\"\n        data = _build_sample_dataset()\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'data': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]], 'headers': ['first_name', 'last_name', 'age']}, list)\n\ntests\\Tablib\\functional_test.py:278: AssertionError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       h", "stdout_sha1": "511875ab19c4324e1be0d6f845fa9336d89c11d7", "stdout_len": 6397, "stdout": "FF..F..FFF.                                                              [100%]\n================================== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n        assert loaded_csv.height == data.height\n        assert loaded_csv.width == data.width\n    \n        orig_dict_norm = _normalize_dict_rows(data.dict)\n        loaded_dict_norm = _normalize_dict_rows(loaded_csv.dict)\n        assert loaded_dict_norm == orig_dict_norm\n    \n        # JSON roundtrip via export + .json setter.\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'data': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]], 'headers': ['first_name', 'last_name', 'age']}, list)\n\ntests\\Tablib\\functional_test.py:146: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000128F941DF70>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        fmt = (fmt or \"\").lower()\n        if fmt == \"csv\":\n            return csv_format.export_dataset(self)\n        if fmt == \"json\":\n            return json_format.export_dataset(self)\n>       raise ValueError(f\"Unsupported format: {fmt}\")\nE       ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\core.py:135: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n________________ test_dataset_export_json_contains_all_records ________________\n\n    def test_dataset_export_json_contains_all_records() -> None:\n        \"\"\"JSON export should serialize all dataset records in a list-like structure.\"\"\"\n        data = _build_sample_dataset()\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'data': [['John', 'Adams', 90], ['George', 'Washington', 67], ['Ada', 'Lovelace', 36]], 'headers': ['first_name', 'last_name', 'age']}, list)\n\ntests\\Tablib\\functional_test.py:278: AssertionError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x00000128F93FF970>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        fmt = (fmt or \"\").lower()\n        if fmt == \"csv\":\n            return csv_format.export_dataset(self)\n        if fmt == \"json\":\n            return json_format.export_dataset(self)\n>       raise ValueError(f\"Unsupported format: {fmt}\")\nE       ValueError: Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:135: ValueError\n__________________ test_databook_multi_sheet_json_roundtrip ___________________\n\n    def test_databook_multi_sheet_json_roundtrip() -> None:\n        \"\"\"Databook should preserve sheet structure when exported/imported as JSON.\"\"\"\n        sheet1 = tablib.Dataset(\n            (1, \"a\"),\n            (2, \"b\"),\n            headers=(\"id\", \"value\"),\n        )\n        sheet1.title = \"First\"\n    \n        sheet2 = tablib.Dataset(\n            (3, \"c\"),\n            (4, \"d\"),\n            headers=(\"id\", \"value\"),\n        )\n        sheet2.title = \"Second\"\n    \n        book = tablib.Databook([sheet1, sheet2])\n    \n        json_text = book.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'sheets': [{'data': [[1, 'a'], [2, 'b']], 'headers': ['id', 'value'], 'title': 'First'}, {'data': [[3, 'c'], [4, 'd']], 'headers': ['id', 'value'], 'title': 'Second'}]}, list)\n\ntests\\Tablib\\functional_test.py:324: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_csv_and_json_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_export_json_contains_all_records\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\nFAILED tests/Tablib/functional_test.py::test_databook_multi_sheet_json_roundtrip\n6 failed, 5 passed in 0.55s\n"}
{"model": "gpt-5.2", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "tabulate() got an unexpected keyword argument 'maxcolwidths'", "returncode": 1, "elapsed_time_s": 1.73156, "avg_memory_mb": 32.62, "avg_cpu_percent": 99.0, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2026-01-01 00:46:40", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n        assert lines[0].strip().startswith(\"Name\")\n        assert \"Age\" in lines[0]\n        # separator line usually contains dashes\n>       assert \"-\" in lines[1].replace(\" \", \"\")\nE       AssertionError: assert '-' in 'Alice24'\nE        +  where 'Alice24' = <built-in method replace of str object at 0x0000018BF7D56830>(' ', '')\nE        +    where <built-in method replace of str object at 0x0000018BF7D56830> = 'Alice   24'.replace\n\ntests\\Tabulate\\functional_test.py:123: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n2 failed, 10 passed in 0.48s\n", "stdout_sha1": "5c0a8e87da73d7e54d05df8abb469311b5af0ed7", "stdout_len": 1866, "stdout": "..F.......F.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n        assert lines[0].strip().startswith(\"Name\")\n        assert \"Age\" in lines[0]\n        # separator line usually contains dashes\n>       assert \"-\" in lines[1].replace(\" \", \"\")\nE       AssertionError: assert '-' in 'Alice24'\nE        +  where 'Alice24' = <built-in method replace of str object at 0x0000018BF7D56830>(' ', '')\nE        +    where <built-in method replace of str object at 0x0000018BF7D56830> = 'Alice   24'.replace\n\ntests\\Tabulate\\functional_test.py:123: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n2 failed, 10 passed in 0.48s\n"}
{"model": "gpt-5.2", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "ValueError", "exception_msg": "Series 0 has length 1 but labels has length 2", "returncode": 1, "elapsed_time_s": 26.541059, "avg_memory_mb": 32.7, "avg_cpu_percent": 0.54, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 00:48:08", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC13550>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[3], [5], [2]], series=[['A'], ['B'], ['C']])\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 3\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC84DF0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[1, 2], [3, 4]], series=[['X'], ['Y']])\nlabels = [[1, 2], [3, 4]], series = ['X', 'Y']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC13670>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[4], [1]], series=[['D'], ['E']]), labels = [[4], [1]]\nseries = ['D', 'E']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n       ", "stdout_sha1": "d6a9e2a936b346243b7e458b2ab418879bdfa719", "stdout_len": 17697, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC13550>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[3], [5], [2]], series=[['A'], ['B'], ['C']])\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 3\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC84DF0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[1, 2], [3, 4]], series=[['X'], ['Y']])\nlabels = [[1, 2], [3, 4]], series = ['X', 'Y']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC13670>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[4], [1]], series=[['D'], ['E']]), labels = [[4], [1]]\nseries = ['D', 'E']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC015B0>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[2], [7]], series=[['A'], ['B']]), labels = [[2], [7]]\nseries = ['A', 'B']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CBFAA60>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[1], [2], [3]], series=[['L', '1'], ['L', '2'], ['L', '3']])\nlabels = [[1], [2], [3]], series = ['L1', 'L2', 'L3']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 2 but labels has length 3\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CCB69A0>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[12.5], [7.0]], series=[['C', 'P', 'U'], ['R', 'A', 'M']])\nlabels = [[12.5], [7.0]], series = ['CPU', 'RAM']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 3 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CBFEEE0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[3.14159], [2.71828]], series=[['P'], ['Q']])\nlabels = [[3.14159], [2.71828]], series = ['P', 'Q']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC74A00>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[1, 1], [2, 1], [1, 3]], series=[['S', '1'], ['S', '2'], ['S', '3']])\nlabels = [[1, 1], [2, 1], [1, 3]], series = ['S1', 'S2', 'S3']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 2 but labels has length 3\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CCB0070>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[1, 2, 3], [3, 2, 1]], series=[['A'], ['B']])\nlabels = [[1, 2, 3], [3, 2, 1]], series = ['A', 'B']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC11F40>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Data(labels=[[4], [6]], series=[['U'], ['V']]), labels = [[4], [6]]\nseries = ['U', 'V']\n\n    def __init__(\n        self,\n        labels: Optional[Sequence[str]] = None,\n        series: Optional[Sequence[Sequence[Number]]] = None,\n    ):\n        self.labels = list(labels) if labels is not None else []\n        self.series = [list(s) for s in series] if series is not None else []\n    \n        # Normalize empty inputs\n        if self.labels is None:\n            self.labels = []\n        if self.series is None:\n            self.series = []\n    \n        # Basic validation/normalization: ensure rectangular where possible\n        if self.series and self.labels:\n            n = len(self.labels)\n            for idx, s in enumerate(self.series):\n                if len(s) != n:\n>                   raise ValueError(\n                        f\"Series {idx} has length {len(s)} but labels has length {n}\"\n                    )\nE                   ValueError: Series 0 has length 1 but labels has length 2\n\ngeneration\\Termgraph\\termgraph\\data.py:43: ValueError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002522CC131F0>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n        BarChart(data, args_narrow).draw()\n        out_narrow = capsys.readouterr().out\n    \n        args_wide = _make_args(title=\"Wide\", width=40, format=\"{:>4.1f}\")\n        BarChart(data, args_wide).draw()\n        out_wide = capsys.readouterr().out\n    \n>       assert \"Narrow\" in out_narrow\nE       AssertionError: assert 'Narrow' in ''\n\ntests\\Termgraph\\functional_test.py:260: AssertionError\n---------------------------- Captured stdout call -----------------------------\nNarrow\n[9]:  W\nWide\n[9]:  W\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 25.31s\n"}
{"model": "gpt-5.2", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 2.180301, "avg_memory_mb": 32.21, "avg_cpu_percent": 98.8, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-01 00:49:35", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "68261390566d7a90b614a195bb062d3c61d16e3c", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-379/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-379/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-379/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000018D95DF1310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.85s\n"}
{"model": "gpt-5.2", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "syntax_error", "exception_type": "SyntaxError", "exception_msg": "invalid syntax", "returncode": 2, "elapsed_time_s": 2.085484, "avg_memory_mb": 36.89, "avg_cpu_percent": 99.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 00:51:16", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\ngeneration\\TinyDB\\tinydb\\__init__.py:11: in <module>\n    from .database import Database\ngeneration\\TinyDB\\tinydb\\database.py:7: in <module>\n    from .table import Table\ngeneration\\TinyDB\\tinydb\\table.py:7: in <module>\n    from .queries import Query\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\queries.py\", line 48\nE       def ==(self, other: Any) -> Query:  # type: ignore[misc]\nE           ^\nE   SyntaxError: invalid syntax\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n", "stdout_sha1": "5fe790ccd549dc40ee880a85dee720572e5ead44", "stdout_len": 1811, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\ngeneration\\TinyDB\\tinydb\\__init__.py:11: in <module>\n    from .database import Database\ngeneration\\TinyDB\\tinydb\\database.py:7: in <module>\n    from .table import Table\ngeneration\\TinyDB\\tinydb\\table.py:7: in <module>\n    from .queries import Query\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\queries.py\", line 48\nE       def ==(self, other: Any) -> Query:  # type: ignore[misc]\nE           ^\nE   SyntaxError: invalid syntax\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.65s\n"}
{"model": "gpt-5.2", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where 1 = Result(stdout='', stderr=\"Error: unsupported operand type(s) for -: 'str' and 'int'\\n\", exit_code=1, exception=TypeError(\"unsupported operand type(s) for -: 'str' and 'int'\")).exit_code", "returncode": 1, "elapsed_time_s": 1.97494, "avg_memory_mb": 32.69, "avg_cpu_percent": 98.3, "passed": 2, "failed": 10, "skipped": 0, "total": 12, "functional_score": 0.1667, "timestamp": "2026-01-01 00:52:47", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"World\"])\n>       assert result.exit_code == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = Result(stdout='', stderr='Error: No such command: World\\n', exit_code=2, exception=None).exit_code\n\ntests\\Typer\\functional_test.py:199: AssertionError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n        app = _create_greeter_app()\n        # Safer ordering across Click versions: options before args.\n        result = runner.invoke(app, [\"--excited\", \"World\"])\n>       assert result.exit_code == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = Result(stdout='', stderr='Error: No such option: --excited\\n', exit_code=2, exception=None).exit_code\n\ntests\\Typer\\functional_test.py:207: AssertionError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"--excited\" in out\nE       AssertionError: assert '--excited' in 'Usage: app [OPTIONS] COMMAND [ARGS]...\\n\\nOptions:\\n  --help         Show this message and exit.\\n\\nCommands:\\n'\n\ntests\\Typer\\functional_test.py:216: AssertionError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n        assert r.exit_code == 0\n>       assert \"No tasks.\" in r.stdout\nE       AssertionError: assert 'No tasks.' in ''\nE        +  where '' = Result(stdout='', stderr='', exit_code=0, exception=None).stdout\n\ntests\\Typer\\functional_test.py:224: AssertionError\n---------------------------- Captured stdout call -----------------------------\nNo tasks.\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n        assert r1.exit_code == 0\n>       assert \"Added: Write tests\" in r1.stdout\nE       AssertionError: assert 'Added: Write tests' in ''\nE        +  where '' = Result(stdout='', stderr='', exit_code=0, exception=None).stdout\n\ntests\\Typer\\functional_test.py:234: AssertionError\n---------------------------- Captured stdout call -----------------------------\nAdded: Write tests\nAdded: Review PRs\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = Result(stdout='', stderr=\"Error: unsupported operand type(s) for -: 'str' and 'int'\\n\", exit_code=1, exception=TypeError(\"unsupported operand type(s) for -: 'str' and 'int'\")).exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n---------------------------- Captured stdout call -----------------------------\nAdded: Task 1\nAdded: Task 2\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" beh", "stdout_sha1": "762c5b9325e0a3932f991091dcaf7aa04e113031", "stdout_len": 7547, "stdout": "FFFFFF..FFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"World\"])\n>       assert result.exit_code == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = Result(stdout='', stderr='Error: No such command: World\\n', exit_code=2, exception=None).exit_code\n\ntests\\Typer\\functional_test.py:199: AssertionError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n        app = _create_greeter_app()\n        # Safer ordering across Click versions: options before args.\n        result = runner.invoke(app, [\"--excited\", \"World\"])\n>       assert result.exit_code == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = Result(stdout='', stderr='Error: No such option: --excited\\n', exit_code=2, exception=None).exit_code\n\ntests\\Typer\\functional_test.py:207: AssertionError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n        app = _create_greeter_app()\n        result = runner.invoke(app, [\"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"--excited\" in out\nE       AssertionError: assert '--excited' in 'Usage: app [OPTIONS] COMMAND [ARGS]...\\n\\nOptions:\\n  --help         Show this message and exit.\\n\\nCommands:\\n'\n\ntests\\Typer\\functional_test.py:216: AssertionError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n        app = _create_todo_app()\n        r = runner.invoke(app, [\"list\"])\n        assert r.exit_code == 0\n>       assert \"No tasks.\" in r.stdout\nE       AssertionError: assert 'No tasks.' in ''\nE        +  where '' = Result(stdout='', stderr='', exit_code=0, exception=None).stdout\n\ntests\\Typer\\functional_test.py:224: AssertionError\n---------------------------- Captured stdout call -----------------------------\nNo tasks.\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n        assert r1.exit_code == 0\n>       assert \"Added: Write tests\" in r1.stdout\nE       AssertionError: assert 'Added: Write tests' in ''\nE        +  where '' = Result(stdout='', stderr='', exit_code=0, exception=None).stdout\n\ntests\\Typer\\functional_test.py:234: AssertionError\n---------------------------- Captured stdout call -----------------------------\nAdded: Write tests\nAdded: Review PRs\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = Result(stdout='', stderr=\"Error: unsupported operand type(s) for -: 'str' and 'int'\\n\", exit_code=1, exception=TypeError(\"unsupported operand type(s) for -: 'str' and 'int'\")).exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n---------------------------- Captured stdout call -----------------------------\nAdded: Task 1\nAdded: Task 2\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: Option() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000014E9821E190>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: Option() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n        app = _create_callback_app()\n    \n        r1 = runner.invoke(app, [\"run\"])\n        assert r1.exit_code == 0\n>       assert \"running\" in r1.stdout\nE       AssertionError: assert 'running' in ''\nE        +  where '' = Result(stdout='', stderr='', exit_code=0, exception=None).stdout\n\ntests\\Typer\\functional_test.py:301: AssertionError\n---------------------------- Captured stdout call -----------------------------\nrunning\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n        app = _create_types_app()\n        # Now stable: \"calc\" always exists as a subcommand (multi-command app).\n        r = runner.invoke(app, [\"calc\", \"2\", \"3\", \"--scale\", \"2.0\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = Result(stdout='', stderr=\"Error: can't multiply sequence by non-int of type 'str'\\n\", exit_code=1, exception=TypeError(\"can't multiply sequence by non-int of type 'str'\")).exit_code\n\ntests\\Typer\\functional_test.py:313: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AssertionE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - As...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_list_empty_shows_no_tasks - ...\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - AssertionErro...\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n10 failed, 2 passed in 0.68s\n"}
{"model": "gpt-5.2", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.908252, "avg_memory_mb": 36.4, "avg_cpu_percent": 100.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 00:53:51", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.63s\n", "stdout_sha1": "99c9709413393524d6aa76ae5b1d711a3f1cc2af", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.63s\n"}
{"model": "o1", "project": "Astral", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'astral'", "returncode": 2, "elapsed_time_s": 2.1903, "avg_memory_mb": 35.73, "avg_cpu_percent": 94.7, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 07:05:06", "stdout_excerpt": "====\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Astral\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\nE   ModuleNotFoundError: No module named 'astral'\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.71s\n", "stdout_sha1": "cd407a12724e85094e1ff2adbe9c8df04abcca85", "stdout_len": 888, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Astral/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Astral\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Astral\\functional_test.py:49: in <module>\n    from astral import LocationInfo, moon  # type: ignore\nE   ModuleNotFoundError: No module named 'astral'\n=========================== short test summary info ===========================\nERROR tests/Astral/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.71s\n"}
{"model": "o1", "project": "Cachetools", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'answer' not in TTLCache(maxsize=10, size=1)", "returncode": 1, "elapsed_time_s": 3.495705, "avg_memory_mb": 32.38, "avg_cpu_percent": 52.8, "passed": 12, "failed": 1, "skipped": 0, "total": 13, "functional_score": 0.9231, "timestamp": "2026-01-02 07:06:21", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_ttl_cache_expiration __________________________\n\n    def test_ttl_cache_expiration():\n        ttl_seconds = 0.2\n        cache = TTLCache(maxsize=10, ttl=ttl_seconds)\n    \n        cache[\"answer\"] = 42\n        assert cache[\"answer\"] == 42\n        assert \"answer\" in cache\n    \n        # Wait long enough for the entry to expire\n        time.sleep(ttl_seconds + 0.3)\n    \n        # After TTL has passed, the key should no longer be considered valid\n        # Implementations may clean up lazily, but membership and access\n        # must not behave as if the value is still present.\n>       assert \"answer\" not in cache\nE       AssertionError: assert 'answer' not in TTLCache(maxsize=10, size=1)\n\ntests\\Cachetools\\functional_test.py:62: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_ttl_cache_expiration - Asser...\n1 failed, 12 passed in 2.06s\n", "stdout_sha1": "336c767b31312c68880848ec6a0e0f2436fbb14c", "stdout_len": 1130, "stdout": ".F...........                                                            [100%]\n================================== FAILURES ===================================\n__________________________ test_ttl_cache_expiration __________________________\n\n    def test_ttl_cache_expiration():\n        ttl_seconds = 0.2\n        cache = TTLCache(maxsize=10, ttl=ttl_seconds)\n    \n        cache[\"answer\"] = 42\n        assert cache[\"answer\"] == 42\n        assert \"answer\" in cache\n    \n        # Wait long enough for the entry to expire\n        time.sleep(ttl_seconds + 0.3)\n    \n        # After TTL has passed, the key should no longer be considered valid\n        # Implementations may clean up lazily, but membership and access\n        # must not behave as if the value is still present.\n>       assert \"answer\" not in cache\nE       AssertionError: assert 'answer' not in TTLCache(maxsize=10, size=1)\n\ntests\\Cachetools\\functional_test.py:62: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Cachetools/functional_test.py::test_ttl_cache_expiration - Asser...\n1 failed, 12 passed in 2.06s\n"}
{"model": "o1", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "+  where", "returncode": 1, "elapsed_time_s": 5.517474, "avg_memory_mb": 32.91, "avg_cpu_percent": 99.4, "passed": 1, "failed": 10, "skipped": 0, "total": 11, "functional_score": 0.0909, "timestamp": "2026-01-02 07:08:55", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n>       @click.option(\"--count\", \"-c\", type=int, default=1)\nE       TypeError: option() takes 1 positional argument but 2 were given\n\ntests\\Click\\functional_test.py:134: TypeError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000019762BB8760>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:33: in decorator\n    f.__click_params__.append(Option(name, **kwargs))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x0000019762C27C70>, name = '--config'\nkwargs = {'default': 'default.cfg', 'type': <class 'str'>}\n\n    def __init__(self, name, **kwargs):\n        #  e.g. name could be '--count'\n>       super().__init__(name, **kwargs)\nE       TypeError: __init__() got an unexpected keyword argument 'type'\n\ngeneration\\Click\\click\\core.py:89: TypeError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n>       def cli(name: str) -> None:\n\ntests\\Click\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:33: in decorator\n    f.__click_params__.append(Option(name, **kwargs))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x0000019762BBD460>, name = '--name'\nkwargs = {'default': 'fallback', 'envvar': 'CLICK_TEST_NAME'}\n\n    def __init__(self, name, **kwargs):\n        #  e.g. name could be '--count'\n>       super().__init__(name, **kwargs)\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ngeneration\\Click\\click\\core.py:89: TypeError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where", "stdout_sha1": "1967977069dd03530a47762609f40d465c367326", "stdout_len": 6813, "stdout": "FFFFF.FFFFF                                                              [100%]\n================================== FAILURES ===================================\n________________ test_simple_command_with_argument_and_option _________________\n\n    def test_simple_command_with_argument_and_option():\n        @click.command()\n>       @click.option(\"--count\", \"-c\", type=int, default=1)\nE       TypeError: option() takes 1 positional argument but 2 were given\n\ntests\\Click\\functional_test.py:134: TypeError\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000019762BB8760>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n_________________________ test_group_with_subcommands _________________________\n\n    def test_group_with_subcommands():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:170: AttributeError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n>       @cli.command(help=\"Say hello\")\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:196: AttributeError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n>       def cli(config: str) -> None:\n\ntests\\Click\\functional_test.py:222: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:33: in decorator\n    f.__click_params__.append(Option(name, **kwargs))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x0000019762C27C70>, name = '--config'\nkwargs = {'default': 'default.cfg', 'type': <class 'str'>}\n\n    def __init__(self, name, **kwargs):\n        #  e.g. name could be '--count'\n>       super().__init__(name, **kwargs)\nE       TypeError: __init__() got an unexpected keyword argument 'type'\n\ngeneration\\Click\\click\\core.py:89: TypeError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n>       def cli(name: str) -> None:\n\ntests\\Click\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:33: in decorator\n    f.__click_params__.append(Option(name, **kwargs))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x0000019762BBD460>, name = '--name'\nkwargs = {'default': 'fallback', 'envvar': 'CLICK_TEST_NAME'}\n\n    def __init__(self, name, **kwargs):\n        #  e.g. name could be '--count'\n>       super().__init__(name, **kwargs)\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ngeneration\\Click\\click\\core.py:89: TypeError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <click.testing.Result object at 0x0000019762B69A30>.exit_code\n\ntests\\Click\\functional_test.py:285: AssertionError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n>       @cli.command()\nE       AttributeError: 'Group' object has no attribute 'command'\n\ntests\\Click\\functional_test.py:294: AttributeError\n_______________ test_parameter_type_validation_error_exit_code ________________\n\n    def test_parameter_type_validation_error_exit_code():\n        @click.command()\n        @click.option(\"--count\", type=int, required=True)\n>       def cli(count: int) -> None:\n\ntests\\Click\\functional_test.py:308: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:33: in decorator\n    f.__click_params__.append(Option(name, **kwargs))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x0000019762B80070>, name = '--count'\nkwargs = {'required': True, 'type': <class 'int'>}\n\n    def __init__(self, name, **kwargs):\n        #  e.g. name could be '--count'\n>       super().__init__(name, **kwargs)\nE       TypeError: __init__() got an unexpected keyword argument 'type'\n\ngeneration\\Click\\click\\core.py:89: TypeError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_simple_command_with_argument_and_option\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\nFAILED tests/Click/functional_test.py::test_group_with_subcommands - Attribut...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - T...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n10 failed, 1 passed in 4.08s\n"}
{"model": "o1", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where [] = _db_tables(<dataset.database.Database object at 0x000001EACF719280>)", "returncode": 1, "elapsed_time_s": 5.164003, "avg_memory_mb": 33.83, "avg_cpu_percent": 96.3, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-02 07:10:37", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000001EACF67F2B0>\nfilters = {'age': {'>=': 40}}, where_parts = ['\"age\" = :age'], k = 'age'\nwhere_clause = '\"age\" = :age', sql = 'SELECT * FROM \"users\" WHERE \"age\" = :age'\n\n    def find(self, **filters):\n        \"\"\"\n        Yield rows matching the given filters as dictionaries.\n        \"\"\"\n        if not filters:\n            yield from self.all()\n            return\n    \n        where_parts = []\n        for k in filters:\n            where_parts.append(f'\"{k}\" = :{k}')\n        where_clause = \" AND \".join(where_parts)\n        sql = f'SELECT * FROM \"{self.name}\" WHERE {where_clause}'\n>       cur = self._db._connection.execute(sql, filters)\nE       sqlite3.InterfaceError: Error binding parameter :age - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\table.py:153: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x000001EACF719280>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        ", "stdout_sha1": "bc902eee60defe482d416933647f066cef8b80c1", "stdout_len": 5147, "stdout": "FF...F..F.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000001EACF67F2B0>\nfilters = {'age': {'>=': 40}}, where_parts = ['\"age\" = :age'], k = 'age'\nwhere_clause = '\"age\" = :age', sql = 'SELECT * FROM \"users\" WHERE \"age\" = :age'\n\n    def find(self, **filters):\n        \"\"\"\n        Yield rows matching the given filters as dictionaries.\n        \"\"\"\n        if not filters:\n            yield from self.all()\n            return\n    \n        where_parts = []\n        for k in filters:\n            where_parts.append(f'\"{k}\" = :{k}')\n        where_clause = \" AND \".join(where_parts)\n        sql = f'SELECT * FROM \"{self.name}\" WHERE {where_clause}'\n>       cur = self._db._connection.execute(sql, filters)\nE       sqlite3.InterfaceError: Error binding parameter :age - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\table.py:153: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x000001EACF719280>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001EACF6E3A00>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - ass...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - as...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n5 failed, 6 passed in 3.79s\n"}
{"model": "o1", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert ('failregex' in 'import re\\n\\ndef isvalidip(ipaddr):\\n    \"\"\"\\n    check if the provided string is a valid ipv4 or ipv6 address.\\n    ...:\\n        candidate = match.group(0)\\n        if isvalidip(candidate):\\n            return candidate\\n    return none' or '<host>' in 'import re\\n\\ndef isvalidip(ipaddr):\\n    \"\"\"\\n    check if the provided string is a valid ipv4 or ipv6 address.\\n    ...:\\n        candidate = match.group(0)\\n        if isvalidip(candidate):\\n            return candidate\\n    return none')", "returncode": 1, "elapsed_time_s": 2.528681, "avg_memory_mb": 31.54, "avg_cpu_percent": 73.4, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2026-01-02 07:12:29", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\n\\ndef isvalidip(ipaddr):\\n    \"\"\"\\n    check if the provided string is a valid ipv4 or ipv6 address.\\n    ...:\\n        candidate = match.group(0)\\n        if isvalidip(candidate):\\n            return candidate\\n    return none' or '<host>' in 'import re\\n\\ndef isvalidip(ipaddr):\\n    \"\"\"\\n    check if the provided string is a valid ipv4 or ipv6 address.\\n    ...:\\n        candidate = match.group(0)\\n        if isvalidip(candidate):\\n            return candidate\\n    return none')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\n2 failed, 10 passed in 1.18s\n", "stdout_sha1": "2b1e866b3c3f32baeae0c704df950dd87ada6fed", "stdout_len": 2897, "stdout": "...F....F...                                                             [100%]\n================================== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in 'import re\\n\\ndef isvalidip(ipaddr):\\n    \"\"\"\\n    check if the provided string is a valid ipv4 or ipv6 address.\\n    ...:\\n        candidate = match.group(0)\\n        if isvalidip(candidate):\\n            return candidate\\n    return none' or '<host>' in 'import re\\n\\ndef isvalidip(ipaddr):\\n    \"\"\"\\n    check if the provided string is a valid ipv4 or ipv6 address.\\n    ...:\\n        candidate = match.group(0)\\n        if isvalidip(candidate):\\n            return candidate\\n    return none')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\n2 failed, 10 passed in 1.18s\n"}
{"model": "o1", "project": "Humanize", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "naturaltime() got an unexpected keyword argument 'when'", "returncode": 1, "elapsed_time_s": 2.010835, "avg_memory_mb": 31.93, "avg_cpu_percent": 101.6, "passed": 13, "failed": 2, "skipped": 0, "total": 15, "functional_score": 0.8667, "timestamp": "2026-01-02 07:15:27", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n2 failed, 13 passed in 0.51s\n", "stdout_sha1": "4ea2b0484539bc58d3386c8e6c88e283c20b8f4d", "stdout_len": 1237, "stdout": ".....F...F.....                                                          [100%]\n================================== FAILURES ===================================\n______________________ test_naturaltime_reference_point _______________________\n\n    def test_naturaltime_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        earlier = ref - timedelta(minutes=10)\n>       s = humanize.naturaltime(earlier, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:129: TypeError\n___________________ test_naturaltime_future_reference_point ___________________\n\n    def test_naturaltime_future_reference_point() -> None:\n        ref = datetime(2020, 1, 1, 12, 0, 0)\n        later = ref + timedelta(minutes=10)\n>       s = humanize.naturaltime(later, when=ref)\nE       TypeError: naturaltime() got an unexpected keyword argument 'when'\n\ntests\\Humanize\\functional_test.py:165: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturaltime_reference_point - ...\nFAILED tests/Humanize/functional_test.py::test_naturaltime_future_reference_point\n2 failed, 13 passed in 0.51s\n"}
{"model": "o1", "project": "Lifelines", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 2.839837, "avg_memory_mb": 69.02, "avg_cpu_percent": 98.3, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 07:23:03", "stdout_excerpt": "\n1 skipped in 1.36s\n", "stdout_sha1": "216a26696f2006aa93bf41e719224da0940452fe", "stdout_len": 20, "stdout": "\n1 skipped in 1.36s\n"}
{"model": "o1", "project": "Loguru", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "add() got an unexpected keyword argument 'colorize'", "returncode": 1, "elapsed_time_s": 27.19318, "avg_memory_mb": 33.09, "avg_cpu_percent": 0.74, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-02 07:44:50", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable", "stdout_sha1": "e99f30c749977ae58a7cfff084e393010e4ca136", "stdout_len": 12301, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_basic_levels_and_formatting _______________________\n\n    def test_basic_levels_and_formatting() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________________ test_level_filtering _____________________________\n\n    def test_level_filtering() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"INFO\")\n\ntests\\Loguru\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_log_method_with_level_name _______________________\n\n    def test_log_method_with_level_name() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\")\n\ntests\\Loguru\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_______________________ test_bind_extra_renders_fields ________________________\n\n    def test_bind_extra_renders_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{level}:{message} user={extra[user]} req={extra[request_id]}\")\n\ntests\\Loguru\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message} user={extra[user]} req={extra[request_id]}'\nlevel = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________ test_contextualize_adds_extra_fields _____________________\n\n    def test_contextualize_adds_extra_fields() -> None:\n>       log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\")\n\ntests\\Loguru\\functional_test.py:147: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} user={extra[user]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n__________________ test_multiple_sinks_receive_same_message ___________________\n\n    def test_multiple_sinks_receive_same_message() -> None:\n        buf1 = io.StringIO()\n        buf2 = io.StringIO()\n    \n        logger.remove()\n        logger.add(buf1, format=\"{level}:{message}\", level=\"INFO\")\n        logger.add(buf2, format=\"{level}:{message}\", level=\"INFO\")\n    \n        logger.info(\"fanout\")\n    \n        out1 = buf1.getvalue()\n        out2 = buf2.getvalue()\n>       assert \"fanout\" in out1\nE       AssertionError: assert 'fanout' in ''\n\ntests\\Loguru\\functional_test.py:169: AssertionError\n_______________________ test_add_file_sink_writes_lines _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-483/test_add_file_sink_writes_line0')\n\n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n        log_path = tmp_path / \"loguru_test.log\"\n    \n        logger.remove()\n        logger.add(log_path, format=\"{level}:{message}\", level=\"INFO\")\n    \n        logger.info(\"file-line-1\")\n        logger.warning(\"file-line-2\")\n    \n>       assert log_path.exists()\nE       AssertionError: assert False\nE        +  where False = exists()\nE        +    where exists = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-483/test_add_file_sink_writes_line0/loguru_test.log').exists\n\ntests\\Loguru\\functional_test.py:184: AssertionError\n______________ test_serialize_output_contains_message_and_level _______________\n\n    def test_serialize_output_contains_message_and_level() -> None:\n        # serialize=True should emit JSON per record into the sink\n>       log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n\ntests\\Loguru\\functional_test.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'INFO'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n_____________________ test_patch_can_enrich_record_extra ______________________\n\n    def test_patch_can_enrich_record_extra() -> None:\n        # patch() lets us enrich record data in a typical usage pattern\n>       log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\")\n\ntests\\Loguru\\functional_test.py:209: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{message} patched={extra[patched]}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n________________ test_filter_callable_allows_subset_of_records ________________\n\n    def test_filter_callable_allows_subset_of_records() -> None:\n        def only_info(record) -> bool:\n            return record[\"level\"].name == \"INFO\"\n    \n>       log, buf = make_buffer_logger(fmt=\"{level}:{message}\", level=\"DEBUG\", filter_=only_info)\n\ntests\\Loguru\\functional_test.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfmt = '{level}:{message}', level = 'DEBUG'\n\n    def make_buffer_logger(\n        fmt: str = \"{level}:{message}\",\n        level: str = \"DEBUG\",\n        *,\n        colorize: bool = False,\n        serialize: bool = False,\n        filter_: Callable[..., bool] = None,\n    ) -> Tuple[\"logger.__class__\", io.StringIO]:\n        \"\"\"Create a logger configured with a single StringIO sink (happy-path).\"\"\"\n        buf = io.StringIO()\n        logger.remove()\n        add_kwargs = {\"format\": fmt, \"level\": level, \"colorize\": colorize, \"serialize\": serialize}\n        if filter_ is not None:\n            add_kwargs[\"filter\"] = filter_\n>       logger.add(buf, **add_kwargs)\nE       TypeError: add() got an unexpected keyword argument 'colorize'\n\ntests\\Loguru\\functional_test.py:85: TypeError\n____________________ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format() -> None:\n        # Default format should include some timestamp-like content, level, and message.\n        buf = io.StringIO()\n        logger.remove()\n        logger.add(buf)\n    \n        logger.info(\"default-format-test\")\n    \n        output = buf.getvalue()\n>       assert \"INFO\" in output\nE       AssertionError: assert 'INFO' in ''\n\ntests\\Loguru\\functional_test.py:243: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_basic_levels_and_formatting - Ty...\nFAILED tests/Loguru/functional_test.py::test_level_filtering - TypeError: add...\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name - Typ...\nFAILED tests/Loguru/functional_test.py::test_bind_extra_renders_fields - Type...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\nFAILED tests/Loguru/functional_test.py::test_multiple_sinks_receive_same_message\nFAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Ass...\nFAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\nFAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra - ...\nFAILED tests/Loguru/functional_test.py::test_filter_callable_allows_subset_of_records\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n11 failed in 0.77s\n"}
{"model": "o1", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 2.905032, "avg_memory_mb": 36.13, "avg_cpu_percent": 68.2, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 07:45:30", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.56s\n", "stdout_sha1": "a89fe242af26feb26592e80eeaee6e2dc371add0", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.56s\n"}
{"model": "o1", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert ('<em>' in '<p>Second document with &lt;em>emphasis&lt;/em>.</p>' or '<i>' in '<p>Second document with &lt;em>emphasis&lt;/em>.</p>')", "returncode": 1, "elapsed_time_s": 2.181281, "avg_memory_mb": 34.01, "avg_cpu_percent": 96.2, "passed": 4, "failed": 6, "skipped": 9, "total": 19, "functional_score": 0.2105, "timestamp": "2026-01-02 07:46:44", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_emphasis_and_strong ___________________________\n\n    def test_emphasis_and_strong() -> None:\n        src = \"This is *italic* and **bold** and __also bold__.\"\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<em>\" in norm and \"</em>\" in norm\nE       AssertionError: assert ('<em>' in '<p>This is &lt;em>italic&lt;/em> and &lt;strong>bold&lt;/strong> and &lt;strong>also bold&lt;/strong>.</p>')\n\ntests\\Markdown\\functional_test.py:122: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       assert ('<a ' in '<p>A &lt;a href=\"https://example.com\">link&lt;/a> and\\nan image: &lt;img src=\"https://example.com/image.png\" alt=\"alt text\" /></p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b>raw HTML&lt;/b> here.</p>\\n<pre><code>literal &lt;b> tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n__________________ test_markdown_class_multiple_conversions ___________________\n\n    def test_markdown_class_multiple_conversions() -> None:\n        src1 = \"# First\\n\\nParagraph.\"\n        src2 = \"Second document with *emphasis*.\"\n    \n        md = markdown.Markdown()\n        html1 = md.convert(src1)\n        if hasattr(md, \"reset\"):\n            md.reset()\n        html2 = md.convert(src2)\n    \n        norm1 = normalize_html(html1)\n        norm2 = normalize_html(html2)\n    \n        assert \"First\" in norm1\n        assert \"Paragraph.\" in norm1\n        assert \"<h1>\" in norm1\n    \n        assert \"Second document\" in norm2\n>       assert \"<em>\" in norm2 or \"<i>\" in norm2\nE       AssertionError: assert ('<em>' in '<p>Second document with &lt;em>emphasis&lt;/em>.</p>' or '<i>' in '<p>Second document with &lt;em>emphasis&lt;/em>.</p>')\n\ntests\\Markdown\\functional_test.py:231: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-484/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n        markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n>       html = out_path.read_text(encoding=\"utf-8\")\n\ntests\\Markdown\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-484", "stdout_sha1": "bcd2c5444f39138bd753c4c82d213729dce7aba7", "stdout_len": 5884, "stdout": ".F...FFFFFsssssssss                                                      [100%]\n================================== FAILURES ===================================\n__________________________ test_emphasis_and_strong ___________________________\n\n    def test_emphasis_and_strong() -> None:\n        src = \"This is *italic* and **bold** and __also bold__.\"\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<em>\" in norm and \"</em>\" in norm\nE       AssertionError: assert ('<em>' in '<p>This is &lt;em>italic&lt;/em> and &lt;strong>bold&lt;/strong> and &lt;strong>also bold&lt;/strong>.</p>')\n\ntests\\Markdown\\functional_test.py:122: AssertionError\n____________________________ test_links_and_images ____________________________\n\n    def test_links_and_images() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            A [link](https://example.com) and\n            an image: ![alt text](https://example.com/image.png)\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<a \" in norm and \"</a>\" in norm\nE       assert ('<a ' in '<p>A &lt;a href=\"https://example.com\">link&lt;/a> and\\nan image: &lt;img src=\"https://example.com/image.png\" alt=\"alt text\" /></p>')\n\ntests\\Markdown\\functional_test.py:189: AssertionError\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b>raw HTML&lt;/b> here.</p>\\n<pre><code>literal &lt;b> tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n__________________ test_markdown_class_multiple_conversions ___________________\n\n    def test_markdown_class_multiple_conversions() -> None:\n        src1 = \"# First\\n\\nParagraph.\"\n        src2 = \"Second document with *emphasis*.\"\n    \n        md = markdown.Markdown()\n        html1 = md.convert(src1)\n        if hasattr(md, \"reset\"):\n            md.reset()\n        html2 = md.convert(src2)\n    \n        norm1 = normalize_html(html1)\n        norm2 = normalize_html(html2)\n    \n        assert \"First\" in norm1\n        assert \"Paragraph.\" in norm1\n        assert \"<h1>\" in norm1\n    \n        assert \"Second document\" in norm2\n>       assert \"<em>\" in norm2 or \"<i>\" in norm2\nE       AssertionError: assert ('<em>' in '<p>Second document with &lt;em>emphasis&lt;/em>.</p>' or '<i>' in '<p>Second document with &lt;em>emphasis&lt;/em>.</p>')\n\ntests\\Markdown\\functional_test.py:231: AssertionError\n___________________________ test_markdown_from_file ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-484/test_markdown_from_file0')\n\n    def test_markdown_from_file(tmp_path: Path) -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            # Title from file\n    \n            Some text from file.\n            \"\"\"\n        )\n        md_path = tmp_path / \"input.md\"\n        md_path.write_text(src, encoding=\"utf-8\")\n    \n        out_path = tmp_path / \"output.html\"\n        markdown.markdownFromFile(input=str(md_path), output=str(out_path))\n>       html = out_path.read_text(encoding=\"utf-8\")\n\ntests\\Markdown\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-484/test_markdown_from_file0/output.html')\nname = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-484\\\\test_markdown_from_file0\\\\output.html'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-484\\\\test_markdown_from_file0\\\\output.html'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_emphasis_and_strong - Assertio...\nFAILED tests/Markdown/functional_test.py::test_links_and_images - assert ('<a...\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_markdown_class_multiple_conversions\nFAILED tests/Markdown/functional_test.py::test_markdown_from_file - FileNotFo...\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n6 failed, 4 passed, 9 skipped in 0.71s\n"}
{"model": "o1", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "FileNotFoundError", "exception_msg": "[Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'", "returncode": 1, "elapsed_time_s": 2.074042, "avg_memory_mb": 33.54, "avg_cpu_percent": 100.0, "passed": 4, "failed": 7, "skipped": 0, "total": 11, "functional_score": 0.3636, "timestamp": "2026-01-02 07:47:16", "stdout_excerpt": "==== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs", "stdout_sha1": "abe80dad8d7514fcd59f48e8c2898d047ec7bdc8", "stdout_len": 7137, "stdout": "..FF.FF.FFF                                                              [100%]\n================================== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n>       assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\nE       AssertionError: Expected one of these to exist: ['D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\version.py', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\__init__.py']\nE       assert []\n\ntests\\Mitmproxy\\functional_test.py:95: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_003_version_source_file_exists_and_has_version_like_token\nFAILED tests/Mitmproxy/functional_test.py::test_004_tools_main_file_exists - ...\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_007_tools_main_defines_mitmdump_function_or_wrapper\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n7 failed, 4 passed in 0.73s\n"}
{"model": "o1", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.500209, "avg_memory_mb": 31.45, "avg_cpu_percent": 102.2, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 07:48:50", "stdout_excerpt": "\n1 skipped in 0.17s\n", "stdout_sha1": "66bd18a62ec687100e9a9e996a20b12b6bd4dc1e", "stdout_len": 20, "stdout": "\n1 skipped in 0.17s\n"}
{"model": "o1", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'DateTime' object has no attribute 'start_of'", "returncode": 1, "elapsed_time_s": 2.078524, "avg_memory_mb": 32.34, "avg_cpu_percent": 99.2, "passed": 0, "failed": 12, "skipped": 1, "total": 13, "functional_score": 0.0, "timestamp": "2026-01-02 07:50:04", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n>       assert offset_tokyo.total_seconds() == 9 * 60 * 60\nE       assert 0.0 == ((9 * 60) * 60)\nE        +  where 0.0 = <built-in method total_seconds of datetime.timedelta object at 0x0000018AE98844B0>()\nE        +    where <built-in method total_seconds of datetime.timedelta object at 0x0000018AE98844B0> = datetime.timedelta(0).total_seconds\n\ntests\\Pendulum\\functional_test.py:79: AssertionError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n>       shifted = base.add(days=2, hours=5, minutes=15)\nE       TypeError: add() got an unexpected keyword argument 'days'\n\ntests\\Pendulum\\functional_test.py:89: TypeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\nE       TypeError: add() got an unexpected keyword argument 'months'\n\ntests\\Pendulum\\functional_test.py:104: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wed", "stdout_sha1": "1f13045289107c9b09dc839f41c14c529cbcf22f", "stdout_len": 7333, "stdout": "FFFFFFFFFsFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n>       assert offset_tokyo.total_seconds() == 9 * 60 * 60\nE       assert 0.0 == ((9 * 60) * 60)\nE        +  where 0.0 = <built-in method total_seconds of datetime.timedelta object at 0x0000018AE98844B0>()\nE        +    where <built-in method total_seconds of datetime.timedelta object at 0x0000018AE98844B0> = datetime.timedelta(0).total_seconds\n\ntests\\Pendulum\\functional_test.py:79: AssertionError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n>       shifted = base.add(days=2, hours=5, minutes=15)\nE       TypeError: add() got an unexpected keyword argument 'days'\n\ntests\\Pendulum\\functional_test.py:89: TypeError\n_________________________ test_diff_for_humans_months _________________________\n\n    def test_diff_for_humans_months() -> None:\n        \"\"\"Human-readable differences between two datetimes.\"\"\"\n        start = pendulum.datetime(2011, 8, 1, tz=\"UTC\")\n>       end = start.add(months=1)\nE       TypeError: add() got an unexpected keyword argument 'months'\n\ntests\\Pendulum\\functional_test.py:104: TypeError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n        d = pendulum.parse(\"2020-02-29\")\n        assert d.year == 2020\n        assert d.month == 2\n        assert d.day == 29\n>       assert d.to_date_string() == \"2020-02-29\"\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:121: AttributeError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_________________ test_duration_total_seconds_and_components __________________\n\n    def test_duration_total_seconds_and_components() -> None:\n        \"\"\"Verify duration reports correct total seconds and has component attributes.\"\"\"\n        dur = pendulum.duration(days=1, hours=2, minutes=3, seconds=4)\n    \n        # Total seconds is the most stable cross-version contract.\n        assert dur.total_seconds() == 1 * 86400 + 2 * 3600 + 3 * 60 + 4\n    \n        # Component attributes commonly exist; assert them when present.\n>       assert dur.days == 1\nE       AttributeError: 'Duration' object has no attribute 'days'\n\ntests\\Pendulum\\functional_test.py:168: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n        dt_ny = dt_utc.in_timezone(\"America/New_York\")\n    \n        assert int(dt_utc.timestamp()) == int(dt_ny.timestamp())\n>       assert dt_ny.to_date_string() in (\"2020-05-31\", \"2020-06-01\")\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:202: AttributeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_datetime_arithmetic_and_duration\nFAILED tests/Pendulum/functional_test.py::test_diff_for_humans_months - TypeE...\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_duration_total_seconds_and_components\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n12 failed, 1 skipped in 0.68s\n"}
{"model": "o1", "project": "Petl", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "Use -v to get more diff", "returncode": 1, "elapsed_time_s": 2.011067, "avg_memory_mb": 32.09, "avg_cpu_percent": 100.0, "passed": 3, "failed": 3, "skipped": 6, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-02 07:51:27", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:17: in __iter__\n    for row in it:\ngeneration\\Petl\\petl\\transform\\conversions.py:63: in __iter__\n    val = self.func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = [1, 10]\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: list indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-485/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n3 failed, 3 passed, 6 skipped in 0.64s\n", "stdout_sha1": "6bcc37957815a815ca80b1ee1be047b0e5da1a5c", "stdout_len": 3393, "stdout": ".F.ss.FsFsss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_fromdicts_addfield_and_select ______________________\n\n    def test_fromdicts_addfield_and_select() -> None:\n        \"\"\"Validate fromdicts, addfield, and select with a small in-memory table.\"\"\"\n        records = [\n            {\"id\": 1, \"value\": 10},\n            {\"id\": 2, \"value\": 20},\n            {\"id\": 3, \"value\": 30},\n            {\"id\": 4, \"value\": 40},\n        ]\n        table = petl.fromdicts(records, header=[\"id\", \"value\"])\n    \n        table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\n        table = petl.select(table, lambda rec: int(rec[\"double\"]) >= 60)\n    \n>       result = _table_to_list_of_dicts(table)\n\ntests\\Petl\\functional_test.py:168: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Petl\\functional_test.py:87: in _table_to_list_of_dicts\n    for row in iterator:\ngeneration\\Petl\\petl\\transform\\selects.py:17: in __iter__\n    for row in it:\ngeneration\\Petl\\petl\\transform\\conversions.py:63: in __iter__\n    val = self.func(row)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nrec = [1, 10]\n\n>   table = petl.addfield(table, \"double\", lambda rec: int(rec[\"value\"]) * 2)\nE   TypeError: list indices must be integers or slices, not str\n\ntests\\Petl\\functional_test.py:165: TypeError\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n___________________ test_tocsv_then_fromcsv_preserves_data ____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-485/test_tocsv_then_fromcsv_preser0')\n\n    def test_tocsv_then_fromcsv_preserves_data(tmp_path: Path) -> None:\n        \"\"\"Write a table to CSV and read it back, verifying header and row content.\"\"\"\n        src = tmp_path / \"roundtrip.csv\"\n    \n        table = petl.fromdicts(\n            [{\"a\": 1, \"b\": \"x\"}, {\"a\": 2, \"b\": \"y\"}],\n            header=[\"a\", \"b\"],\n        )\n        petl.tocsv(table, str(src))\n        assert src.exists()\n    \n        table2 = petl.fromcsv(str(src))\n        rows = list(table2)\n    \n>       assert rows[0] == (\"a\", \"b\")\nE       AssertionError: assert ['a', 'b'] == ('a', 'b')\nE         \nE         Use -v to get more diff\n\ntests\\Petl\\functional_test.py:330: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_fromdicts_addfield_and_select - Ty...\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\nFAILED tests/Petl/functional_test.py::test_tocsv_then_fromcsv_preserves_data\n3 failed, 3 passed, 6 skipped in 0.64s\n"}
{"model": "o1", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.397933, "avg_memory_mb": 14.34, "avg_cpu_percent": 105.6, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 07:52:41", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n", "stdout_sha1": "3d43d73e26be0f48c50fe96012d3c4dcf351a1b9", "stdout_len": 1401, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 15, in <module>\n    from pygments.lexer import Lexer\nModuleNotFoundError: No module named 'pygments.lexer'\n"}
{"model": "o1", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 2.008409, "avg_memory_mb": 33.72, "avg_cpu_percent": 100.8, "passed": 5, "failed": 5, "skipped": 1, "total": 11, "functional_score": 0.4545, "timestamp": "2026-01-02 07:53:28", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n            # Only HS256 is supported in this simple implementation\n>           raise NotImplementedError(\"Only HS256 is supported\")\nE           NotImplementedError: Only HS256 is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:25: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000026065327700>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:25: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \"", "stdout_sha1": "9035af28b99d6e6aa8c34fe7584d9e2ce62f75ee", "stdout_len": 8675, "stdout": ".F.FF...FFs                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', kwargs = {}\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n            # Only HS256 is supported in this simple implementation\n>           raise NotImplementedError(\"Only HS256 is supported\")\nE           NotImplementedError: Only HS256 is supported\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:21: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:25: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000026065327700>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:25: in encode\n    payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000026065392C10>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n_________________________ test_decode_with_bytes_key __________________________\n\n    def test_decode_with_bytes_key() -> None:\n        payload = {\"user\": \"bob\", \"plan\": \"pro\"}\n        key = b\"secret-bytes\"\n>       decoded = _encode_decode(payload, key=key, algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\npayload = {'plan': 'pro', 'user': 'bob'}, key = b'secret-bytes'\nalgorithm = 'HS256', kwargs = {}, header = {'alg': 'HS256', 'typ': 'JWT'}\nheader_json = '{\"alg\":\"HS256\",\"typ\":\"JWT\"}'\npayload_json = '{\"plan\":\"pro\",\"user\":\"bob\"}'\nheader_b64 = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9'\npayload_b64 = 'eyJwbGFuIjoicHJvIiwidXNlciI6ImJvYiJ9'\nsigning_input = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwbGFuIjoicHJvIiwidXNlciI6ImJvYiJ9'\n\n    def encode(payload, key, algorithm=\"HS256\", **kwargs):\n        if algorithm != \"HS256\":\n            # Only HS256 is supported in this simple implementation\n            raise NotImplementedError(\"Only HS256 is supported\")\n    \n        header = {\"alg\": algorithm, \"typ\": \"JWT\"}\n        header_json = json.dumps(header, separators=(\",\", \":\"), sort_keys=True)\n        payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True)\n    \n        header_b64 = base64url_encode(header_json.encode(\"utf-8\"))\n        payload_b64 = base64url_encode(payload_json.encode(\"utf-8\"))\n        signing_input = f\"{header_b64}.{payload_b64}\"\n    \n        # HS256 signature\n        signature = hmac.new(\n>           key.encode(\"utf-8\"),\n            signing_input.encode(\"utf-8\"),\n            hashlib.sha256\n        ).digest()\nE       AttributeError: 'bytes' object has no attribute 'encode'\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:33: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\nFAILED tests/PyJWT/functional_test.py::test_decode_with_bytes_key - Attribute...\n5 failed, 5 passed, 1 skipped in 0.64s\n"}
{"model": "o1", "project": "PyPDF", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.468151, "avg_memory_mb": 30.51, "avg_cpu_percent": 95.4, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 07:54:41", "stdout_excerpt": "\n1 skipped in 0.13s\n", "stdout_sha1": "4c4ceb412a81fcf19d92b45ee51d2d9a1553d8c3", "stdout_len": 20, "stdout": "\n1 skipped in 0.13s\n"}
{"model": "o1", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.568737, "avg_memory_mb": 31.37, "avg_cpu_percent": 98.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 07:56:45", "stdout_excerpt": "\n1 skipped in 0.18s\n", "stdout_sha1": "635cfd0c225802c418c315f97bcf9f1555f8b14a", "stdout_len": 20, "stdout": "\n1 skipped in 0.18s\n"}
{"model": "o1", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'schedule' has no attribute 'clear'", "returncode": 1, "elapsed_time_s": 2.048767, "avg_memory_mb": 32.39, "avg_cpu_percent": 100.8, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-02 07:57:32", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n>       _clear()\n\nt", "stdout_sha1": "9e38ce59b4f707a7a9161ebfc3b31e785a1228e4", "stdout_len": 7625, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_run_pending_executes_due_job_without_sleep _______________\n\n    def test_run_pending_executes_due_job_without_sleep() -> None:\n        \"\"\"run_pending executes jobs that are due, without relying on real time waiting.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:178: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_______________ test_job_next_run_is_datetime_after_scheduling ________________\n\n    def test_job_next_run_is_datetime_after_scheduling() -> None:\n        \"\"\"A newly scheduled job should have a next_run datetime set.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:193: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_every_day_at_sets_time_component_in_next_run ______________\n\n    def test_every_day_at_sets_time_component_in_next_run() -> None:\n        \"\"\"Scheduling with .day.at('HH:MM') should include that time in the next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________ test_weekday_scheduling_creates_job_and_next_run _______________\n\n    def test_weekday_scheduling_creates_job_and_next_run() -> None:\n        \"\"\"Weekday scheduling (e.g., monday) should create a job with next_run.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:248: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:261: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n______________________ test_run_all_sets_last_run_on_job ______________________\n\n    def test_run_all_sets_last_run_on_job() -> None:\n        \"\"\"After running, last_run should be populated on the job in typical implementations.\"\"\"\n>       _clear()\n\ntests\\Schedule\\functional_test.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _clear() -> None:\n>       schedule.clear()\nE       AttributeError: module 'schedule' has no attribute 'clear'\n\ntests\\Schedule\\functional_test.py:64: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_run_pending_executes_due_job_without_sleep\nFAILED tests/Schedule/functional_test.py::test_job_next_run_is_datetime_after_scheduling\nFAILED tests/Schedule/functional_test.py::test_every_day_at_sets_time_component_in_next_run\nFAILED tests/Schedule/functional_test.py::test_weekday_scheduling_creates_job_and_next_run\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\nFAILED tests/Schedule/functional_test.py::test_run_all_sets_last_run_on_job\n12 failed in 0.69s\n"}
{"model": "o1", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "assert ('no such option' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n' or 'unrecognized' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n' or 'unknown' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n')", "returncode": 1, "elapsed_time_s": 3.259359, "avg_memory_mb": 32.02, "avg_cpu_percent": 56.4, "passed": 8, "failed": 1, "skipped": 0, "total": 9, "functional_score": 0.8889, "timestamp": "2026-01-02 07:59:04", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       AssertionError: assert ('no such option' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n' or 'unrecognized' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n' or 'unknown' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_006_invalid_option_reports_error_cleanly\n1 failed, 8 passed in 1.93s\n", "stdout_sha1": "460555ea13de5a68b54069fdfbc20963e2d8535b", "stdout_len": 1537, "stdout": ".....F...                                                                [100%]\n================================== FAILURES ===================================\n________________ test_006_invalid_option_reports_error_cleanly ________________\n\n    def test_006_invalid_option_reports_error_cleanly():\n        \"\"\"\n        In sqlmap reference, invalid options can still return code 0 in some paths,\n        but stderr includes 'no such option' (argparse style). We assert on the message.\n        \"\"\"\n        p = _run_cli([\"--this-option-should-not-exist\"], timeout_s=30)\n        out = _out(p)\n    \n        # Must clearly indicate option parsing failure; do NOT assert return code.\n>       assert (\"no such option\" in out) or (\"unrecognized\" in out) or (\"unknown\" in out)\nE       AssertionError: assert ('no such option' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n' or 'unrecognized' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n' or 'unknown' in '[*] starting the sqlmap-like tool (mock).\\n[*] no actual sql injection testing is performed in this mock implementation.\\n[*] exiting now.\\n\\n')\n\ntests\\Sqlmap\\functional_test.py:92: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_006_invalid_option_reports_error_cleanly\n1 failed, 8 passed in 1.93s\n"}
{"model": "o1", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "'_SQLModelMetadata' object has no attribute 'clear'", "returncode": 2, "elapsed_time_s": 1.907489, "avg_memory_mb": 36.18, "avg_cpu_percent": 99.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 08:00:31", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: '_SQLModelMetadata' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: '_SQLModelMetadata'...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n", "stdout_sha1": "b34c8df9b4a524548f3cd58270897fd763913a32", "stdout_len": 571, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: '_SQLModelMetadata' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: '_SQLModelMetadata'...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n"}
{"model": "o1", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute 'mode'", "returncode": 1, "elapsed_time_s": 46.765549, "avg_memory_mb": 37.85, "avg_cpu_percent": 0.31, "passed": 2, "failed": 10, "skipped": 0, "total": 12, "functional_score": 0.1667, "timestamp": "2026-01-02 08:02:42", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: str,\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text message in the image using LSB steganography.\n        :param image: PIL Image to use as cover.\n        :param message: The text message to hide.\n        :param generator: Iterator of pixel indices to use for hiding bits (default: consecutive).\n        :param shift: Number of LSB positions to skip from the start (default 0).\n        :param encoding: Text encoding for the message (default: UTF-8).\n        :param auto_convert_rgb: If True and image is not 'RGB', convert it.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       elif image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:33: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x00000246AC653EB0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: str,\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text message in the image using LSB steganography.\n        :param image: PIL Image to use as cover.\n        :param message: The text message to hide.\n        :param generator: Iterator of pixel indices to use for hiding bits (default: consecutive).\n        :param shift: Number of LSB positions to skip from the start (default 0).\n        :param encoding: Text encoding for the message (default: UTF-8).\n        :param auto_convert_rgb: If True and image is not 'RGB', convert it.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       elif image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:33: AttributeError\n__________", "stdout_sha1": "00b1cf7b6abb1af1885006359b6d643b99ccb7b4", "stdout_len": 27447, "stdout": "FFFFFF..FFFF                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'hello world', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: str,\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text message in the image using LSB steganography.\n        :param image: PIL Image to use as cover.\n        :param message: The text message to hide.\n        :param generator: Iterator of pixel indices to use for hiding bits (default: consecutive).\n        :param shift: Number of LSB positions to skip from the start (default 0).\n        :param encoding: Text encoding for the message (default: UTF-8).\n        :param auto_convert_rgb: If True and image is not 'RGB', convert it.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       elif image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:33: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'generator secret'\ngenerator = <generator object eratosthenes at 0x00000246AC653EB0>, shift = 0\nencoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: str,\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text message in the image using LSB steganography.\n        :param image: PIL Image to use as cover.\n        :param message: The text message to hide.\n        :param generator: Iterator of pixel indices to use for hiding bits (default: consecutive).\n        :param shift: Number of LSB positions to skip from the start (default 0).\n        :param encoding: Text encoding for the message (default: UTF-8).\n        :param auto_convert_rgb: If True and image is not 'RGB', convert it.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       elif image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:33: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'This is a longer secret message with punctuation: 12345, hello-world!'\ngenerator = None, shift = 0, encoding = 'UTF-8', auto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: str,\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text message in the image using LSB steganography.\n        :param image: PIL Image to use as cover.\n        :param message: The text message to hide.\n        :param generator: Iterator of pixel indices to use for hiding bits (default: consecutive).\n        :param shift: Number of LSB positions to skip from the start (default 0).\n        :param encoding: Text encoding for the message (default: UTF-8).\n        :param auto_convert_rgb: If True and image is not 'RGB', convert it.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       elif image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:33: AttributeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n>       img_obj = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'object input', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: str,\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text message in the image using LSB steganography.\n        :param image: PIL Image to use as cover.\n        :param message: The text message to hide.\n        :param generator: Iterator of pixel indices to use for hiding bits (default: consecutive).\n        :param shift: Number of LSB positions to skip from the start (default 0).\n        :param encoding: Text encoding for the message (default: UTF-8).\n        :param auto_convert_rgb: If True and image is not 'RGB', convert it.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       elif image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:33: AttributeError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'red secret'\n\n    def hide(image: Image.Image, message: str) -> Image.Image:\n        \"\"\"\n        Hide a text message using only the red channel.\n        :param image: PIL Image to use as cover (RGB or RGBA ideally).\n        :param message: The text message to hide.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\red\\red.py:18: AttributeError\n________________ test_red_hide_and_reveal_extended_latin_text _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_red_hide_and_reveal_exten0')\n\n    def test_red_hide_and_reveal_extended_latin_text(tmp_path: Path) -> None:\n        \"\"\"Red backend stores per-char ord() into a byte channel; Latin-1 chars like 'é' are valid.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"Café au lait\"\n        output = tmp_path / \"red_latin.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'Café au lait'\n\n    def hide(image: Image.Image, message: str) -> Image.Image:\n        \"\"\"\n        Hide a text message using only the red channel.\n        :param image: PIL Image to use as cover (RGB or RGBA ideally).\n        :param message: The text message to hide.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n>       if image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\red\\red.py:18: AttributeError\n________________________ test_wav_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_wav_hide_and_reveal_text0')\n\n    def test_wav_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"wav.hide writes output WAV; wav.reveal returns the same string.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"wav secret\"\n        output = tmp_path / \"out.wav\"\n    \n>       wav.hide(str(wav_in), secret, str(output))\n\ntests\\Stegano\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ninput_file = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\free-software-song.wav'\nmessage = 'wav secret'\noutput_file = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-489\\\\test_wav_hide_and_reveal_text0\\\\out.wav'\nkwargs = {}\nf_in = <_io.BufferedReader name='D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\free-software-song.wav'>\nwav_data = b'RIFF\\xdai\\x1a\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00@\\x1f\\x00\\x00\\x80>\\x00\\x00\\x02\\x00\\x10\\x00data\\xb6i\\x1a\\x00...fe\\xd4\\xfd\\xb6\\xfd\\xe6\\xfd\\xc2\\xfe\\xf6\\xfe\\xf7\\xfe\\xb9\\xff\\xd9\\x00\\xe7\\x01\\xdc\\x01\\xa7\\x01F\\x01\\xb3\\x00;\\x00M\\xffR\\xfe'\noffset = 36, fmt_offset = 12, data_offset = 44, data_size = 1730998\nchunk_id = b'data'\n\n    def hide(input_file, message, output_file, **kwargs):\n        \"\"\"\n        Hide a message string in a 16-bit PCM WAV file, in the LSB of each sample.\n        Writes a new file to output_file.\n        :param input_file: path to the cover WAV file.\n        :param message: the text message to embed.\n        :param output_file: output path for the modified WAV.\n        :param kwargs: additional arguments (ignored for signature compatibility).\n        \"\"\"\n        with open(input_file, \"rb\") as f_in:\n            wav_data = f_in.read()\n    \n        # Parse header\n        if not wav_data.startswith(b\"RIFF\") or not wav_data[8:12] == b\"WAVE\":\n            raise ValueError(\"Not a valid WAV file (missing RIFF/WAVE).\")\n    \n        # Search for 'fmt ' chunk, 'data' chunk\n        # We'll do a simple pass to find them\n        offset = 12  # skip RIFF header\n        fmt_offset = None\n        data_offset = None\n        data_size = None\n    \n        while offset < len(wav_data):\n            chunk_id = wav_data[offset:offset+4]\n            chunk_size = struct.unpack(\"<I\", wav_data[offset+4:offset+8])[0]\n            if chunk_id == b\"fmt \":\n                fmt_offset = offset\n            elif chunk_id == b\"data\":\n                data_offset = offset + 8\n                data_size = chunk_size\n                break\n            offset += 8 + chunk_size\n    \n        if fmt_offset is None or data_offset is None or data_size is None:\n            raise ValueError(\"Could not find required chunks in WAV file.\")\n    \n        # Check if it's 16-bit PCM\n        # Format code is at fmt_offset+8 (2 bytes)\n        audio_format, num_channels, sample_rate, byte_rate, block_align, bits_per_sample = struct.unpack(\n            \"<HHIIHH\", wav_data[fmt_offset+8:fmt_offset+8+16]\n        )\n        if audio_format != 1 or bits_per_sample != 16:\n            raise ValueError(\"Only 16-bit PCM WAV is supported by this simple steganography.\")\n    \n        # Get the sample data\n        audio_data = bytearray(wav_data[data_offset:data_offset+data_size])\n    \n        # Convert message to bits\n        # We'll store len(message) as 4 bytes + message\n        message_bytes = message.encode(\"utf-8\")\n        msg_len = len(message_bytes)\n        length_bytes = struct.pack(\"<I\", msg_len)\n        full_payload = length_bytes + message_bytes\n    \n        # Each sample is 2 bytes => we can store 1 bit per sample (LSB).\n        num_samples = len(audio_data) // 2\n    \n        total_bits = len(full_payload) * 8\n        if total_bits > num_samples:\n            raise ValueError(\"Message is too large to fit in the given WAV.\")\n    \n        # Hide bits\n        bit_idx = 0\n        for i in range(len(full_payload)):\n            byte_val = full_payload[i]\n            for b in range(8):\n                bit = (byte_val >> b) & 1\n                # replace LSB of sample\n                sample_idx = bit_idx\n                sample_bytes = audio_data[sample_idx*2:(sample_idx*2)+2]\n                sample_val = struct.unpack(\"<h\", sample_bytes)[0]\n                sample_val = (sample_val & 0xFFFE) | bit\n>               audio_data[sample_idx*2:(sample_idx*2)+2] = struct.pack(\"<h\", sample_val)\nE               struct.error: short format requires (-32768) <= number <= 32767\n\ngeneration\\Stegano\\stegano\\wav\\wav.py:82: error\n_____________________ test_wav_hide_and_reveal_short_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_wav_hide_and_reveal_short0')\n\n    def test_wav_hide_and_reveal_short_text(tmp_path: Path) -> None:\n        \"\"\"A short message should also roundtrip.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"ok\"\n        output = tmp_path / \"out_short.wav\"\n    \n>       wav.hide(str(wav_in), secret, str(output))\n\ntests\\Stegano\\functional_test.py:234: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ninput_file = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\free-software-song.wav'\nmessage = 'ok'\noutput_file = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-489\\\\test_wav_hide_and_reveal_short0\\\\out_short.wav'\nkwargs = {}\nf_in = <_io.BufferedReader name='D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\free-software-song.wav'>\nwav_data = b'RIFF\\xdai\\x1a\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00@\\x1f\\x00\\x00\\x80>\\x00\\x00\\x02\\x00\\x10\\x00data\\xb6i\\x1a\\x00...fe\\xd4\\xfd\\xb6\\xfd\\xe6\\xfd\\xc2\\xfe\\xf6\\xfe\\xf7\\xfe\\xb9\\xff\\xd9\\x00\\xe7\\x01\\xdc\\x01\\xa7\\x01F\\x01\\xb3\\x00;\\x00M\\xffR\\xfe'\noffset = 36, fmt_offset = 12, data_offset = 44, data_size = 1730998\nchunk_id = b'data'\n\n    def hide(input_file, message, output_file, **kwargs):\n        \"\"\"\n        Hide a message string in a 16-bit PCM WAV file, in the LSB of each sample.\n        Writes a new file to output_file.\n        :param input_file: path to the cover WAV file.\n        :param message: the text message to embed.\n        :param output_file: output path for the modified WAV.\n        :param kwargs: additional arguments (ignored for signature compatibility).\n        \"\"\"\n        with open(input_file, \"rb\") as f_in:\n            wav_data = f_in.read()\n    \n        # Parse header\n        if not wav_data.startswith(b\"RIFF\") or not wav_data[8:12] == b\"WAVE\":\n            raise ValueError(\"Not a valid WAV file (missing RIFF/WAVE).\")\n    \n        # Search for 'fmt ' chunk, 'data' chunk\n        # We'll do a simple pass to find them\n        offset = 12  # skip RIFF header\n        fmt_offset = None\n        data_offset = None\n        data_size = None\n    \n        while offset < len(wav_data):\n            chunk_id = wav_data[offset:offset+4]\n            chunk_size = struct.unpack(\"<I\", wav_data[offset+4:offset+8])[0]\n            if chunk_id == b\"fmt \":\n                fmt_offset = offset\n            elif chunk_id == b\"data\":\n                data_offset = offset + 8\n                data_size = chunk_size\n                break\n            offset += 8 + chunk_size\n    \n        if fmt_offset is None or data_offset is None or data_size is None:\n            raise ValueError(\"Could not find required chunks in WAV file.\")\n    \n        # Check if it's 16-bit PCM\n        # Format code is at fmt_offset+8 (2 bytes)\n        audio_format, num_channels, sample_rate, byte_rate, block_align, bits_per_sample = struct.unpack(\n            \"<HHIIHH\", wav_data[fmt_offset+8:fmt_offset+8+16]\n        )\n        if audio_format != 1 or bits_per_sample != 16:\n            raise ValueError(\"Only 16-bit PCM WAV is supported by this simple steganography.\")\n    \n        # Get the sample data\n        audio_data = bytearray(wav_data[data_offset:data_offset+data_size])\n    \n        # Convert message to bits\n        # We'll store len(message) as 4 bytes + message\n        message_bytes = message.encode(\"utf-8\")\n        msg_len = len(message_bytes)\n        length_bytes = struct.pack(\"<I\", msg_len)\n        full_payload = length_bytes + message_bytes\n    \n        # Each sample is 2 bytes => we can store 1 bit per sample (LSB).\n        num_samples = len(audio_data) // 2\n    \n        total_bits = len(full_payload) * 8\n        if total_bits > num_samples:\n            raise ValueError(\"Message is too large to fit in the given WAV.\")\n    \n        # Hide bits\n        bit_idx = 0\n        for i in range(len(full_payload)):\n            byte_val = full_payload[i]\n            for b in range(8):\n                bit = (byte_val >> b) & 1\n                # replace LSB of sample\n                sample_idx = bit_idx\n                sample_bytes = audio_data[sample_idx*2:(sample_idx*2)+2]\n                sample_val = struct.unpack(\"<h\", sample_bytes)[0]\n                sample_val = (sample_val & 0xFFFE) | bit\n>               audio_data[sample_idx*2:(sample_idx*2)+2] = struct.pack(\"<h\", sample_val)\nE               struct.error: short format requires (-32768) <= number <= 32767\n\ngeneration\\Stegano\\stegano\\wav\\wav.py:82: error\n____________________ test_wav_hide_and_reveal_longer_text _____________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_wav_hide_and_reveal_longe0')\n\n    def test_wav_hide_and_reveal_longer_text(tmp_path: Path) -> None:\n        \"\"\"Roundtrip a longer ASCII message via WAV backend.\"\"\"\n        wav_in = _pick_sample_wav()\n    \n        secret = \"WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz\"\n        output = tmp_path / \"out_long.wav\"\n    \n>       wav.hide(str(wav_in), secret, str(output))\n\ntests\\Stegano\\functional_test.py:249: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ninput_file = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\free-software-song.wav'\nmessage = 'WAV backend long message: 1234567890 abcdefghijklmnopqrstuvwxyz'\noutput_file = 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-489\\\\test_wav_hide_and_reveal_longe0\\\\out_long.wav'\nkwargs = {}\nf_in = <_io.BufferedReader name='D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\free-software-song.wav'>\nwav_data = b'RIFF\\xdai\\x1a\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00@\\x1f\\x00\\x00\\x80>\\x00\\x00\\x02\\x00\\x10\\x00data\\xb6i\\x1a\\x00...fe\\xd4\\xfd\\xb6\\xfd\\xe6\\xfd\\xc2\\xfe\\xf6\\xfe\\xf7\\xfe\\xb9\\xff\\xd9\\x00\\xe7\\x01\\xdc\\x01\\xa7\\x01F\\x01\\xb3\\x00;\\x00M\\xffR\\xfe'\noffset = 36, fmt_offset = 12, data_offset = 44, data_size = 1730998\nchunk_id = b'data'\n\n    def hide(input_file, message, output_file, **kwargs):\n        \"\"\"\n        Hide a message string in a 16-bit PCM WAV file, in the LSB of each sample.\n        Writes a new file to output_file.\n        :param input_file: path to the cover WAV file.\n        :param message: the text message to embed.\n        :param output_file: output path for the modified WAV.\n        :param kwargs: additional arguments (ignored for signature compatibility).\n        \"\"\"\n        with open(input_file, \"rb\") as f_in:\n            wav_data = f_in.read()\n    \n        # Parse header\n        if not wav_data.startswith(b\"RIFF\") or not wav_data[8:12] == b\"WAVE\":\n            raise ValueError(\"Not a valid WAV file (missing RIFF/WAVE).\")\n    \n        # Search for 'fmt ' chunk, 'data' chunk\n        # We'll do a simple pass to find them\n        offset = 12  # skip RIFF header\n        fmt_offset = None\n        data_offset = None\n        data_size = None\n    \n        while offset < len(wav_data):\n            chunk_id = wav_data[offset:offset+4]\n            chunk_size = struct.unpack(\"<I\", wav_data[offset+4:offset+8])[0]\n            if chunk_id == b\"fmt \":\n                fmt_offset = offset\n            elif chunk_id == b\"data\":\n                data_offset = offset + 8\n                data_size = chunk_size\n                break\n            offset += 8 + chunk_size\n    \n        if fmt_offset is None or data_offset is None or data_size is None:\n            raise ValueError(\"Could not find required chunks in WAV file.\")\n    \n        # Check if it's 16-bit PCM\n        # Format code is at fmt_offset+8 (2 bytes)\n        audio_format, num_channels, sample_rate, byte_rate, block_align, bits_per_sample = struct.unpack(\n            \"<HHIIHH\", wav_data[fmt_offset+8:fmt_offset+8+16]\n        )\n        if audio_format != 1 or bits_per_sample != 16:\n            raise ValueError(\"Only 16-bit PCM WAV is supported by this simple steganography.\")\n    \n        # Get the sample data\n        audio_data = bytearray(wav_data[data_offset:data_offset+data_size])\n    \n        # Convert message to bits\n        # We'll store len(message) as 4 bytes + message\n        message_bytes = message.encode(\"utf-8\")\n        msg_len = len(message_bytes)\n        length_bytes = struct.pack(\"<I\", msg_len)\n        full_payload = length_bytes + message_bytes\n    \n        # Each sample is 2 bytes => we can store 1 bit per sample (LSB).\n        num_samples = len(audio_data) // 2\n    \n        total_bits = len(full_payload) * 8\n        if total_bits > num_samples:\n            raise ValueError(\"Message is too large to fit in the given WAV.\")\n    \n        # Hide bits\n        bit_idx = 0\n        for i in range(len(full_payload)):\n            byte_val = full_payload[i]\n            for b in range(8):\n                bit = (byte_val >> b) & 1\n                # replace LSB of sample\n                sample_idx = bit_idx\n                sample_bytes = audio_data[sample_idx*2:(sample_idx*2)+2]\n                sample_val = struct.unpack(\"<h\", sample_bytes)[0]\n                sample_val = (sample_val & 0xFFFE) | bit\n>               audio_data[sample_idx*2:(sample_idx*2)+2] = struct.pack(\"<h\", sample_val)\nE               struct.error: short format requires (-32768) <= number <= 32767\n\ngeneration\\Stegano\\stegano\\wav\\wav.py:82: error\n_____________________ test_lsb_and_red_outputs_are_files ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-489/test_lsb_and_red_outputs_are_f0')\n\n    def test_lsb_and_red_outputs_are_files(tmp_path: Path) -> None:\n        \"\"\"Ensure image-encoding backends produce files that can be written to disk.\"\"\"\n        _ensure_image_samples_exist()\n    \n        out_lsb = tmp_path / \"lsb_file.png\"\n        out_red = tmp_path / \"red_file.png\"\n    \n>       lsb.hide(str(LENNA_PNG), \"x\").save(str(out_lsb))\n\ntests\\Stegano\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\nmessage = 'x', generator = None, shift = 0, encoding = 'UTF-8'\nauto_convert_rgb = False\n\n    def hide(\n        image: Image.Image,\n        message: str,\n        generator: Optional[Iterator[int]] = None,\n        shift: int = 0,\n        encoding: str = \"UTF-8\",\n        auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Hide a text message in the image using LSB steganography.\n        :param image: PIL Image to use as cover.\n        :param message: The text message to hide.\n        :param generator: Iterator of pixel indices to use for hiding bits (default: consecutive).\n        :param shift: Number of LSB positions to skip from the start (default 0).\n        :param encoding: Text encoding for the message (default: UTF-8).\n        :param auto_convert_rgb: If True and image is not 'RGB', convert it.\n        :return: A new PIL Image with the hidden message.\n        \"\"\"\n        if auto_convert_rgb and image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n>       elif image.mode not in (\"RGB\", \"RGBA\"):\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:33: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_extended_latin_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_text - stru...\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_short_text\nFAILED tests/Stegano/functional_test.py::test_wav_hide_and_reveal_longer_text\nFAILED tests/Stegano/functional_test.py::test_lsb_and_red_outputs_are_files\n10 failed, 2 passed in 45.49s\n"}
{"model": "o1", "project": "Tablib", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'Dataset' object has no attribute 'insert'", "returncode": 1, "elapsed_time_s": 1.997051, "avg_memory_mb": 32.74, "avg_cpu_percent": 100.0, "passed": 4, "failed": 7, "skipped": 0, "total": 11, "functional_score": 0.3636, "timestamp": "2026-01-02 08:03:35", "stdout_excerpt": "==== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n        assert loaded_csv.height == data.height\n        assert loaded_csv.width == data.width\n    \n        orig_dict_norm = _normalize_dict_rows(data.dict)\n        loaded_dict_norm = _normalize_dict_rows(loaded_csv.dict)\n        assert loaded_dict_norm == orig_dict_norm\n    \n        # JSON roundtrip via export + .json setter.\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'data': [['John', 'Adams', '90'], ['George', 'Washington', '67'], ['Ada', 'Lovelace', '36']], 'headers': ['first_name', 'last_name', 'age'], 'title': None}, list)\n\ntests\\Tablib\\functional_test.py:146: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001FA7EEA6CD0>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"\n        Export this dataset to a string in the requested format ('csv' or 'json').\n        \"\"\"\n        if fmt == \"csv\":\n            return csv_format.export_set(self)\n        elif fmt == \"json\":\n            return json_format.export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format '{fmt}'.\")\nE           ValueError: Unsupported format 'tsv'.\n\ngeneration\\Tablib\\tablib\\core.py:97: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence __________________\n\n    def test_dataset_title_and_headers_persistence() -> None:\n        \"\"\"Dataset title and headers should be assignable and remain consistent.\"\"\"\n        data = tablib.Dataset(headers=(\"k\", \"v\"))\n        data.title = \"Config\"\n        data.append((\"a\", 1))\n        data.append((\"b\", 2))\n    \n        assert getattr(data, \"title\") == \"Config\"\n        assert tuple(data.headers) == (\"k\", \"v\")\n        assert data.height == 2\n>       assert data[1][0] == \"b\"\n\ntests\\Tablib\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001FA7EF19F70>, key = 1\n\n    def __getitem__(self, key):\n        \"\"\"\n        - If key is a slice, return a list of row tuples (start:stop).\n        - If key is a string, return the column data for that header.\n        \"\"\"\n        if isinstance(key, slice):\n            return [tuple(row) for row in self._data", "stdout_sha1": "000d48d3a5c35f8e9622fb114515d57e7b025437", "stdout_len": 9009, "stdout": "FF..F.FFF.F                                                              [100%]\n================================== FAILURES ===================================\n______________ test_dataset_export_import_csv_and_json_roundtrip ______________\n\n    def test_dataset_export_import_csv_and_json_roundtrip() -> None:\n        \"\"\"Exercise core CSV/JSON export and import roundtrips on Dataset.\"\"\"\n        data = _build_sample_dataset()\n    \n        # CSV roundtrip via export + .csv setter.\n        csv_text = data.export(\"csv\")\n        assert isinstance(csv_text, str)\n    \n        loaded_csv = tablib.Dataset()\n        loaded_csv.csv = csv_text\n    \n        assert loaded_csv.headers == data.headers\n        assert loaded_csv.height == data.height\n        assert loaded_csv.width == data.width\n    \n        orig_dict_norm = _normalize_dict_rows(data.dict)\n        loaded_dict_norm = _normalize_dict_rows(loaded_csv.dict)\n        assert loaded_dict_norm == orig_dict_norm\n    \n        # JSON roundtrip via export + .json setter.\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'data': [['John', 'Adams', '90'], ['George', 'Washington', '67'], ['Ada', 'Lovelace', '36']], 'headers': ['first_name', 'last_name', 'age'], 'title': None}, list)\n\ntests\\Tablib\\functional_test.py:146: AssertionError\n__________________ test_dataset_export_import_tsv_roundtrip ___________________\n\n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"TSV export/import should preserve shape and values (type-coercion tolerant).\"\"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001FA7EEA6CD0>, fmt = 'tsv'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"\n        Export this dataset to a string in the requested format ('csv' or 'json').\n        \"\"\"\n        if fmt == \"csv\":\n            return csv_format.export_set(self)\n        elif fmt == \"json\":\n            return json_format.export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format '{fmt}'.\")\nE           ValueError: Unsupported format 'tsv'.\n\ngeneration\\Tablib\\tablib\\core.py:97: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics __________________\n\n    def test_dataset_insert_and_pop_row_semantics() -> None:\n        \"\"\"Dataset should support inserting and popping rows (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\ntests\\Tablib\\functional_test.py:233: AttributeError\n_________________ test_dataset_title_and_headers_persistence __________________\n\n    def test_dataset_title_and_headers_persistence() -> None:\n        \"\"\"Dataset title and headers should be assignable and remain consistent.\"\"\"\n        data = tablib.Dataset(headers=(\"k\", \"v\"))\n        data.title = \"Config\"\n        data.append((\"a\", 1))\n        data.append((\"b\", 2))\n    \n        assert getattr(data, \"title\") == \"Config\"\n        assert tuple(data.headers) == (\"k\", \"v\")\n        assert data.height == 2\n>       assert data[1][0] == \"b\"\n\ntests\\Tablib\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001FA7EF19F70>, key = 1\n\n    def __getitem__(self, key):\n        \"\"\"\n        - If key is a slice, return a list of row tuples (start:stop).\n        - If key is a string, return the column data for that header.\n        \"\"\"\n        if isinstance(key, slice):\n            return [tuple(row) for row in self._data[key]]\n        elif isinstance(key, str):\n            if key not in self._headers:\n                raise KeyError(f\"Column '{key}' does not exist in headers.\")\n            col_idx = self._headers.index(key)\n            return [row[col_idx] for row in self._data]\n        else:\n>           raise TypeError(\"Dataset indices must be slice or str (column name).\")\nE           TypeError: Dataset indices must be slice or str (column name).\n\ngeneration\\Tablib\\tablib\\core.py:58: TypeError\n________________ test_dataset_export_json_contains_all_records ________________\n\n    def test_dataset_export_json_contains_all_records() -> None:\n        \"\"\"JSON export should serialize all dataset records in a list-like structure.\"\"\"\n        data = _build_sample_dataset()\n        json_text = data.export(\"json\")\n        assert isinstance(json_text, str)\n    \n        parsed = json.loads(json_text)\n>       assert isinstance(parsed, list)\nE       AssertionError: assert False\nE        +  where False = isinstance({'data': [['John', 'Adams', '90'], ['George', 'Washington', '67'], ['Ada', 'Lovelace', '36']], 'headers': ['first_name', 'last_name', 'age'], 'title': None}, list)\n\ntests\\Tablib\\functional_test.py:278: AssertionError\n______________ test_dataset_export_html_contains_table_structure ______________\n\n    def test_dataset_export_html_contains_table_structure() -> None:\n        \"\"\"HTML export (if available) should include a table-like structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n            pytest.skip(\"html format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001FA7EF0E2E0>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n        \"\"\"\n        Export this dataset to a string in the requested format ('csv' or 'json').\n        \"\"\"\n        if fmt == \"csv\":\n            return csv_format.export_set(self)\n        elif fmt == \"json\":\n            return json_format.export_set(self)\n        else:\n>           raise ValueError(f\"Unsupported format '{fmt}'.\")\nE           ValueError: Unsupported format 'html'.\n\ngeneration\\Tablib\\tablib\\core.py:97: ValueError\n_________________ test_databook_add_sheet_and_iteration_order _________________\n\n    def test_databook_add_sheet_and_iteration_order() -> None:\n        \"\"\"Databook should allow adding sheets and preserve the order in iteration.\"\"\"\n        s1 = tablib.Dataset((1, \"x\"), headers=(\"id\", \"val\"))\n        s1.title = \"S1\"\n        s2 = tablib.Dataset((2, \"y\"), headers=(\"id\", \"val\"))\n        s2.title = \"S2\"\n    \n        book = tablib.Databook([s1])\n    \n        if hasattr(book, \"add_sheet\"):\n            book.add_sheet(s2)  # type: ignore[attr-defined]\n        else:\n            # Fallback: reconstruct via the public constructor (still normal usage).\n            book = tablib.Databook([s1, s2])\n    \n        assert book.size == 2\n    \n        sheets = _iter_databook_sheets(book)\n        assert len(sheets) == 2\n        assert sheets[0].title == \"S1\"\n        assert sheets[1].title == \"S2\"\n>       assert sheets[0][0] == (1, \"x\")\n\ntests\\Tablib\\functional_test.py:365: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tablib.core.Dataset object at 0x000001FA7EF4D880>, key = 0\n\n    def __getitem__(self, key):\n        \"\"\"\n        - If key is a slice, return a list of row tuples (start:stop).\n        - If key is a string, return the column data for that header.\n        \"\"\"\n        if isinstance(key, slice):\n            return [tuple(row) for row in self._data[key]]\n        elif isinstance(key, str):\n            if key not in self._headers:\n                raise KeyError(f\"Column '{key}' does not exist in headers.\")\n            col_idx = self._headers.index(key)\n            return [row[col_idx] for row in self._data]\n        else:\n>           raise TypeError(\"Dataset indices must be slice or str (column name).\")\nE           TypeError: Dataset indices must be slice or str (column name).\n\ngeneration\\Tablib\\tablib\\core.py:58: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_csv_and_json_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\nFAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\nFAILED tests/Tablib/functional_test.py::test_dataset_title_and_headers_persistence\nFAILED tests/Tablib/functional_test.py::test_dataset_export_json_contains_all_records\nFAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\nFAILED tests/Tablib/functional_test.py::test_databook_add_sheet_and_iteration_order\n7 failed, 4 passed in 0.69s\n"}
{"model": "o1", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'N/A' in 'name  status\\nAlice None  \\nBob   ok'", "returncode": 1, "elapsed_time_s": 2.00363, "avg_memory_mb": 32.31, "avg_cpu_percent": 98.4, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-02 08:04:35", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n>       assert lines[0].strip().startswith(\"Name\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000002343918B710>('Name')\nE        +    where <built-in method startswith of str object at 0x000002343918B710> = 'f     i   r s t r o w'.startswith\nE        +      where 'f     i   r s t r o w' = <built-in method strip of str object at 0x000002343918B710>()\nE        +        where <built-in method strip of str object at 0x000002343918B710> = 'f     i   r s t r o w'.strip\n\ntests\\Tabulate\\functional_test.py:120: AssertionError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n        out_true = tabulate(table, showindex=True)\n        lines_true = _lines(out_true)\n        assert any(line.lstrip().startswith(\"0\") for line in lines_true)\n>       assert any(line.lstrip().startswith(\"1\") for line in lines_true)\nE       assert False\nE        +  where False = any(<generator object test_showindex_variants.<locals>.<genexpr> at 0x0000023439152190>)\n\ntests\\Tabulate\\functional_test.py:154: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000023439192730>('|')\nE        +    where <built-in method startswith of str object at 0x0000023439192730> = 'item  qty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            {\"name\": \"Alice\", \"score\": 10},\n            {\"name\": \"Bob\", \"score\": 12},\n        ]\n        output = tabulate(rows, headers=\"keys\", tablefmt=\"plain\")\n        lines = _lines(output)\n    \n        header = lines[0]\n>       assert \"name\" in header\nE       AssertionError: assert 'name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:194: AssertionError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n        output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\n        lines = _lines(output)\n    \n        joined = \"\\n\".join(lines)\n        assert \"Alice\" in joined\n        assert \"Bob\" in joined\n>       assert \"N/A\" in joined\nE       AssertionError: assert 'N/A' in 'name  status\\nAlice None  \\nBob   ok'\n\ntests\\Tabulate\\functional_test.py:213: AssertionError\n__________________ test_floatfmt_controls_numer", "stdout_sha1": "4e06389799047353fc8342f1218a87bf271551c2", "stdout_len": 6969, "stdout": "..FFFFFFF.FF                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n>       assert lines[0].strip().startswith(\"Name\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x000002343918B710>('Name')\nE        +    where <built-in method startswith of str object at 0x000002343918B710> = 'f     i   r s t r o w'.startswith\nE        +      where 'f     i   r s t r o w' = <built-in method strip of str object at 0x000002343918B710>()\nE        +        where <built-in method strip of str object at 0x000002343918B710> = 'f     i   r s t r o w'.strip\n\ntests\\Tabulate\\functional_test.py:120: AssertionError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n___________________________ test_showindex_variants ___________________________\n\n    def test_showindex_variants() -> None:\n        table = [\n            [\"F\", 24],\n            [\"M\", 19],\n        ]\n    \n        out_true = tabulate(table, showindex=True)\n        lines_true = _lines(out_true)\n        assert any(line.lstrip().startswith(\"0\") for line in lines_true)\n>       assert any(line.lstrip().startswith(\"1\") for line in lines_true)\nE       assert False\nE        +  where False = any(<generator object test_showindex_variants.<locals>.<genexpr> at 0x0000023439152190>)\n\ntests\\Tabulate\\functional_test.py:154: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n        out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n        lines_gh = _lines(out_github)\n>       assert lines_gh[0].startswith(\"|\")\nE       AssertionError: assert False\nE        +  where False = <built-in method startswith of str object at 0x0000023439192730>('|')\nE        +    where <built-in method startswith of str object at 0x0000023439192730> = 'item  qty'.startswith\n\ntests\\Tabulate\\functional_test.py:172: AssertionError\n____________________ test_list_of_dicts_headers_keys_plain ____________________\n\n    def test_list_of_dicts_headers_keys_plain() -> None:\n        rows = [\n            {\"name\": \"Alice\", \"score\": 10},\n            {\"name\": \"Bob\", \"score\": 12},\n        ]\n        output = tabulate(rows, headers=\"keys\", tablefmt=\"plain\")\n        lines = _lines(output)\n    \n        header = lines[0]\n>       assert \"name\" in header\nE       AssertionError: assert 'name' in 'k e y s'\n\ntests\\Tabulate\\functional_test.py:194: AssertionError\n_____________________ test_missingval_renders_placeholder _____________________\n\n    def test_missingval_renders_placeholder() -> None:\n        rows = [\n            [\"Alice\", None],\n            [\"Bob\", \"ok\"],\n        ]\n        output = tabulate(rows, headers=[\"name\", \"status\"], tablefmt=\"plain\", missingval=\"N/A\")\n        lines = _lines(output)\n    \n        joined = \"\\n\".join(lines)\n        assert \"Alice\" in joined\n        assert \"Bob\" in joined\n>       assert \"N/A\" in joined\nE       AssertionError: assert 'N/A' in 'name  status\\nAlice None  \\nBob   ok'\n\ntests\\Tabulate\\functional_test.py:213: AssertionError\n__________________ test_floatfmt_controls_numeric_rendering ___________________\n\n    def test_floatfmt_controls_numeric_rendering() -> None:\n        rows = [\n            [\"pi\", 3.14159],\n            [\"e\", 2.71828],\n        ]\n        output = tabulate(rows, headers=[\"name\", \"value\"], tablefmt=\"plain\", floatfmt=\".2f\")\n        lines = _lines(output)\n    \n        joined = \"\\n\".join(lines)\n        assert \"pi\" in joined and \"3.14\" in joined\n>       assert \"e\" in joined and \"2.72\" in joined\nE       AssertionError: assert ('e' in 'name value  \\npi   3.14159\\ne    2.71828' and '2.72' in 'name value  \\npi   3.14159\\ne    2.71828')\n\ntests\\Tabulate\\functional_test.py:227: AssertionError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n        output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\n        lines = _lines(output)\n    \n        # With wrapping, the output typically spans more than (header + separator + 2 rows).\n>       assert len(lines) >= 5\nE       AssertionError: assert 3 >= 5\nE        +  where 3 = len(['id note                               ', ' 1 alpha beta gamma delta epsilon zeta', ' 2 short'])\n\ntests\\Tabulate\\functional_test.py:260: AssertionError\n___________________ test_pipe_format_has_pipes_and_headers ____________________\n\n    def test_pipe_format_has_pipes_and_headers() -> None:\n        rows = [\n            [\"name\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n        ]\n        output = tabulate(rows[1:], headers=rows[0], tablefmt=\"pipe\")\n        lines = _lines(output)\n    \n        # Pipe tables use | delimiters; keep assertions permissive.\n>       assert \"|\" in lines[0]\nE       AssertionError: assert '|' in 'name qty'\n\ntests\\Tabulate\\functional_test.py:278: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_showindex_variants - assert False\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Asse...\nFAILED tests/Tabulate/functional_test.py::test_list_of_dicts_headers_keys_plain\nFAILED tests/Tabulate/functional_test.py::test_missingval_renders_placeholder\nFAILED tests/Tabulate/functional_test.py::test_floatfmt_controls_numeric_rendering\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\nFAILED tests/Tabulate/functional_test.py::test_pipe_format_has_pipes_and_headers\n9 failed, 3 passed in 0.61s\n"}
{"model": "o1", "project": "Termgraph", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Data' from 'termgraph' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Termgraph\\termgraph\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.945293, "avg_memory_mb": 35.28, "avg_cpu_percent": 100.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 08:05:31", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Termgraph/functional_test.py _____________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Termgraph\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Termgraph\\functional_test.py:45: in <module>\n    from termgraph import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Data' from 'termgraph' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Termgraph\\termgraph\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/Termgraph/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.53s\n", "stdout_sha1": "785149d925d853e1873e510ec35b822a3101d81d", "stdout_len": 988, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Termgraph/functional_test.py _____________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Termgraph\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Termgraph\\functional_test.py:45: in <module>\n    from termgraph import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Data' from 'termgraph' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Termgraph\\termgraph\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/Termgraph/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.53s\n"}
{"model": "o1", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ModuleNotFoundError", "exception_msg": "No module named 'thefuck.rules.no_command'", "returncode": 1, "elapsed_time_s": 2.209324, "avg_memory_mb": 16.09, "avg_cpu_percent": 49.6, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-02 08:06:27", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _", "stdout_sha1": "823d69782686dcec5aba7b385d9dabd4d9a0abe5", "stdout_len": 11384, "stdout": ".FFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-490/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-490/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-490/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'thefuck.rules.no_command'\nimport_ = <function _gcd_import at 0x0000016262D51310>\n\n>   ???\nE   ModuleNotFoundError: No module named 'thefuck.rules.no_command'\n\n<frozen importlib._bootstrap>:984: ModuleNotFoundError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n9 failed, 3 passed in 0.80s\n"}
{"model": "o1", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Query' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)", "returncode": 2, "elapsed_time_s": 1.987856, "avg_memory_mb": 35.11, "avg_cpu_percent": 97.5, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 08:07:21", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Query' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.62s\n", "stdout_sha1": "3575d3072476901b4f606ee63ec4038bf3336a7d", "stdout_len": 987, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\TinyDB\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'Query' from 'tinydb' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\__init__.py)\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.62s\n"}
{"model": "o1", "project": "Typer", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert ('TITLE' in 'Application\\n\\nUsage:\\n  C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\pytest\\\\__main__.py [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add\\n  list\\n  remove\\n\\n' or 'title' in 'Application\\n\\nUsage:\\n  C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\pytest\\\\__main__.py [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add\\n  list\\n  remove\\n\\n')", "returncode": 1, "elapsed_time_s": 2.002025, "avg_memory_mb": 32.39, "avg_cpu_percent": 100.9, "passed": 2, "failed": 10, "skipped": 0, "total": 12, "functional_score": 0.1667, "timestamp": "2026-01-02 08:08:16", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.InvokeResult object at 0x000002235A943AC0>.exit_code\n\ntests\\Typer\\functional_test.py:233: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.InvokeResult object at 0x000002235A9A2B50>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'Application\\n\\nUsage:\\n  C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\pytest\\\\__main__.py [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add\\n  list\\n  remove\\n\\n' or 'title' in 'Application\\n\\nUsage:\\n  C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\pytest\\\\__main__.py [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add\\n  list\\n  remove\\n\\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_ap", "stdout_sha1": "b6c45df157af15520669c518d9cf67a9aac5f50e", "stdout_len": 7773, "stdout": "FFF.FF.FFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:70: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n        app = _create_todo_app()\n    \n        r1 = runner.invoke(app, [\"add\", \"Write tests\"])\n        r2 = runner.invoke(app, [\"add\", \"Review PRs\"])\n    \n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.InvokeResult object at 0x000002235A943AC0>.exit_code\n\ntests\\Typer\\functional_test.py:233: AssertionError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n        app = _create_todo_app()\n    \n        runner.invoke(app, [\"add\", \"Task 1\"])\n        runner.invoke(app, [\"add\", \"Task 2\"])\n    \n        r_remove = runner.invoke(app, [\"remove\", \"1\"])\n>       assert r_remove.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.InvokeResult object at 0x000002235A9A2B50>.exit_code\n\ntests\\Typer\\functional_test.py:252: AssertionError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n        app = _create_todo_app()\n        result = runner.invoke(app, [\"add\", \"--help\"])\n        assert result.exit_code == 0\n        out = result.stdout\n>       assert \"TITLE\" in out or \"title\" in out\nE       AssertionError: assert ('TITLE' in 'Application\\n\\nUsage:\\n  C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\pytest\\\\__main__.py [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add\\n  list\\n  remove\\n\\n' or 'title' in 'Application\\n\\nUsage:\\n  C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\site-packages\\\\pytest\\\\__main__.py [OPTIONS] COMMAND [ARGS]...\\n\\nCommands:\\n  add\\n  list\\n  remove\\n\\n')\n\ntests\\Typer\\functional_test.py:276: AssertionError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_prompt_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to avoid Typer's single-command \"collapse\" behavior in\n        some versions. This guarantees that \"greet\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n        def greet(\n>           name: str = typer.Option(\n                None,\n                \"--name\",\n                prompt=True,\n                help=\"Name to greet (prompted when missing).\",\n            )\n        ) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'prompt'\n\ntests\\Typer\\functional_test.py:121: TypeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x000002235A8F8F40>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_env_app() -> typer.Typer:\n        \"\"\"\n        Multi-command app to guarantee that \"show\" exists as a subcommand.\n        \"\"\"\n        app = typer.Typer()\n    \n        @app.command()\n>       def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ntests\\Typer\\functional_test.py:144: TypeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       AttributeError: 'Typer' object has no attribute 'callback'\n\ntests\\Typer\\functional_test.py:159: AttributeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n        app = _create_types_app()\n        # Now stable: \"calc\" always exists as a subcommand (multi-command app).\n        r = runner.invoke(app, [\"calc\", \"2\", \"3\", \"--scale\", \"2.0\"])\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <typer.testing.InvokeResult object at 0x000002235A92BA00>.exit_code\n\ntests\\Typer\\functional_test.py:313: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - AttributeE...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - At...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - assert 1 == 0\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - a...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - TypeEr...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n10 failed, 2 passed in 0.63s\n"}
{"model": "o1", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 2.068955, "avg_memory_mb": 34.95, "avg_cpu_percent": 96.1, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-02 08:10:26", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n", "stdout_sha1": "352943246994d2354c461e84e68b266cfc210638", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.60s\n"}
{"model": "o1", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert {'#text': '1'} == '1'", "returncode": 1, "elapsed_time_s": 2.006363, "avg_memory_mb": 32.4, "avg_cpu_percent": 98.4, "passed": 3, "failed": 9, "skipped": 0, "total": 12, "functional_score": 0.25, "timestamp": "2026-01-02 08:11:28", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n        assert any(k.startswith(\"x:\") for k in keys)\n    \n        key = next(k for k in keys if k.startswith(\"x:\"))\n>       assert root[key] == \"value\"\nE       AssertionError: assert {'#text': 'value'} == 'value'\n\ntests\\Xmltodict\\functional_test.py:134: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n            assert isinstance(item, list)\n            assert item == [\"1\"]\n        else:\n            # Fallback: without force_list support, single element is typically a scalar string.\n>           assert item == \"1\"\nE           AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:169: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n            assert \"@id\" not in user\n            assert user[\"name\"] == \"Alice\"\n        else:\n            # Fa", "stdout_sha1": "368470d6cba6cdaede571732f4028a5883dc0c35", "stdout_len": 7579, "stdout": "FF..FFF.FFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n        data = _parse(xml)\n    \n        assert \"root\" in data\n>       assert data[\"root\"][\"message\"] == \"Hello\"\nE       AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:80: AssertionError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n        data = _parse(xml)\n    \n        items = data[\"root\"][\"item\"]\n        assert isinstance(items, list)\n>       assert items == [\"1\", \"2\", \"3\"]\nE       AssertionError: assert [{'#text': '1...'#text': '3'}] == ['1', '2', '3']\nE         \nE         At index 0 diff: {'#text': '1'} != '1'\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:90: AssertionError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n    \n        root = data[\"root\"]\n        keys = [k for k in root.keys() if isinstance(k, str)]\n        assert any(k.startswith(\"x:\") for k in keys)\n    \n        key = next(k for k in keys if k.startswith(\"x:\"))\n>       assert root[key] == \"value\"\nE       AssertionError: assert {'#text': 'value'} == 'value'\n\ntests\\Xmltodict\\functional_test.py:134: AssertionError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n        data = _parse(xml)\n>       assert data[\"root\"][\"user\"][\"name\"] == \"Ada\"\nE       AssertionError: assert {'#text': 'Ada'} == 'Ada'\n\ntests\\Xmltodict\\functional_test.py:151: AssertionError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n        data = _parse(xml, force_list=(\"item\",))\n    \n        item = data[\"root\"][\"item\"]\n        if \"force_list\" in _PARSE_PARAMS:\n            assert isinstance(item, list)\n            assert item == [\"1\"]\n        else:\n            # Fallback: without force_list support, single element is typically a scalar string.\n>           assert item == \"1\"\nE           AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:169: AssertionError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n        data = _parse(xml, xml_attribs=False)\n        user = data[\"user\"]\n    \n        if \"xml_attribs\" in _PARSE_PARAMS:\n            # With xml_attribs=False, attribute keys should not be present.\n            assert \"@id\" not in user\n            assert user[\"name\"] == \"Alice\"\n        else:\n            # Fallback: attribute is included in typical default behavior.\n            assert user.get(\"@id\") == \"9\"\n>           assert user[\"name\"] == \"Alice\"\nE           AssertionError: assert {'#text': 'Alice'} == 'Alice'\n\ntests\\Xmltodict\\functional_test.py:201: AssertionError\n______________________ test_dict_constructor_ordereddict ______________________\n\n    def test_dict_constructor_ordereddict() -> None:\n        \"\"\"dict_constructor should allow choosing mapping type (e.g., OrderedDict) when supported.\"\"\"\n        xml = \"<root><a>1</a><b>2</b></root>\"\n        data = _parse(xml, dict_constructor=OrderedDict)\n    \n        if \"dict_constructor\" in _PARSE_PARAMS:\n            assert isinstance(data, OrderedDict)\n            assert isinstance(data[\"root\"], OrderedDict)\n        else:\n            assert isinstance(data, dict)\n    \n>       assert data[\"root\"][\"a\"] == \"1\"\nE       AssertionError: assert {'#text': '1'} == '1'\n\ntests\\Xmltodict\\functional_test.py:215: AssertionError\n_____________________ test_unparse_pretty_and_parse_back ______________________\n\n    def test_unparse_pretty_and_parse_back() -> None:\n        \"\"\"Pretty/full_document knobs should not break roundtrip of basic structure.\"\"\"\n        original: Dict[str, Any] = {\"root\": {\"x\": \"1\", \"y\": \"2\"}}\n    \n        xml = _unparse(original, pretty=True, full_document=True)\n        assert \"<root>\" in xml or \"<root\" in xml\n    \n        round_tripped = _parse(xml)\n>       assert round_tripped == original\nE       AssertionError: assert {'root': {'x'...#text': '2'}}} == {'root': {'x': '1', 'y': '2'}}\nE         \nE         Differing items:\nE         {'root': {'x': {'#text': '1'}, 'y': {'#text': '2'}}} != {'root': {'x': '1', 'y': '2'}}\nE         Use -v to get more diff\n\ntests\\Xmltodict\\functional_test.py:227: AssertionError\n______________ test_postprocessor_transforms_value_if_supported _______________\n\n    def test_postprocessor_transforms_value_if_supported() -> None:\n        \"\"\"postprocessor can transform values in a happy-path parse when supported.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n    \n        def _pp(path: Any, key: str, value: Any) -> Any:\n            if key == \"message\" and isinstance(value, str):\n                return key, value.upper()\n            return key, value\n    \n        data = _parse(xml, postprocessor=_pp)\n    \n        if \"postprocessor\" in _PARSE_PARAMS:\n            assert data[\"root\"][\"message\"] == \"HELLO\"\n        else:\n>           assert data[\"root\"][\"message\"] == \"Hello\"\nE           AssertionError: assert {'#text': 'Hello'} == 'Hello'\n\ntests\\Xmltodict\\functional_test.py:244: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Xmltodict/functional_test.py::test_parse_simple_element - Assert...\nFAILED tests/Xmltodict/functional_test.py::test_parse_repeated_elements_as_list\nFAILED tests/Xmltodict/functional_test.py::test_namespace_prefix_is_preserved\nFAILED tests/Xmltodict/functional_test.py::test_parse_nested_structure - Asse...\nFAILED tests/Xmltodict/functional_test.py::test_force_list_option_for_single_element\nFAILED tests/Xmltodict/functional_test.py::test_xml_attribs_false_drops_attributes_if_supported\nFAILED tests/Xmltodict/functional_test.py::test_dict_constructor_ordereddict\nFAILED tests/Xmltodict/functional_test.py::test_unparse_pretty_and_parse_back\nFAILED tests/Xmltodict/functional_test.py::test_postprocessor_transforms_value_if_supported\n9 failed, 3 passed in 0.67s\n"}
{"model": "o3", "project": "Celery", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "update() missing 1 required positional argument: 'mapping'", "returncode": 1, "elapsed_time_s": 28.693285, "avg_memory_mb": 32.65, "avg_cpu_percent": 0.54, "passed": 0, "failed": 10, "skipped": 0, "total": 10, "functional_score": 0.0, "timestamp": "2026-01-01 21:24:47", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_seri", "stdout_sha1": "7654a99d7a22d3ce672f76cf9686646fcffc8d1b", "stdout_len": 13203, "stdout": "FFFFFFFFFF                                                               [100%]\n================================== FAILURES ===================================\n___________________ test_001_import_celery_and_core_symbols ___________________\n\n    def test_001_import_celery_and_core_symbols() -> None:\n        _ensure_celery_importable()\n        import celery  # noqa: F401\n    \n        from celery import Celery  # noqa: F401\n>       from celery import chain, chord, group, signature  # noqa: F401\nE       ImportError: cannot import name 'chain' from 'celery' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Celery\\celery\\__init__.py)\n\ntests\\Celery\\functional_test.py:61: ImportError\n______________ test_002_create_app_and_register_task_runs_delay _______________\n\n    def test_002_create_app_and_register_task_runs_delay() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____ test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager ____\n\n    def test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n__________________ test_004_group_collects_results_in_order ___________________\n\n    def test_004_group_collects_results_in_order() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________________ test_005_chain_passes_previous_result ____________________\n\n    def test_005_chain_passes_previous_result() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_006_chord_runs_callback_over_group_results _______________\n\n    def test_006_chord_runs_callback_over_group_results() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n______________ test_007_task_exception_propagates_in_eager_mode _______________\n\n    def test_007_task_exception_propagates_in_eager_mode() -> None:\n        \"\"\"\n        In some Celery versions/configs with task_always_eager=True and\n        task_eager_propagates=True, the exception is raised immediately during\n        delay()/apply_async() rather than on AsyncResult.get().\n    \n        This test accepts both correct behaviors:\n        - delay raises ValueError directly, OR\n        - delay returns a result whose .get() raises ValueError.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_____________ test_008_disable_propagation_returns_failed_result ______________\n\n    def test_008_disable_propagation_returns_failed_result() -> None:\n        \"\"\"\n        With task_eager_propagates=False:\n          - Some Celery builds still raise on get(..., propagate=True)\n          - get(..., propagate=False) may return None OR return the exception object\n        We accept both behaviors as long as the task is marked failed.\n        \"\"\"\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:165: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n_______________ test_009_signature_freeze_has_id_and_task_name ________________\n\n    def test_009_signature_freeze_has_id_and_task_name() -> None:\n>       app = _make_app()\n\ntests\\Celery\\functional_test.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n____________ test_010_default_app_does_not_break_custom_app_usage _____________\n\n    def test_010_default_app_does_not_break_custom_app_usage() -> None:\n        \"\"\"\n        Ensure that importing celery and using a custom app is not polluted by globals.\n        \"\"\"\n>       app = _make_app(\"celery_test_app_2\")\n\ntests\\Celery\\functional_test.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'celery_test_app_2'\n\n    def _make_app(name: str = \"celery_test_app\"):\n        _ensure_celery_importable()\n        from celery import Celery\n    \n        app = Celery(\n            name,\n            broker=\"memory://\",\n            backend=\"cache+memory://\",\n            include=[],\n        )\n        # Pure local, synchronous execution: no broker/worker needed.\n>       app.conf.update(\n            task_always_eager=True,\n            task_eager_propagates=True,\n            task_store_eager_result=True,\n            result_backend=\"cache+memory://\",\n            broker_url=\"memory://\",\n            enable_utc=True,\n            timezone=\"UTC\",\n            accept_content=[\"json\"],\n            task_serializer=\"json\",\n            result_serializer=\"json\",\n        )\nE       TypeError: update() missing 1 required positional argument: 'mapping'\n\ntests\\Celery\\functional_test.py:41: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Celery/functional_test.py::test_001_import_celery_and_core_symbols\nFAILED tests/Celery/functional_test.py::test_002_create_app_and_register_task_runs_delay\nFAILED tests/Celery/functional_test.py::test_003_apply_async_supports_kwargs_and_counts_down_ignored_in_eager\nFAILED tests/Celery/functional_test.py::test_004_group_collects_results_in_order\nFAILED tests/Celery/functional_test.py::test_005_chain_passes_previous_result\nFAILED tests/Celery/functional_test.py::test_006_chord_runs_callback_over_group_results\nFAILED tests/Celery/functional_test.py::test_007_task_exception_propagates_in_eager_mode\nFAILED tests/Celery/functional_test.py::test_008_disable_propagation_returns_failed_result\nFAILED tests/Celery/functional_test.py::test_009_signature_freeze_has_id_and_task_name\nFAILED tests/Celery/functional_test.py::test_010_default_app_does_not_break_custom_app_usage\n10 failed in 0.47s\n"}
{"model": "o3", "project": "Click", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "__init__() got an unexpected keyword argument 'envvar'", "returncode": 1, "elapsed_time_s": 4.072924, "avg_memory_mb": 33.2, "avg_cpu_percent": 100.8, "passed": 3, "failed": 8, "skipped": 0, "total": 11, "functional_score": 0.2727, "timestamp": "2026-01-01 21:26:05", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result 1>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n        @cli.command(help=\"Say hello\")\n        @click.option(\"--shout/--no-shout\", default=False)\n        @click.argument(\"name\")\n        def hello(name: str, shout: bool) -> None:\n            msg = f\"Hello {name}\"\n            if shout:\n                msg = msg.upper()\n            click.echo(msg)\n    \n        runner = CliRunner()\n    \n        group_help = runner.invoke(cli, [\"--help\"])\n        assert group_help.exit_code == 0\n        assert \"Top level group\" in group_help.output\n        assert \"hello\" in group_help.output\n    \n        cmd_help = runner.invoke(cli, [\"hello\", \"--help\"])\n        assert cmd_help.exit_code == 0\n        assert \"Say hello\" in cmd_help.output\n>       assert \"--shout\" in cmd_help.output\nE       AssertionError: assert '--shout' in 'Usage: cli COMMAND [ARGS]...\\n\\nTop level group\\n\\nCommands:\\n  hello  Say hello\\n'\nE        +  where 'Usage: cli COMMAND [ARGS]...\\n\\nTop level group\\n\\nCommands:\\n  hello  Say hello\\n' = <Result 0>.output\n\ntests\\Click\\functional_test.py:215: AssertionError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n        @cli.command()\n        def show() -> None:\n            ctx = click.get_current_context()\n            cfg = ctx.obj.get(\"config\")\n            click.echo(f\"CONFIG={cfg}\")\n    \n        runner = CliRunner()\n        result = runner.invoke(cli, [\"--config\", \"custom.cfg\", \"show\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result 1>.exit_code\n\ntests\\Click\\functional_test.py:235: AssertionError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n>       def cli(name: str) -> None:\n\ntests\\Click\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:34: in decorator\n    _attach_param(f, Option(param_decls, **attrs))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x000001A2D33794F0>\nparam_decls = ('--name',), is_flag = False\nattrs = {'default': 'fallback', 'envvar': 'CLICK_TEST_NAME'}, name = 'name'\n\n    def __init__(\n        self,\n        param_decls: Sequence[str],\n        is_flag: bool = False,\n        **attrs: Any,\n    ) -> None:\n        if not param_decls:\n            raise TypeError(\"At least one option string is required.\")\n        self.param_decls = list(param_decls)\n        name = self._infer_name()\n>       super().__init__(name, param_type=\"option\", **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ngeneration\\Click\\click\\core.py:207: TypeError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.", "stdout_sha1": "482db54cbd4004da9f7649208409eaf22bc0551c", "stdout_len": 6920, "stdout": ".F.FF.FFFFF                                                              [100%]\n================================== FAILURES ===================================\n________________________ test_boolean_flag_option_pair ________________________\n\n    def test_boolean_flag_option_pair():\n        @click.command()\n        @click.option(\"--flag/--no-flag\", default=False)\n        def cli(flag: bool) -> None:\n            click.echo(f\"FLAG={flag}\")\n    \n        runner = CliRunner()\n    \n        r1 = runner.invoke(cli, [\"--flag\"])\n>       assert r1.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result 1>.exit_code\n\ntests\\Click\\functional_test.py:157: AssertionError\n___________________ test_help_output_for_command_and_group ____________________\n\n    def test_help_output_for_command_and_group():\n        @click.group(help=\"Top level group\")\n        def cli() -> None:\n            pass\n    \n        @cli.command(help=\"Say hello\")\n        @click.option(\"--shout/--no-shout\", default=False)\n        @click.argument(\"name\")\n        def hello(name: str, shout: bool) -> None:\n            msg = f\"Hello {name}\"\n            if shout:\n                msg = msg.upper()\n            click.echo(msg)\n    \n        runner = CliRunner()\n    \n        group_help = runner.invoke(cli, [\"--help\"])\n        assert group_help.exit_code == 0\n        assert \"Top level group\" in group_help.output\n        assert \"hello\" in group_help.output\n    \n        cmd_help = runner.invoke(cli, [\"hello\", \"--help\"])\n        assert cmd_help.exit_code == 0\n        assert \"Say hello\" in cmd_help.output\n>       assert \"--shout\" in cmd_help.output\nE       AssertionError: assert '--shout' in 'Usage: cli COMMAND [ARGS]...\\n\\nTop level group\\n\\nCommands:\\n  hello  Say hello\\n'\nE        +  where 'Usage: cli COMMAND [ARGS]...\\n\\nTop level group\\n\\nCommands:\\n  hello  Say hello\\n' = <Result 0>.output\n\ntests\\Click\\functional_test.py:215: AssertionError\n____________________ test_get_current_context_propagation _____________________\n\n    def test_get_current_context_propagation():\n        @click.group()\n        @click.option(\"--config\", type=str, default=\"default.cfg\")\n        def cli(config: str) -> None:\n            ctx = click.get_current_context()\n            ctx.obj = {\"config\": config}\n    \n        @cli.command()\n        def show() -> None:\n            ctx = click.get_current_context()\n            cfg = ctx.obj.get(\"config\")\n            click.echo(f\"CONFIG={cfg}\")\n    \n        runner = CliRunner()\n        result = runner.invoke(cli, [\"--config\", \"custom.cfg\", \"show\"])\n    \n>       assert result.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result 1>.exit_code\n\ntests\\Click\\functional_test.py:235: AssertionError\n_____________________ test_option_envvar_default_is_used ______________________\n\n    def test_option_envvar_default_is_used():\n        @click.command()\n        @click.option(\"--name\", envvar=\"CLICK_TEST_NAME\", default=\"fallback\")\n>       def cli(name: str) -> None:\n\ntests\\Click\\functional_test.py:263: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Click\\click\\decorators.py:34: in decorator\n    _attach_param(f, Option(param_decls, **attrs))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.core.Option object at 0x000001A2D33794F0>\nparam_decls = ('--name',), is_flag = False\nattrs = {'default': 'fallback', 'envvar': 'CLICK_TEST_NAME'}, name = 'name'\n\n    def __init__(\n        self,\n        param_decls: Sequence[str],\n        is_flag: bool = False,\n        **attrs: Any,\n    ) -> None:\n        if not param_decls:\n            raise TypeError(\"At least one option string is required.\")\n        self.param_decls = list(param_decls)\n        name = self._infer_name()\n>       super().__init__(name, param_type=\"option\", **attrs)\nE       TypeError: __init__() got an unexpected keyword argument 'envvar'\n\ngeneration\\Click\\click\\core.py:207: TypeError\n________________ test_prompt_option_can_be_satisfied_via_input ________________\n\n    def test_prompt_option_can_be_satisfied_via_input():\n        @click.command()\n        @click.option(\"--token\", prompt=True)\n        def cli(token: str) -> None:\n            click.echo(f\"TOKEN={token}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [], input=\"secret-token\\n\")\n>       assert r.exit_code == 0\nE       assert 1 == 0\nE        +  where 1 = <Result 1>.exit_code\n\ntests\\Click\\functional_test.py:285: AssertionError\n_______________ test_default_map_provides_default_option_value ________________\n\n    def test_default_map_provides_default_option_value():\n        @click.group()\n        def cli() -> None:\n            pass\n    \n        @cli.command()\n        @click.option(\"--count\", type=int, default=1)\n        def run(count: int) -> None:\n            click.echo(f\"COUNT={count}\")\n    \n        runner = CliRunner()\n>       r = runner.invoke(cli, [\"run\"], default_map={\"run\": {\"count\": 7}})\nE       TypeError: invoke() got an unexpected keyword argument 'default_map'\n\ntests\\Click\\functional_test.py:300: TypeError\n_______________ test_parameter_type_validation_error_exit_code ________________\n\n    def test_parameter_type_validation_error_exit_code():\n        @click.command()\n        @click.option(\"--count\", type=int, required=True)\n        def cli(count: int) -> None:\n            click.echo(f\"COUNT={count}\")\n    \n        runner = CliRunner()\n        r = runner.invoke(cli, [\"--count\", \"not-an-int\"])\n        assert r.exit_code != 0\n>       assert (\"Invalid value\" in r.output) or (\"Error\" in r.output)\nE       AssertionError: assert ('Invalid value' in '' or 'Error' in '')\nE        +  where '' = <Result 1>.output\nE        +  and   '' = <Result 1>.output\n\ntests\\Click\\functional_test.py:314: AssertionError\n_____________ test_path_type_creates_writable_path_in_isolated_fs _____________\n\n    def test_path_type_creates_writable_path_in_isolated_fs():\n        @click.command()\n>       @click.option(\"--out\", type=click.Path(dir_okay=False, writable=True))\nE       AttributeError: module 'click' has no attribute 'Path'\n\ntests\\Click\\functional_test.py:319: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Click/functional_test.py::test_boolean_flag_option_pair - assert...\nFAILED tests/Click/functional_test.py::test_help_output_for_command_and_group\nFAILED tests/Click/functional_test.py::test_get_current_context_propagation\nFAILED tests/Click/functional_test.py::test_option_envvar_default_is_used - T...\nFAILED tests/Click/functional_test.py::test_prompt_option_can_be_satisfied_via_input\nFAILED tests/Click/functional_test.py::test_default_map_provides_default_option_value\nFAILED tests/Click/functional_test.py::test_parameter_type_validation_error_exit_code\nFAILED tests/Click/functional_test.py::test_path_type_creates_writable_path_in_isolated_fs\n8 failed, 3 passed in 2.94s\n"}
{"model": "o3", "project": "Cmd2", "failure_stage": "in-test", "failure_type": "test_error", "exception_type": "AttributeError", "exception_msg": "module 'contextlib' has no attribute 'partial", "returncode": 1, "elapsed_time_s": 53.010234, "avg_memory_mb": 32.41, "avg_cpu_percent": 0.34, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:27:58", "stdout_excerpt": "==== ERRORS ====================================\n_______________ ERROR at setup of test_simple_command_execution _______________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A0241220>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A0241220>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n______________ ERROR at setup of test_default_argument_behavior _______________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029D790>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029D790>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial", "stdout_sha1": "154f79381d27d5c9085e9f9494703e27adde6685", "stdout_len": 23163, "stdout": "EEEEEEEEEEE                                                              [100%]\n=================================== ERRORS ====================================\n_______________ ERROR at setup of test_simple_command_execution _______________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A0241220>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A0241220>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n______________ ERROR at setup of test_default_argument_behavior _______________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029D790>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029D790>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n______________ ERROR at setup of test_echo_arguments_and_parsing ______________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A024C250>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A024C250>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n______________ ERROR at setup of test_echo_arguments_with_quotes ______________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A0303B20>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A0303B20>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n_______________ ERROR at setup of test_help_for_custom_command ________________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029C430>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029C430>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n_____________ ERROR at setup of test_help_top_level_contains_help _____________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A02419D0>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A02419D0>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n____________ ERROR at setup of test_unknown_command_reports_error _____________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A02823A0>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A02823A0>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n________________ ERROR at setup of test_empty_command_is_noop _________________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A02FA6A0>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A02FA6A0>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n____________ ERROR at setup of test_multiple_commands_and_history _____________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029DD30>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A029DD30>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n___________ ERROR at setup of test_history_object_records_commands ____________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A025CBB0>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A025CBB0>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n_______ ERROR at setup of test_quit_command_sets_stop_flag_and_outputs ________\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A01E6820>\n\n    def __init__(self) -> None:\n        try:\n>           super().__init__(allow_cli_args=False)  # type: ignore[call-arg]\nE           TypeError: __init__() got an unexpected keyword argument 'allow_cli_args'\n\ntests\\Cmd2\\functional_test.py:164: TypeError\n\nDuring handling of the above exception, another exception occurred:\n\n    @pytest.fixture\n    def app() -> Optional[Any]:\n        Cmd, Statement = _try_import_cmd2()\n        if Cmd is None or Statement is None:\n            return None\n        AppCls = _make_app_class(Cmd, Statement)\n>       return AppCls()\n\ntests\\Cmd2\\functional_test.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Cmd2\\functional_test.py:166: in __init__\n    super().__init__()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <functional_test._make_app_class.<locals>.SimpleApp object at 0x00000199A01E6820>\n\n    def __init__(\n        self,\n        *,\n        use_readline: bool = True,\n        completekey: str = \"tab\",\n        stdin=None,\n        stdout=None,\n    ):\n        # The base ``cmd.Cmd`` accepts (completekey, stdin, stdout)\n        super().__init__(completekey=completekey, stdin=stdin, stdout=stdout)\n        self.use_rawinput: bool = stdin is None  # `cmd`'s own default\n        self.use_readline: bool = use_readline\n        self.prompt: str = \"cmd2> \"\n        self.intro: Optional[str] = None\n    \n        # Expose the capture-output context manager on the instance so\n        # that existing patterns such as `self.capture_output()` work.\n        # (We just curry the generic utility so that `self` is bound.)\n>       self.capture_output = contextlib.partial(capture_output, self)\nE       AttributeError: module 'contextlib' has no attribute 'partial'\n\ngeneration\\cmd2\\cmd2\\cmd2.py:75: AttributeError\n=========================== short test summary info ===========================\nERROR tests/Cmd2/functional_test.py::test_simple_command_execution - Attribut...\nERROR tests/Cmd2/functional_test.py::test_default_argument_behavior - Attribu...\nERROR tests/Cmd2/functional_test.py::test_echo_arguments_and_parsing - Attrib...\nERROR tests/Cmd2/functional_test.py::test_echo_arguments_with_quotes - Attrib...\nERROR tests/Cmd2/functional_test.py::test_help_for_custom_command - Attribute...\nERROR tests/Cmd2/functional_test.py::test_help_top_level_contains_help - Attr...\nERROR tests/Cmd2/functional_test.py::test_unknown_command_reports_error - Att...\nERROR tests/Cmd2/functional_test.py::test_empty_command_is_noop - AttributeEr...\nERROR tests/Cmd2/functional_test.py::test_multiple_commands_and_history - Att...\nERROR tests/Cmd2/functional_test.py::test_history_object_records_commands - A...\nERROR tests/Cmd2/functional_test.py::test_quit_command_sets_stop_flag_and_outputs\n11 errors in 27.89s\n"}
{"model": "o3", "project": "Dataset", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+  where [] = _db_tables(<dataset.database.Database object at 0x000001AB570920A0>)", "returncode": 1, "elapsed_time_s": 5.013149, "avg_memory_mb": 34.19, "avg_cpu_percent": 99.7, "passed": 6, "failed": 5, "skipped": 0, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 21:28:58", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000001AB56FFFA90>\nwhere = '\"age\" = :age', params = {'age': {'>=': 40}}\n\n    def _select(\n        self, where: str | None = None, params: Dict[str, Any] | None = None\n    ) -> Iterator[Dict[str, Any]]:\n        sql = f'SELECT * FROM \"{self.name}\"'\n        if where:\n            sql += f\" WHERE {where}\"\n>       cur = self._db.connection.execute(sql, params or {})\nE       sqlite3.InterfaceError: Error binding parameter :age - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\table.py:143: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x000001AB570920A0>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "8ca0744959819f6e7bb0955d501b2af1d7090c05", "stdout_len": 4866, "stdout": "FF...F..F.F                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_insert_and_query_basic_rows _______________________\n\n    def test_insert_and_query_basic_rows() -> None:\n        db = create_in_memory_db()\n        table = db[\"users\"]\n    \n        table.insert({\"name\": \"Alice\", \"age\": 30, \"country\": \"DE\"})\n        table.insert({\"name\": \"Bob\", \"age\": 41, \"country\": \"US\", \"active\": True})\n        table.insert({\"name\": \"Charlie\", \"age\": 41, \"country\": \"US\", \"active\": False})\n    \n        assert \"id\" in _table_columns(table)\n        assert \"name\" in _table_columns(table)\n        assert \"country\" in _table_columns(table)\n        assert len(table) == 3\n    \n        alice = table.find_one(name=\"Alice\")\n        assert alice is not None\n        assert alice[\"country\"] == \"DE\"\n    \n>       older = list(table.find(age={\">=\": 40}))\n\ntests\\Dataset\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <dataset.table.Table object at 0x000001AB56FFFA90>\nwhere = '\"age\" = :age', params = {'age': {'>=': 40}}\n\n    def _select(\n        self, where: str | None = None, params: Dict[str, Any] | None = None\n    ) -> Iterator[Dict[str, Any]]:\n        sql = f'SELECT * FROM \"{self.name}\"'\n        if where:\n            sql += f\" WHERE {where}\"\n>       cur = self._db.connection.execute(sql, params or {})\nE       sqlite3.InterfaceError: Error binding parameter :age - probably unsupported type.\n\ngeneration\\Dataset\\dataset\\table.py:143: InterfaceError\n_______________________ test_update_upsert_and_indexes ________________________\n\n    def test_update_upsert_and_indexes() -> None:\n        db = create_in_memory_db()\n        table = db[\"accounts\"]\n    \n        rows = [\n            {\"account_id\": 1, \"owner\": \"Alice\", \"balance\": 100.0, \"currency\": \"EUR\"},\n            {\"account_id\": 2, \"owner\": \"Bob\", \"balance\": 250.0, \"currency\": \"USD\"},\n        ]\n        table.insert_many(rows)\n    \n        if hasattr(table, \"create_index\") and hasattr(table, \"has_index\"):\n            table.create_index([\"owner\", \"currency\"])\n            assert table.has_index([\"owner\", \"currency\"])\n    \n        table.update({\"account_id\": 1, \"balance\": 150.0}, [\"account_id\"])\n        updated = table.find_one(account_id=1)\n        assert updated is not None\n>       assert pytest.approx(updated[\"balance\"]) == 150.0\nE       assert 150.0 == 150.0\nE         \nE         comparison failed\nE         Obtained: 150.0\nE         Expected: 150.0\n\ntests\\Dataset\\functional_test.py:184: AssertionError\n_______________________ test_find_order_by_limit_offset _______________________\n\n    def test_find_order_by_limit_offset() -> None:\n        db = create_in_memory_db()\n        table = db[\"nums\"]\n        for i in range(10):\n            table.insert({\"n\": i})\n    \n        rows = list(table.find(order_by=\"n\", _limit=3, _offset=4))\n>       assert [r[\"n\"] for r in rows] == [4, 5, 6]\nE       assert [] == [4, 5, 6]\nE         \nE         Right contains 3 more items, first extra item: 4\nE         Use -v to get more diff\n\ntests\\Dataset\\functional_test.py:249: AssertionError\n___________________ test_drop_table_removes_from_db_tables ____________________\n\n    def test_drop_table_removes_from_db_tables() -> None:\n        db = create_in_memory_db()\n        table = db[\"to_drop\"]\n        table.insert({\"x\": 1})\n    \n>       assert \"to_drop\" in _db_tables(db)\nE       AssertionError: assert 'to_drop' in []\nE        +  where [] = _db_tables(<dataset.database.Database object at 0x000001AB570920A0>)\n\ntests\\Dataset\\functional_test.py:301: AssertionError\n_____________________ test_distinct_returns_unique_values _____________________\n\n    def test_distinct_returns_unique_values() -> None:\n        db = create_in_memory_db()\n        table = db[\"colors\"]\n        table.insert_many([{\"c\": \"red\"}, {\"c\": \"red\"}, {\"c\": \"blue\"}])\n    \n        distinct = list(table.distinct(\"c\"))\n>       values = {r[\"c\"] for r in distinct}\n\ntests\\Dataset\\functional_test.py:333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n.0 = <list_iterator object at 0x000001AB56FBF610>\n\n>   values = {r[\"c\"] for r in distinct}\nE   TypeError: string indices must be integers\n\ntests\\Dataset\\functional_test.py:333: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Dataset/functional_test.py::test_insert_and_query_basic_rows - s...\nFAILED tests/Dataset/functional_test.py::test_update_upsert_and_indexes - ass...\nFAILED tests/Dataset/functional_test.py::test_find_order_by_limit_offset - as...\nFAILED tests/Dataset/functional_test.py::test_drop_table_removes_from_db_tables\nFAILED tests/Dataset/functional_test.py::test_distinct_returns_unique_values\n5 failed, 6 passed in 3.70s\n"}
{"model": "o3", "project": "Dateutil", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": null, "elapsed_time_s": 0.0, "avg_memory_mb": 0.0, "avg_cpu_percent": 0.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:31:29", "stdout_excerpt": "", "stdout_sha1": "", "stdout_len": 0, "stdout": ""}
{"model": "o3", "project": "Fail2ban", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert ('failregex' in '\"\"\"\\nfail2ban.server.filter\\n======================\\n\\na *very* small helper module that offers the api surface requi...ier to locate.\\n    m4 = _ipv4_re.search(text)\\n    if m4:\\n        return m4.group(0)\\n\\n    return _first_ipv6(text)' or '<host>' in '\"\"\"\\nfail2ban.server.filter\\n======================\\n\\na *very* small helper module that offers the api surface requi...ier to locate.\\n    m4 = _ipv4_re.search(text)\\n    if m4:\\n        return m4.group(0)\\n\\n    return _first_ipv6(text)')", "returncode": 1, "elapsed_time_s": 2.534632, "avg_memory_mb": 32.29, "avg_cpu_percent": 69.0, "passed": 10, "failed": 2, "skipped": 0, "total": 12, "functional_score": 0.8333, "timestamp": "2026-01-01 21:32:46", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in '\"\"\"\\nfail2ban.server.filter\\n======================\\n\\na *very* small helper module that offers the api surface requi...ier to locate.\\n    m4 = _ipv4_re.search(text)\\n    if m4:\\n        return m4.group(0)\\n\\n    return _first_ipv6(text)' or '<host>' in '\"\"\"\\nfail2ban.server.filter\\n======================\\n\\na *very* small helper module that offers the api surface requi...ier to locate.\\n    m4 = _ipv4_re.search(text)\\n    if m4:\\n        return m4.group(0)\\n\\n    return _first_ipv6(text)')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\n2 failed, 10 passed in 1.26s\n", "stdout_sha1": "9d4968654edf8f85a264df8109a2a631aa5d6343", "stdout_len": 2897, "stdout": "...F....F...                                                             [100%]\n================================== FAILURES ===================================\n________________ test_004_filter_core_symbols_exist_statically ________________\n\n    def test_004_filter_core_symbols_exist_statically():\n        \"\"\"\n        Do not assume helper names like isValidIP/searchIP (they vary across versions).\n        Instead, require stable core anchors in fail2ban.server.filter:\n          - A Filter class (or similarly named core filter object), OR\n          - presence of key tokens that indicate regex-driven filtering (failregex/<HOST>).\n        \"\"\"\n        filter_py = _pkg_dir() / \"server\" / \"filter.py\"\n        src = _read_text(filter_py)\n    \n        has_filter_class = _ast_has_class(filter_py, \"Filter\") or (\"class Filter\" in src)\n        has_regex_tokens = (\"failregex\" in src.lower()) or (\"<host>\" in src.lower())\n    \n>       assert has_filter_class or has_regex_tokens, \"Expected core filter anchors (Filter class or failregex/<HOST> tokens).\"\nE       AssertionError: Expected core filter anchors (Filter class or failregex/<HOST> tokens).\nE       assert (False or False)\n\ntests\\Fail2ban\\functional_test.py:129: AssertionError\n____________ test_009_import_filter_and_basic_behavior_if_possible ____________\n\n    def test_009_import_filter_and_basic_behavior_if_possible():\n        _prepend_import_path()\n        try:\n            from fail2ban.server import filter as f\n        except ModuleNotFoundError as e:\n            msg = str(e).lower()\n            assert any(k in msg for k in [\"pwd\", \"grp\", \"resource\", \"fcntl\"]), f\"Unexpected import failure: {e}\"\n            return\n    \n        # If import works, ensure the module exposes a core Filter-like object or regex constants.\n        if hasattr(f, \"Filter\"):\n            assert callable(getattr(f, \"Filter\"))\n        else:\n            src = _read_text(_pkg_dir() / \"server\" / \"filter.py\").lower()\n>           assert (\"failregex\" in src) or (\"<host>\" in src)\nE           assert ('failregex' in '\"\"\"\\nfail2ban.server.filter\\n======================\\n\\na *very* small helper module that offers the api surface requi...ier to locate.\\n    m4 = _ipv4_re.search(text)\\n    if m4:\\n        return m4.group(0)\\n\\n    return _first_ipv6(text)' or '<host>' in '\"\"\"\\nfail2ban.server.filter\\n======================\\n\\na *very* small helper module that offers the api surface requi...ier to locate.\\n    m4 = _ipv4_re.search(text)\\n    if m4:\\n        return m4.group(0)\\n\\n    return _first_ipv6(text)')\n\ntests\\Fail2ban\\functional_test.py:187: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Fail2ban/functional_test.py::test_004_filter_core_symbols_exist_statically\nFAILED tests/Fail2ban/functional_test.py::test_009_import_filter_and_basic_behavior_if_possible\n2 failed, 10 passed in 1.26s\n"}
{"model": "o3", "project": "Folium", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "SyntaxError", "exception_msg": "", "returncode": 1, "elapsed_time_s": 1.903902, "avg_memory_mb": 32.29, "avg_cpu_percent": 99.1, "passed": 1, "failed": 11, "skipped": 0, "total": 12, "functional_score": 0.0833, "timestamp": "2026-01-01 21:34:17", "stdout_excerpt": "==== FAILURES ===================================\n___________________________ test_001_import_folium ____________________________\n\n    def test_001_import_folium():\n        _prepend_import_path()\n>       import folium  # noqa: F401\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:39: SyntaxError\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:44: SyntaxError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:53: SyntaxError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:64: SyntaxError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:77: SyntaxError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:89: SyntaxError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:101: SyntaxError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:123: SyntaxError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-464/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE        ", "stdout_sha1": "1c3853652e8efcba7370e3015cb5d7774a9d6fdf", "stdout_len": 7672, "stdout": ".FFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n___________________________ test_001_import_folium ____________________________\n\n    def test_001_import_folium():\n        _prepend_import_path()\n>       import folium  # noqa: F401\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:39: SyntaxError\n__________________ test_002_create_basic_map_renders_leaflet __________________\n\n    def test_002_create_basic_map_renders_leaflet():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:44: SyntaxError\n_________________________ test_003_map_has_html_root __________________________\n\n    def test_003_map_has_html_root():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:53: SyntaxError\n__________________ test_004_add_marker_layer_changes_output ___________________\n\n    def test_004_add_marker_layer_changes_output():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:64: SyntaxError\n__________________ test_005_add_circle_marker_changes_output __________________\n\n    def test_005_add_circle_marker_changes_output():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:77: SyntaxError\n__________________ test_006_add_tile_layer_and_layer_control __________________\n\n    def test_006_add_tile_layer_and_layer_control():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:89: SyntaxError\n__________________ test_007_geojson_adds_feature_collection ___________________\n\n    def test_007_geojson_adds_feature_collection():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:101: SyntaxError\n_________________ test_008_geojson_style_function_serializes __________________\n\n    def test_008_geojson_style_function_serializes():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:123: SyntaxError\n________________________ test_009_map_save_writes_html ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-464/test_009_map_save_writes_html0')\n\n    def test_009_map_save_writes_html(tmp_path: Path):\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:149: SyntaxError\n______________ test_010_plugins_markercluster_module_importable _______________\n\n    def test_010_plugins_markercluster_module_importable():\n        _prepend_import_path()\n>       plugins = _plugins_module()\n\ntests\\Folium\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Folium\\functional_test.py:29: in _plugins_module\n    return importlib.import_module(\"folium.plugins\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:786: in exec_module\n    ???\n<frozen importlib._bootstrap_external>:923: in get_code\n    ???\n<frozen importlib._bootstrap_external>:853: in source_to_code\n    ???\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nf = <built-in function compile>\nargs = (b'\"\"\"\\r\\nA very small subset of the `folium` API implemented in pure-Python.\\r\\n\\r\\nOnly the functionality required b... of folium.plugins.__init__', 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Folium\\\\folium\\\\__init__.py', 'exec')\nkwds = {'dont_inherit': True, 'optimize': -1}\n\n>   ???\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE       \"\"\"\nE          ^\nE   SyntaxError: f-string expression part cannot include a backslash\n\n<frozen importlib._bootstrap>:228: SyntaxError\n_________________ test_011_markercluster_adds_cluster_snippet _________________\n\n    def test_011_markercluster_adds_cluster_snippet():\n        _prepend_import_path()\n>       import folium\nE         File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Folium\\folium\\__init__.py\", line 305\nE           \"\"\"\nE              ^\nE       SyntaxError: f-string expression part cannot include a backslash\n\ntests\\Folium\\functional_test.py:168: SyntaxError\n=========================== short test summary info ===========================\nFAILED tests/Folium/functional_test.py::test_001_import_folium -   File \"D:\\...\nFAILED tests/Folium/functional_test.py::test_002_create_basic_map_renders_leaflet\nFAILED tests/Folium/functional_test.py::test_003_map_has_html_root -   File \"...\nFAILED tests/Folium/functional_test.py::test_004_add_marker_layer_changes_output\nFAILED tests/Folium/functional_test.py::test_005_add_circle_marker_changes_output\nFAILED tests/Folium/functional_test.py::test_006_add_tile_layer_and_layer_control\nFAILED tests/Folium/functional_test.py::test_007_geojson_adds_feature_collection\nFAILED tests/Folium/functional_test.py::test_008_geojson_style_function_serializes\nFAILED tests/Folium/functional_test.py::test_009_map_save_writes_html -   Fil...\nFAILED tests/Folium/functional_test.py::test_010_plugins_markercluster_module_importable\nFAILED tests/Folium/functional_test.py::test_011_markercluster_adds_cluster_snippet\n11 failed, 1 passed in 0.60s\n"}
{"model": "o3", "project": "Humanize", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+ 1 kB", "returncode": 1, "elapsed_time_s": 1.897677, "avg_memory_mb": 32.41, "avg_cpu_percent": 100.9, "passed": 11, "failed": 1, "skipped": 3, "total": 15, "functional_score": 0.7333, "timestamp": "2026-01-01 21:36:29", "stdout_excerpt": "==== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1 kB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?  --\nE         + 1 kB\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\n1 failed, 11 passed, 3 skipped in 0.50s\n", "stdout_sha1": "a4b9640633ef7e98b68a0d2a87d1d94019aad442", "stdout_len": 700, "stdout": "..F.......sss..                                                          [100%]\n================================== FAILURES ===================================\n______________________________ test_naturalsize _______________________________\n\n    def test_naturalsize() -> None:\n>       assert humanize.naturalsize(1024) == \"1.0 kB\"\nE       AssertionError: assert '1 kB' == '1.0 kB'\nE         \nE         - 1.0 kB\nE         ?  --\nE         + 1 kB\n\ntests\\Humanize\\functional_test.py:107: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Humanize/functional_test.py::test_naturalsize - AssertionError: ...\n1 failed, 11 passed, 3 skipped in 0.50s\n"}
{"model": "o3", "project": "Imageio", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'imageio.v3' has no attribute 'imopen'", "returncode": 1, "elapsed_time_s": 2.212957, "avg_memory_mb": 43.83, "avg_cpu_percent": 96.3, "passed": 7, "failed": 3, "skipped": 0, "total": 10, "functional_score": 0.7, "timestamp": "2026-01-01 21:37:20", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-467/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-467/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n3 failed, 7 passed in 0.93s\n", "stdout_sha1": "77430beedf081689c6f074fb59a9075eb857b918", "stdout_len": 2328, "stdout": "...F...FF.                                                               [100%]\n================================== FAILURES ===================================\n_____________________ test_png_roundtrip_via_bytes_buffer _____________________\n\n    def test_png_roundtrip_via_bytes_buffer() -> None:\n        \"\"\"Write PNG to in-memory bytes, then read back using extension.\"\"\"\n        img = _make_color_image(height=20, width=31)\n    \n>       blob = iio.imwrite(\"<bytes>\", img, extension=\".png\")\nE       TypeError: imwrite() got an unexpected keyword argument 'extension'\n\ntests\\Imageio\\functional_test.py:139: TypeError\n___________ test_gif_imread_index0_matches_first_imiter_frame_shape ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-467/test_gif_imread_index0_matches0')\n\n    def test_gif_imread_index0_matches_first_imiter_frame_shape(tmp_path: Path) -> None:\n        \"\"\"Read first GIF frame using both index=0 and imiter; verify consistent spatial shape.\"\"\"\n        frames = _make_grayscale_frames(num_frames=4, height=19, width=23)\n        path = tmp_path / \"index0.gif\"\n    \n        iio.imwrite(path, frames)\n        assert path.exists()\n    \n>       first_by_index = iio.imread(path, index=0)\nE       TypeError: imread() got an unexpected keyword argument 'index'\n\ntests\\Imageio\\functional_test.py:206: TypeError\n_______________________ test_imopen_write_then_read_png _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-467/test_imopen_write_then_read_pn0')\n\n    def test_imopen_write_then_read_png(tmp_path: Path) -> None:\n        \"\"\"Use the v3 imopen context manager to write then read a PNG.\"\"\"\n        img = _make_color_image(height=16, width=20)\n        path = tmp_path / \"imopen.png\"\n    \n>       with iio.imopen(path, \"w\") as f:\nE       AttributeError: module 'imageio.v3' has no attribute 'imopen'\n\ntests\\Imageio\\functional_test.py:221: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Imageio/functional_test.py::test_png_roundtrip_via_bytes_buffer\nFAILED tests/Imageio/functional_test.py::test_gif_imread_index0_matches_first_imiter_frame_shape\nFAILED tests/Imageio/functional_test.py::test_imopen_write_then_read_png - At...\n3 failed, 7 passed in 0.93s\n"}
{"model": "o3", "project": "Lifelines", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'KaplanMeierFitter' object has no attribute 'median_survival_time_'", "returncode": 1, "elapsed_time_s": 3.79554, "avg_memory_mb": 72.23, "avg_cpu_percent": 95.97, "passed": 4, "failed": 11, "skipped": 0, "total": 15, "functional_score": 0.2667, "timestamp": "2026-01-01 21:38:32", "stdout_excerpt": "==== FAILURES ===================================\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.001841  0.011457\\ntreatment  0.648316  0.707976.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002BFFD6C6F70>()\nE        +    where <built-in method lower of str object at 0x000002BFFD6C6F70> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x000002BFDAA64670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x000002BFDAA64670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.001841  0.011457\\ntreatment  0.648316  0.707976.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n_________________ test_coxph_params_index_matches_covariates __________________\n\n    def test_coxph_params_index_matches_covariates() -> None:\n        \"\"\"Cox model params_ should be indexed by covariate names.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", e", "stdout_sha1": "45f2be43c6f1e0867119eea37aa2155b8e79197f", "stdout_len": 9309, "stdout": "..F..FFFFFFFFFF                                                          [100%]\n================================== FAILURES ===================================\n____________________________ test_coxph_basic_fit _____________________________\n\n    def test_coxph_basic_fit() -> None:\n        \"\"\"Fit a simple Cox proportional hazards model on a toy dataset.\"\"\"\n        df = _toy_cox_df()\n    \n        cph = CoxPHFitter()\n        cph.fit(df, duration_col=\"duration\", event_col=\"event\")\n        summary = cph.summary\n    \n        assert \"coef\" in summary.columns\n        assert \"se(coef)\" in summary.columns\n>       assert \"p\" in summary.columns or \"p\" in \"\".join(summary.columns).lower()\nE       AssertionError: assert ('p' in Index(['coef', 'se(coef)'], dtype='object') or 'p' in 'coefse(coef)')\nE        +  where Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.001841  0.011457\\ntreatment  0.648316  0.707976.columns\nE        +  and   'coefse(coef)' = <built-in method lower of str object at 0x000002BFFD6C6F70>()\nE        +    where <built-in method lower of str object at 0x000002BFFD6C6F70> = 'coefse(coef)'.lower\nE        +      where 'coefse(coef)' = <built-in method join of str object at 0x000002BFDAA64670>(Index(['coef', 'se(coef)'], dtype='object'))\nE        +        where <built-in method join of str object at 0x000002BFDAA64670> = ''.join\nE        +        and   Index(['coef', 'se(coef)'], dtype='object') =                coef  se(coef)\\nage       -0.001841  0.011457\\ntreatment  0.648316  0.707976.columns\n\ntests\\Lifelines\\functional_test.py:127: AssertionError\n________________ test_kmf_cumulative_density_is_non_decreasing ________________\n\n    def test_kmf_cumulative_density_is_non_decreasing() -> None:\n        \"\"\"Cumulative density should be non-decreasing and within [0, 1].\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       cd = kmf.cumulative_density_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'cumulative_density_'\n\ntests\\Lifelines\\functional_test.py:170: AttributeError\n__________________ test_kmf_event_table_has_standard_columns __________________\n\n    def test_kmf_event_table_has_standard_columns() -> None:\n        \"\"\"KM event table should include standard bookkeeping columns.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       et = kmf.event_table\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'event_table'\n\ntests\\Lifelines\\functional_test.py:183: AttributeError\n_____________ test_kmf_confidence_interval_matches_survival_index _____________\n\n    def test_kmf_confidence_interval_matches_survival_index() -> None:\n        \"\"\"Confidence intervals should align with survival function index.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n>       ci = kmf.confidence_interval_\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'confidence_interval_'\n\ntests\\Lifelines\\functional_test.py:192: AttributeError\n___________ test_kmf_median_survival_time_is_within_duration_range ____________\n\n    def test_kmf_median_survival_time_is_within_duration_range() -> None:\n        \"\"\"Median survival time should be within the observed duration range.\"\"\"\n        durations, events = _toy_kmf_data()\n        kmf = KaplanMeierFitter().fit(durations=durations, event_observed=events, label=\"km\")\n    \n>       m = float(kmf.median_survival_time_)\nE       AttributeError: 'KaplanMeierFitter' object has no attribute 'median_survival_time_'\n\ntests\\Lifelines\\functional_test.py:206: AttributeError\n_________________ test_coxph_params_index_matches_covariates __________________\n\n    def test_coxph_params_index_matches_covariates() -> None:\n        \"\"\"Cox model params_ should be indexed by covariate names.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        params = cph.params_\n>       assert list(params.index) == [\"age\", \"treatment\"]\nE       AttributeError: 'numpy.ndarray' object has no attribute 'index'\n\ntests\\Lifelines\\functional_test.py:216: AttributeError\n___________ test_coxph_baseline_cumulative_hazard_is_non_decreasing ___________\n\n    def test_coxph_baseline_cumulative_hazard_is_non_decreasing() -> None:\n        \"\"\"Baseline cumulative hazard should be non-decreasing over time.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       bch = cph.baseline_cumulative_hazard_\nE       AttributeError: 'CoxPHFitter' object has no attribute 'baseline_cumulative_hazard_'\n\ntests\\Lifelines\\functional_test.py:225: AttributeError\n__________ test_coxph_predict_partial_hazard_is_positive_and_varies ___________\n\n    def test_coxph_predict_partial_hazard_is_positive_and_varies() -> None:\n        \"\"\"Partial hazards should be positive and reflect covariate differences.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x_low = pd.DataFrame({\"age\": [25], \"treatment\": [0]})\n        x_high = pd.DataFrame({\"age\": [55], \"treatment\": [1]})\n    \n>       h_low = float(cph.predict_partial_hazard(x_low).iloc[0])\nE       AttributeError: 'CoxPHFitter' object has no attribute 'predict_partial_hazard'\n\ntests\\Lifelines\\functional_test.py:240: AttributeError\n____________ test_coxph_predict_survival_function_shape_and_bounds ____________\n\n    def test_coxph_predict_survival_function_shape_and_bounds() -> None:\n        \"\"\"Predict survival functions for two individuals; verify shape and bounds.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n        x = pd.DataFrame({\"age\": [30, 60], \"treatment\": [0, 1]})\n>       sf = cph.predict_survival_function(x)\n\ntests\\Lifelines\\functional_test.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <lifelines.coxph_fitter.CoxPHFitter object at 0x000002BFFF75BF70>\nrow =    age  treatment\n0   30          0\n1   60          1, times = None\n\n    def predict_survival_function(\n        self, row: pd.DataFrame, times: Optional[np.ndarray] = None\n    ) -> pd.DataFrame:\n        \"\"\"\n        Predict the survival function for a single row of covariate values.\n        \"\"\"\n        if self.params_ is None:\n            raise RuntimeError(\"Model has not been fitted yet.\")\n        if row.shape[0] != 1:\n>           raise ValueError(\"Row must contain exactly one observation.\")\nE           ValueError: Row must contain exactly one observation.\n\ngeneration\\Lifelines\\lifelines\\coxph_fitter.py:191: ValueError\n________________ test_coxph_concordance_index_in_unit_interval ________________\n\n    def test_coxph_concordance_index_in_unit_interval() -> None:\n        \"\"\"Concordance index should lie in [0, 1] after fitting.\"\"\"\n        df = _toy_cox_df()\n        cph = CoxPHFitter().fit(df, duration_col=\"duration\", event_col=\"event\")\n    \n>       c = float(cph.concordance_index_)\nE       AttributeError: 'CoxPHFitter' object has no attribute 'concordance_index_'\n\ntests\\Lifelines\\functional_test.py:269: AttributeError\n_____________ test_coxph_fit_on_waltons_with_binary_group_feature _____________\n\n    def test_coxph_fit_on_waltons_with_binary_group_feature() -> None:\n        \"\"\"Fit CoxPH on Waltons dataset using a binary treated indicator derived from group.\"\"\"\n        df = load_waltons()\n        assert {\"T\", \"E\", \"group\"}.issubset(df.columns)\n    \n        df2 = df.copy()\n        df2[\"treated\"] = (df2[\"group\"] != \"control\").astype(int)\n    \n        model_df = df2[[\"T\", \"E\", \"treated\"]].rename(columns={\"T\": \"duration\", \"E\": \"event\"})\n    \n        cph = CoxPHFitter()\n        cph.fit(model_df, duration_col=\"duration\", event_col=\"event\")\n    \n>       coef = float(cph.params_.loc[\"treated\"])\nE       AttributeError: 'numpy.ndarray' object has no attribute 'loc'\n\ntests\\Lifelines\\functional_test.py:286: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Lifelines/functional_test.py::test_coxph_basic_fit - AssertionEr...\nFAILED tests/Lifelines/functional_test.py::test_kmf_cumulative_density_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_kmf_event_table_has_standard_columns\nFAILED tests/Lifelines/functional_test.py::test_kmf_confidence_interval_matches_survival_index\nFAILED tests/Lifelines/functional_test.py::test_kmf_median_survival_time_is_within_duration_range\nFAILED tests/Lifelines/functional_test.py::test_coxph_params_index_matches_covariates\nFAILED tests/Lifelines/functional_test.py::test_coxph_baseline_cumulative_hazard_is_non_decreasing\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_partial_hazard_is_positive_and_varies\nFAILED tests/Lifelines/functional_test.py::test_coxph_predict_survival_function_shape_and_bounds\nFAILED tests/Lifelines/functional_test.py::test_coxph_concordance_index_in_unit_interval\nFAILED tests/Lifelines/functional_test.py::test_coxph_fit_on_waltons_with_binary_group_feature\n11 failed, 4 passed in 2.30s\n"}
{"model": "o3", "project": "Loguru", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.581366, "avg_memory_mb": 30.77, "avg_cpu_percent": 98.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:39:20", "stdout_excerpt": "\n1 skipped in 0.11s\n", "stdout_sha1": "75923eec7092d4a8427af710fe49bcf2a0b64e5b", "stdout_len": 20, "stdout": "\n1 skipped in 0.11s\n"}
{"model": "o3", "project": "Mailpile", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)", "returncode": 2, "elapsed_time_s": 2.672868, "avg_memory_mb": 36.62, "avg_cpu_percent": 68.9, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:40:38", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.38s\n", "stdout_sha1": "317df1ea0190b3ec7fc8a7cbf44eb17899be4289", "stdout_len": 1023, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Mailpile/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Mailpile\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Mailpile\\functional_test.py:176: in <module>\n    from mailpile.safe_popen import PIPE, Popen, Safe_Pipe  # type: ignore\nE   ImportError: cannot import name 'PIPE' from 'mailpile.safe_popen' (D:\\桌面\\RealAppCodeBench_generic_eval\\.converted\\Mailpile\\generated\\mailpile\\safe_popen.py)\n=========================== short test summary info ===========================\nERROR tests/Mailpile/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 1.38s\n"}
{"model": "o3", "project": "Markdown", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'", "returncode": 1, "elapsed_time_s": 1.921858, "avg_memory_mb": 32.65, "avg_cpu_percent": 95.7, "passed": 8, "failed": 2, "skipped": 9, "total": 19, "functional_score": 0.4211, "timestamp": "2026-01-01 21:41:50", "stdout_excerpt": "==== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n2 failed, 8 passed, 9 skipped in 0.57s\n", "stdout_sha1": "7d38ed0558e67f3442e9246a2ac92f4490434196", "stdout_len": 1640, "stdout": "......F..Fsssssssss                                                      [100%]\n================================== FAILURES ===================================\n_________________ test_html_escaping_in_text_but_not_in_code __________________\n\n    def test_html_escaping_in_text_but_not_in_code() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Use <b>raw HTML</b> here.\n    \n            ```\n            literal <b> tag in code block\n            ```\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<b>\" in norm\nE       AssertionError: assert '<b>' in '<p>Use &lt;b&gt;raw HTML&lt;/b&gt; here.</p>\\n<pre><code>literal &lt;b&gt; tag in code block</code></pre>'\n\ntests\\Markdown\\functional_test.py:209: AssertionError\n_______________________ test_horizontal_rule_renders_hr _______________________\n\n    def test_horizontal_rule_renders_hr() -> None:\n        src = textwrap.dedent(\n            \"\"\"\n            Paragraph above\n    \n            ---\n    \n            Paragraph below\n            \"\"\"\n        )\n        html = markdown.markdown(src)\n        norm = normalize_html(html)\n    \n>       assert \"<hr\" in norm\nE       AssertionError: assert '<hr' in '<p>Paragraph above</p>\\n<p>---</p>\\n<p>Paragraph below</p>'\n\ntests\\Markdown\\functional_test.py:272: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Markdown/functional_test.py::test_html_escaping_in_text_but_not_in_code\nFAILED tests/Markdown/functional_test.py::test_horizontal_rule_renders_hr - A...\n2 failed, 8 passed, 9 skipped in 0.57s\n"}
{"model": "o3", "project": "Mitmproxy", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "+    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file", "returncode": 1, "elapsed_time_s": 2.050046, "avg_memory_mb": 34.27, "avg_cpu_percent": 99.2, "passed": 4, "failed": 7, "skipped": 0, "total": 11, "functional_score": 0.3636, "timestamp": "2026-01-01 21:43:12", "stdout_excerpt": "==== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n        assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\n    \n        text = \"\\n\".join(_file(p).lower() for p in existing)\n    \n        # Accept multiple common patterns.\n        # Examples: __version__ = \"10.0.0\", VERSION = \"10.0.0\", version = \"10.0.0\"\n        import re\n    \n>       assert (\n            re.search(r\"__version__\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\b\", text)\n        ), \"Expected a version-like assignment or token in version source files.\"\nE       AssertionError: Expected a version-like assignment or token in version source files.\nE       assert (None or None or None)\nE        +  where None = <function search at 0x0000020506DA99D0>('__version__\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '\"\"\"\\na **very** small stub of the real *mitmproxy* package.\\n\\nthe intention of this repository is **not** to ship a ...(\"mitmproxy.flow\")\\naddonmanager = _import_module(\"mitmproxy.addonmanager\")\\ntools = _import_module(\"mitmproxy.tools\")')\nE        +    where <function search at 0x0000020506DA99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000020506DA99D0>('\\\\bversion\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '\"\"\"\\na **very** small stub of the real *mitmproxy* package.\\n\\nthe intention of this repository is **not** to ship a ...(\"mitmproxy.flow\")\\naddonmanager = _import_module(\"mitmproxy.addonmanager\")\\ntools = _import_module(\"mitmproxy.tools\")')\nE        +    where <function search at 0x0000020506DA99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000020506DA99D0>('\\\\bversion\\\\b', '\"\"\"\\na **very** small stub of the real *mitmproxy* package.\\n\\nthe intention of this repository is **not** to ship a ...(\"mitmproxy.flow\")\\naddonmanager = _import_module(\"mitmproxy.addonmanager\")\\ntools = _import_module(\"mitmproxy.tools\")')\nE        +    where <function search at 0x0000020506DA99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\n\ntests\\Mitmproxy\\functional_test.py:103: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: Ass", "stdout_sha1": "bc34494c95269d774038b94ddc5f9dcb1013e4d8", "stdout_len": 9042, "stdout": "..FF.FF.FFF                                                              [100%]\n================================== FAILURES ===================================\n_______ test_003_version_source_file_exists_and_has_version_like_token ________\n\n    def test_003_version_source_file_exists_and_has_version_like_token():\n        \"\"\"\n        Do NOT assume mitmproxy exposes __version__ at top-level.\n        Instead, require a stable version source file under the package and a version-like token inside.\n    \n        This aligns better with how many projects store version information (e.g. version.py, __init__.py, or pyproject).\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n    \n        candidates = [\n            pkg / \"version.py\",\n            pkg / \"__init__.py\",\n        ]\n    \n        existing = [p for p in candidates if p.is_file()]\n        assert existing, f\"Expected one of these to exist: {[str(p) for p in candidates]}\"\n    \n        text = \"\\n\".join(_file(p).lower() for p in existing)\n    \n        # Accept multiple common patterns.\n        # Examples: __version__ = \"10.0.0\", VERSION = \"10.0.0\", version = \"10.0.0\"\n        import re\n    \n>       assert (\n            re.search(r\"__version__\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\s*=\\s*['\\\"][^'\\\"]+['\\\"]\", text)\n            or re.search(r\"\\bversion\\b\", text)\n        ), \"Expected a version-like assignment or token in version source files.\"\nE       AssertionError: Expected a version-like assignment or token in version source files.\nE       assert (None or None or None)\nE        +  where None = <function search at 0x0000020506DA99D0>('__version__\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '\"\"\"\\na **very** small stub of the real *mitmproxy* package.\\n\\nthe intention of this repository is **not** to ship a ...(\"mitmproxy.flow\")\\naddonmanager = _import_module(\"mitmproxy.addonmanager\")\\ntools = _import_module(\"mitmproxy.tools\")')\nE        +    where <function search at 0x0000020506DA99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000020506DA99D0>('\\\\bversion\\\\s*=\\\\s*[\\'\\\\\"][^\\'\\\\\"]+[\\'\\\\\"]', '\"\"\"\\na **very** small stub of the real *mitmproxy* package.\\n\\nthe intention of this repository is **not** to ship a ...(\"mitmproxy.flow\")\\naddonmanager = _import_module(\"mitmproxy.addonmanager\")\\ntools = _import_module(\"mitmproxy.tools\")')\nE        +    where <function search at 0x0000020506DA99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\nE        +  and   None = <function search at 0x0000020506DA99D0>('\\\\bversion\\\\b', '\"\"\"\\na **very** small stub of the real *mitmproxy* package.\\n\\nthe intention of this repository is **not** to ship a ...(\"mitmproxy.flow\")\\naddonmanager = _import_module(\"mitmproxy.addonmanager\")\\ntools = _import_module(\"mitmproxy.tools\")')\nE        +    where <function search at 0x0000020506DA99D0> = <module 're' from 'C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\re.py'>.search\n\ntests\\Mitmproxy\\functional_test.py:103: AssertionError\n_______________________ test_004_tools_main_file_exists _______________________\n\n    def test_004_tools_main_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"main.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'main.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:112: AssertionError\n_____________________ test_006_tools_cmdline_file_exists ______________________\n\n    def test_006_tools_cmdline_file_exists():\n        pkg = _mitmproxy_pkg_dir()\n>       assert (pkg / \"tools\" / \"cmdline.py\").is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = ((WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy') / 'tools') / 'cmdline.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:122: AssertionError\n__________ test_007_tools_main_defines_mitmdump_function_or_wrapper ___________\n\n    def test_007_tools_main_defines_mitmdump_function_or_wrapper():\n        \"\"\"\n        Anchor: mitmproxy.tools.main.mitmdump should exist.\n        If runtime import is blocked by missing mitmproxy_rs, we still enforce the symbol statically.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        main_py = pkg / \"tools\" / \"main.py\"\n>       src = _file(main_py)\n\ntests\\Mitmproxy\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Mitmproxy\\functional_test.py:44: in _file\n    return path.read_text(encoding=\"utf-8\", errors=\"replace\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1255: in read_text\n    with self.open(mode='r', encoding=encoding, errors=errors) as f:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1241: in open\n    return io.open(self, mode, buffering, encoding, errors, newline,\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/tools/main.py')\nname = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\nflags = 32896, mode = 438\n\n    def _opener(self, name, flags, mode=0o666):\n        # A stub for the opener argument to built-in open()\n>       return self._accessor.open(self, flags, mode)\nE       FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\generation\\\\Mitmproxy\\\\mitmproxy\\\\tools\\\\main.py'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pathlib.py:1109: FileNotFoundError\n________________ test_009_proxy_mode_specs_mentions_ProxyMode _________________\n\n    def test_009_proxy_mode_specs_mentions_ProxyMode():\n        \"\"\"\n        Anchor: mitmproxy.proxy.mode_specs is part of the CLI import chain.\n        Runtime import may require mitmproxy_rs; we assert the file contains ProxyMode constructs.\n        \"\"\"\n        pkg = _mitmproxy_pkg_dir()\n        ms_py = pkg / \"proxy\" / \"mode_specs.py\"\n>       assert ms_py.is_file()\nE       AssertionError: assert False\nE        +  where False = is_file()\nE        +    where is_file = WindowsPath('D:/桌面/RealAppCodeBench_generic_eval/generation/Mitmproxy/mitmproxy/proxy/mode_specs.py').is_file\n\ntests\\Mitmproxy\\functional_test.py:156: AssertionError\n_________ test_010_conditional_import_http_module_depends_on_OpenSSL __________\n\n    def test_010_conditional_import_http_module_depends_on_OpenSSL():\n        \"\"\"\n        Importing mitmproxy.http may require pyOpenSSL (OpenSSL module) through mitmproxy.certs.\n        If OpenSSL is installed, import must succeed.\n        If not installed, import must fail with ModuleNotFoundError mentioning OpenSSL.\n        \"\"\"\n        _prepend_import_path()\n        have_openssl = _has_module(\"OpenSSL\")\n        if have_openssl:\n            import mitmproxy.http  # noqa: F401\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               import mitmproxy.http  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:173: Failed\n_______ test_011_conditional_import_tools_main_depends_on_mitmproxy_rs ________\n\n    def test_011_conditional_import_tools_main_depends_on_mitmproxy_rs():\n        \"\"\"\n        Importing mitmproxy.tools.main currently pulls in mitmproxy.proxy.mode_specs,\n        which imports mitmproxy_rs. If mitmproxy_rs is installed, import should succeed.\n        Otherwise, it should fail with ModuleNotFoundError mentioning mitmproxy_rs.\n        \"\"\"\n        _prepend_import_path()\n        have_rs = _has_module(\"mitmproxy_rs\")\n        if have_rs:\n            from mitmproxy.tools import main as tools_main  # noqa: F401\n            assert hasattr(tools_main, \"mitmdump\")\n        else:\n            with pytest.raises(ModuleNotFoundError) as ei:\n>               from mitmproxy.tools import main as tools_main  # noqa: F401\nE               Failed: DID NOT RAISE <class 'ModuleNotFoundError'>\n\ntests\\Mitmproxy\\functional_test.py:190: Failed\n=========================== short test summary info ===========================\nFAILED tests/Mitmproxy/functional_test.py::test_003_version_source_file_exists_and_has_version_like_token\nFAILED tests/Mitmproxy/functional_test.py::test_004_tools_main_file_exists - ...\nFAILED tests/Mitmproxy/functional_test.py::test_006_tools_cmdline_file_exists\nFAILED tests/Mitmproxy/functional_test.py::test_007_tools_main_defines_mitmdump_function_or_wrapper\nFAILED tests/Mitmproxy/functional_test.py::test_009_proxy_mode_specs_mentions_ProxyMode\nFAILED tests/Mitmproxy/functional_test.py::test_010_conditional_import_http_module_depends_on_OpenSSL\nFAILED tests/Mitmproxy/functional_test.py::test_011_conditional_import_tools_main_depends_on_mitmproxy_rs\n7 failed, 4 passed in 0.75s\n"}
{"model": "o3", "project": "Mutagen", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.620705, "avg_memory_mb": 31.66, "avg_cpu_percent": 98.9, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:44:44", "stdout_excerpt": "\n1 skipped in 0.15s\n", "stdout_sha1": "c5b93e95dac752b922f78a9473a84b272945e75e", "stdout_len": 20, "stdout": "\n1 skipped in 0.15s\n"}
{"model": "o3", "project": "Pendulum", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AttributeError", "exception_msg": "'DateTime' object has no attribute 'start_of'", "returncode": 1, "elapsed_time_s": 1.98237, "avg_memory_mb": 33.34, "avg_cpu_percent": 99.2, "passed": 2, "failed": 10, "skipped": 1, "total": 13, "functional_score": 0.1538, "timestamp": "2026-01-01 21:45:58", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n        assert offset_tokyo.total_seconds() == 9 * 60 * 60\n    \n>       as_str = dt_tokyo.to_datetime_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_datetime_string'\n\ntests\\Pendulum\\functional_test.py:81: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n        shifted = base.add(days=2, hours=5, minutes=15)\n        delta = shifted - base\n    \n>       assert delta.days == 2\nE       assert 0 == 2\nE        +  where 0 = Duration(seconds=191700).days\n\ntests\\Pendulum\\functional_test.py:92: AssertionError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n>       d = pendulum.parse(\"2020-02-29\")\n\ntests\\Pendulum\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:63: in parse\n    dt = _parse_iso_datetime(timestring)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nval = '2020-02-29'\n\n    def _parse_iso_datetime(val: str) -> DateTime:\n        \"\"\"\n        Very naive ISO-8601 parser sufficient for YYYY-MM-DDTHH:MM:SS[.ffffff][Z|±HH:MM]\n        \"\"\"\n        m = _DATETIME_ISO_RE.match(val)\n        if not m:\n>           raise ValueError(f\"Invalid ISO-8601 datetime string: {val!r}\")\nE           ValueError: Invalid ISO-8601 datetime string: '2020-02-29'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:223: ValueError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wedn", "stdout_sha1": "0a20ae9f2b612cd504657ea0e897969b26018adc", "stdout_len": 6500, "stdout": "FF.FFFFF.sFFF                                                            [100%]\n================================== FAILURES ===================================\n_____________________ test_parse_and_timezone_conversion ______________________\n\n    def test_parse_and_timezone_conversion() -> None:\n        \"\"\"Parse an ISO string and convert between timezones.\"\"\"\n        dt_utc = pendulum.parse(\"2020-01-01T12:00:00+00:00\")\n    \n        assert dt_utc.year == 2020\n        assert dt_utc.month == 1\n        assert dt_utc.day == 1\n    \n        offset_utc = dt_utc.utcoffset()\n        assert offset_utc is not None\n        assert offset_utc.total_seconds() == 0\n    \n        dt_tokyo = dt_utc.in_timezone(\"Asia/Tokyo\")\n        offset_tokyo = dt_tokyo.utcoffset()\n        assert offset_tokyo is not None\n        assert offset_tokyo.total_seconds() == 9 * 60 * 60\n    \n>       as_str = dt_tokyo.to_datetime_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_datetime_string'\n\ntests\\Pendulum\\functional_test.py:81: AttributeError\n____________________ test_datetime_arithmetic_and_duration ____________________\n\n    def test_datetime_arithmetic_and_duration() -> None:\n        \"\"\"Basic arithmetic with pendulum.datetime and pendulum.duration.\"\"\"\n        base = pendulum.datetime(2021, 3, 15, 10, 30, 0, tz=\"UTC\")\n    \n        shifted = base.add(days=2, hours=5, minutes=15)\n        delta = shifted - base\n    \n>       assert delta.days == 2\nE       assert 0 == 2\nE        +  where 0 = Duration(seconds=191700).days\n\ntests\\Pendulum\\functional_test.py:92: AssertionError\n_____________________ test_parse_date_only_to_date_string _____________________\n\n    def test_parse_date_only_to_date_string() -> None:\n        \"\"\"Parse a date-only string and verify normalized date output.\"\"\"\n>       d = pendulum.parse(\"2020-02-29\")\n\ntests\\Pendulum\\functional_test.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Pendulum\\pendulum\\__init__.py:63: in parse\n    dt = _parse_iso_datetime(timestring)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nval = '2020-02-29'\n\n    def _parse_iso_datetime(val: str) -> DateTime:\n        \"\"\"\n        Very naive ISO-8601 parser sufficient for YYYY-MM-DDTHH:MM:SS[.ffffff][Z|±HH:MM]\n        \"\"\"\n        m = _DATETIME_ISO_RE.match(val)\n        if not m:\n>           raise ValueError(f\"Invalid ISO-8601 datetime string: {val!r}\")\nE           ValueError: Invalid ISO-8601 datetime string: '2020-02-29'\n\ngeneration\\Pendulum\\pendulum\\datetime.py:223: ValueError\n__________________ test_datetime_to_iso8601_string_roundtrip __________________\n\n    def test_datetime_to_iso8601_string_roundtrip() -> None:\n        \"\"\"Create a datetime and verify ISO8601 string contains expected offset.\"\"\"\n        dt = pendulum.datetime(2020, 1, 1, 12, 0, 0, tz=\"UTC\")\n>       iso = dt.to_iso8601_string()\nE       AttributeError: 'DateTime' object has no attribute 'to_iso8601_string'\n\ntests\\Pendulum\\functional_test.py:127: AttributeError\n_____________________ test_formatting_with_custom_pattern _____________________\n\n    def test_formatting_with_custom_pattern() -> None:\n        \"\"\"Verify formatting with a custom pattern is stable for a fixed datetime.\"\"\"\n        dt = pendulum.datetime(2021, 12, 31, 23, 59, 58, tz=\"UTC\")\n>       s = dt.format(\"YYYY/MM/DD HH:mm:ss\")\nE       AttributeError: 'DateTime' object has no attribute 'format'\n\ntests\\Pendulum\\functional_test.py:136: AttributeError\n__________________________ test_start_of_end_of_day ___________________________\n\n    def test_start_of_end_of_day() -> None:\n        \"\"\"Check start_of and end_of for a day boundary.\"\"\"\n        dt = pendulum.datetime(2020, 5, 20, 13, 14, 15, tz=\"UTC\")\n    \n>       sod = dt.start_of(\"day\")\nE       AttributeError: 'DateTime' object has no attribute 'start_of'\n\ntests\\Pendulum\\functional_test.py:144: AttributeError\n_____________________ test_weekday_and_isoweekday_values ______________________\n\n    def test_weekday_and_isoweekday_values() -> None:\n        \"\"\"Validate weekday values for a known date (2020-01-01 is Wednesday).\"\"\"\n>       dt = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:155: AttributeError\n_____________________ test_in_timezone_preserves_instant ______________________\n\n    def test_in_timezone_preserves_instant() -> None:\n        \"\"\"Converting timezones should preserve the instant (timestamp).\"\"\"\n        dt_utc = pendulum.datetime(2020, 6, 1, 0, 0, 0, tz=\"UTC\")\n        dt_ny = dt_utc.in_timezone(\"America/New_York\")\n    \n        assert int(dt_utc.timestamp()) == int(dt_ny.timestamp())\n>       assert dt_ny.to_date_string() in (\"2020-05-31\", \"2020-06-01\")\nE       AttributeError: 'DateTime' object has no attribute 'to_date_string'\n\ntests\\Pendulum\\functional_test.py:202: AttributeError\n________________________ test_diff_in_days_is_integer _________________________\n\n    def test_diff_in_days_is_integer() -> None:\n        \"\"\"Compute diff in days between two dates.\"\"\"\n>       a = pendulum.date(2020, 1, 1)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:207: AttributeError\n____________________ test_add_months_across_year_boundary _____________________\n\n    def test_add_months_across_year_boundary() -> None:\n        \"\"\"Add months and verify year boundary transitions.\"\"\"\n>       dt = pendulum.date(2019, 12, 15)\nE       AttributeError: module 'pendulum' has no attribute 'date'\n\ntests\\Pendulum\\functional_test.py:217: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Pendulum/functional_test.py::test_parse_and_timezone_conversion\nFAILED tests/Pendulum/functional_test.py::test_datetime_arithmetic_and_duration\nFAILED tests/Pendulum/functional_test.py::test_parse_date_only_to_date_string\nFAILED tests/Pendulum/functional_test.py::test_datetime_to_iso8601_string_roundtrip\nFAILED tests/Pendulum/functional_test.py::test_formatting_with_custom_pattern\nFAILED tests/Pendulum/functional_test.py::test_start_of_end_of_day - Attribut...\nFAILED tests/Pendulum/functional_test.py::test_weekday_and_isoweekday_values\nFAILED tests/Pendulum/functional_test.py::test_in_timezone_preserves_instant\nFAILED tests/Pendulum/functional_test.py::test_diff_in_days_is_integer - Attr...\nFAILED tests/Pendulum/functional_test.py::test_add_months_across_year_boundary\n10 failed, 2 passed, 1 skipped in 0.70s\n"}
{"model": "o3", "project": "Petl", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "sort() got an unexpected keyword argument 'reverse'", "returncode": 1, "elapsed_time_s": 1.847915, "avg_memory_mb": 32.41, "avg_cpu_percent": 99.1, "passed": 5, "failed": 1, "skipped": 6, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 21:47:09", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n1 failed, 5 passed, 6 skipped in 0.52s\n", "stdout_sha1": "6f3763f89420b7851a27c457a66a66129b955c83", "stdout_len": 1049, "stdout": "...ss.Fs.sss                                                             [100%]\n================================== FAILURES ===================================\n_____________________ test_sort_descending_orders_values ______________________\n\n    def test_sort_descending_orders_values() -> None:\n        \"\"\"Sort descending by a numeric field.\"\"\"\n        _require_attr(\"sort\")\n    \n        records = [\n            {\"name\": \"A\", \"score\": 10},\n            {\"name\": \"B\", \"score\": 30},\n            {\"name\": \"C\", \"score\": 20},\n        ]\n        table = petl.fromdicts(records, header=[\"name\", \"score\"])\n    \n        # petl.sort supports reverse=True in typical implementations.\n>       sorted_tbl = petl.sort(table, \"score\", reverse=True)\nE       TypeError: sort() got an unexpected keyword argument 'reverse'\n\ntests\\Petl\\functional_test.py:278: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Petl/functional_test.py::test_sort_descending_orders_values - Ty...\n1 failed, 5 passed, 6 skipped in 0.52s\n"}
{"model": "o3", "project": "Pygments", "failure_stage": "in-test", "failure_type": "test_failure", "exception_type": "", "exception_msg": "", "returncode": 1, "elapsed_time_s": 0.388245, "avg_memory_mb": 14.63, "avg_cpu_percent": 89.0, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:48:38", "stdout_excerpt": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 14, in <module>\n    from pygments.lex import lex   # type: ignore  # re-export\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py\", line 7, in <module>\n    from pygments.lexers import get_lexer_by_name\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 16, in <module>\n    TokenStream = Iterable[Tuple[Token, str]]\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 243, in inner\n    return func(*args, **kwds)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 856, in __getitem__\n    params = tuple(_type_check(p, msg) for p in params)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 856, in <genexpr>\n    params = tuple(_type_check(p, msg) for p in params)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 151, in _type_check\n    raise TypeError(f\"{msg} Got {arg!r:.100}.\")\nTypeError: Tuple[t0, t1, ...]: each t must be a type. Got Token.\n", "stdout_sha1": "1bf93a7fef2af36fc0729c7b4547bfd9d7f21e28", "stdout_len": 2474, "stdout": "Traceback (most recent call last):\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 188, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 147, in _get_module_details\n    return _get_module_details(pkg_main_name, error)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 111, in _get_module_details\n    __import__(pkg_name)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytest\\__init__.py\", line 8, in <module>\n    from _pytest._code import ExceptionInfo\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\__init__.py\", line 5, in <module>\n    from .code import Code\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_code\\code.py\", line 44, in <module>\n    from _pytest._io import TerminalWriter\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\__init__.py\", line 3, in <module>\n    from .terminalwriter import get_terminal_width\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\_io\\terminalwriter.py\", line 13, in <module>\n    import pygments\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\__init__.py\", line 14, in <module>\n    from pygments.lex import lex   # type: ignore  # re-export\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lex.py\", line 7, in <module>\n    from pygments.lexers import get_lexer_by_name\n  File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Pygments\\pygments\\lexers\\__init__.py\", line 16, in <module>\n    TokenStream = Iterable[Tuple[Token, str]]\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 243, in inner\n    return func(*args, **kwds)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 856, in __getitem__\n    params = tuple(_type_check(p, msg) for p in params)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 856, in <genexpr>\n    params = tuple(_type_check(p, msg) for p in params)\n  File \"C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py\", line 151, in _type_check\n    raise TypeError(f\"{msg} Got {arg!r:.100}.\")\nTypeError: Tuple[t0, t1, ...]: each t must be a type. Got Token.\n"}
{"model": "o3", "project": "PyJWT", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "Object of type datetime is not JSON serializable", "returncode": 1, "elapsed_time_s": 1.970489, "avg_memory_mb": 33.82, "avg_cpu_percent": 96.7, "passed": 6, "failed": 4, "skipped": 1, "total": 11, "functional_score": 0.5455, "timestamp": "2026-01-01 21:49:25", "stdout_excerpt": "==== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x0000023629CE9040>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None\n\n    def encode(\n        self,\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        headers: Optional[Dict[str, Any]] = None,\n        json_encoder: Optional[json.JSONEncoder] = None,\n    ) -> str:\n        \"\"\"\n        Create a JSON Web Token.\n    \n        Only HS256 (HMAC + SHA-256) is supported. The returned value is\n        a ``str`` instance containing the compact JWT.\n        \"\"\"\n        algorithm = (algorithm or \"\").upper()\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported in this implementation\")\nE           NotImplementedError: Only HS256 algorithm is supported in this implementation\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:105: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:117: in encode\n    _json_dumps(payload).encode(\"utf-8\")\ngeneration\\PyJWT\\jwt\\api_jwt.py:59: in _json_dumps\n    return json.dumps(data, separators=(\",\", \":\"), ensure_ascii=False)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000023629D88A60>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def", "stdout_sha1": "46152b41d7ea17ca2056256e06e2c69a12ebd2a8", "stdout_len": 7304, "stdout": ".F.FF...F.s                                                              [100%]\n================================== FAILURES ===================================\n_____________________ test_hs512_encode_decode_roundtrip ______________________\n\n    def test_hs512_encode_decode_roundtrip() -> None:\n        payload = {\"scope\": [\"read\", \"write\"], \"active\": True}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS512\")\n\ntests\\PyJWT\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <jwt.api_jwt.PyJWT object at 0x0000023629CE9040>\npayload = {'active': True, 'scope': ['read', 'write']}, key = 'secret'\nalgorithm = 'HS512', headers = None, json_encoder = None\n\n    def encode(\n        self,\n        payload: Dict[str, Any],\n        key: Union[str, bytes],\n        algorithm: str = \"HS256\",\n        headers: Optional[Dict[str, Any]] = None,\n        json_encoder: Optional[json.JSONEncoder] = None,\n    ) -> str:\n        \"\"\"\n        Create a JSON Web Token.\n    \n        Only HS256 (HMAC + SHA-256) is supported. The returned value is\n        a ``str`` instance containing the compact JWT.\n        \"\"\"\n        algorithm = (algorithm or \"\").upper()\n        if algorithm != \"HS256\":\n>           raise NotImplementedError(\"Only HS256 algorithm is supported in this implementation\")\nE           NotImplementedError: Only HS256 algorithm is supported in this implementation\n\ngeneration\\PyJWT\\jwt\\api_jwt.py:105: NotImplementedError\n_______________ test_encode_decode_with_datetime_exp_in_future ________________\n\n    def test_encode_decode_with_datetime_exp_in_future() -> None:\n        exp_dt = _fixed_dt_utc(2099, 1, 1, 0, 0, 0)\n        payload = {\"sub\": \"u-123\", \"exp\": exp_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:117: in encode\n    _json_dumps(payload).encode(\"utf-8\")\ngeneration\\PyJWT\\jwt\\api_jwt.py:59: in _json_dumps\n    return json.dumps(data, separators=(\",\", \":\"), ensure_ascii=False)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000023629D88A60>\no = datetime.datetime(2099, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n________________ test_encode_decode_with_datetime_nbf_in_past _________________\n\n    def test_encode_decode_with_datetime_nbf_in_past() -> None:\n        nbf_dt = _fixed_dt_utc(2000, 1, 1, 0, 0, 0)\n        payload = {\"feature\": \"enabled\", \"nbf\": nbf_dt}\n>       decoded = _encode_decode(payload, key=\"secret\", algorithm=\"HS256\")\n\ntests\\PyJWT\\functional_test.py:171: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyJWT\\functional_test.py:130: in _encode_decode\n    token = _normalize_token(jwt.encode(payload, key, algorithm=algorithm))\ngeneration\\PyJWT\\jwt\\api_jwt.py:117: in encode\n    _json_dumps(payload).encode(\"utf-8\")\ngeneration\\PyJWT\\jwt\\api_jwt.py:59: in _json_dumps\n    return json.dumps(data, separators=(\",\", \":\"), ensure_ascii=False)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:234: in dumps\n    return cls(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:199: in encode\n    chunks = self.iterencode(o, _one_shot=True)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:257: in iterencode\n    return _iterencode(o, 0)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.encoder.JSONEncoder object at 0x0000023629DC44C0>\no = datetime.datetime(2000, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)\n\n    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n    \n        For example, to support arbitrary iterators, you could\n        implement default like this::\n    \n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n    \n        \"\"\"\n>       raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')\nE       TypeError: Object of type datetime is not JSON serializable\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\encoder.py:179: TypeError\n_____________ test_unverified_header_contains_alg_and_custom_kid ______________\n\n    def test_unverified_header_contains_alg_and_custom_kid() -> None:\n        payload = {\"foo\": \"bar\"}\n        key = \"secret\"\n        token = _normalize_token(jwt.encode(payload, key, algorithm=\"HS256\", headers={\"kid\": \"k1\", \"typ\": \"JWT\"}))\n    \n>       header = jwt.get_unverified_header(token)\nE       AttributeError: module 'jwt' has no attribute 'get_unverified_header'\n\ntests\\PyJWT\\functional_test.py:210: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyJWT/functional_test.py::test_hs512_encode_decode_roundtrip - N...\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_exp_in_future\nFAILED tests/PyJWT/functional_test.py::test_encode_decode_with_datetime_nbf_in_past\nFAILED tests/PyJWT/functional_test.py::test_unverified_header_contains_alg_and_custom_kid\n4 failed, 6 passed, 1 skipped in 0.64s\n"}
{"model": "o3", "project": "PyPDF", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "module 'io' has no attribute 'PathLike'", "returncode": 1, "elapsed_time_s": 24.439654, "avg_memory_mb": 33.02, "avg_cpu_percent": 0.6, "passed": 0, "failed": 11, "skipped": 1, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-01 21:50:45", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=3)\n\ntests\\PyPDF\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD39A22E0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_create_and_read_blank_pdf0\\\\simple.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD39A09D0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_blank_page_has_expected_s0\\\\size.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n>       _create_simple_pdf(pdf1, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:159: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ", "stdout_sha1": "02b2334e1728e5e50b2b9a66694aafab26af90bf", "stdout_len": 19653, "stdout": "FFFFFFFFFFsF                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_create_and_read_blank_pdf ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_create_and_read_blank_pdf0')\n\n    def test_create_and_read_blank_pdf(tmp_path: Path) -> None:\n        pdf_path = tmp_path / \"simple.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=3)\n\ntests\\PyPDF\\functional_test.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD39A22E0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_create_and_read_blank_pdf0\\\\simple.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n______________________ test_blank_page_has_expected_size ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_blank_page_has_expected_s0')\n\n    def test_blank_page_has_expected_size(tmp_path: Path) -> None:\n        \"\"\"The first blank page should have the width/height we set.\"\"\"\n        pdf_path = tmp_path / \"size.pdf\"\n>       _create_simple_pdf(pdf_path, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD39A09D0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_blank_page_has_expected_s0\\\\size.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n_____________________________ test_merge_two_pdfs _____________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_merge_two_pdfs0')\n\n    def test_merge_two_pdfs(tmp_path: Path) -> None:\n        pdf1 = tmp_path / \"p1.pdf\"\n        pdf2 = tmp_path / \"p2.pdf\"\n        merged = tmp_path / \"merged.pdf\"\n    \n>       _create_simple_pdf(pdf1, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:159: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD399C3D0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_merge_two_pdfs0\\\\p1.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n__________________ test_writer_add_page_preserves_page_count __________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_writer_add_page_preserves0')\n\n    def test_writer_add_page_preserves_page_count(tmp_path: Path) -> None:\n        \"\"\"Add pages from a reader into a writer and verify count is preserved.\"\"\"\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"dst.pdf\"\n>       _create_simple_pdf(src, num_pages=4)\n\ntests\\PyPDF\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD39A3730>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_writer_add_page_preserves0\\\\src.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n______________________________ test_rotate_page _______________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_rotate_page0')\n\n    def test_rotate_page(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        rotated = tmp_path / \"rotated.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD399C0D0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_rotate_page0\\\\src.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n_______________________ test_rotate_preserves_page_size _______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_rotate_preserves_page_siz0')\n\n    def test_rotate_preserves_page_size(tmp_path: Path) -> None:\n        \"\"\"Rotating a blank page should keep a valid mediabox size.\"\"\"\n        src = tmp_path / \"src_size.pdf\"\n        rotated = tmp_path / \"rot_size.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:210: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD3A1DEE0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_rotate_preserves_page_siz0\\\\src_size.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n__________________________ test_encrypt_and_decrypt ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_encrypt_and_decrypt0')\n\n    def test_encrypt_and_decrypt(tmp_path: Path) -> None:\n        src = tmp_path / \"plain.pdf\"\n        enc = tmp_path / \"encrypted.pdf\"\n>       _create_simple_pdf(src, num_pages=2)\n\ntests\\PyPDF\\functional_test.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD3A7FE80>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_encrypt_and_decrypt0\\\\plain.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n_____________ test_encrypted_pdf_allows_page_access_after_decrypt _____________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_encrypted_pdf_allows_page0')\n\n    def test_encrypted_pdf_allows_page_access_after_decrypt(tmp_path: Path) -> None:\n        \"\"\"After decrypting, basic page access should succeed and page size is valid.\"\"\"\n        src = tmp_path / \"plain2.pdf\"\n        enc = tmp_path / \"encrypted2.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:256: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD39A0340>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_encrypted_pdf_allows_page0\\\\plain2.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n___________________________ test_metadata_roundtrip ___________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_metadata_roundtrip0')\n\n    def test_metadata_roundtrip(tmp_path: Path) -> None:\n        src = tmp_path / \"src.pdf\"\n        dst = tmp_path / \"meta.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:278: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD3A574F0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_metadata_roundtrip0\\\\src.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n___________________ test_metadata_multiple_fields_roundtrip ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_metadata_multiple_fields_0')\n\n    def test_metadata_multiple_fields_roundtrip(tmp_path: Path) -> None:\n        \"\"\"Add several info dict fields and ensure they can be read back.\"\"\"\n        src = tmp_path / \"src_info.pdf\"\n        dst = tmp_path / \"info.pdf\"\n>       _create_simple_pdf(src, num_pages=1)\n\ntests\\PyPDF\\functional_test.py:306: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD3A3CCA0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_metadata_multiple_fields_0\\\\src_info.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n_________________ test_clone_document_by_writing_reader_pages _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-470/test_clone_document_by_writing0')\n\n    def test_clone_document_by_writing_reader_pages(tmp_path: Path) -> None:\n        \"\"\"Clone a document by copying pages and verify page count matches.\"\"\"\n        src = tmp_path / \"orig.pdf\"\n        dst = tmp_path / \"clone.pdf\"\n>       _create_simple_pdf(src, num_pages=3)\n\ntests\\PyPDF\\functional_test.py:361: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\PyPDF\\functional_test.py:78: in _create_simple_pdf\n    writer.write(fp)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pypdf._writer.PdfWriter object at 0x000001ECD23989D0>\nstream = <_io.BufferedWriter name='C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-86152\\\\pytest-470\\\\test_clone_document_by_writing0\\\\orig.pdf'>\n\n    def write(self, stream: Union[str, IO[bytes], io.BufferedIOBase]):\n        \"\"\"\n        Serialise the current document into *stream*.\n    \n        *stream* may be:\n          \\u2022 a str / Path \\u2013 interpreted as a file path to open,\n          \\u2022 a binary file-like object.\n        \"\"\"\n        data = dumps_doc(\n            {\n                \"pages\": [p.to_dict() for p in self._pages],\n                \"metadata\": self._metadata,\n                \"encrypted\": self._encrypt_password is not None,\n                \"password\": self._encrypt_password or \"\",\n            }\n        )\n    \n>       if isinstance(stream, (str, bytes, io.PathLike)):\nE       AttributeError: module 'io' has no attribute 'PathLike'\n\ngeneration\\PyPDF\\pypdf\\_writer.py:73: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/PyPDF/functional_test.py::test_create_and_read_blank_pdf - Attri...\nFAILED tests/PyPDF/functional_test.py::test_blank_page_has_expected_size - At...\nFAILED tests/PyPDF/functional_test.py::test_merge_two_pdfs - AttributeError: ...\nFAILED tests/PyPDF/functional_test.py::test_writer_add_page_preserves_page_count\nFAILED tests/PyPDF/functional_test.py::test_rotate_page - AttributeError: mod...\nFAILED tests/PyPDF/functional_test.py::test_rotate_preserves_page_size - Attr...\nFAILED tests/PyPDF/functional_test.py::test_encrypt_and_decrypt - AttributeEr...\nFAILED tests/PyPDF/functional_test.py::test_encrypted_pdf_allows_page_access_after_decrypt\nFAILED tests/PyPDF/functional_test.py::test_metadata_roundtrip - AttributeErr...\nFAILED tests/PyPDF/functional_test.py::test_metadata_multiple_fields_roundtrip\nFAILED tests/PyPDF/functional_test.py::test_clone_document_by_writing_reader_pages\n11 failed, 1 skipped in 23.09s\n"}
{"model": "o3", "project": "Requests", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "TypeError", "exception_msg": "unsupported operand type(s) for |: 'type' and 'NoneType'", "returncode": 2, "elapsed_time_s": 2.080005, "avg_memory_mb": 37.86, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:51:51", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Requests/functional_test.py ______________\ntests\\Requests\\functional_test.py:40: in <module>\n    import requests  # noqa: E402\ngeneration\\Requests\\requests\\__init__.py:15: in <module>\n    from .api import delete, get, head, options, patch, post, put, request\ngeneration\\Requests\\requests\\api.py:33: in <module>\n    def get(url: str, params: dict | None = None, **kwargs):\nE   TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'\n=========================== short test summary info ===========================\nERROR tests/Requests/functional_test.py - TypeError: unsupported operand type...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.74s\n", "stdout_sha1": "9e6817a33217ddfc4c32361df530d91b45318ff6", "stdout_len": 820, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Requests/functional_test.py ______________\ntests\\Requests\\functional_test.py:40: in <module>\n    import requests  # noqa: E402\ngeneration\\Requests\\requests\\__init__.py:15: in <module>\n    from .api import delete, get, head, options, patch, post, put, request\ngeneration\\Requests\\requests\\api.py:33: in <module>\n    def get(url: str, params: dict | None = None, **kwargs):\nE   TypeError: unsupported operand type(s) for |: 'type' and 'NoneType'\n=========================== short test summary info ===========================\nERROR tests/Requests/functional_test.py - TypeError: unsupported operand type...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.74s\n"}
{"model": "o3", "project": "Rich", "failure_stage": "pre-test", "failure_type": "unknown_failure", "exception_type": "", "exception_msg": "", "returncode": 5, "elapsed_time_s": 1.507884, "avg_memory_mb": 31.53, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 1, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:53:36", "stdout_excerpt": "\n1 skipped in 0.17s\n", "stdout_sha1": "66bd18a62ec687100e9a9e996a20b12b6bd4dc1e", "stdout_len": 20, "stdout": "\n1 skipped in 0.17s\n"}
{"model": "o3", "project": "Schedule", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "repeat", "returncode": 1, "elapsed_time_s": 1.99909, "avg_memory_mb": 32.45, "avg_cpu_percent": 98.4, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 21:55:15", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\n        schedule.every().minutes.do(job2).tag(\"min\", \"common\")\n    \n>       jobs = schedule.get_jobs()\n\ntests\\Schedule\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'get_jobs'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: get_jobs\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n        schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\n        schedule.every().hour.do(job_drop).tag(\"drop\", \"group\")\n    \n>       drop_jobs = schedule.get_jobs(\"drop\")\n\ntests\\Schedule\\functional_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'get_jobs'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: get_jobs\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n        schedule.cancel_job(j2)\n    \n        schedule.run_all()\n        assert calls == [\"job1\"]\n>       assert j1 in schedule.get_jobs()\n\ntests\\Schedule\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'get_jobs'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: get_jobs\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\n\ntests\\Schedule\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'repeat'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: repeat\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    de", "stdout_sha1": "375c339c49bdab505959bfb921d7035525df3df1", "stdout_len": 6969, "stdout": "FFFF....FFF.                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_basic_every_and_run_all _________________________\n\n    def test_basic_every_and_run_all() -> None:\n        \"\"\"every(...).seconds/minutes + run_all execute jobs.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        schedule.every(5).seconds.do(job1).tag(\"sec\", \"common\")\n        schedule.every().minutes.do(job2).tag(\"min\", \"common\")\n    \n>       jobs = schedule.get_jobs()\n\ntests\\Schedule\\functional_test.py:100: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'get_jobs'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: get_jobs\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n_________________________ test_tags_and_clear_by_tag __________________________\n\n    def test_tags_and_clear_by_tag() -> None:\n        \"\"\"Jobs can be tagged, selected by tag, and cleared by tag.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job_keep() -> None:\n            calls.append(\"keep\")\n    \n        def job_drop() -> None:\n            calls.append(\"drop\")\n    \n        schedule.every().hour.do(job_keep).tag(\"keep\", \"group\")\n        schedule.every().hour.do(job_drop).tag(\"drop\", \"group\")\n    \n>       drop_jobs = schedule.get_jobs(\"drop\")\n\ntests\\Schedule\\functional_test.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'get_jobs'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: get_jobs\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n_____________________ test_cancel_job_removes_single_job ______________________\n\n    def test_cancel_job_removes_single_job() -> None:\n        \"\"\"cancel_job removes a single job from the scheduler.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job1() -> None:\n            calls.append(\"job1\")\n    \n        def job2() -> None:\n            calls.append(\"job2\")\n    \n        j1 = schedule.every().day.do(job1)\n        j2 = schedule.every().day.at(\"10:30\").do(job2)\n    \n        schedule.cancel_job(j2)\n    \n        schedule.run_all()\n        assert calls == [\"job1\"]\n>       assert j1 in schedule.get_jobs()\n\ntests\\Schedule\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'get_jobs'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: get_jobs\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n__________________ test_repeat_decorator_registers_and_runs ___________________\n\n    def test_repeat_decorator_registers_and_runs() -> None:\n        \"\"\"@repeat(every(...)) schedules a function correctly and run_all triggers it.\"\"\"\n        _clear()\n        call_count = 0\n    \n>       @schedule.repeat(schedule.every().seconds)\n\ntests\\Schedule\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'repeat'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: repeat\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n________________ test_every_to_creates_job_with_interval_range ________________\n\n    def test_every_to_creates_job_with_interval_range() -> None:\n        \"\"\"every(A).to(B).seconds should create a job and be runnable via run_all.\"\"\"\n        _clear()\n        calls: List[str] = []\n    \n        def job() -> None:\n            calls.append(\"x\")\n    \n>       j = schedule.every(2).to(5).seconds.do(job)\nE       AttributeError: 'Job' object has no attribute 'to'\n\ntests\\Schedule\\functional_test.py:239: AttributeError\n______________________ test_idle_seconds_returns_number _______________________\n\n    def test_idle_seconds_returns_number() -> None:\n        \"\"\"idle_seconds should return a numeric value when jobs exist.\"\"\"\n        _clear()\n    \n        def job() -> None:\n            return None\n    \n        schedule.every().hour.do(job)\n>       idle = schedule.idle_seconds()\n\ntests\\Schedule\\functional_test.py:254: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'idle_seconds'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: idle_seconds\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n_____________________ test_get_jobs_by_tag_filters_subset _____________________\n\n    def test_get_jobs_by_tag_filters_subset() -> None:\n        \"\"\"get_jobs(tag) should return only jobs with that tag.\"\"\"\n        _clear()\n    \n        def a() -> None:\n            return None\n    \n        def b() -> None:\n            return None\n    \n        schedule.every().minute.do(a).tag(\"alpha\")\n        schedule.every().minute.do(b).tag(\"beta\")\n    \n>       alpha_jobs = schedule.get_jobs(\"alpha\")\n\ntests\\Schedule\\functional_test.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nname = 'get_jobs'\n\n    def __getattr__(name: str) -> Any:  # noqa: D401\n        if name == \"datetime\":\n            return _datetime_module\n        if name == \"time\":\n            return _time_module\n>       raise AttributeError(name)\nE       AttributeError: get_jobs\n\ngeneration\\Schedule\\schedule\\__init__.py:463: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Schedule/functional_test.py::test_basic_every_and_run_all - Attr...\nFAILED tests/Schedule/functional_test.py::test_tags_and_clear_by_tag - Attrib...\nFAILED tests/Schedule/functional_test.py::test_cancel_job_removes_single_job\nFAILED tests/Schedule/functional_test.py::test_repeat_decorator_registers_and_runs\nFAILED tests/Schedule/functional_test.py::test_every_to_creates_job_with_interval_range\nFAILED tests/Schedule/functional_test.py::test_idle_seconds_returns_number - ...\nFAILED tests/Schedule/functional_test.py::test_get_jobs_by_tag_filters_subset\n7 failed, 5 passed in 0.56s\n"}
{"model": "o3", "project": "Slugify", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "AssertionError", "exception_msg": "assert 'this-is-a-test' in '___thisisatest___'", "returncode": 1, "elapsed_time_s": 1.705891, "avg_memory_mb": 32.16, "avg_cpu_percent": 100.0, "passed": 11, "failed": 1, "skipped": 0, "total": 12, "functional_score": 0.9167, "timestamp": "2026-01-01 21:56:00", "stdout_excerpt": "==== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.41s\n", "stdout_sha1": "89faf545b916353bffb5b0e7f3ed51902ec7a936", "stdout_len": 956, "stdout": ".......F....                                                             [100%]\n================================== FAILURES ===================================\n________________ test_regex_pattern_allows_underscore_prefixes ________________\n\n    def test_regex_pattern_allows_underscore_prefixes() -> None:\n        \"\"\"Custom regex_pattern can allow underscores to remain.\"\"\"\n        text = \"___This is a test___\"\n        regex_pattern = r\"[^-a-z0-9_]+\"\n    \n        result_default_sep = slugify(text, regex_pattern=regex_pattern)\n        assert result_default_sep.startswith(\"___\")\n>       assert \"this-is-a-test\" in result_default_sep\nE       AssertionError: assert 'this-is-a-test' in '___thisisatest___'\n\ntests\\Slugify\\functional_test.py:174: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Slugify/functional_test.py::test_regex_pattern_allows_underscore_prefixes\n1 failed, 11 passed in 0.41s\n"}
{"model": "o3", "project": "Sqlmap", "failure_stage": "in-test", "failure_type": "timeout", "exception_type": "AssertionError", "exception_msg": "+  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... stdout='', stderr='usage: sqlmap.py [-h] [-hh] [--version]\\nsqlmap.py: error: unrecognized arguments: --output-dir\\n').returncode", "returncode": 1, "elapsed_time_s": 3.236855, "avg_memory_mb": 31.97, "avg_cpu_percent": 53.5, "passed": 6, "failed": 3, "skipped": 0, "total": 9, "functional_score": 0.6667, "timestamp": "2026-01-01 21:56:57", "stdout_excerpt": "==== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x00000211BCF999D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-h] [-hh] [--version]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x00000211BCF999D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_importable():\n        \"\"\"\n        Alignment anchors (must exist in BOTH reference and generated repos):\n    \n          - lib.parse.cmdline.cmdLineParser\n          - lib.core.option.init, lib.core.option.initOptions\n          - lib.core.data: cmdLineOptions, conf, kb\n          - lib.core.settings: VERSION, DESCRIPTION\n          - lib.controller.controller.start\n    \n        Only checks importability + symbol presence; does not execute scanning logic.\n        \"\"\"\n        repo = _repo_root()\n        sys.path.insert(0, str(repo))\n        try:\n            from lib.parse.cmdline import cmdLineParser  # noqa: F401\n            from lib.core.option import init, initOptions  # noqa: F401\n            from lib.core.data import cmdLineOptions, conf, kb  # noqa: F401\n            from lib.core.settings import VERSION, DESCRIPTION  # noqa: F401\n            from lib.controller.controller import start  # noqa: F401\n    \n            assert callable(cmdLineParser)\n            assert callable(init)\n            assert callable(initOptions)\n>           assert cmdLineOptions is not None\nE           assert None is not None\n\ntests\\Sqlmap\\functional_test.py:119: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... stdout='', stderr='usage: sqlmap.py [-h] [-hh] [--version]\\nsqlmap.py: error: unrecognized arguments: --output-dir\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_007_alignment_api_surface_symbols_importable\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n3 failed, 6 passed in 1.91s\n", "stdout_sha1": "fd14a2a15ea3c4f3020dff77559b10a7848216af", "stdout_len": 3703, "stdout": "....F.F.F                                                                [100%]\n================================== FAILURES ===================================\n_____________ test_005_version_runs_and_prints_version_like_token _____________\n\n    def test_005_version_runs_and_prints_version_like_token():\n        \"\"\"\n        sqlmap --version may print a raw version token (e.g. 1.9.12.3#dev) and may also\n        print an 'exit' message. Do not require specific words like 'sqlmap'/'version'.\n        \"\"\"\n        # --batch helps avoid interactive prompts on some builds, but keep tolerance regardless.\n        p = _run_cli([\"--batch\", \"--version\"], timeout_s=30)\n        out = _out(p)\n    \n        # Require a version-like token such as \"1.9.12.3\" optionally with suffix \"#dev\"\n>       assert re.search(r\"\\b\\d+\\.\\d+(?:\\.\\d+){0,3}(?:#[a-z0-9]+)?\\b\", out) is not None\nE       AssertionError: assert None is not None\nE        +  where None = <function search at 0x00000211BCF999D0>('\\\\b\\\\d+\\\\.\\\\d+(?:\\\\.\\\\d+){0,3}(?:#[a-z0-9]+)?\\\\b', '\\nusage: sqlmap.py [-h] [-hh] [--version]\\nsqlmap.py: error: unrecognized arguments: --batch\\n')\nE        +    where <function search at 0x00000211BCF999D0> = re.search\n\ntests\\Sqlmap\\functional_test.py:80: AssertionError\n______________ test_007_alignment_api_surface_symbols_importable ______________\n\n    def test_007_alignment_api_surface_symbols_importable():\n        \"\"\"\n        Alignment anchors (must exist in BOTH reference and generated repos):\n    \n          - lib.parse.cmdline.cmdLineParser\n          - lib.core.option.init, lib.core.option.initOptions\n          - lib.core.data: cmdLineOptions, conf, kb\n          - lib.core.settings: VERSION, DESCRIPTION\n          - lib.controller.controller.start\n    \n        Only checks importability + symbol presence; does not execute scanning logic.\n        \"\"\"\n        repo = _repo_root()\n        sys.path.insert(0, str(repo))\n        try:\n            from lib.parse.cmdline import cmdLineParser  # noqa: F401\n            from lib.core.option import init, initOptions  # noqa: F401\n            from lib.core.data import cmdLineOptions, conf, kb  # noqa: F401\n            from lib.core.settings import VERSION, DESCRIPTION  # noqa: F401\n            from lib.controller.controller import start  # noqa: F401\n    \n            assert callable(cmdLineParser)\n            assert callable(init)\n            assert callable(initOptions)\n>           assert cmdLineOptions is not None\nE           assert None is not None\n\ntests\\Sqlmap\\functional_test.py:119: AssertionError\n__________ test_009_unicode_output_dir_argument_stable_in_help_mode ___________\n\n    def test_009_unicode_output_dir_argument_stable_in_help_mode():\n        root = _project_root()\n        out_dir = root / \"generation\" / \"Sqlmap\" / \"tmp_输出\"\n        out_dir.mkdir(parents=True, exist_ok=True)\n    \n        p = _run_cli([\"-h\", \"--output-dir\", str(out_dir)], timeout_s=30)\n>       assert p.returncode == 0\nE       AssertionError: assert 2 == 0\nE        +  where 2 = CompletedProcess(args=['C:\\\\Users\\\\86152\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\python.exe', 'D:\\\\桌面\\\\RealAppCod... stdout='', stderr='usage: sqlmap.py [-h] [-hh] [--version]\\nsqlmap.py: error: unrecognized arguments: --output-dir\\n').returncode\n\ntests\\Sqlmap\\functional_test.py:142: AssertionError\n=========================== short test summary info ===========================\nFAILED tests/Sqlmap/functional_test.py::test_005_version_runs_and_prints_version_like_token\nFAILED tests/Sqlmap/functional_test.py::test_007_alignment_api_surface_symbols_importable\nFAILED tests/Sqlmap/functional_test.py::test_009_unicode_output_dir_argument_stable_in_help_mode\n3 failed, 6 passed in 1.91s\n"}
{"model": "o3", "project": "SQLModel", "failure_stage": "pre-test", "failure_type": "collection_error", "exception_type": "AttributeError", "exception_msg": "'_Column' object has no attribute 'clear'", "returncode": 2, "elapsed_time_s": 1.819204, "avg_memory_mb": 36.39, "avg_cpu_percent": 100.0, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 21:58:30", "stdout_excerpt": "====\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: '_Column' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: '_Column' object ha...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.53s\n", "stdout_sha1": "d7bb3f1f64d05a42b6be7f7b8f6c3af9be9935b5", "stdout_len": 561, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/SQLModel/functional_test.py ______________\ntests\\SQLModel\\functional_test.py:34: in <module>\n    SQLModel.metadata.clear()\nE   AttributeError: '_Column' object has no attribute 'clear'\n=========================== short test summary info ===========================\nERROR tests/SQLModel/functional_test.py - AttributeError: '_Column' object ha...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.53s\n"}
{"model": "o3", "project": "Stegano", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute 'mode'", "returncode": 1, "elapsed_time_s": 3.930081, "avg_memory_mb": 35.68, "avg_cpu_percent": 99.15, "passed": 5, "failed": 7, "skipped": 0, "total": 12, "functional_score": 0.4167, "timestamp": "2026-01-01 22:00:16", "stdout_excerpt": "==== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is in RGB mode (3×8-bit) because the current\n        implementation depends on that layout.\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:27: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is in RGB mode (3×8-bit) because the current\n        implementation depends on that layout.\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:27: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is", "stdout_sha1": "812f033edf6affd49bb5ec9ee2c046a8a3a75787", "stdout_len": 9869, "stdout": "FFFFFF.....F                                                             [100%]\n================================== FAILURES ===================================\n________________________ test_lsb_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_lsb_hide_and_reveal_text0')\n\n    def test_lsb_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"lsb.hide(..., str) then lsb.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"hello world\"\n        output = tmp_path / \"lsb_lenna.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is in RGB mode (3×8-bit) because the current\n        implementation depends on that layout.\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:27: AttributeError\n___________________ test_lsb_hide_and_reveal_with_generator ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_lsb_hide_and_reveal_with_0')\n\n    def test_lsb_hide_and_reveal_with_generator(tmp_path: Path) -> None:\n        \"\"\"lsb hide/reveal with a deterministic generator.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"generator secret\"\n        output = tmp_path / \"lsb_generator.png\"\n    \n        gen = generators.eratosthenes()\n>       encoded_img = lsb.hide(str(LENNA_PNG), secret, generator=gen)\n\ntests\\Stegano\\functional_test.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is in RGB mode (3×8-bit) because the current\n        implementation depends on that layout.\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:27: AttributeError\n__________________ test_lsb_hide_and_reveal_long_ascii_text ___________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_lsb_hide_and_reveal_long_0')\n\n    def test_lsb_hide_and_reveal_long_ascii_text(tmp_path: Path) -> None:\n        \"\"\"LSB should roundtrip a longer ASCII text message (still < typical capacity).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"This is a longer secret message with punctuation: 12345, hello-world!\"\n        output = tmp_path / \"lsb_long.png\"\n    \n>       encoded_img = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is in RGB mode (3×8-bit) because the current\n        implementation depends on that layout.\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:27: AttributeError\n______________________ test_lsb_reveal_from_image_object ______________________\n\n    def test_lsb_reveal_from_image_object() -> None:\n        \"\"\"lsb.reveal should work when passed a PIL.Image object (common API usage).\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"object input\"\n>       img_obj = lsb.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is in RGB mode (3×8-bit) because the current\n        implementation depends on that layout.\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:27: AttributeError\n________________________ test_red_hide_and_reveal_text ________________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_red_hide_and_reveal_text0')\n\n    def test_red_hide_and_reveal_text(tmp_path: Path) -> None:\n        \"\"\"red.hide(..., str) then red.reveal(...) returns the same string.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"red secret\"\n        output = tmp_path / \"red_lenna.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\red\\red.py:28: in hide\n    img = _prepare_image(image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimg = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(img: Image.Image) -> Image.Image:\n>       if img.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\red\\red.py:19: AttributeError\n________________ test_red_hide_and_reveal_extended_latin_text _________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_red_hide_and_reveal_exten0')\n\n    def test_red_hide_and_reveal_extended_latin_text(tmp_path: Path) -> None:\n        \"\"\"Red backend stores per-char ord() into a byte channel; Latin-1 chars like 'é' are valid.\"\"\"\n        _ensure_image_samples_exist()\n    \n        secret = \"Café au lait\"\n        output = tmp_path / \"red_latin.png\"\n    \n>       encoded_img = red.hide(str(LENNA_PNG), secret)\n\ntests\\Stegano\\functional_test.py:162: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\red\\red.py:28: in hide\n    img = _prepare_image(image)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimg = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(img: Image.Image) -> Image.Image:\n>       if img.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\red\\red.py:19: AttributeError\n_____________________ test_lsb_and_red_outputs_are_files ______________________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-473/test_lsb_and_red_outputs_are_f0')\n\n    def test_lsb_and_red_outputs_are_files(tmp_path: Path) -> None:\n        \"\"\"Ensure image-encoding backends produce files that can be written to disk.\"\"\"\n        _ensure_image_samples_exist()\n    \n        out_lsb = tmp_path / \"lsb_file.png\"\n        out_red = tmp_path / \"red_file.png\"\n    \n>       lsb.hide(str(LENNA_PNG), \"x\").save(str(out_lsb))\n\ntests\\Stegano\\functional_test.py:268: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:94: in hide\n    img = _prepare_image(image, auto_convert_rgb=auto_convert_rgb)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nimage = 'D:\\\\桌面\\\\RealAppCodeBench_generic_eval\\\\repositories\\\\Stegano\\\\tests\\\\sample-files\\\\Lenna.png'\n\n    def _prepare_image(\n        image: Image.Image, *, auto_convert_rgb: bool = False\n    ) -> Image.Image:\n        \"\"\"\n        Makes sure the supplied image is in RGB mode (3×8-bit) because the current\n        implementation depends on that layout.\n        \"\"\"\n>       if image.mode != \"RGB\":\nE       AttributeError: 'str' object has no attribute 'mode'\n\ngeneration\\Stegano\\stegano\\lsb\\lsb.py:27: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_with_generator\nFAILED tests/Stegano/functional_test.py::test_lsb_hide_and_reveal_long_ascii_text\nFAILED tests/Stegano/functional_test.py::test_lsb_reveal_from_image_object - ...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_text - Attr...\nFAILED tests/Stegano/functional_test.py::test_red_hide_and_reveal_extended_latin_text\nFAILED tests/Stegano/functional_test.py::test_lsb_and_red_outputs_are_files\n7 failed, 5 passed in 2.50s\n"}
{"model": "o3", "project": "Tablib", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)", "returncode": 2, "elapsed_time_s": 1.88665, "avg_memory_mb": 36.2, "avg_cpu_percent": 95.6, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 22:01:07", "stdout_excerpt": "====\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:10: in <module>\n    from .core import Dataset, Databook        # noqa: F401\ngeneration\\Tablib\\tablib\\core.py:13: in <module>\n    from .formats import _csv as csv_format\ngeneration\\Tablib\\tablib\\formats\\_csv.py:9: in <module>\n    from ..core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n", "stdout_sha1": "7c0c29ec678711218d1864362f580296d672d856", "stdout_len": 1325, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/Tablib/functional_test.py _______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Tablib\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Tablib\\functional_test.py:59: in <module>\n    import tablib  # type: ignore  # noqa: E402\ngeneration\\Tablib\\tablib\\__init__.py:10: in <module>\n    from .core import Dataset, Databook        # noqa: F401\ngeneration\\Tablib\\tablib\\core.py:13: in <module>\n    from .formats import _csv as csv_format\ngeneration\\Tablib\\tablib\\formats\\_csv.py:9: in <module>\n    from ..core import Dataset\nE   ImportError: cannot import name 'Dataset' from partially initialized module 'tablib.core' (most likely due to a circular import) (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Tablib\\tablib\\core.py)\n=========================== short test summary info ===========================\nERROR tests/Tablib/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n"}
{"model": "o3", "project": "Tabulate", "failure_stage": "in-test", "failure_type": "assertion_failure", "exception_type": "TypeError", "exception_msg": "tabulate() got an unexpected keyword argument 'maxcolwidths'", "returncode": 1, "elapsed_time_s": 1.812845, "avg_memory_mb": 33.23, "avg_cpu_percent": 100.0, "passed": 7, "failed": 5, "skipped": 0, "total": 12, "functional_score": 0.5833, "timestamp": "2026-01-01 22:02:30", "stdout_excerpt": "==== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n        assert lines[0].strip().startswith(\"Name\")\n        assert \"Age\" in lines[0]\n        # separator line usually contains dashes\n>       assert \"-\" in lines[1].replace(\" \", \"\")\nE       AssertionError: assert '-' in 'Alice24'\nE        +  where 'Alice24' = <built-in method replace of str object at 0x0000024BE0E16BF0>(' ', '')\nE        +    where <built-in method replace of str object at 0x0000024BE0E16BF0> = 'Alice  24'.replace\n\ntests\\Tabulate\\functional_test.py:123: AssertionError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'key  value           '\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['spam', 42], ['eggs', 451], ['bacon', 0]]\nheaders = ['item', 'qty'], tablefmt = 'github', showindex = False\nstralign = 'left', numalign = 'decimal', floatfmt = 'g', missingval = ''\n\n    def tabulate(\n        tabular_data: Any,\n        headers: Any = (),\n        tablefmt: str = \"simple\",\n        showindex: bool | Sequence[Any] = False,\n        stralign: str | None = \"left\",\n        numalign: str | None = \"decimal\",\n        floatfmt: str = \"g\",\n        missingval: str = \"\",\n    ) -> str:\n        \"\"\"\n        Format *tabular_data* into a table.\n    \n        Only a subset of arguments of the original *tabulate* function\n        is implemented, but the most frequently used ones are present.\n        \"\"\"\n    \n        fmt = TABLE_FORMATS.get(tablefmt)\n        if fmt is None:\n>           raise ValueError(f\"Unknown table format {tablefmt!r}\")\nE           ValueError: Unknown table format 'github'\n\ngeneration\\Tabulate\\tabulate\\core.py:173: ValueError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functio", "stdout_sha1": "9e97e02e54d565befcbacae9bbad246bc35596c7", "stdout_len": 4519, "stdout": "..FF.F...FF.                                                             [100%]\n================================== FAILURES ===================================\n___________________ test_headers_firstrow_and_simple_format ___________________\n\n    def test_headers_firstrow_and_simple_format() -> None:\n        table = [\n            [\"Name\", \"Age\"],\n            [\"Alice\", 24],\n            [\"Bob\", 19],\n        ]\n    \n        output = tabulate(table, headers=\"firstrow\", tablefmt=\"simple\")\n        lines = _lines(output)\n    \n        assert lines[0].strip().startswith(\"Name\")\n        assert \"Age\" in lines[0]\n        # separator line usually contains dashes\n>       assert \"-\" in lines[1].replace(\" \", \"\")\nE       AssertionError: assert '-' in 'Alice24'\nE        +  where 'Alice24' = <built-in method replace of str object at 0x0000024BE0E16BF0>(' ', '')\nE        +    where <built-in method replace of str object at 0x0000024BE0E16BF0> = 'Alice  24'.replace\n\ntests\\Tabulate\\functional_test.py:123: AssertionError\n___________________ test_headers_keys_on_dict_of_iterables ____________________\n\n    def test_headers_keys_on_dict_of_iterables() -> None:\n        table = {\n            \"Name\": [\"Alice\", \"Bob\"],\n            \"Age\": [24, 19],\n        }\n    \n        output = tabulate(table, headers=\"keys\")\n        lines = _lines(output)\n    \n>       assert \"Name\" in lines[0]\nE       AssertionError: assert 'Name' in 'key  value           '\n\ntests\\Tabulate\\functional_test.py:137: AssertionError\n________________________ test_github_and_grid_formats _________________________\n\n    def test_github_and_grid_formats() -> None:\n        table = [\n            [\"item\", \"qty\"],\n            [\"spam\", 42],\n            [\"eggs\", 451],\n            [\"bacon\", 0],\n        ]\n    \n>       out_github = tabulate(table[1:], headers=table[0], tablefmt=\"github\")\n\ntests\\Tabulate\\functional_test.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntabular_data = [['spam', 42], ['eggs', 451], ['bacon', 0]]\nheaders = ['item', 'qty'], tablefmt = 'github', showindex = False\nstralign = 'left', numalign = 'decimal', floatfmt = 'g', missingval = ''\n\n    def tabulate(\n        tabular_data: Any,\n        headers: Any = (),\n        tablefmt: str = \"simple\",\n        showindex: bool | Sequence[Any] = False,\n        stralign: str | None = \"left\",\n        numalign: str | None = \"decimal\",\n        floatfmt: str = \"g\",\n        missingval: str = \"\",\n    ) -> str:\n        \"\"\"\n        Format *tabular_data* into a table.\n    \n        Only a subset of arguments of the original *tabulate* function\n        is implemented, but the most frequently used ones are present.\n        \"\"\"\n    \n        fmt = TABLE_FORMATS.get(tablefmt)\n        if fmt is None:\n>           raise ValueError(f\"Unknown table format {tablefmt!r}\")\nE           ValueError: Unknown table format 'github'\n\ngeneration\\Tabulate\\tabulate\\core.py:173: ValueError\n_______________ test_disable_numparse_preserves_numeric_strings _______________\n\n    def test_disable_numparse_preserves_numeric_strings() -> None:\n        rows = [\n            [\"code\", \"value\"],\n            [\"A\", \"001\"],\n            [\"B\", \"010\"],\n        ]\n>       output = tabulate(rows[1:], headers=rows[0], tablefmt=\"plain\", disable_numparse=True)\nE       TypeError: tabulate() got an unexpected keyword argument 'disable_numparse'\n\ntests\\Tabulate\\functional_test.py:236: TypeError\n______________________ test_maxcolwidths_wraps_long_text ______________________\n\n    def test_maxcolwidths_wraps_long_text() -> None:\n        long_text = \"alpha beta gamma delta epsilon zeta\"\n        rows = [\n            [\"id\", \"note\"],\n            [1, long_text],\n            [2, \"short\"],\n        ]\n>       output = tabulate(\n            rows[1:],\n            headers=rows[0],\n            tablefmt=\"simple\",\n            maxcolwidths=[None, 10],\n        )\nE       TypeError: tabulate() got an unexpected keyword argument 'maxcolwidths'\n\ntests\\Tabulate\\functional_test.py:251: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Tabulate/functional_test.py::test_headers_firstrow_and_simple_format\nFAILED tests/Tabulate/functional_test.py::test_headers_keys_on_dict_of_iterables\nFAILED tests/Tabulate/functional_test.py::test_github_and_grid_formats - Valu...\nFAILED tests/Tabulate/functional_test.py::test_disable_numparse_preserves_numeric_strings\nFAILED tests/Tabulate/functional_test.py::test_maxcolwidths_wraps_long_text\n5 failed, 7 passed in 0.50s\n"}
{"model": "o3", "project": "Termgraph", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "every series must have the same length as labels", "returncode": 1, "elapsed_time_s": 24.345501, "avg_memory_mb": 32.83, "avg_cpu_percent": 0.72, "passed": 0, "failed": 11, "skipped": 0, "total": 11, "functional_score": 0.0, "timestamp": "2026-01-01 22:04:02", "stdout_excerpt": "==== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD27BFD0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd282490>\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD2F48E0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd2f4c40>\nlabels = [[1, 2], [3, 4]], series = ['X', 'Y']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD282BB0>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd27ce80>\nlabels = [[4], [1]], series = ['D', 'E']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n___________________ test_bar_chart_respects_no_values_flag _______", "stdout_sha1": "d9304655bc9171a3ed92b9d6fa446162598ba317", "stdout_len": 15901, "stdout": "FFFFFFFFFFF                                                              [100%]\n================================== FAILURES ===================================\n______________________ test_simple_horizontal_bar_chart _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD27BFD0>\n\n    def test_simple_horizontal_bar_chart(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\", \"C\"]\n        values = [[3], [5], [2]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd282490>\nlabels = [[3], [5], [2]], series = ['A', 'B', 'C']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n_____________________ test_stacked_chart_multiple_series ______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD2F48E0>\n\n    def test_stacked_chart_multiple_series(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"X\", \"Y\"]\n        values = [[1, 2], [3, 4]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:107: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd2f4c40>\nlabels = [[1, 2], [3, 4]], series = ['X', 'Y']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n_______________________ test_bar_chart_object_interface _______________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD282BB0>\n\n    def test_bar_chart_object_interface(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"D\", \"E\"]\n        values = [[4], [1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:123: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd27ce80>\nlabels = [[4], [1]], series = ['D', 'E']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n___________________ test_bar_chart_respects_no_values_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD26D070>\n\n    def test_bar_chart_respects_no_values_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[2], [7]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:139: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd26d370>\nlabels = [[2], [7]], series = ['A', 'B']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n___________________ test_bar_chart_respects_no_labels_flag ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD2F56A0>\n\n    def test_bar_chart_respects_no_labels_flag(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"L1\", \"L2\", \"L3\"]\n        values = [[1], [2], [3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:155: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd2f5160>\nlabels = [[1], [2], [3]], series = ['L1', 'L2', 'L3']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n__________________ test_bar_chart_suffix_appended_to_values ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD26DA30>\n\n    def test_bar_chart_suffix_appended_to_values(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"CPU\", \"RAM\"]\n        values = [[12.5], [7.0]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd26d280>\nlabels = [[12.5], [7.0]], series = ['CPU', 'RAM']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n___________ test_bar_chart_custom_format_changes_numeric_rendering ____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD25D1F0>\n\n    def test_bar_chart_custom_format_changes_numeric_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"P\", \"Q\"]\n        values = [[3.14159], [2.71828]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:188: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd3423a0>\nlabels = [[3.14159], [2.71828]], series = ['P', 'Q']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n____________________ test_stacked_chart_renders_all_labels ____________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD343BB0>\n\n    def test_stacked_chart_renders_all_labels(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"S1\", \"S2\", \"S3\"]\n        values = [[1, 1], [2, 1], [1, 3]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd343c40>\nlabels = [[1, 1], [2, 1], [1, 3]], series = ['S1', 'S2', 'S3']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n____________ test_stacked_chart_no_values_still_renders_structure _____________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD342B20>\n\n    def test_stacked_chart_no_values_still_renders_structure(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"A\", \"B\"]\n        values = [[1, 2, 3], [3, 2, 1]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd3429d0>\nlabels = [[1, 2, 3], [3, 2, 1]], series = ['A', 'B']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n__________________ test_title_none_does_not_break_rendering ___________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD34D400>\n\n    def test_title_none_does_not_break_rendering(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"U\", \"V\"]\n        values = [[4], [6]]\n    \n>       data = Data(values, labels)\n\ntests\\Termgraph\\functional_test.py:235: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[AttributeError(\"'Data' object has no attribute 'labels'\") raised in repr()] Data object at 0x2bcfd34d2e0>\nlabels = [[4], [6]], series = ['U', 'V']\n\n    def __init__(self, labels, series):\n        if not isinstance(labels, (list, tuple)):\n            raise TypeError(\"labels must be a sequence\")\n    \n        if not isinstance(series, (list, tuple)):\n            raise TypeError(\"series must be a sequence of sequences\")\n    \n        # Basic sanity ---------------------------------------------------------\n        row_count = len(labels)\n        for s in series:\n            if len(s) != row_count:\n>               raise ValueError(\"every series must have the same length as labels\")\nE               ValueError: every series must have the same length as labels\n\ngeneration\\Termgraph\\termgraph\\data.py:33: ValueError\n________________ test_width_parameter_affects_output_presence _________________\n\ncapsys = <_pytest.capture.CaptureFixture object at 0x000002BCFD335040>\n\n    def test_width_parameter_affects_output_presence(capsys: pytest.CaptureFixture[str]) -> None:\n        labels = [\"W\"]\n        values = [[9]]\n    \n        data = Data(values, labels)\n    \n        args_narrow = _make_args(title=\"Narrow\", width=5, format=\"{:>4.1f}\")\n>       BarChart(data, args_narrow).draw()\n\ntests\\Termgraph\\functional_test.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <termgraph.charts.BarChart object at 0x000002BCFD335070>\ndata = Data(labels=[[9]], series=[['W']])\nargs = Args(width=5, stacked=False, different_scale=False, no_labels=False, format='{:>4.1f}', suffix='', vertical=False, histogram=False, no_values=False, color=None, labels=None, title='Narrow')\nstream = None\n\n    def __init__(self, data: Data, args: Args, stream=None):\n        self.data = data\n        self.args = args\n        self.stream = stream if stream is not None else sys.stdout\n    \n        # Prepare values -------------------------------------------------------\n        # Flatten to compute a global maximum when `different_scale` is False.\n        if not args.different_scale:\n            flat_values = list(itertools.chain.from_iterable(self.data.series))\n            # Avoid division by zero.  Use 1 to make every bar zero width.\n>           self._global_max = max(max(flat_values), 1)\nE           TypeError: '>' not supported between instances of 'int' and 'str'\n\ngeneration\\Termgraph\\termgraph\\charts.py:37: TypeError\n=========================== short test summary info ===========================\nFAILED tests/Termgraph/functional_test.py::test_simple_horizontal_bar_chart\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_multiple_series\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_object_interface - ...\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_values_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_respects_no_labels_flag\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_suffix_appended_to_values\nFAILED tests/Termgraph/functional_test.py::test_bar_chart_custom_format_changes_numeric_rendering\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_renders_all_labels\nFAILED tests/Termgraph/functional_test.py::test_stacked_chart_no_values_still_renders_structure\nFAILED tests/Termgraph/functional_test.py::test_title_none_does_not_break_rendering\nFAILED tests/Termgraph/functional_test.py::test_width_parameter_affects_output_presence\n11 failed in 0.68s\n"}
{"model": "o3", "project": "TheFuck", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "TypeError", "exception_msg": "dataclass() got an unexpected keyword argument 'slots'", "returncode": 1, "elapsed_time_s": 50.209131, "avg_memory_mb": 33.42, "avg_cpu_percent": 0.38, "passed": 2, "failed": 10, "skipped": 0, "total": 12, "functional_score": 0.1667, "timestamp": "2026-01-01 22:06:20", "stdout_excerpt": "==== FAILURES ===================================\n_______________________ test_001_import_thefuck_package _______________________\n\n    def test_001_import_thefuck_package() -> None:\n>       import thefuck  # noqa: F401\n\ntests\\TheFuck\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen impor", "stdout_sha1": "42d440e6b77bfc17db65b98114eabc881c7f4a27", "stdout_len": 22753, "stdout": "FFFFFFFFFF..                                                             [100%]\n================================== FAILURES ===================================\n_______________________ test_001_import_thefuck_package _______________________\n\n    def test_001_import_thefuck_package() -> None:\n>       import thefuck  # noqa: F401\n\ntests\\TheFuck\\functional_test.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n___________________ test_002_import_no_command_rule_module ____________________\n\n    def test_002_import_no_command_rule_module() -> None:\n>       importlib.import_module(\"thefuck.rules.no_command\")\n\ntests\\TheFuck\\functional_test.py:116: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n_____________ test_003_no_command_match_returns_bool_windows_like _____________\n\n    def test_003_no_command_match_returns_bool_windows_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n______________ test_004_no_command_match_returns_bool_bash_like _______________\n\n    def test_004_no_command_match_returns_bool_bash_like() -> None:\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n______ test_005_no_command_like_rule_matches_at_least_one_typical_output ______\n\n    def test_005_no_command_like_rule_matches_at_least_one_typical_output() -> None:\n        \"\"\"\n        Ensure the reference no_command rule actually matches a typical 'command not found' output.\n        We check both Windows and bash variants, and require at least one to match.\n        \"\"\"\n>       match_fn, _ = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n___________ test_006_no_command_get_new_command_returns_string_like ___________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-474/test_006_no_command_get_new_co0')\n\n    def test_006_no_command_get_new_command_returns_string_like(tmp_path: Path) -> None:\n        \"\"\"\n        get_new_command should return something string-like (or iterable of strings).\n        Do not require a specific suggestion yet.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:164: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n________ test_007_no_command_suggests_python_when_only_python_in_path _________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-474/test_007_no_command_suggests_p0')\n\n    def test_007_no_command_suggests_python_when_only_python_in_path(tmp_path: Path) -> None:\n        \"\"\"\n        With PATH constrained to a directory containing only python.cmd,\n        the best correction for 'pythno' should include 'python' in the suggestion.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n_______________ test_008_no_command_suggestion_is_deterministic _______________\n\ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-474/test_008_no_command_suggestion0')\n\n    def test_008_no_command_suggestion_is_deterministic(tmp_path: Path) -> None:\n        \"\"\"\n        Same input should yield same first suggestion in a controlled PATH.\n        \"\"\"\n>       _, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:202: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n_____________ test_009_no_command_does_not_crash_on_empty_output ______________\n\n    def test_009_no_command_does_not_crash_on_empty_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:218: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n_________________ test_010_no_command_handles_unicode_output __________________\n\n    def test_010_no_command_handles_unicode_output() -> None:\n>       match_fn, get_new_fn = _import_no_command_rule()\n\ntests\\TheFuck\\functional_test.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\TheFuck\\functional_test.py:42: in _import_no_command_rule\n    mod = importlib.import_module(\"thefuck.rules.no_command\")\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:972: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\n<frozen importlib._bootstrap_external>:790: in exec_module\n    ???\n<frozen importlib._bootstrap>:228: in _call_with_frames_removed\n    ???\ngeneration\\TheFuck\\thefuck\\__init__.py:21: in <module>\n    from .command import Command           # Re-export for the tests\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    \"\"\"\n    Very small re-implementation of the *Command* helper from *The Fuck*.\n    \n    It is nothing more than a glorified named-tuple but with a few convenience\n    methods that the rules can rely on.\n    \"\"\"\n    from __future__ import annotations\n    from dataclasses import dataclass\n    \n    \n>   @dataclass(slots=True)\nE   TypeError: dataclass() got an unexpected keyword argument 'slots'\n\ngeneration\\TheFuck\\thefuck\\command.py:11: TypeError\n=========================== short test summary info ===========================\nFAILED tests/TheFuck/functional_test.py::test_001_import_thefuck_package - Ty...\nFAILED tests/TheFuck/functional_test.py::test_002_import_no_command_rule_module\nFAILED tests/TheFuck/functional_test.py::test_003_no_command_match_returns_bool_windows_like\nFAILED tests/TheFuck/functional_test.py::test_004_no_command_match_returns_bool_bash_like\nFAILED tests/TheFuck/functional_test.py::test_005_no_command_like_rule_matches_at_least_one_typical_output\nFAILED tests/TheFuck/functional_test.py::test_006_no_command_get_new_command_returns_string_like\nFAILED tests/TheFuck/functional_test.py::test_007_no_command_suggests_python_when_only_python_in_path\nFAILED tests/TheFuck/functional_test.py::test_008_no_command_suggestion_is_deterministic\nFAILED tests/TheFuck/functional_test.py::test_009_no_command_does_not_crash_on_empty_output\nFAILED tests/TheFuck/functional_test.py::test_010_no_command_handles_unicode_output\n10 failed, 2 passed in 25.40s\n"}
{"model": "o3", "project": "TinyDB", "failure_stage": "pre-test", "failure_type": "syntax_error", "exception_type": "SyntaxError", "exception_msg": "invalid syntax", "returncode": 2, "elapsed_time_s": 2.103883, "avg_memory_mb": 36.98, "avg_cpu_percent": 97.7, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 22:07:20", "stdout_excerpt": "====\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\ngeneration\\TinyDB\\tinydb\\__init__.py:16: in <module>\n    from .database import TinyDB\ngeneration\\TinyDB\\tinydb\\database.py:11: in <module>\n    from .table import Table\ngeneration\\TinyDB\\tinydb\\table.py:19: in <module>\n    from .queries import Condition\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\queries.py\", line 127\nE       def _drill(self, document: dict, default=_Ellipsis := object()):\nE                                                          ^\nE   SyntaxError: invalid syntax\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.71s\n", "stdout_sha1": "787591983f17bccfbad139bb5dd4246613d491d8", "stdout_len": 1871, "stdout": "\n=================================== ERRORS ====================================\n______________ ERROR collecting tests/TinyDB/functional_test.py _______________\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986: in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n    exec(co, module.__dict__)\ntests\\TinyDB\\functional_test.py:49: in <module>\n    from tinydb import TinyDB, Query, where  # type: ignore  # noqa: E402\ngeneration\\TinyDB\\tinydb\\__init__.py:16: in <module>\n    from .database import TinyDB\ngeneration\\TinyDB\\tinydb\\database.py:11: in <module>\n    from .table import Table\ngeneration\\TinyDB\\tinydb\\table.py:19: in <module>\n    from .queries import Condition\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\TinyDB\\tinydb\\queries.py\", line 127\nE       def _drill(self, document: dict, default=_Ellipsis := object()):\nE                                                          ^\nE   SyntaxError: invalid syntax\n=========================== short test summary info ===========================\nERROR tests/TinyDB/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.71s\n"}
{"model": "o3", "project": "Typer", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "AttributeError", "exception_msg": "'str' object has no attribute '__name__'", "returncode": 1, "elapsed_time_s": 23.340025, "avg_memory_mb": 37.86, "avg_cpu_percent": 0.82, "passed": 0, "failed": 12, "skipped": 0, "total": 12, "functional_score": 0.0, "timestamp": "2026-01-01 22:08:52", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: 'NoneType' object is not callable\n\ntests\\Typer\\functional_test.py:70: TypeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: 'NoneType' object is not callable\n\ntests\\Typer\\functional_test.py:70: TypeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: 'NoneType' object is not callable\n\ntests\\Typer\\functional_test.py:70: TypeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n>       app = _create_todo_app()\n\ntests\\Typer\\functional_test.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:92: in _create_todo_app\n    def add(title: str) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2994: in __init__\n    super().__init__(param_decls, required=required, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA56A520>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n>       app = _create_todo_app()\n\ntests\\Typer\\functional_test.py:228: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:92: in _create_todo_app\n    def add(title: str) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Loc", "stdout_sha1": "a99575851a90edf86ff9fbec4e7335026e8c0642", "stdout_len": 15879, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_simple_hello_command __________________________\n\n    def test_simple_hello_command() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: 'NoneType' object is not callable\n\ntests\\Typer\\functional_test.py:70: TypeError\n______________________ test_simple_hello_command_excited ______________________\n\n    def test_simple_hello_command_excited() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: 'NoneType' object is not callable\n\ntests\\Typer\\functional_test.py:70: TypeError\n_______________ test_greeter_help_mentions_option_and_argument ________________\n\n    def test_greeter_help_mentions_option_and_argument() -> None:\n>       app = _create_greeter_app()\n\ntests\\Typer\\functional_test.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_greeter_app() -> typer.Typer:\n        \"\"\"\n        Single-command style app (callback-only):\n          app NAME [--excited]\n        \"\"\"\n        app = typer.Typer()\n    \n>       @app.callback(invoke_without_command=True)\nE       TypeError: 'NoneType' object is not callable\n\ntests\\Typer\\functional_test.py:70: TypeError\n_____________________ test_todo_list_empty_shows_no_tasks _____________________\n\n    def test_todo_list_empty_shows_no_tasks() -> None:\n>       app = _create_todo_app()\n\ntests\\Typer\\functional_test.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:92: in _create_todo_app\n    def add(title: str) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2994: in __init__\n    super().__init__(param_decls, required=required, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA56A520>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n___________________________ test_todo_add_and_list ____________________________\n\n    def test_todo_add_and_list() -> None:\n>       app = _create_todo_app()\n\ntests\\Typer\\functional_test.py:228: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:92: in _create_todo_app\n    def add(title: str) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2994: in __init__\n    super().__init__(param_decls, required=required, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCAFC1AF0>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n_____________________ test_todo_remove_then_list_updates ______________________\n\n    def test_todo_remove_then_list_updates() -> None:\n>       app = _create_todo_app()\n\ntests\\Typer\\functional_test.py:246: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:92: in _create_todo_app\n    def add(title: str) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2994: in __init__\n    super().__init__(param_decls, required=required, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA4AF1C0>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n_____________________ test_help_output_includes_commands ______________________\n\n    def test_help_output_includes_commands() -> None:\n>       app = _create_todo_app()\n\ntests\\Typer\\functional_test.py:262: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:92: in _create_todo_app\n    def add(title: str) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2994: in __init__\n    super().__init__(param_decls, required=required, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA5D3A00>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n_______________ test_subcommand_help_for_add_mentions_argument ________________\n\n    def test_subcommand_help_for_add_mentions_argument() -> None:\n>       app = _create_todo_app()\n\ntests\\Typer\\functional_test.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:92: in _create_todo_app\n    def add(title: str) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2994: in __init__\n    super().__init__(param_decls, required=required, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA585520>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n________________________ test_prompt_option_happy_path ________________________\n\n    def test_prompt_option_happy_path() -> None:\n>       app = _create_prompt_app()\n\ntests\\Typer\\functional_test.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:120: in _create_prompt_app\n    def greet(\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:130: in _build_click_params\n    option = click.Option(list(decls), **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2536: in __init__\n    super().__init__(param_decls, type=type, multiple=multiple, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA72F3D0>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n________________________ test_envvar_option_happy_path ________________________\n\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000021BCA49F070>\n\n    def test_envvar_option_happy_path(monkeypatch: pytest.MonkeyPatch) -> None:\n>       app = _create_env_app()\n\ntests\\Typer\\functional_test.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:144: in _create_env_app\n    def show(token: str = typer.Option(..., \"--token\", envvar=\"APP_TOKEN\")) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:130: in _build_click_params\n    option = click.Option(list(decls), **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2536: in __init__\n    super().__init__(param_decls, type=type, multiple=multiple, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA49F100>, func = 'str'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n_____________ test_callback_global_option_affects_command_output ______________\n\n    def test_callback_global_option_affects_command_output() -> None:\n>       app = _create_callback_app()\n\ntests\\Typer\\functional_test.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def _create_callback_app() -> typer.Typer:\n        \"\"\"App with a callback global option that influences command output.\"\"\"\n        app = typer.Typer()\n        state: Dict[str, bool] = {\"verbose\": False}\n    \n>       @app.callback()\nE       TypeError: 'NoneType' object is not callable\n\ntests\\Typer\\functional_test.py:159: TypeError\n____________________ test_typed_arguments_and_float_option ____________________\n\n    def test_typed_arguments_and_float_option() -> None:\n>       app = _create_types_app()\n\ntests\\Typer\\functional_test.py:310: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Typer\\functional_test.py:181: in _create_types_app\n    def calc(x: int, y: int, scale: float = typer.Option(1.0, \"--scale\")) -> None:\ngeneration\\Typer\\typer\\__init__.py:196: in decorator\n    params = _build_click_params(fn)\ngeneration\\Typer\\typer\\__init__.py:160: in _build_click_params\n    argument = click.Argument(decls, **kwargs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2994: in __init__\n    super().__init__(param_decls, required=required, **attrs)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\core.py:2114: in __init__\n    self.type: types.ParamType = types.convert_type(type, default)\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:1056: in convert_type\n    return FuncParamType(ty)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <click.types.FuncParamType object at 0x0000021BCA610E50>, func = 'int'\n\n    def __init__(self, func: t.Callable[[t.Any], t.Any]) -> None:\n>       self.name: str = func.__name__\nE       AttributeError: 'str' object has no attribute '__name__'\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\click\\types.py:166: AttributeError\n=========================== short test summary info ===========================\nFAILED tests/Typer/functional_test.py::test_simple_hello_command - TypeError:...\nFAILED tests/Typer/functional_test.py::test_simple_hello_command_excited - Ty...\nFAILED tests/Typer/functional_test.py::test_greeter_help_mentions_option_and_argument\nFAILED tests/Typer/functional_test.py::test_todo_list_empty_shows_no_tasks - ...\nFAILED tests/Typer/functional_test.py::test_todo_add_and_list - AttributeErro...\nFAILED tests/Typer/functional_test.py::test_todo_remove_then_list_updates - A...\nFAILED tests/Typer/functional_test.py::test_help_output_includes_commands - A...\nFAILED tests/Typer/functional_test.py::test_subcommand_help_for_add_mentions_argument\nFAILED tests/Typer/functional_test.py::test_prompt_option_happy_path - Attrib...\nFAILED tests/Typer/functional_test.py::test_envvar_option_happy_path - Attrib...\nFAILED tests/Typer/functional_test.py::test_callback_global_option_affects_command_output\nFAILED tests/Typer/functional_test.py::test_typed_arguments_and_float_option\n12 failed in 1.69s\n"}
{"model": "o3", "project": "Watchdog", "failure_stage": "pre-test", "failure_type": "import_error", "exception_type": "ImportError", "exception_msg": "cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)", "returncode": 2, "elapsed_time_s": 1.881115, "avg_memory_mb": 36.18, "avg_cpu_percent": 101.8, "passed": 0, "failed": 0, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 22:10:09", "stdout_excerpt": "====\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n", "stdout_sha1": "d4bb50f171ace793db32b44ef1161ab7b4cfaad5", "stdout_len": 1016, "stdout": "\n=================================== ERRORS ====================================\n_____________ ERROR collecting tests/Watchdog/functional_test.py ______________\nImportError while importing test module 'D:\\桌面\\RealAppCodeBench_generic_eval\\tests\\Watchdog\\functional_test.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests\\Watchdog\\functional_test.py:55: in <module>\n    from watchdog.events import (  # type: ignore  # noqa: E402\nE   ImportError: cannot import name 'PatternMatchingEventHandler' from 'watchdog.events' (D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Watchdog\\watchdog\\events.py)\n=========================== short test summary info ===========================\nERROR tests/Watchdog/functional_test.py\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.59s\n"}
{"model": "o3", "project": "Xmltodict", "failure_stage": "in-test", "failure_type": "runtime_exception", "exception_type": "ValueError", "exception_msg": "too many values to unpack (expected 2)", "returncode": 124, "elapsed_time_s": 60.019536, "avg_memory_mb": 32.95, "avg_cpu_percent": 0.25, "passed": 0, "failed": 1, "skipped": 0, "total": 1, "functional_score": 0.0, "timestamp": "2026-01-01 22:12:00", "stdout_excerpt": "==== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'root' at 0x0000027F5928F130>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'root' at 0x0000027F591ECD60>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text ", "stdout_sha1": "98ffce6857aae5f55480e085b57c90e14707951d", "stdout_len": 19532, "stdout": "FFFFFFFFFFFF                                                             [100%]\n================================== FAILURES ===================================\n__________________________ test_parse_simple_element __________________________\n\n    def test_parse_simple_element() -> None:\n        \"\"\"Parsing a simple XML element should produce the expected dict.\"\"\"\n        xml = \"<root><message>Hello</message></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'root' at 0x0000027F5928F130>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n____________________ test_parse_repeated_elements_as_list _____________________\n\n    def test_parse_repeated_elements_as_list() -> None:\n        \"\"\"Repeated child elements should be represented as a list.\"\"\"\n        xml = \"<root><item>1</item><item>2</item><item>3</item></root>\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'root' at 0x0000027F591ECD60>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n_______________________ test_parse_attributes_and_text ________________________\n\n    def test_parse_attributes_and_text() -> None:\n        \"\"\"Attributes and text content should be exposed using @attr and #text keys.\"\"\"\n        xml = '<user id=\"123\">Alice</user>'\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'user' at 0x0000027F59315040>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n___________________ test_unparse_roundtrip_basic_structure ____________________\n\n    def test_unparse_roundtrip_basic_structure() -> None:\n        \"\"\"unparse() followed by parse() should preserve the logical structure.\"\"\"\n        original = {\n            \"root\": {\n                \"item\": [\n                    {\"@id\": \"1\", \"#text\": \"A\"},\n                    {\"@id\": \"2\", \"#text\": \"B\"},\n                ]\n            }\n        }\n    \n        xml = _unparse(original)\n>       round_tripped = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:115: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\ngeneration\\Xmltodict\\xmltodict.py:121: in _convert\n    child_mapping = _convert(child)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'item' at 0x0000027F591ECB30>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n_____________________ test_namespace_prefix_is_preserved ______________________\n\n    def test_namespace_prefix_is_preserved() -> None:\n        \"\"\"Namespace prefixes in element names should be preserved in dict keys.\"\"\"\n        xml = \"\"\"\n        <root xmlns:x=\"http://example.com/x\">\n            <x:item>value</x:item>\n        </root>\n        \"\"\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'root' at 0x0000027F59209770>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n_________________________ test_parse_nested_structure _________________________\n\n    def test_parse_nested_structure() -> None:\n        \"\"\"Nested XML elements should map to nested dict structures.\"\"\"\n        xml = \"\"\"\n        <root>\n            <user>\n                <name>Ada</name>\n                <address>\n                    <city>London</city>\n                    <country>UK</country>\n                </address>\n            </user>\n        </root>\n        \"\"\"\n>       data = _parse(xml)\n\ntests\\Xmltodict\\functional_test.py:150: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\ngeneration\\Xmltodict\\xmltodict.py:121: in _convert\n    child_mapping = _convert(child)\ngeneration\\Xmltodict\\xmltodict.py:121: in _convert\n    child_mapping = _convert(child)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'address' at 0x0000027F592BBD60>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n__________________ test_force_list_option_for_single_element __________________\n\n    def test_force_list_option_for_single_element() -> None:\n        \"\"\"force_list should allow representing a single child as a list when supported.\"\"\"\n        xml = \"<root><item>1</item></root>\"\n    \n        # Prefer a targeted force_list that is common in xmltodict.\n>       data = _parse(xml, force_list=(\"item\",))\n\ntests\\Xmltodict\\functional_test.py:161: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'root' at 0x0000027F59277E00>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n_____________ test_custom_attr_prefix_and_cdata_key_if_supported ______________\n\n    def test_custom_attr_prefix_and_cdata_key_if_supported() -> None:\n        \"\"\"attr_prefix / cdata_key customization should reflect in output when supported.\"\"\"\n        xml = '<user id=\"7\">Bob</user>'\n    \n>       data = _parse(xml, attr_prefix=\"$\", cdata_key=\"text\")\n\ntests\\Xmltodict\\functional_test.py:176: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'user' at 0x0000027F591ECF40>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n        \"\"\"\n        node_map: MutableMapping[str, Any] = dict_constructor()\n    \n        # Attributes ---------------------------------------------------- #\n        for k, v in el.attrib.items():\n            node_map[f\"{attr_prefix}{k}\"] = v\n    \n        # Children ------------------------------------------------------ #\n        for child in el:\n            child_mapping = _convert(child)\n            tag, value = next(iter(child_mapping.items()))\n    \n            if tag in node_map:\n                existing = node_map[tag]\n                if isinstance(existing, list):\n                    existing.append(value)\n                else:\n                    node_map[tag] = [existing, value]\n            else:\n                node_map[tag] = value\n    \n        # Text ---------------------------------------------------------- #\n        text = (el.text or \"\").strip()\n        if text:\n            if node_map:\n                node_map[cdata_key] = text\n            else:\n                # No attributes/children – represent directly as text\n                return dict_constructor(((el.tag, text),))\n    \n>       return dict_constructor(((el.tag, node_map)))\nE       ValueError: too many values to unpack (expected 2)\n\ngeneration\\Xmltodict\\xmltodict.py:142: ValueError\n____________ test_xml_attribs_false_drops_attributes_if_supported _____________\n\n    def test_xml_attribs_false_drops_attributes_if_supported() -> None:\n        \"\"\"xml_attribs=False should omit attribute keys when supported.\"\"\"\n        xml = '<user id=\"9\"><name>Alice</name></user>'\n    \n>       data = _parse(xml, xml_attribs=False)\n\ntests\\Xmltodict\\functional_test.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ntests\\Xmltodict\\functional_test.py:62: in _parse\n    return xmltodict.parse(xml, **filtered)  # type: ignore[arg-type]\ngeneration\\Xmltodict\\xmltodict.py:144: in parse\n    return _convert(root)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nel = <Element 'user' at 0x0000027F5928FC20>\n\n    def _convert(el: _ET.Element) -> Mapping[str, Any]:\n        \"\"\"\n        Convert *el* into mapping according to the rules described above and\n        return ``{el.tag: value}``.\n"}
