project_name: Loguru
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Loguru\loguru.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Loguru
timestamp: '2026-01-01 01:53:33'
functional_score: 0.4545
non_functional_score: 0.4345
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 0.0
  performance: 0.6205
  resource: 1.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: "..F.F.FFF.F                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      _______________________ test_log_method_with_level_name _______________________\n\
      \n    def test_log_method_with_level_name() -> None:\n        log, buf = make_buffer_logger(fmt=\"\
      {level}:{message}\", level=\"DEBUG\")\n    \n>       log.log(\"INFO\", \"hello-info\"\
      )\nE       AttributeError: 'Logger' object has no attribute 'log'\n\ntests\\\
      Loguru\\functional_test.py:125: AttributeError\n____________________ test_contextualize_adds_extra_fields\
      \ _____________________\n\n    def test_contextualize_adds_extra_fields() ->\
      \ None:\n        log, buf = make_buffer_logger(fmt=\"{message} user={extra[user]}\"\
      )\n    \n>       with log.contextualize(user=\"bob\"):\nE       AttributeError:\
      \ 'Logger' object has no attribute 'contextualize'\n\ntests\\Loguru\\functional_test.py:149:\
      \ AttributeError\n_______________________ test_add_file_sink_writes_lines _______________________\n\
      \ntmp_path = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-386/test_add_file_sink_writes_line0')\n\
      \n    def test_add_file_sink_writes_lines(tmp_path: Path) -> None:\n       \
      \ log_path = tmp_path / \"loguru_test.log\"\n    \n        logger.remove()\n\
      >       logger.add(log_path, format=\"{level}:{message}\", level=\"INFO\")\n\
      \ntests\\Loguru\\functional_test.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <loguru._logger.Logger\
      \ object at 0x00000252BFF1EFD0>\nsink = WindowsPath('C:/Users/86152/AppData/Local/Temp/pytest-of-86152/pytest-386/test_add_file_sink_writes_line0/loguru_test.log')\n\
      level = 'INFO', format = '{level}:{message}', filter = None, kwargs = {}\nlevel_no\
      \ = 20, writer = None\n\n    def add(self, sink, *, level=\"DEBUG\", format=\"\
      {message}\\n\", filter=None, **kwargs):\n        level_no = self._level_name_to_no[level].no\
      \ if isinstance(level, str) else level\n    \n        writer = None\n      \
      \  if isinstance(sink, str):\n            writer = open(sink, \"a\", encoding=\"\
      utf-8\")\n        elif hasattr(sink, 'write'):\n            writer = sink\n\
      \        elif callable(sink):\n            # For callable sinks, the writer\
      \ is a wrapper\n            writer = lambda msg: sink(msg)\n    \n        if\
      \ writer is None:\n>           raise ValueError(\"Invalid sink specified\")\n\
      E           ValueError: Invalid sink specified\n\ngeneration\\Loguru\\loguru\\\
      _logger.py:168: ValueError\n______________ test_serialize_output_contains_message_and_level\
      \ _______________\n\n    def test_serialize_output_contains_message_and_level()\
      \ -> None:\n        # serialize=True should emit JSON per record into the sink\n\
      \        log, buf = make_buffer_logger(level=\"INFO\", serialize=True)\n   \
      \ \n        log.info(\"json-msg\")\n    \n        raw_lines = _lines(buf)\n\
      \        assert len(raw_lines) >= 1\n    \n>       record = json.loads(raw_lines[-1])\n\
      \ntests\\Loguru\\functional_test.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\86152\\AppData\\\
      Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346: in loads\n  \
      \  return _default_decoder.decode(s)\nC:\\Users\\86152\\AppData\\Local\\Programs\\\
      Python\\Python39\\lib\\json\\decoder.py:337: in decode\n    obj, end = self.raw_decode(s,\
      \ idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <json.decoder.JSONDecoder object at 0x00000252BDD4BCD0>\n\
      s = 'INFO:json-msg', idx = 0\n\n    def raw_decode(self, s, idx=0):\n      \
      \  \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n     \
      \   a JSON document) and return a 2-tuple of the Python\n        representation\
      \ and the index in ``s`` where the document ended.\n    \n        This can be\
      \ used to decode a JSON document from a string that may\n        have extraneous\
      \ data at the end.\n    \n        \"\"\"\n        try:\n            obj, end\
      \ = self.scan_once(s, idx)\n        except StopIteration as err:\n>        \
      \   raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE  \
      \         json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char\
      \ 0)\n\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\\
      json\\decoder.py:355: JSONDecodeError\n_____________________ test_patch_can_enrich_record_extra\
      \ ______________________\n\n    def test_patch_can_enrich_record_extra() ->\
      \ None:\n        # patch() lets us enrich record data in a typical usage pattern\n\
      \        log, buf = make_buffer_logger(fmt=\"{message} patched={extra[patched]}\"\
      )\n    \n>       patched = log.patch(lambda r: r[\"extra\"].update({\"patched\"\
      : \"yes\"}))\nE       AttributeError: 'Logger' object has no attribute 'patch'\n\
      \ntests\\Loguru\\functional_test.py:211: AttributeError\n____________________\
      \ test_time_and_level_in_default_format ____________________\n\n    def test_time_and_level_in_default_format()\
      \ -> None:\n        # Default format should include some timestamp-like content,\
      \ level, and message.\n        buf = io.StringIO()\n        logger.remove()\n\
      \        logger.add(buf)\n    \n        logger.info(\"default-format-test\"\
      )\n    \n        output = buf.getvalue()\n>       assert \"INFO\" in output\n\
      E       AssertionError: assert 'INFO' in 'default-format-test\\n'\n\ntests\\\
      Loguru\\functional_test.py:243: AssertionError\n===========================\
      \ short test summary info ===========================\nFAILED tests/Loguru/functional_test.py::test_log_method_with_level_name\
      \ - Att...\nFAILED tests/Loguru/functional_test.py::test_contextualize_adds_extra_fields\n\
      FAILED tests/Loguru/functional_test.py::test_add_file_sink_writes_lines - Val...\n\
      FAILED tests/Loguru/functional_test.py::test_serialize_output_contains_message_and_level\n\
      FAILED tests/Loguru/functional_test.py::test_patch_can_enrich_record_extra -\
      \ ...\nFAILED tests/Loguru/functional_test.py::test_time_and_level_in_default_format\n\
      6 failed, 5 passed in 0.56s\n"
    elapsed_time_s: 1.933372
    avg_memory_mb: 33.23
    avg_cpu_percent: 98.3
    passed: 5
    failed: 6
    skipped: 0
    total: 11
    score_inputs_passed: 5
    score_inputs_failed: 6
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 2.78s

      '
    elapsed_time_s: 4.069437
    avg_memory_mb: 31.67
    avg_cpu_percent: 100.4
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.524903
    score_inputs_actual_time_s: 4.069437
  resource:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 3.46s

      '
    elapsed_time_s: 4.927922
    avg_memory_mb: 34.79
    avg_cpu_percent: 98.7
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 37.9
    score_inputs_baseline_cpu_pct: 99.4
    score_inputs_actual_mem_mb: 34.79
    score_inputs_actual_cpu_pct: 98.7
  robustness:
    returncode: 1
    stdout: '..FError in sys.excepthook:


      Original exception was:

      '
    elapsed_time_s: 1.998509
    avg_memory_mb: 33.85
    avg_cpu_percent: 98.3
    passed: 0
    failed: 1
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 1
    score_inputs_total: 1
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=2.0 total_loc=200.0

      .

      1 passed in 0.13s

      '
    elapsed_time_s: 1.478243
    avg_memory_mb: 31.6
    avg_cpu_percent: 103.4
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 2.0
      total_loc: 200.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 1.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=20.8114 files_scanned=2.0 total_loc=200.0 max_cc=15.0

      .

      1 passed in 0.15s

      '
    elapsed_time_s: 1.493458
    avg_memory_mb: 31.66
    avg_cpu_percent: 101.1
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 20.8114
      files_scanned: 2.0
      total_loc: 200.0
      max_cc: 15.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 20.8114
baseline_metrics:
  performance:
    performance_suite_time_s: 2.524903
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 2.683393
    resource_tests_total: 1
    avg_memory_mb: 37.9
    avg_cpu_percent: 99.4
  functional:
    functional_suite_time_s: 1.656537
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.560491
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.416348
    security_tests_total: 1
    metrics:
      high_risk_count: 1.0
      files_scanned: 19.0
      total_loc: 4015.0
  maintainability:
    maintainability_suite_time_s: 1.770687
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 19.0
      total_loc: 4015.0
      max_cc: 56.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Loguru\pytest_logs
