project_name: Tablib
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Tablib\tablib.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Tablib
timestamp: '2026-01-02 00:35:47'
functional_score: 0.7273
non_functional_score: 0.4
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 1
    stdout: ".F..F...F..                                                         \
      \     [100%]\n================================== FAILURES ===================================\n\
      __________________ test_dataset_export_import_tsv_roundtrip ___________________\n\
      \n    def test_dataset_export_import_tsv_roundtrip() -> None:\n        \"\"\"\
      TSV export/import should preserve shape and values (type-coercion tolerant).\"\
      \"\"\n        if not _format_supported(\"tsv\"):\n            pytest.skip(\"\
      tsv format not available in this tablib build\")\n    \n        data = _build_sample_dataset()\n\
      >       tsv_text = data.export(\"tsv\")\n\ntests\\Tablib\\functional_test.py:163:\
      \ \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _\n\nself = <Dataset height=3, width=3>, fmt = 'tsv'\n\n    def export(self,\
      \ fmt: str) -> str:\n        \"\"\"Export dataset to specified format.\"\"\"\
      \n        if fmt == 'csv':\n            from .formats._csv import export_csv\n\
      \            return export_csv(self)\n        elif fmt == 'json':\n        \
      \    from .formats._json import export_json\n            return export_json(self)\n\
      \        else:\n>           raise ValueError(f\"Unsupported format: {fmt}\"\
      )\nE           ValueError: Unsupported format: tsv\n\ngeneration\\Tablib\\tablib\\\
      core.py:167: ValueError\n__________________ test_dataset_insert_and_pop_row_semantics\
      \ __________________\n\n    def test_dataset_insert_and_pop_row_semantics()\
      \ -> None:\n        \"\"\"Dataset should support inserting and popping rows\
      \ (list-like usage).\"\"\"\n        data = tablib.Dataset(headers=(\"id\", \"\
      name\"))\n        data.append((1, \"a\"))\n        data.append((3, \"c\"))\n\
      \    \n        # Insert a missing middle row.\n>       data.insert(1, (2, \"\
      b\"))\nE       AttributeError: 'Dataset' object has no attribute 'insert'\n\n\
      tests\\Tablib\\functional_test.py:233: AttributeError\n______________ test_dataset_export_html_contains_table_structure\
      \ ______________\n\n    def test_dataset_export_html_contains_table_structure()\
      \ -> None:\n        \"\"\"HTML export (if available) should include a table-like\
      \ structure and headers.\"\"\"\n        if not _format_supported(\"html\"):\n\
      \            pytest.skip(\"html format not available in this tablib build\"\
      )\n    \n        data = _build_sample_dataset()\n>       html = data.export(\"\
      html\")\n\ntests\\Tablib\\functional_test.py:292: \n_ _ _ _ _ _ _ _ _ _ _ _\
      \ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Dataset\
      \ height=3, width=3>, fmt = 'html'\n\n    def export(self, fmt: str) -> str:\n\
      \        \"\"\"Export dataset to specified format.\"\"\"\n        if fmt ==\
      \ 'csv':\n            from .formats._csv import export_csv\n            return\
      \ export_csv(self)\n        elif fmt == 'json':\n            from .formats._json\
      \ import export_json\n            return export_json(self)\n        else:\n\
      >           raise ValueError(f\"Unsupported format: {fmt}\")\nE           ValueError:\
      \ Unsupported format: html\n\ngeneration\\Tablib\\tablib\\core.py:167: ValueError\n\
      =========================== short test summary info ===========================\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_import_tsv_roundtrip\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_insert_and_pop_row_semantics\n\
      FAILED tests/Tablib/functional_test.py::test_dataset_export_html_contains_table_structure\n\
      3 failed, 8 passed in 0.54s\n"
    elapsed_time_s: 2.026849
    avg_memory_mb: 33.18
    avg_cpu_percent: 101.7
    passed: 8
    failed: 3
    skipped: 0
    total: 11
    score_inputs_passed: 8
    score_inputs_failed: 3
    score_inputs_total: 11
    score_inputs_returncode: 1
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Tablib/performance_test.py ______________\n\
      tests\\Tablib\\performance_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported TABLIB_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/performance_test.py -\
      \ RuntimeError: Unsupported TABLIB_TAR...\n!!!!!!!!!!!!!!!!!!! Interrupted:\
      \ 1 error during collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.52s\n"
    elapsed_time_s: 1.892296
    avg_memory_mb: 34.78
    avg_cpu_percent: 101.7
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.267515
    score_inputs_actual_time_s: 1.892296
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _______________ ERROR collecting tests/Tablib/resource_test.py ________________\n\
      tests\\Tablib\\resource_test.py:18: in <module>\n    raise RuntimeError(f\"\
      Unsupported TABLIB_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ TABLIB_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Tablib/resource_test.py - RuntimeError:\
      \ Unsupported TABLIB_TARGET...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during\
      \ collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.50s\n"
    elapsed_time_s: 1.995694
    avg_memory_mb: 35.42
    avg_cpu_percent: 98.4
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 34.54
    score_inputs_baseline_cpu_pct: 99.1
    score_inputs_actual_mem_mb: 35.42
    score_inputs_actual_cpu_pct: 98.4
  robustness:
    returncode: 0
    stdout: '....                                                                     [100%]

      4 passed in 0.16s

      '
    elapsed_time_s: 1.559982
    avg_memory_mb: 31.41
    avg_cpu_percent: 101.1
    passed: 4
    failed: 0
    skipped: 0
    total: 4
    score_inputs_passed: 4
    score_inputs_failed: 0
    score_inputs_total: 4
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=4.0 total_loc=293.0

      .

      1 passed in 0.11s

      '
    elapsed_time_s: 1.447763
    avg_memory_mb: 31.31
    avg_cpu_percent: 95.4
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 4.0
      total_loc: 293.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=22.4366 files_scanned=4.0 total_loc=293.0 max_cc=16.0

      .

      1 passed in 0.16s

      '
    elapsed_time_s: 1.524766
    avg_memory_mb: 31.33
    avg_cpu_percent: 98.9
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 22.4366
      files_scanned: 4.0
      total_loc: 293.0
      max_cc: 16.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 22.4366
baseline_metrics:
  performance:
    performance_suite_time_s: 2.267515
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 5.457667
    resource_tests_total: 2
    avg_memory_mb: 34.54
    avg_cpu_percent: 99.1
  functional:
    functional_suite_time_s: 1.550296
    functional_tests_total: 11
  robustness:
    robustness_suite_time_s: 1.567555
    robustness_tests_total: 4
  security:
    security_suite_time_s: 1.666207
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 31.0
      total_loc: 3330.0
  maintainability:
    maintainability_suite_time_s: 2.204547
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 31.0
      total_loc: 4978.0
      max_cc: 17.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Tablib\pytest_logs
