project_name: Markdown
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Markdown\markdown.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Markdown
timestamp: '2026-01-01 23:35:12'
functional_score: 0.0
non_functional_score: 0.24
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 0.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 5
    stdout: '

      1 skipped in 0.13s

      '
    elapsed_time_s: 1.498021
    avg_memory_mb: 31.04
    avg_cpu_percent: 97.8
    passed: 0
    failed: 0
    skipped: 1
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 5
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _____________ ERROR collecting tests/Markdown/performance_test.py _____________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\\
      _pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\\
      86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\\
      pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\\
      Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127:\
      \ in import_module\n    return _bootstrap._gcd_import(name[level:], package,\
      \ level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen\
      \ importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\ntests\\Markdown\\performance_test.py:26: in\
      \ <module>\n    import markdown  # type: ignore  # noqa: E402\ngeneration\\\
      Markdown\\markdown\\__init__.py:9: in <module>\n    from .core import Markdown,\
      \ markdown, markdownFromFile\nE     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\\
      generation\\Markdown\\markdown\\core.py\", line 56\nE       html_blocks.append(f'<pre><code>{html.escape(\"\
      \\n\".join(code_block))}</code></pre>')\nE                                 \
      \                                                        ^\nE   SyntaxError:\
      \ f-string expression part cannot include a backslash\n===========================\
      \ short test summary info ===========================\nERROR tests/Markdown/performance_test.py\n\
      !!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n\
      1 error in 0.82s\n"
    elapsed_time_s: 2.401351
    avg_memory_mb: 36.48
    avg_cpu_percent: 98.6
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 1.488889
    score_inputs_actual_time_s: 2.401351
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ______________ ERROR collecting tests/Markdown/resource_test.py _______________\n\
      C:\\Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\\
      _pytest\\python.py:498: in importtestmodule\n    mod = import_path(\nC:\\Users\\\
      86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\_pytest\\\
      pathlib.py:587: in import_path\n    importlib.import_module(module_name)\nC:\\\
      Users\\86152\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127:\
      \ in import_module\n    return _bootstrap._gcd_import(name[level:], package,\
      \ level)\n<frozen importlib._bootstrap>:1030: in _gcd_import\n    ???\n<frozen\
      \ importlib._bootstrap>:1007: in _find_and_load\n    ???\n<frozen importlib._bootstrap>:986:\
      \ in _find_and_load_unlocked\n    ???\n<frozen importlib._bootstrap>:680: in\
      \ _load_unlocked\n    ???\nC:\\Users\\86152\\AppData\\Local\\Programs\\Python\\\
      Python39\\lib\\site-packages\\_pytest\\assertion\\rewrite.py:186: in exec_module\n\
      \    exec(co, module.__dict__)\ntests\\Markdown\\resource_test.py:25: in <module>\n\
      \    import markdown  # type: ignore  # noqa: E402\ngeneration\\Markdown\\markdown\\\
      __init__.py:9: in <module>\n    from .core import Markdown, markdown, markdownFromFile\n\
      E     File \"D:\\桌面\\RealAppCodeBench_generic_eval\\generation\\Markdown\\markdown\\\
      core.py\", line 56\nE       html_blocks.append(f'<pre><code>{html.escape(\"\\\
      n\".join(code_block))}</code></pre>')\nE                                   \
      \                                                      ^\nE   SyntaxError: f-string\
      \ expression part cannot include a backslash\n=========================== short\
      \ test summary info ===========================\nERROR tests/Markdown/resource_test.py\n\
      !!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n\
      1 error in 0.81s\n"
    elapsed_time_s: 2.377183
    avg_memory_mb: 35.29
    avg_cpu_percent: 98.6
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 31.96
    score_inputs_baseline_cpu_pct: 100.0
    score_inputs_actual_mem_mb: 35.29
    score_inputs_actual_cpu_pct: 98.6
  robustness:
    returncode: 0
    stdout: 's                                                                        [100%]

      1 skipped in 0.15s

      '
    elapsed_time_s: 1.730034
    avg_memory_mb: 31.29
    avg_cpu_percent: 99.1
    passed: 0
    failed: 0
    skipped: 1
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=3.0 total_loc=164.0

      .

      1 passed in 0.14s

      '
    elapsed_time_s: 1.627063
    avg_memory_mb: 30.81
    avg_cpu_percent: 98.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 3.0
      total_loc: 164.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 0.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=0.0000 files_scanned=3.0 total_loc=164.0 max_cc=1.0

      .

      1 passed in 0.15s

      '
    elapsed_time_s: 1.688647
    avg_memory_mb: 31.07
    avg_cpu_percent: 100.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 3.0
      total_loc: 164.0
      max_cc: 1.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 5.374
    score_inputs_generated_mi_min: 0.0
    score_inputs_ratio_g_over_b: 0.0
baseline_metrics:
  performance:
    performance_suite_time_s: 1.488889
    performance_tests_total: 1
  resource:
    resource_suite_time_s: 1.323826
    resource_tests_total: 2
    avg_memory_mb: 31.96
    avg_cpu_percent: 100.0
  functional:
    functional_suite_time_s: 1.640586
    functional_tests_total: 19
  robustness:
    robustness_suite_time_s: 1.41468
    robustness_tests_total: 1
  security:
    security_suite_time_s: 1.482427
    security_tests_total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 33.0
      total_loc: 5698.0
  maintainability:
    maintainability_suite_time_s: 1.975499
    maintainability_tests_total: 1
    metrics:
      mi_min: 5.374
      files_scanned: 33.0
      total_loc: 5698.0
      max_cc: 33.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Markdown\pytest_logs
