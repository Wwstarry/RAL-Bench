project_name: Petl
task_file: D:\桌面\RealAppCodeBench_generic_eval\tasks\Petl\petl.yaml
generated_repo: D:\桌面\RealAppCodeBench_generic_eval\generation\Petl
timestamp: '2025-12-31 22:58:49'
functional_score: 0.0
non_functional_score: 0.4
non_functional_subscores:
  maintainability: 0.0
  security: 1.0
  robustness: 1.0
  performance: 0.0
  resource: 0.0
non_functional_weights:
  maintainability: 0.36
  security: 0.24
  robustness: 0.16
  performance: 0.12
  resource: 0.12
results:
  functional:
    returncode: 5
    stdout: '

      1 skipped in 0.15s

      '
    elapsed_time_s: 1.443989
    avg_memory_mb: 30.84
    avg_cpu_percent: 96.5
    passed: 0
    failed: 0
    skipped: 1
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 5
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - functional_suite_time_s
    - functional_tests_total
  performance:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      _______________ ERROR collecting tests/Petl/performance_test.py _______________\n\
      tests\\Petl\\performance_test.py:21: in <module>\n    raise RuntimeError(f\"\
      Unsupported PETL_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported\
      \ PETL_TARGET value: generated\n=========================== short test summary\
      \ info ===========================\nERROR tests/Petl/performance_test.py - RuntimeError:\
      \ Unsupported PETL_TARGET ...\n!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during\
      \ collection !!!!!!!!!!!!!!!!!!!!\n1 error in 0.47s\n"
    elapsed_time_s: 1.822946
    avg_memory_mb: 35.06
    avg_cpu_percent: 100.9
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - performance_suite_time_s
    - performance_tests_total
    score_inputs_baseline_time_s: 2.294684
    score_inputs_actual_time_s: 1.822946
  resource:
    returncode: 2
    stdout: "\n=================================== ERRORS ====================================\n\
      ________________ ERROR collecting tests/Petl/resource_test.py _________________\n\
      tests\\Petl\\resource_test.py:20: in <module>\n    raise RuntimeError(f\"Unsupported\
      \ PETL_TARGET value: {TARGET_ENV}\")\nE   RuntimeError: Unsupported PETL_TARGET\
      \ value: generated\n=========================== short test summary info ===========================\n\
      ERROR tests/Petl/resource_test.py - RuntimeError: Unsupported PETL_TARGET val...\n\
      !!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n\
      1 error in 0.54s\n"
    elapsed_time_s: 1.918525
    avg_memory_mb: 35.75
    avg_cpu_percent: 100.9
    passed: 0
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 0
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 2
    score_inputs_failed_suite: true
    score_inputs_baseline_keys:
    - avg_cpu_percent
    - avg_memory_mb
    - resource_suite_time_s
    - resource_tests_total
    score_inputs_baseline_mem_mb: 39.25
    score_inputs_baseline_cpu_pct: 98.3
    score_inputs_actual_mem_mb: 35.75
    score_inputs_actual_cpu_pct: 100.9
  robustness:
    returncode: 0
    stdout: '.                                                                        [100%]

      1 passed in 0.13s

      '
    elapsed_time_s: 1.507658
    avg_memory_mb: 31.1
    avg_cpu_percent: 101.1
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - robustness_suite_time_s
    - robustness_tests_total
  security:
    returncode: 0
    stdout: 'SECURITY_METRICS high_risk_count=0.0 files_scanned=6.0 total_loc=308.0

      .

      1 passed in 0.13s

      '
    elapsed_time_s: 1.52169
    avg_memory_mb: 30.87
    avg_cpu_percent: 75.0
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      high_risk_count: 0.0
      files_scanned: 6.0
      total_loc: 308.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - metrics
    - security_suite_time_s
    - security_tests_total
    score_inputs_baseline_high_risk_count: 6.0
    score_inputs_generated_high_risk_count: 0.0
  maintainability:
    returncode: 0
    stdout: 'MAINT_METRICS mi_min=32.2617 files_scanned=6.0 total_loc=308.0 max_cc=10.0

      .

      1 passed in 0.15s

      '
    elapsed_time_s: 1.440786
    avg_memory_mb: 31.49
    avg_cpu_percent: 98.8
    passed: 1
    failed: 0
    skipped: 0
    total: 1
    metrics:
      mi_min: 32.2617
      files_scanned: 6.0
      total_loc: 308.0
      max_cc: 10.0
    score_inputs_passed: 1
    score_inputs_failed: 0
    score_inputs_total: 1
    score_inputs_returncode: 0
    score_inputs_failed_suite: false
    score_inputs_baseline_keys:
    - maintainability_suite_time_s
    - maintainability_tests_total
    - metrics
    score_inputs_baseline_mi_min: 0.0
    score_inputs_generated_mi_min: 32.2617
baseline_metrics:
  performance:
    performance_suite_time_s: 2.294684
    performance_tests_total: 2
  resource:
    resource_suite_time_s: 2.52548
    resource_tests_total: 2
    avg_memory_mb: 39.25
    avg_cpu_percent: 98.3
  functional:
    functional_suite_time_s: 1.986035
    functional_tests_total: 12
  robustness:
    robustness_suite_time_s: 1.335635
    robustness_tests_total: 1
  security:
    security_suite_time_s: 1.826552
    security_tests_total: 1
    metrics:
      high_risk_count: 6.0
      files_scanned: 125.0
      total_loc: 26979.0
  maintainability:
    maintainability_suite_time_s: 3.446776
    maintainability_tests_total: 1
    metrics:
      mi_min: 0.0
      files_scanned: 124.0
      total_loc: 26979.0
      max_cc: 33.0
pytest_logs_dir: D:\桌面\RealAppCodeBench_generic_eval\results\Petl\pytest_logs
